start	end	text
0	20000	我是張雁勇,我是今天Tierra的主持人,我們今天要進行Tierra今年的第二場演講,今天的講者呢是,等一下喔,我要先滑到上面去。
20000	30000	今天的講者是莊碧耀,她來自DC的喬治華盛頓大學,目前是機械系博士班四年級。
30000	40000	她主要專攻的領域是流體力學的Numerical Simulation,還有Computation of Fluid Dynamics。
40000	51000	那我們就歡迎她今天跟我們討論,她今天要跟我們講的題目是Flux Reconstruction Correlation Procedure via Reconstruction in Computation of Fluid Dynamics。
51000	55000	那我們就歡迎她,然後就交給你。
55000	65000	大家好,我叫莊碧耀,然後我現在是DC喬治華盛頓大學博士班四年級。
65000	77000	那我主要的研究內容主要是數值模擬,數值方法,然後還有高效能計算,就是像什麼平行化GPU計算那些東西。
77000	88000	那我最近剛好學到一個新的數值方法叫做那個Flux Reconstruction,突然發現有title打錯,沒關係,先這樣。
88000	104000	就是它叫那個,它應該沒有中文名字,因為它是2007年第一次被提出來,然後大概到09年才有第二篇paper,然後到了大概12年13年的時候才突然就是有其他group加入這個領域。
104000	111000	所以目前應該還沒有中文方面都還沒有名字什麼的,那它就叫做Flux Reconstruction。
111000	119000	是Reconstruction,現在大家看到的title那個有title,它是重建,所以是Reconstruction,那簡稱FR。
119000	131000	那有些group研究之後覺得這個名字不好,所以他們又給它重新取了一個名字叫做Correlation Procedure via Reconstruction,然後簡稱CPR,但基本上它是一樣的。
132000	142000	像現在有主要英國兩個團隊在做這個,一個是,應該算三個,一個在NASA,一個在Stanford,一個在英國。
142000	155000	那英國跟Stanford那邊他們主要都叫做FR,Flux Reconstruction,然後NASA那邊的他們都叫CPR,就是Correlation Procedure via Reconstruction。
155000	165000	那我最近學了這個之後,我覺得它可以拿來做我的博士研究,因為它在計算流體力學方面才剛起步而已,就還有很多發展空間。
165000	178000	然後我最近剛好,因為剛學完這個東西就讀了很多paper在學這些東西,所以有些心得,那就剛好上來做個進度報告,就是跟大家分享這個數值方法到底在幹嘛。
179000	197000	我今天要講的就是,首先介紹一些基本的數值方法概念,就是因為我不太確定大家的背景到底是如何,所以會有一些基本的數值方法的介紹,就是避免說一些人沒有在做數值模擬,聽不太懂。
198000	215000	再來就會介紹怎麼去推導一些數值,Flux Reconstruction這個方法。基本上前面的部分都是像數學課一樣,就是數學推導。最後一部分是,我想要怎麼把它應用到所謂的不可壓縮流,Incompressible Flow。
215000	227000	因為我主要的研究是做Incompressible Flow,然後提出Flux Reconstruction的group,還有像Stanford或者英國,他們通通都是在做Compressible Flow,就是可壓縮流。
227000	243000	所以至少到目前為止,找Literature Review的話,沒有看到任何group在使用這個方法在Incompressible Flow,所以我打算我的研究會往這個方向進行,所以我會大概簡單講一下我的未來的計劃是什麼。
246000	261000	首先我要先介紹的是數值方法裡面一個非常重要的概念,它叫做權重殘值法。它可以推導出各式各樣不同的數值方法,等於說是基礎中的基礎,所以我把它提出來介紹一下。
262000	280000	今天有一個偏微分方程式,目前自然界很多的現象都是由偏微分方程式來統一,我們叫統一方程式。我現在用一個符號,類似L的符號來代表偏微分的operator,就是偏微分的符號。
281000	291000	像一個範例,就是L的一個例子,就是所謂的熱擴散方程式。現在影片看到的就是一個熱擴散方程式的operator。
292000	306000	U就是我們一個未知的函數,我們希望去求解的一個函數。如果在熱擴散方程式,它可能就是一個溫度場,溫度場是隨時間跟空間變化的。如果在流體裡面,U可能就是一個速度場。
307000	326000	F是一個在等號右手邊的函數,它是一個已知的,它可能跟你的物理現象有關。譬如說在流體力學裡面,F可能就是一個重力場。在熱擴散方程式裡面,F可能就是一個熱源,就是源源不絕產生熱量的一個東西。
327000	344000	如果今天偏微分方程式的exact solution,就是真實世界真正的解,叫做Uexact的話,我們雖然希望能夠求得Uexact是什麼,因為它是真正的解,但實際上現實生活中,我們完全無法求出這個東西。
345000	351000	我不太確定怎麼樣,但是理論上應該是不能保證說一定有真正的解存在的。
352000	369000	我們今天沒辦法得到真正的解,我們就想到另外一種方法,我們就先自己假設一個解。假設說,以溫度場來說,今天這個U如果是代表溫度,我們就假設說今天在這塊空間裡面,溫度可能看起來像長什麼樣子。
370000	388000	我們假設說它長什麼樣子之後,它裡面就會有一些未知數,我們再去求解。比如說,今天我們假設溫度場會是一個函數,叫庶列級數,像佛利耶級數或者拉普拉斯級數這種東西。
389000	414000	你可以寫成一個σ,CI,Φi。CI就是一個未知的常數,然後Φi就是我們假設它長什麼樣子的東西。比如說,我今天這裡投影片上有一個很簡單的例子,就是如果Φi定義為Xi,就等於說如果Φ0就是一個常數,然後Φ1就是X,Φ2就是X平方,Φ3就是X三次方。
414000	433000	我今天就是假設說我今天的溫度場分布就是C0加上C1乘以X,加上C2乘以X平方,加上C3乘以X三次方。今天我們就已經假設溫度場長這個樣子了,剩下裡面我們需要決定的就是C0、C1、C2到底是多少。
434000	456000	所以整個數值方法、數值模擬、數值偏微分這些所有東西,其實追根究底全部都是在探討兩個問題,就是我們該假設這個U到底該長什麼樣子,就是這個Φi到底是什麼。它可以是sin、cos,也可以像我剛剛講的例子是X、X平方、X三次方,所以到底什麼樣的假設才是最好的,這是一個問題。
456000	474000	第二個問題就是我們該怎麼去找出C0是多少、C1是多少、C2是多少。所以整個數值方法、數值分析,你修這些課的時候,其實追根究底都是圍繞著這兩個問題在旋轉,圍繞著這兩個問題在探討。
474000	494000	我們今天講到要怎麼決定C0、C1、C2這些到底是多少的時候,我們就要講到說,我們到底希望這個猜測的函數這個U到底該怎麼去決定C是多少。
495000	513000	我們今天當然就是希望說我們能找到一組C0、C1、C2這些常數,能夠讓說我今天猜測的這個所謂的猜測的approximation這個假設的函數帶回原本PDE的時候,它的殘值會是0,殘值就是這個R。
513000	533000	那它的定義就是說,你這個假設的函數帶回PDE之後是完美的零誤差的,無論在任何地方,就無論你今天X是在什麼地方,X等於1、X等於2,你這個假設的函數永遠都是完美的,不會有任何殘值在裡面。
533000	552000	可是這個問題就是這不可能,因為如果你今天這個猜測的函數帶進去能夠完美的無殘值,就等於說你今天猜測的函數就是這麼剛好的exact solution,那這樣子的話它就不叫猜測的函數了,我們也不需要猜了,所以這是幾乎不可能的。
552000	565000	只有一些就是教科書上的一些toy problem,你才會這麼巧,就是隨便猜一個函數,猜它是C0加C1X,結果剛剛好就是exact solution,但是現實生活中就是不切實際的。
566000	579000	第二個問題就是,如果你今天是用這個方法來找出C1、C2這些是多少,你會發現你有好幾個未知數,但是你只有一個方程式。
579000	608000	舉例來說,如果我今天猜測這個u這個場,這個函數是C0加C1X加C2X平方加C3X平方,然後我今天要求解一個poisson equation,那你把這個猜測的函數帶進原本的poisson equation之後,就是做二階導數,就會剩下的u的二階導數就是2C2加上6C3X,那你把它帶進去之後,你的殘值就會變成這個樣子。
609000	627000	螢幕上看到的是2C2加6C3X減sinπX,那你只有一個方程式,可是你今天有從C0到C3總共四個未知數,你沒有辦法去求解,所以這些問題就是說,等於說我們沒有辦法用這種方式去找出未知數。
628000	641000	所以我們今天數字方法裡面就會去放寬我們的要求,我們今天不要它是完全完美的,我們讓它有一些瑕疵,但只要某些條件能夠符合就好。
641000	660000	那這個就叫做權重殘值,就是你看到這個list上面第一點,這個積分,積分意思就是說,R還是一樣是殘值,在空間中任何一個點的殘值,可是我今天要把它乘上一個權重,這個權重就是說,在空間中某些地方的殘值比較重要。
661000	678000	比如說X等於2這個地方,這個地方非常重要,我希望它的殘值乘以十倍,然後在X等於3這個地方,它的殘值我沒有那麼care,就是我不care說到底我的假設的函數對不對,所以它的權重可能只有0.1。
678000	700000	然後我今天放寬的那個要求就是說,我對整個空間的積分,整個空間的所有殘值的加起來會是0,這樣就好,就是說乘以權重之後的總殘值是0就好,我不再要求說所有地方任何一個點的殘值都是0,那這樣就是一種放寬的條件。
700000	704000	然後我們今天在找這個權重,
730000	737000	就像delta函數,就在某個點它會有無限大的權重,然後在其他地方全部都是0。
761000	774000	就是你現在這個積分的這個equation除掉,然後它的分母是一樣的equation,但是沒有那個r,就是W自己dx這樣。
775000	793000	我們沒有做這樣,就是因為殘值理論上它就是0嘛,那其實你除上別的東西,假如這個你的方法非常完美的話,你除上別的東西它還是0,所以其實我們就是直接積分而已。
794000	796000	好,我懂了,謝謝。
797000	813000	那我們今天,然後我們繼續講就是這個權重,你看我這裡有個j,其實它意思就是說我今天不是只有一組權重而已,我剛剛舉的例子,比如說x等於1這個地方權重是10,x等於3的地方權重是-0.1好了,那這是一組權重。
813000	842000	可是我今天在設計方法的時候,我不會只設計一組權重,我通常會設計就是足夠多的權重讓我能夠解除我的未知數,比如說我剛剛前面那個例子有c0到c3四個未知數,那我今天就要設計四組不同的權重,然後我就會有四組線性方程式,我就會得到那個連立方程式,所以我就可以解除四個c0到c3這四個未知的常數。
844000	856000	所以我們等於簡化,我剛剛不是說數值方法它是圍繞兩個問題,一個是我們該怎麼假設那個phi是長什麼樣子,然後第二個是要怎麼去計算c0到c多少這種常數。
856000	866000	那第二個問題就是怎麼計算c這個常數,我們就可以把它換句話說變成另外一個問題,就會變成說我們該怎麼去定義我們的權重。
866000	877000	然後我們現在這個問題,我們剛剛前面這個問題我們先停在這裡,我們等一下就記得,會回到這個問題。
878000	892000	然後我們剛剛前面講的是那個已經放寬的標準,就是只要乘以權重之後再積分的殘值是0就好,然後在數值方法裡面我們又會再更進一步的放鬆條件。
892000	903000	就是我們常常聽到,你可能會聽到有限元素啊,然後網格啊,或者一些比較正式的說法會叫做piecewise solution。
903000	916000	它就是說,我們今天這個空間有興趣的空間,我投影片上寫叫做space,我space裡面再把它切分成更細小的一個區域,比如說subdomain1、subdomain2。
916000	926000	那這種subdomain就叫做element,就是你常聽到的有限元素裡面所謂的元素,或者你聽到那個網格裡面的一個網格。
926000	933000	那我今天用一個1來代表這種subdomain,然後k下標就是代表說不同的subdomain。
933000	952000	然後我今天再放寬它就是說,我每個元素裡面有各自自己的猜測,比如說u0就是指第0個subdomain裡面它有自己一個假設的函數,那u1裡面就是1號這個element裡面它也有自己一個猜測函數。
953000	969000	然後所以整個global的猜測函數其實就是很多不同的小元素組合起來的,如果今天x在第0個元素裡面,那我們就用第0個猜測函數,那今天如果x在第1個元素裡面,我們就用第1個猜測函數。
969000	989000	那為什麼說會說這是一種relaxation呢?就為什麼說它是一種放寬條件?因為等於說今天如果真實世界的exact solution是非常高階的一個函數,比如說一個高階的polynomial或者是一個sine、sine wave或cosine wave,它的波動非常大。
989000	1014000	你看像這個例子裡面,黑線是exact solution,它有三個波動,它等於是至少有三階以上的,它的solution是三階以上的polynomial,甚至是sine或cosine。可是如果我今天把整個domain拆成很多小元素,像這個例子裡面,我把它拆成6個小元素,我等於說我每個元素裡面只要用一條直線,然後6個元素加起來,我就可以近似我的真實的解。
1014500	1035000	所以這是一種relaxation,等於說我在猜我這個函數長什麼樣子的時候,我用最簡單的一條直線,我就可以當我的假設,就可以去猜它這個函數長什麼樣子。所以我們會說這種把它劃分成subdomain、elements或cells是一種更加放寬的條件。
1036000	1057000	這個投影片講的就是說,這種放寬的條件,就像我剛剛講的它的優點就是,即使你的真實函數是非常高階的函數,高階的多項式或非常震盪、波動非常大的東西的話,我也可以用非常低階的猜測去近似這個exact solution,這就是它的優點。
1057000	1084000	缺點就是,我們今天這個domain被拆成很多小小的subdomain,那subdomain跟subdomain之間到底該是什麼關係?這就是一個新的問題,新浮現出來的問題。比如說,第一號元素跟零號元素,它們之間該有什麼樣的關係?總不可能完全沒有關係,因為它們都是在描述同一個真實解的不同區段,所以它們還是有關係,所以你必須要做一些假設。
1085000	1110000	今天我們數值方法裡面最常用的就是所謂的我們叫做C0的連續函數,等於說今天假如有兩個連在一起的element,像圖上如果你看到這條藍色的element跟黃色的element,C0連續就是說它們只要在連接的這個interface的地方,值是連續的就好,這是最簡單的。
1111000	1122000	所以今天你可以看到這個藍色的線跟橘色的線在這個點是接在一起的。至於它的導數是不是也接在一起,就是在這個C0的條件裡面我們不在乎的。
1123000	1140000	所以如果我們重新再講一次的話,replace一次的話,就是說今天現代的數值方法都是圍繞的,剛剛是講圍繞兩個問題,其實現在就可以再多加一個問題,就變成圍繞三個問題來討論。
1141000	1155000	第一個是PhiI這個假設的函數到底該長什麼樣子?第二個是這個權重函數到底該是什麼樣子?第三個就是當我們把domain切分成很多小元素的時候,元素跟元素之間到底該有什麼關係?
1156000	1165000	這三個問題的不同答案的組合就會給你各式各樣不同的所謂的數值方法。
1166000	1191000	我又有問題,可是我的問題可能都很基本,就是懂的人覺得說很基本。我的問題是這樣,比如說你剛剛形容的東西是一個像量一個座標場好了,可是如果你在乎的性質,它的物理性質可能是速度或是加速度,那它是要跟一階導數或二階導數有關的,
1191000	1197000	是不是就必須要要求比如說C1或C2在那個boundary要是連續的?
1197000	1223000	是的,沒錯。所以你就會知道,就會讓它變得更,因為你今天C0條件的話,你只要很簡單的就是左邊跟右邊相等就好,可是如果你今天是C1的話,你就變成要先左邊的先求它求出它的一階導數,然後右邊再求出一階導數,然後限制它們兩個要相等,你等於說條件會更tough,更難去滿足這個條件。
1223000	1231000	但是這每一個小的element的boundary condition要設得多強,所以實際上的操作會跟你要解決什麼問題有關?
1232000	1248000	對,就是跟你實際的問題會有關。這就是為什麼不同領域的會用不同的數值方法,比如說也許我們最常聽見的就是有限差分、有限元素、有限體積,這是三個最常聽到的。
1248000	1263000	那你就會發現說為什麼計算力學的人會用有限元素,然後為什麼流體力學會用有限體積,然後其他人會用有限差分,就是因為他們很可能就是對這種C0或C1這種的要求不一樣。
1263000	1277000	對,然後回到這邊三個問題,然後所以這邊就有一些例子,就是對這三個問題不同的答案會產生什麼樣不同的數值方法。
1277000	1294000	那第一種,它的正式名稱叫做pseudospectral,或者證交,我不知道中文叫什麼,orthogonal collocation。那為什麼會提這個,因為我們最常聽到的有限差分,finite difference,就是一個special case,這種情況的special case。
1294000	1317000	那這個數值方法就是說它的權重是一個delta function,就是我剛剛講的,就是在xj這個點它會無限大。那delta function這個東西很有趣,就是你積分的時候,它會變成是,我不曉得,就是它積分之後,應該可以回到剛剛那個投影片。
1317000	1340000	delta function就是積分之後變成就只有這個點有值而已,有點慢。就是像這個積分,第一點這個積分,如果wj是delta function,那delta function它無限大那個點在xj的話,那這個積分就會變成,右手邊等於就會變成Rof然後xj,就是這樣。
1341000	1354000	所以這就是為什麼你在有限差分完全看不到任何什麼權重、積分,看不到。它就是有限差分都是定義在點上面,如果大家對有限差分還有印象的話。
1354000	1374000	然後有限差分就是這個所謂pseudospectral的一個特例,就是除了權重是delta函數之外,它的近似也非常低,它就是用直線,它的所謂的phi就是一個直線猜測而已。
1374000	1389000	像你可以看到它的那個uhat假設的解,它只有phi0跟phi1兩個東西而已,所以今天你在做有限差分的時候,其實你在解的就是c0跟c1兩個常數而已。
1390000	1409000	然後有限差分用的是c0的連續條件。那有限體積的話,是像流體力學比較常用的,就是它的權重是,只要是在我今天定義在ej這個元素裡面,它的權重都是1,通通都是1。
1409000	1424000	但只要除了這個元素外面,它的權重全部都是0,這是它的權重的定義。然後它的那個假設的解,就是uhat這個東西,這個我們猜測的解,它比有限差分更簡單,它就是只是一個常數而已。
1424000	1440000	等於說,今天在一個element,在一個subdomain裡面,我們猜說,比如說溫度場,溫度場在這個subdomain裡面只是一個常數,它不會有任何變化。然後它在連續條件上,它就不是用c0條件了,它會變得很複雜。
1441000	1462000	它會用所謂的一個reman jump的條件。它蠻複雜的,但是我只是想表達說,它不是c0條件。那它到底是什麼,就是比較超出今天的範圍,所以就沒有講。那它只是作為一個例子說,我們怎麼回答剛剛那三個問題,就會定義出不一樣的數值方法。
1462000	1485000	第三個就是所謂的連續的galactic method,我們常聽到有限元素就是這種情況下的一個特例。這種情況下就是說,它的權重就會等於我們用來猜測的那個函數,就是φj。φj就是我們剛剛猜測的那個假設的函數,它的權重就是這個。
1485000	1497000	只要用這種權重的,通通都叫做galactic method。那有限元素它就更進一步,它除了權重是這樣定義之外,它還使用了c0的連續條件。
1498000	1516000	但是至於這個φi到底是什麼,到底是sin,cos,還是polynomial,還是exponential,其實在傳統的galactic method裡面,它並沒有去講。只是在有限元素裡面,傳統上φi這種東西都是用跟有限差分一樣,用直線去定義。
1516000	1536000	它是一個直線的polynomial。那這個投影片就只是跟大家介紹一下說,我們數值方法都是圍繞著什麼東西在轉,那就是這三個問題。那我今天介紹這個權重殘值法,就是因為等一下那個flux reconstruction會用權重殘值法去推導。
1536000	1553000	那我在投影片裡面有提到所謂一些low order method或者high order numerical method,所以我想說今天在這裡也要介紹一下,因為可能不是大家都是有數值方法的背景。
1553000	1580000	那所以先要介紹這個order到底是什麼。那我們像剛剛,我們剛剛前面投影片有提到一個例子就是說,今天假如有一個真實世界的物理場,比如說這條黑線是它的真實的場,就是我們不知道我們猜不出來的場,然後我們用六個元素去近似它,然後每個元素裡面我們猜它是一個直線的分布,那就是會長上圖上這個樣子。
1581000	1598000	那如果今天我們要,你可以很明顯看到就是,雖然在某些點,我們猜測的函數基本上就是貼近於真實世界物理場,但是其他部分,你看像這條藍色直線跟那個黑色的曲線,中間就有很大很明顯的誤差。
1598000	1619000	那所以如果我們今天要改善這個誤差,我們可以怎麼辦?那我們可以做的第一個就是使用更多的element,就是把它切得更細,所以每個element裡面還是用直線,但是直線就可能因為它範圍比較小,它就會比較貼近真實的物理場。
1620000	1643000	那下一個投影片就是一個例子,像這個投影片就是我今天增加了六個element,讓總共element的數量變成十二,但是我每個element裡面仍然使用直線的猜測,那我們就會發現我只是增加了六個element,我現在整個猜測的解就會變得非常接近真實的解。
1643000	1664000	那這種方式就是一種減少error,然後增加準確度的一種方法。那為什麼會提到這個呢?因為我們在定義order的時候就是會跟這個有關。order就是說當我今天增加我element的數量的時候,我的error會以怎麼樣的速度去減少。
1665000	1684000	那我們在定義這個速度的時候是以指數來定義,比如說我的element數量增加了m倍,那我的error的速度是m的幾次方,那個幾次方就是所謂的order,就是我們在定義數值方法order的時候的一個定義。
1685000	1706000	然後這個order或者這個所謂的rate又被叫做convergence rate,就是收斂的速度。然後像一些例子,就比如說今天如果我的element數量從n1變化到兩倍的n1,然後我的誤差從epsilon降低到二分之一的epsilon,那這種方法就叫做first order method。
1707000	1731000	因為我今天這個m,前面提到這個m就是2,那我今天那個誤差變為二分之一,那它就是二的一次方而已,所以它就是first order method。那如果我今天n1從n1提升到兩倍的n1,但是我誤差從原本的epsilon降低到八分之一的epsilon,那這就是三階的third order method,因為八是二的三次方。
1731000	1752000	那這就是我們所謂的order,那所謂low order,我們在講low order method的話,通常都是指first order或second order method,就是說你double了你的element數量,結果你的誤差值只降低一半,或者誤差只變成四分之一而已。那high order通常就是三階以上,我們通常都會叫high order。
1753000	1779000	那這裡要提到一個就是high degree expansion,就是要跟high order做區分。我們剛剛的假設的函數,就那個u上面有一個hat,我們用一個sigma,然後ci乘以5i,那我今天這個i用的越多,比如說我從c0到c10用的越多,那我們就會說這是一個更高degree的expansion。
1779000	1794000	比如說c0,如果你今天的猜測是c0加上c1,51而已,那這就是可能你可以說它是degree of 1,然後如果你今天用c0,c1,c2,c3,那它就是degree of 3。
1795000	1814000	那今天很巧的是,如果我在建立我的假設的那個函數的時候,如果我用的也是high degree expansion,就是我那個級數裡面數列series裡面有更多項的話,有更多phi的話,它通常也會是一個high order method,就是說它誤差收斂的速度會更快。
1815000	1829000	你可能只要,比如說你如果用,裡面你的phi總共有10個的話,你可能element數量只要乘以2,它的那個誤差可能收斂就是直接變成1%而已,就是誤差變小的速度很快。
1830000	1838000	同時,它除了誤差收斂的速度變快之外,所謂的high degree expansion,它通常也可以直接給我們更準確的解。
1839000	1849000	像這下面這個圖就是一個例子,就是我仍然使用6個element,可是我今天每個element裡面,我不再假設它只是一個直線,我假設它是一個二次方程式。
1850000	1861000	我只是這樣子多加了一個x平方這個項而已,我還是用6個element,但是你可以很明顯看出,它整個非常非常接近真實界,我只是做了這樣一個假設而已。
1862000	1871000	所以,就可以看出,你今天element裡面如果degree越高,它給你的accuracy就會越好。
1873000	1890000	那這個其實,那我還要強調一點就是,不能搞混所謂的convergence rate,就是所謂的order,然後不能把它跟accuracy搞混,因為order這個東西只是定義你誤差變小的速度多快而已,但不代表說它給你的誤差非常小。
1891000	1908000	那accuracy則是說,我今天給你的誤差非常非常小,但不代表說我element數量加倍之後,它誤差真的會變得更小,甚至有可能你10個element給你這樣的誤差,你double成20個element之後,你的誤差反而變大了。
1908000	1912000	所以accuracy跟order是不能搞混。
1939000	1951000	那事實上,你用到3、4、5、6、7、8、9,都不會再有更多的improvement,因為它的critical,就它已經完美描述了這個問題了嘛。
1953000	1959000	因為你之後所有的coefficient都會是0,可是那這樣子的情況,不就是case by case嗎?
1959000	1988000	對,所以你這樣講沒有錯,但是我們沒有辦法知道真實界到底是什麼,因為今天我這個是一個例子,所以我用一個三次方程式去畫它,但是真實世界你不知道它是三次方程式,所以你當然只能用越來越多的order去看它到底長什麼樣。
1990000	2012000	你意思是說,自然界真正的signal可能你弄到五次方可以描述某一些性質,然後可能你弄到十次方之後,它開始可以描述某另外一種的perturbation,然後十五次方可以描述某一種noise,它會不斷地描述更小的signal這樣嗎?
2013000	2032000	不是我在講的是,我想講的就是,我今天在建立這個UJ,它到底該用幾項的時候,它的確是case by case,因為我不知道真實的界到底長什麼樣子,所以我也沒辦法知道說我到底該用幾項,UJ裡面該用幾項。
2033000	2056000	我能做的就是,譬如說我剛剛做的同樣六個element,我先假設它是C0加C1x,就只是這樣,然後看它誤差是多少,然後我今天做第二次計算的時候,我再加上一項加上C2x平方,然後看它誤差是多少,然後看它收斂會不會差異越來越小。
2056000	2083000	譬如說如果我今天用三項,像現在我投影片上三項的話,如果誤差是十的負十次方,一乘以十的負十,然後今天如果我再加上一個C3x三次方再去算一次,結果四項的那個假設跟三項的假設誤差只有譬如說只有一的負十二次方的話,那等於說你今天再增加一個C3這一項的時候,它並沒有幫助。
2086000	2099000	所以就是說等於說其實我們不知道到底該用幾項,我們只能用這種手段去猜,有點難形容。
2099000	2118000	我大概可以理解你要講什麼,但是你現在在講的基本上是假設在一個完美的數學的討論上,可是事實上你在寫 code 的時候,我猜你一直增加你的 degree 的話,你可能會一直減少你的 uncertainty 或是 inaccuracy,
2118000	2130000	可是到某一個程度,你不再有那麼多的優勢去減少 model 和實際的差異,但是你開始會放大你自己 computation 的 error 嗎?會嗎?
2130000	2144000	會的,所以那邊大概就是你不會再想要再弄更多了。對,那個時候到那個點,你就知道你可能就不需要再放更多的那個項進去你的 UJ 裡面。
2145000	2147000	Oh, I see. OK 好,謝謝。
2147000	2170000	然後下一頁,所以像剛剛講的就是,前面投影片除了說用更多項在你的假設的函數裡面,它除了給你更精準的答案之外,同時它的 convergence rate 也非常高。
2171000	2181000	所以它等於是它收斂速度,它誤差減小的速度也快,然後同時它給你的誤差也非常小,那它是一個非常聽起來非常吸引人的方法。
2182000	2190000	那事實上從有電腦開始,從有數值方法開始,高所謂的 high degree 這種 approximation,大家就都一直想用。
2190000	2199000	那可是為什麼到現在大家都還是用非常簡陋的有限差分、有限元素跟有限體積,那追根究底就是它有很多缺陷。
2199000	2212000	那缺陷就是如果我今天的物理場是一個 time dependent,就是它是一個 unsteady problem,它的統一方程式裡面有對時間的導數,那通常 high degree 這種東西它是非常不穩定。
2212000	2224000	因為電腦會有誤差嘛,電腦它是用 0101 來表示所有數字,所以它有些數字沒辦法表達出來,所以它就會在計算過程中產生誤差。
2224000	2250000	那今天如果我在 t 等於 0.1 秒這個時間點,有一個電腦產生一個非常小的誤差,那所謂 unstable 就是說它很可能在 t 等於 0.2 秒的時候,前一秒產生的誤差在這一秒就讓你的計算整個爆炸,譬如說變成無限大,甚至什麼 divide by zero 或者是無限小,就會出現這種情況,這種情況就叫做 unstable。
2251000	2270000	那高階函數它特別容易 unstable,那原因很明顯嘛,像你剛剛看到如果我們今天用到了十項,有一個 c 十,x 十次方,等於說我今天如果有一個微小的誤差,在這一步有一個微小的誤差是 1 的兩次方好了。
2271000	2285000	1 的兩次方,那你把 1 的誤差帶到 x 十次方,它整個誤差就變成 1 的二十次方,整個就會變成讓你的計算爆炸,所以這種東西它就會變成所謂的非常 unstable。
2286000	2305000	那第二個就是它比較牽扯到線性代數的概念,它是 ill-conditioned,我們剛剛不是說必須要有連立方程式去解那些 c 那些函數,譬如說四個連立方程式去解,那所謂 condition number 有一種東西叫 condition number,就是說這個連立方程式有多難解。
2305000	2334000	那 condition number 越高就表示說這個連立方程式越難解,condition number 越低就表示說這個連立方程式越好解,那通常你用越高項的假設函數,譬如說用到 x 四次方、x 五次方、x 六次方的時候,它就會變成所謂的 ill-conditioned,就是病態,它的連立方程式會非常難解,你可能需要非常非常久的時間才終於解得出那些 c0、c1、c2、c3。
2335000	2354000	那這是所謂 high degree 跟 high order method 的第二個缺點,然後第三個就是你用的越多項當然越複雜,那你在寫電腦程式的時候就會越難寫,那你越難寫的程式就算好不容易寫出來了,它裡面的 bug 可能也會越多,你就會更難去 debug。
2354000	2375000	然後第四個就是像現在大家的程式都是平行化,要在多核上面跑,連我們的電腦都是至少有四個核心、八個核心,那當這種高階的方法你要把它設計成可以同時在八個核心上面一起去求解的時候,它也會變得非常困難,所以這是高階方法最明顯的四個缺點,
2375000	2385000	那這也是為什麼到目前為止大家熟悉的數值方法都還是那種 first order 或 second order 的那種有限差分或有限元素。
2386000	2413000	那可是大家還是很努力的一直研究所謂的高階方法,因為它很 appealing,它就是給你非常小誤差,然後它誤差收斂的又非常慢,所以大家還是一直研究,然後所以大家就想辦法說從我們剛剛說的那三個問題,數值方法圍繞的那三個問題裡面,如果我們能不能找出一種組合,三個答案的組合,能夠給我們比較好的高階方法。
2413000	2437000	那大家都一直在這方面嘗試,那的確這是有可能的,那最近也許大家都有聽過所謂的 discontinuous gallerking,就是不連續的 gallerking method,它就是大概這兩千年之後的一個重大突破,那它就是可以非常高階,然後它的那個也比較 stable,然後它的條件數也比較低,
2437000	2445000	所以兩千年之後你就會非常常聽到所謂的 discontinuous gallerking,因為它就變得非常 popular。
2445000	2474000	那我這裡有一個例子,就是我剛剛講的說,不同的答案能夠給你同樣高階,但是比較穩定或條件數比較低的數值方法。像我這裡上面三個線代表的是三種不同的 Phi i 的假設,那最陡的這個直線就是所謂的,這裡有個打錯字,它應該是 moment expansion,就是我剛剛前面例子一直用的。
2475000	2503000	C0 加上 C1x 加 C2x 平方加 C3x 三次方,也就是說 Phi i 等於 x 的 i 次方,這個就很明顯你看得出 x 軸是幾項,就是我用了幾項的 Phi i,然後 y 軸是條件數,你可以看到它用越多項,它的條件數上升得越來越快,所以等於說你今天用太多項的話,你的那個連立方程式會非常非常難解。
2504000	2530000	然後第二個就是兩個 x 的這種連線,它是用所謂的內差函數,Lagrange polynomial,應該中文叫做拉格朗日內差,然後譬如說 Phi i, Phi 2, Phi 3 就是所謂的 Lagrange polynomial,用這種 polynomial 去定義的假設函數。
2530000	2549000	它的條件數變化就沒有用 moment expansion 變化這麼快,然後甚至第三個三角形這條線就是這幾年比較流行的一種 expansion,就是 Phi 0, Phi 1, Phi 2 就是所謂的 Lagrange polynomial。
2550000	2566000	Phi 0 就是一階的 Lagrange polynomial, Phi 1 就是一階的 Lagrange polynomial,那用這種方式去假設的一個假設的函數,你會發現它隨著你用的 Phi 越多,它的條件數其實變化不大。
2566000	2578000	那等於說你今天用的 Phi 越多的話,你所謂的 EO condition 這個 drawback 就基本上可以算是被 eliminate,就是已經不存在了。
2578000	2590000	那這張圖只是就是 show 給大家看說,就是為什麼不同的答案,那三個問題不同的答案,可以去有可能會解決掉高階方法的那些 drawbacks。
2591000	2602000	我有一個小問題,所以實際上來說,通常 condition number 是不是大約會正比於計算時間?
2603000	2607000	因為你就算一個 condition number,就是一個 linear equation 嘛。
2607000	2621000	對,但是這個我不太曉得,我沒有想過這個問題,其實很難講,因為你要看你用求解的,用來解那個連立方程式的方法是什麼。
2621000	2635000	比如說,你可以用解一個連立方程式,你可以用最基本的高斯消去法,那你也可以用一些比較快的方法,就是像共二梯度法。
2635000	2648000	或者像你可以用一些比較 fancy 的方法,就是先解出它的 eigenvalue,然後用 eigenvalue 再去找出它的特徵向量,然後再用特徵向量組合出它的連立方程式的解。
2648000	2660000	所以我不覺得說不同的方法去解同一個連立方程式,條件數都是正比於求解的時間。
2660000	2667000	而且不一定會正比,因為你基本上要把所有 condition 全部連立起來解。
2667000	2670000	就像你說的,要解 eigenvalue,要 all IC。
2670000	2677000	對,但是我確定的就是說,如果條件數越多它解得越慢。
2677000	2683000	那至於這個慢的比例到底是線性還是怎麼樣,這個我沒有研究過,所以我不太曉得。
2683000	2685000	好,謝謝。
2689000	2700000	好,那所以現在就是進入到正題,就是前面講了 weighted residual method,那個全重殘值法,是用來等一下推導那個 flux reconstruction method。
2700000	2712000	然後剛剛解釋的那個 order 只是就是給大家一個概念說什麼是 low order,什麼是 high order,那為什麼我們要用 high order 的方法,那 high order 有什麼好研究?
2713000	2724000	那這裡就是給大家提示,先給大家一個概念,我們剛剛提到說有三個方法,三個問題的答案可以決定定義出一種新的數值方法。
2724000	2732000	那所以我現在就講,先給大家提示說這個 flux reconstruction,它在這三個問題裡面它的答案是什麼。
2732000	2749000	那對 FR 方法來說,它的假設的函數這個 Phi I,它用的就是,你可以說它是 Lagrangian function,但你也可以說它是 Lagrangian polynomial,就是拉格朗日內差函數。
2749000	2757000	那只是這個內差函數它是定義在,內差函數需要,如果大家有印象的話,應該內差函數就知道你需要一些點去定義內差函數。
2757000	2772000	那今天這個在 FR 裡面,它用的 Phi 的內差函數就是定義在所謂的 Lagender 的 quadrature point,就是大家就先知道它就是某種特別的點,它不是隨機分佈,它也不是均勻分佈。
2772000	2780000	它的點的分佈必須要符合某種規則,這種規則就是 Lagender polynomial,它必須要符合 Lagender 這個規則。
2780000	2794000	那這是它的 expansion,它的 expansion 就是 Phi I 是什麼,那至於它用的權重是什麼,它的權重用的是 Galerkin method,所以它的權重用的就會跟 Phi I 是一樣。
2794000	2805000	Wj 會等於 Phi j,那跟 Galerkin method 一樣,但是等一下我們會 show 給大家看說它跟 Galerkin method 哪裡不一樣,它還是有些不一樣的地方。
2806000	2829000	然後第三個問題就是不同的 element 之間到底是什麼關係,那我今天這裡寫的是 orthogonal polynomial based flux reconstruction,其實說穿了它就是跟有限元素一樣,用的有限體積用的一樣,就是我前面提到的所謂 Riemann jump flux。
2830000	2848000	那如果大家有學過有限體積的話,就大概會有印象,那也沒關係,因為等一下還是會講一下這個 flux 到底是什麼,這個 neighboring 之間到底是怎麼 coupling,那這只是一個 heads up 而已。
2848000	2872000	那現在來開始正式推導,EFA 這個方法2007年提出的時候,它主要是在求解所謂的 hyperbolic conservation law,這種 PDE 長的會是這種形式,那當然你在二維或三維的時候,後面還會有對 y 的維分、對 z 的維分,但在一維的話大概就是長這樣。
2872000	2898000	然後今天我們假如它的有效的 range 是從 xa 到 xb,那這個 range 如果我們把它又切成 n1 個元素的話,然後我們用大 E 來表示每個元素,然後每個元素裡面自己的有效範圍我們把它寫成 xk 到 xk 加 1,然後我們今天建立了兩個猜測函數,第一個是對 u 的猜測函數,
2898000	2921000	那 dk 個 element 裡面的猜測函數就是會長,我們就寫成這個樣子,sigma 然後 uki、phi i, uki 就是指 dk 個元素裡面的第 i 個點,第 i 個位置的值,然後 phi i 是內差函數,然後 f 我們同樣也這樣定義。
2922000	2945000	那可是在這兩個近似函數裡面其實只有 uki 是未知數,是我們需要求解的,因為 fki 是從 uki 定義來的,fki 就是你把 uki 代到你原本 pd 裡面這個 f 函數,你就可以得到 uki,所以雖然我們有兩個近似函數,但是只有 uki 是未知的需要求解的。
2945000	2971000	那我們回到前面講的權重殘值法,那我們把權重殘值法那個積分套用在 dk 個 element,只在 dk 個 element,我們不管其他 element,所以它的積分範圍就是 xk 到 xk 加 1,然後權重 wj,然後右邊是我們原本的 pd 的殘值,就是 r,然後下面第二行我只是把它拆成兩項而已。
2976000	3000000	那我們現在針對第二項,第二項就是權重乘以 f 這函數對 x 的導數,那我們今天用分佈積分,就微積分裡面的分佈積分,我們可以得到等號右邊這個樣子,這個式子,就會變成是 xk 加 1 的值減掉 xk 這個地方的值,然後再減掉另外一個積分函數。
3000000	3027000	那這個函數就是所謂的 weak form,discontinuous gallerking 的 weak form,那我這邊只提一下,因為我們並沒有要做 discontinuous gallerking,然後如果你今天要做 discontinuous gallerking 的話,你導出這個式子之後,你的下一步就會直接跳到說到底我這個 f 在 xk 加 1 這個點該怎麼定義,或者 f 在 xk 這個點該怎麼定義。
3028000	3051000	那我們今天不是要做這個,所以先跳過這一步,我們先進到下一步,下一步就是我剛剛那個等號右手邊那個積分,我再進一步,再做一次分佈積分,那我再做一次分佈積分之後,我又會得到原本的積分函數,就是權重乘以 f 對 x 的導數。
3051000	3080000	可是我左邊我會多了兩項,就是我會多了一個 fk 在 xk 加 1 的值,這就是說我剛剛對 f 的假設的那個函數,內差函數在 xk 加 1 的值,然後這個 fk,然後 xk 就是指 f 這個假設函數在 xk 這個地方的內差出來的值,所以第三行就是只是一個重新整理。
3081000	3110000	你會得到一個原始的積分函數,然後再減掉後面這兩項,權重乘以這個中括弧裡面的東西,那中括弧裡面的東西代表的是什麼?代表就是說一個 jump,就是我希望 xk 這個地方,第一個 f,如果大家能看到我的滑鼠的話,第一個 f 值的是我希望 xk 這個地方該是它的值該是多少,然後第二個這個 f。
3111000	3128000	就是用內差函數去求出來的 f,就是指我今天內差函數實際上算出來在這個點,在這個 xk 這個點是多少,所以它叫 jump,就是我希望的值跟實際上內差出來的值之間的差距,這叫 jump。
3128000	3150000	那這種東西在那個文獻裡面他們會叫做 strong form of discontinuous skeleton,那只是沒有人在求解這個方程式,然後最後一點就是提醒大家注意到兩種不同 f 的定義方式,一個是我希望它是多少,然後一個是內差函數實際上內差出來的值。
3150000	3173000	然後下一頁,有點慢,然後我今天就是在這一頁講的就是只是把剛剛導出來的所謂 strong form of discontinuous skeleton,帶回原本的那個權重殘值法的積分裡面,然後就會長成這樣。
3173000	3181000	你就會發現第一項還是原本的那個權重殘值的積分,然後可是多了兩項跟 jump 有關的東西。
3181000	3210000	然後今天在 flux reconstruction 跟所謂的 strong form of discontinuous skeleton 不一樣的地方就是,它在這個時候用了一個 trick,就是它假設說我前面有一個地方是有 xwjxk 這一項,如果我同樣能把它寫成一個積分的形式,然後找到一個所謂 gl 函數的話,那它就會長成這樣。
3211000	3239000	xwjxk 函數,讓它說 wj 這個權重函數在 xk 這個點的值會等於這個積分,然後 wj 在 xk 加 1 這個點的值會等於用 gr 來定義的這個積分,那我把這兩個定義帶回去原本上一頁的那個權重殘值的那個積分的時候,我就可以把它整個寫成一個所有東西全部都塞到我的積分範圍裡面,就會像這樣。
3239000	3253000	所有東西都會變成積分,然後權重乘以其他所有東西。那為什麼要這樣做呢?因為這樣做的話,我就可以把權重刪掉,我就可以把積分刪掉,變成純粹的一個微分方程式。
3253000	3276000	所以這就是 Flux Reconstruction,我假設 wj 能夠變成一個積分,然後帶回去之後,我就可以把積分跟權重刪掉,變回還原出一個原始的微分方程式,那這一頁就是只是把它重新寫而已。
3277000	3289000	主持人問一個小問題,所以你這個方法基本上 rely on gr 跟 gl 存在嗎?
3289000	3293000	主持人問一個小問題,所以你這個方法基本上 rely on gr 跟 gl 存在嗎?
3319000	3320000	主持人問一個小問題,所以你這個方法基本上 rely on gr 跟 gl 存在嗎?
3320000	3321000	主持人問一個小問題,所以你這個方法基本上 rely on gr 跟 gl 存在嗎?
3321000	3336000	主持人問一個小問題,所以你這個方法基本上 rely on gr 跟 gl 存在嗎?
3336000	3364000	主持人問一個小問題,所以你這個方法基本上 rely on gr 跟 gl 存在嗎?
3366000	3369000	主持人問一個小問題,所以你這個方法基本上 rely on gr 跟 gl 存在嗎?
3369000	3398000	主持人問一個小問題,所以你這個方法基本上 rely on gr 跟 gl 存在嗎?
3399000	3409000	主持人問一個小問題,所以你這個方法基本上 rely on gr 跟 gl 存在嗎?
3409000	3438000	主持人問一個小問題,所以你這個方法基本上 rely on gr 跟 gl 存在嗎?
3439000	3454000	主持人問一個小問題,所以你這個方法基本上 rely on gr 跟 gl 存在嗎?
3454000	3477000	主持人問一個小問題,所以你這個方法基本上 rely on gr 跟 gl 存在嗎?
3477000	3493000	主持人問一個小問題,所以你這個方法基本上 rely on gr 跟 gl 存在嗎?
3493000	3522000	主持人問一個小問題,所以你這個方法基本上 rely on gr 跟 gl 存在嗎?
3523000	3537000	主持人問一個小問題,所以你這個方法基本上 rely on gr 跟 gl 存在嗎?
3537000	3566000	主持人問一個小問題,所以你這個方法基本上 rely on gr 跟 gl 存在嗎?
3567000	3596000	主持人問一個小問題,所以你這個方法基本上 rely on gr 跟 gl 存在嗎?
3597000	3622000	主持人問一個小問題,所以你這個方法基本上 rely on gr 跟 gl 存在嗎?
3622000	3642000	主持人問一個小問題,所以你這個方法基本上 rely on gr 跟 gl 存在嗎?
3642000	3669000	主持人問一個小問題,所以你這個方法基本上 rely on gr 跟 gl 存在嗎?
3672000	3692000	主持人問一個小問題,所以你這個方法基本上 rely on gr 跟 gl 存在嗎?
3692000	3721000	主持人問一個小問題,所以你這個方法基本上 rely on gr 跟 gl 存在嗎?
3722000	3747000	主持人問一個小問題,所以你這個方法基本上 rely on gr 跟 gl 存在嗎?
3747000	3772000	主持人問一個小問題,所以你這個方法基本上 rely on gr 跟 gl 存在嗎?
3772000	3797000	主持人問一個小問題,所以你這個方法基本上 rely on gr 跟 gl 存在嗎?
3797000	3819000	主持人問一個小問題,所以你這個方法基本上 rely on gr 跟 gl 存在嗎?
3819000	3848000	主持人問一個小問題,所以你這個方法基本上 rely on gr 跟 gl 存在嗎?
3849000	3878000	主持人問一個小問題,所以你這個方法基本上 rely on gr 跟 gl 存在嗎?
3879000	3899000	主持人問一個小問題,所以你這個方法基本上 rely on gr 跟 gl 存在嗎?
3899000	3919000	主持人問一個小問題,所以你這個方法基本上 rely on gr 跟 gl 存在嗎?
3919000	3947000	主持人問一個小問題,所以你這個方法基本上 rely on gr 跟 gl 存在嗎?
3949000	3978000	主持人問一個小問題,所以你這個方法基本上 rely on gr 跟 gl 存在嗎?
3979000	4004000	主持人問一個小問題,所以你這個方法基本上 rely on gr 跟 gl 存在嗎?
4004000	4029000	主持人問一個小問題,所以你這個方法基本上 rely on gr 跟 gl 存在嗎?
4030000	4057000	主持人問一個小問題,所以你這個方法基本上 rely on gr 跟 gl 存在嗎?
4057000	4085000	主持人問一個小問題,所以你這個方法基本上 rely on gr 跟 gl 存在嗎?
4087000	4115000	主持人問一個小問題,所以你這個方法基本上 rely on gr 跟 gl 存在嗎?
4117000	4145000	主持人問一個小問題,所以你這個方法基本上 rely on gr 跟 gl 存在嗎?
4147000	4153000	主持人問一個小問題,所以你這個方法基本上 rely on gr 跟 gl 存在嗎?
