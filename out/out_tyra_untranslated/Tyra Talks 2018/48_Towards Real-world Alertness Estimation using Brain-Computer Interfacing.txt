整理&字幕志願者 李仲昌 鴻尚銘 熊少銘 洪勇 洪棠 洪勇
我是今天的主持人,我是洪尚銘,我現在在加州理工做博士後研究員。事不宜遲,我們就來介紹一下今天的講者,是魏群樹博士。
魏群樹博士在交大電子學士班畢業之後留在交大念交大的電控所,畢業之後到UCSD念生物工程博士班。他的指導教授是鍾子平老師。
他有興趣的主要主題或方向是用工程的角度來利用腦機介面研究人類的心智活動。
過去這幾年,他有非常多的發表,包括有接近十篇的會議報告和兩篇的報告。這些都是第一作者的論文。事不宜遲,我們就來聽一下他今天的演講。
Title是Towards Real-World Alertness Estimation Using Brain Computing Basics,我們歡迎他。
魏群樹博士 今天我會介紹說我們怎樣去量測大腦的活動,然後利用腦機介面的方式去監控我們的alertness,我們包括叫清醒程度。
如果演講進行中有任何問題,歡迎隨時打斷,我們可以很輕鬆的做一些討論,隨時打斷沒有關係。
首先,我會先簡單的從大腦開始介紹。
我們的大腦是一個大概三磅,大概一千多克的器官。
我們的大腦的結構上,它的皮質,就是最外圍的部分,會有很多的皺褶。
這些皺褶,我們大腦裡面是有非常多的神經元所組成,大概是八百六十億個神經元。
我們知道大腦有很強很強的運算能力,但是它跟我們現在最強的電腦比起來,它的效能是非常的好。
它在能量的消耗上,它是十萬倍的,就跟一般的CPU比起來,它是十萬倍的能量的運用效率。
所以整個大腦只要十二到二十五瓦就可以運作,這個瓦數相當於電燈泡的瓦數。
所以你可以想像說,有些漫畫裡面,當那個人物在想到什麼點子的時候,他會畫一個燈泡亮起來。
其實就還蠻貼切的,因為我們大腦消耗的功率就是一個燈泡的功率。
這邊再介紹一下,我們的神經元,它的結構就是包含細胞本體,然後會有很多的樹圖。
樹圖的部分是收集周邊其他神經元給這個神經元的訊息。
這個訊息整理到這個神經元之後,它會決定自己要不要放電。
放電的話就會透過軸圖,就啪啪啪啪啪,然後放給其他的神經元。
那這樣子複雜的網路就可以用來控制我們整個人。
那這邊介紹一下我比較常用的一種大腦的訊號,叫做腦電波,就是EEG。
那EEG其實很多人都有接觸過,尤其是像我們醫院,如果你新生兒出生的時候,
我們常常會給他做一個大腦的測試,去看他的視覺或聽覺是不是正常。
那EEG是怎麼產生的呢?就是在我們的大腦裡面,大腦裡面有很多神經元,
那尤其是皮質這邊,很多神經元他們的排列,結構上會有一些規則的排列。
那規則的排列就讓這些神經元在做放電活動的時候,
他們周遭引發的離子流可以有一個加乘的作用,
變成說他這個電場的變化可以大到讓你放在頭皮外面的一個導電的電極,
可以感受到這個電場的變化。
那這個電場的變化再經過一些處理,就變成我們的腦波訊號。
那如果有問題,歡迎隨時打斷我。
好,那我們的腦波訊號呢,他就是,對。
就是那個我不是有問題,是你下面有一行那個bluejeansmeetingsharingyourscreenwithbluejeans.com,
你要按一下那個hide。
哦,好。
要不然就稍微擋住,對,不好意思。
好,你可以繼續。
好,謝謝,謝謝,謝謝。
OK,好,那我們現在就繼續看這個是大腦他的訊號,
他的腦波他的訊號的樣子,
他就是一個時頻時與的訊號,
然後你可以看到就像那個股市走勢一樣,
他是一個叫time series,
然後呢,我們為了量測整個大腦,
我們會在頭殼外每個位置都盡量安排電極在上面,
所以整個量測我們會有同時量量非常多通道的腦波,
那這樣多通道腦波呢,
我們會再去分析他的頻率方面的的能量,
那頻率的部分就是看說他這個時頻時與訊號在在震盪的時候呢,
他震盪的快或慢,
那高頻的成分就是震盪快的部分,
低頻的部分就是震盪慢的部分,
那所以我們會分delta,
他是小於3.5赫茲的低頻的活動,
那他就是非常慢的震盪,
然後往再往高頻的話會分為theta波alpha波或是beta波,
那你可以看到就是越往高頻他的震盪是越來越快,
那我們的大腦就是可以把他分解成不同的頻帶,
然後藉由觀察這個頻帶能量其實我們就可以得到很多訊息,
那這邊介紹一下我們大腦他的通道擺放的位置,
他會有一個標準的劃分的方式,
然後通常我們可以看他的那個通道的命名呢,
就是會區分點面是frontal的話,
就是F開頭的通道,
那中央立點的話就是central,
他是C開頭的,
然後central parietal就是中間偏後,
然後accipital的話就是後腦勺,
這裡他是O開頭的channel,
那每一個channel得到的EEG呢,
我們都可以做這種頻域的分析,
然後我們可以把結合那個時間的變化跟頻域的變化,
我們可以看他不同的頻帶,
然後隨著時間他能量的起起伏伏,
那這個就可以告訴我們很多這個人的一些狀態或是其他相關的訊息,
那我們做實驗的話就可以設計一些實驗,
然後去看說這些大腦的變化,
然後是不是在不同的狀態下我們可以找到一些特徵,
然後反映這個大腦是在不同的狀態,
那腦機介面這個東西呢,
就是我們去讀取大腦的訊號,
然後我們經過一些訊號處理,
就包括剛剛的頻域分析,
或是你可以加很多,
用很多其他不同的訊號處理的方式去取各種不同的特徵,
然後再把這些處理過的一些訊號呢,
去用這個然後去讓他可以辨識出來,
然後我們可以把它轉換成一些指令去控制,
比方說一個機械手臂或是控制輪椅或是控制滑鼠游標,
那或者是用來輸入文字或是一些訊息,
那我們把這個叫做腦機介面,
就是Brain Computer Interface,
簡稱就是BCI,
那BCI可以用來做什麼呢?
就剛剛講到說他可以轉換成一些指令,
所以打電動的時候我們可以用來,
比方說控制這個你的人物的移動,
那當然還包括輪椅,
那包括這個抑制機械手臂,
那當然他也可以用來去監測一個人的認知狀態,
那包括是不是想睡覺,
那這個就衍生出我主要專攻的一個領域,
就是監控他的清醒程度的部分,
那清醒程度這個問題呢,
其實跟Drowsy Driving這個問題很有關係,
就是很多人駕駛的時候他會打瞌睡,
對,然後這個新聞是7月18號發生的事情,
就是最近才發生的一個Drowsy Driving的新聞事件,
請問群數這段你是有放聲音嗎?
還是我們不需要聽到聲音?
有,所以聽不到聲音嗎?
我沒有聽到,
糟糕,看一下怎麼辦,
那沒辦法,因為我現在這個…
你可以直接用電腦放出來,
那我現在這個…
糟糕,看一下怎麼辦,
那沒辦法,因為我現在這個…
你可以直接用電腦放出來嗎?
好,是
喂,聽得到嗎?
可以
喂,你們聽得到我講話嗎?
可以
喂,你們聽得到我講話嗎?
喂,你們聽得到我講話嗎?
可以
好,聽得到
現在有聲音嗎?
有,有,有
那是Drowsy Driving的新聞事件,
而且是兩倍數量的
那是Drowsy Driving的新聞事件,
而且是兩倍數量的
OK
所以剛剛這個就是最近發生的一個Drowsy Driving的事件,
大家剛剛影片可以看到,
卡車就直直的撞上施工的車輛,
然後就造成了兩死三傷,
然後Drowsy Driving每一年可以造成
120萬的車禍,
然後造成5000到8000的死亡,
所以如果可以避免就是Drowsy Driving,
如果我們可以有效的去監控Drowsy Driving的話,
然後去加以管理的話,
也許我們就可以避免掉這方面造成的一些死傷還有損失。
然後剛剛新聞裡面有提到說,
如果你發現你的眼睛開始閉起來,
那你就應該停止拍攝,
但是腦波這方面,
就我上次也有跟少敏有討論過說,
那是不是用眼睛或是眨眼的影像就可以去做這個Alertness的監控,
但是有一個問題是說,
有沒有辦法在他眼睛閉之前,
就去抓到說他其實已經沒有辦法好好的把注意力放在開車上,
那這部分可能就會想要用腦波來去突破這個問題。
那我們用腦機介面做這個Alertness Monitoring的話,
我們就會先當然就要從這個駕駛身上去量他的腦波,
我們取得這個EEG訊號之後,
經過一些Processing,
那我們用Machine Learning的方式去建立一個模型,
那他可以把EEG的Data轉成Alertness,
然後我們知道他的Alertness之後,
就可以設法去給他一些Feedback,
比方說我們可以去叫醒他,
或者是我們可以讓這個車子就自己不能再駕駛了,
可能就是停在路邊,
或是就強迫他休息,
就有一些介入的方式。
那我的研究的話,
就是主要是在說我們怎麼去處理這個訊號,
然後我們怎麼去建立一個Machine Learning的Model,
然後可以很好的去監控Alertness,
然後我們可以正確的去判斷說要不要做一些介入。
我想要稍微Clarify一下,
所以你的意思是說你的研究是要做精神渙散的那個狀態嗎?
還是真的睡著的狀態?
是睡著之前,
就是從清醒到快要睡著的那個狀態,
就是他還沒有真的睡,
因為睡了之後的大腦狀態,
我這邊就沒有去研究,
因為我要抓的是他進入到那個睡之前,
甚至說他其實就是,
因為我自己有就是Drowsy Driving的經驗,
然後我知道說那個時候我眼睛張開了,
但是我其實那個影像已經模糊掉,
然後已經黑掉,
然後我已經沒有在看路,
就有點失神了,
然後忽然又清醒,
然後就會覺得有點抖,
就開始有點抖,
所以就是要抓那個進入到Drowsy的那個時間點,
就看你Alertness什麼時候,
你沒有辦法支撐那個Alertness,
他才掉下去。
那我還有下一個問題,
就是你現在變成是要identify一種signal,
然後你認為你要identify這種signal,
是你現在說的這個狀態,
那你有對照組嗎?
比如說你track他的眼睛,
然後說我定義說眼睛這樣子的行為,
就是精神渙散要睡著了,
然後我去找就是相對應的腦波,
還是說我叫受試者寫說對,
我現在有感覺快睡著之類的,
就你的calibration是什麼?
這個問題非常好,
就是我們是怎麼定義我們所謂的Alertness,
然後我接下來就準備要講,
因為我們覺得Alertness是跟你的反應時間有關的,
所以我們是用反應時間,
然後給我們一個客觀的一個量測方式,
就是剛剛你講的用眼睛,
或者是用subject回報的一個方式,
那眼睛的部分就是說,
眼睛的活動它也是一個生理訊號,
所以它能不能直接的反應這個行為的話,
就是也是另外要做實驗,
就是它的角色跟腦波是同樣的,
那只是看說哪一種生理訊號可以,
那我們更容易去,
更精確的去判定說是不是Alert,
或者是沒有Alert,
那subject report的話,
它是一個主觀的認定,
那主觀的認定就會比較會有一些偏差,
就是說這個subject它回報出來的那個值,
其實並沒有辦法很客觀的去表達,
它剛剛經歷過的狀態,
那我這邊我是認為,
其實很多研究都認為比較客觀的判定方式,
是去看它的反應時間,
所以我們這邊就會,
接下來我就會講說,
我們怎麼去量腦波,
同時去量它的反應時間,
然後怎麼去定義,
最後我還會再講到說,
怎麼去定義Alertness這個東西,
這樣有回答到你的問題嗎?
有有有,謝謝
謝謝謝謝
好,那這邊我就講我們做的實驗,
然後怎麼去取得我們要的Data,
那我們把受測者放在一個模擬駕駛的車子裡面,
那這個車子它有環繞的投影,
投影的螢幕,
然後這個車子它是在一個動態的平台上,
所以在裡面開車,
就是盡量去模擬真實開車的情況,
那這個東西是在交通大學的腦中心,
腦科學中心裡面的一個設備,
然後我們這個實驗呢,
我們會我們是我們這個實驗,
我們是做那個車道維持的這個叫做Task,
那這個車道維持就是說,
這個Subject必須要維持這個車在它的車道上面,
然後這個車我們會自動的去讓它做偏移,
就強迫說Subject一定要定時的就要去矯正它的車的方向,
所以就是它的場景就是在一個直線的一個高速公路上,
但是這個車自己會偏掉,
它會往左邊偏或往右邊偏不一定,
然後每6到10秒就會偏一次,
那所以我們就看說這個Subject,
它去感覺到這個車偏掉,
然後它去動方向盤把車子導正這個動作,
所以我們就去看它從偏掉之後,
它什麼時候去動那個方向盤,
那就是它的反應時間,
所以我們每6到10秒我們可以量測一次反應時間,
那我們最終就是希望從這個偏掉之前的腦波的資料,
我們就可以去預測這個後面所發生的反應時間,
這樣才是有一個prediction的一個作用,
那這邊我接下來我就講我們怎麼去處理這個反應時間,
然後怎麼去得到我們的一個alertness的一個估計,
那剛剛講到我們每6到10秒,
我們會有一個response time的一個sample,
那我這邊把整個,
這邊我是,
Y軸我是畫我們的反應時間,
然後我先取log,
然後橫軸我是那個時間單位是分,
那這個就是我們整個實驗進行的一個長度,
那我們實驗進行的長度不太一定,
那這個比較短,
它只有45分鐘,
但大部分的實驗我們都有進行到超過一小時,
大概一個半小時左右,
然後我們對同一個subject,
我們有時候會叫他來,
就是叫他再回來做,
所以我們最終收集了,
我看一下,
這邊沒有寫,
我們最終收集了三十幾個subject,
然後有五六十筆,
那個開車的實驗的資料,
好,那這邊,
這邊講一下這個每一個點呢,
就是我們剛剛量到的RT,
所以10的0次方大概是一秒,
所以他清醒的時候,
大概一秒或是不到一秒,
就可以把車子導正回來,
然後經過一段時間,
他開始狀況不太好,
他的alertness開始下降之後,
我們會看到有一些比較長的反應時間,
其實反應的就是他的alertness變得比較差,
那我們要把這個RT data做一個處理,
所以我們先對他,
因為RT他是一個不是有範圍,
他只有一邊有範圍,
他另一邊沒有範圍,
所以我們先對他做一個正規化,
然後把他變成一個0到1的值,
那這個正規化的方式,
就是用他的那個
accumulative distribution function,
然後就把他就是mapping成一個
有範圍的一個值,
然後這邊我們再做一個,
這邊我們再做一個smoothing,
smoothing的話,
我是用90秒的moving window,
去把剛剛這個比較,
看起來比較跳動劇烈的一個值,
我們把他變成一個比較平滑的值,
他這部分是因為,
我們RT每6到10秒才sample一次,
所以其實他的,
你如果用太高頻的去看這個資料的話,
那是比較沒有意義的,
所以我們用一個smoothing的話,
就可以去掉一些,
就是這筆data本身的一些,
沒有辦法分析的雜訊,
所以我們就用這個,
alertness deficit index,
就是注意力不足的一個index,
我們去當作我們的,
行為上的一個ground truth在這裡,
那這邊有什麼問題嗎?
假設就是,
RT基本上直接的反映,
這個人的alertness的程度,
RT會變長,
alertness應該是其中一個因素吧?
對,所以就要看說實驗設計裡面,
因為我們另外也假設說,
我們這個實驗設計裡面,
就是影響RT的部分,
我們儘量的去排除,
其他可能影響RT的因素。
因為類似的,
就是實驗的paradigm,
也會被用來研究,
研究譬如說像mind wandering,
那mind wandering跟alertness,
雖然說有一點關係,
可是好像又不完全一樣,
譬如說你的subject開車開一開,
他開始想其他事情,
他的RT就變長,
那這個時候對於你來講,
就是在你的定義裡面,
是基於RT所定義出來的alertness,
那因為今天subject他不去反應,
就像你說的,他可能在想別的東西,
那我們當然是,
當然我們實驗的instruction,
當然是叫他們要專心,
我們能做的就是只能到這邊。
因為我想說這可能會有點影響,
你後去處理你的EG data的部分,
你可以想像一下,如果他RT變長的原因有三個,
那其實你會抓到三個pattern,
那三個pattern可能會不太一樣,
會影響你譬如說你去train的data的時候,
你的accuracy會比較低,
因為你的data不是就同質性不夠高,
有的時候他可能是因為A原因,
有時候因為B原因,有時候因為C原因。
所以就是說不可能到完全正確,
就其實我們沒有辦法去控制,
但是我們這邊他其實他RT變長的時候,
他其實變得蠻長的,
譬如說五秒鐘,那如果他真的五秒鐘都在想別的事,
然後不去照著我們的指示去把他導正的話,
就是我其實也不知道怎麼辦。
OK,因為概念上應該是如果你有一個test,
他看到的是真正的他就是感覺是死亡症,
那可能有一些trial,
就是像你說的有可能是其他因素,
有加入一些雜訊在上面,
那這部分就是沒有辦法排除。
OK,因為就是概念上如果是你的test可以把,
就是不同影響RT的東西分開來,
然後你處理這些資訊的時候分開來處理,
你的model就會更乾淨嘛,理想的情況。
但當然就是一個時間沒辦法一次涵蓋這麼多不一樣的因素。
對啊,所以我們其實可能腦科學方面的實驗常常都有這個問題,
就是你沒有辦法控制subject他在偷偷想什麼。
沒錯。
對,然後就會有點尷尬。
關於這個其實我有一個不太一樣的想法,
就是如果你之後是要把這個data丟machine learning的話,
如果他有三種,就是不管是他想睡,
或是他在想亂七八糟的事或怎麼樣,
最後你的那個algorithm的pattern recognition,
說不定可以被train成就是可以,
他可以identify三種不同的reason,
但是for whatever reason,
他就是會可以標示出這個人現在就是要恍神,
要不注意了,這樣不是也不錯嗎?
有這個可能啊,有這個可能。
所以in the end,他的algorithm就是可以趨向不管什麼理由,
他可以避免你RT時間變長。
我覺得這個時候就要回到最原本的問題,
你想要偵測到什麼東西。
譬如說假設你要推動一個政策好了,
那你想要知道的是,那這個情況你想要避免drowsy driving,
那這整個東西都是為了drowsy driving設定的。
可是你後來發現,影響他們駕車的狀況,
或駕車的時候發生交通狀況的其他一個重要因素是mind wandering,
那即使你可以同時偵測到mind wandering,
可是你在制定政策的時候,這兩個是完全不一樣的東西,
你要怎麼避免A跟避免B,完全不一樣。
所以回過頭來,如果是以腦科學的觀點,
我們想要知道的是,他那段時間到底發生了什麼。
我問這個問題的原因是這樣。
我覺得你說的有可能就是,
Machine Learning做的時候可能同時可以辨認出,
他把所有的pattern都當成是lack of awareness,
那這樣也是有可能的。
所以就是像剛剛彥永提到的那個也是,
就是說如果用Machine Learning下去,
不管怎樣他就是會去學他們data之間的關聯性,
然後你得到的就是一個,
就是你整體影響RT的一個不知道什麼東西。
然後另外就是說我們是有,
剛剛其實我們那樣子討論其實是假設說,
不同的一些認知的一些現象是可以拆解的,
就是可以把它獨立開來看的,
或者是他們之間有一些交互作用的。
那如果說我們想要用我們的data,
然後就可以分解出不同的認知的狀態,
在這個RT上的影響的話,
其實光用一個實驗應該是沒有辦法,
就可能還是要分不同的實驗,
然後才能去估計說哪一項認知的狀態,
對RT的影響會是怎麼樣。
那我們這邊我們這個實驗就是盡量說,
盡量說只有一種影響,盡量,但不能保證。
那如果說我們這個trial裡面,
比方說90%都是照著我們所想像的,
就是因為Trial Z所造成的。
因為我們是在吃完午餐之後讓他去做,
然後我們是在一個全案的實驗室,
叫他去開那個公路。
所以我們是希望說就是藉由這個方式,
讓他睡午覺嘛。
所以至少我們就是,至少這個過程裡面,
他可能就是比較貼近我們希望他所引發的那個性。
這樣可以嗎?
OK,我的問題有被解答到這樣。
因為這部分就是,後面會講,其實這個是很麻煩,
因為很多認知的狀態其實沒有很好的客觀的定義。
那未來我覺得,我覺得有一些,
就是不管是腦機介面或是認知科學要再往前,
其實這個是很大的問題。
那我先繼續講我的研究。
然後,剛剛講到我們腦波可以分成不同的平台的一些特徵,
所以這邊是就是很,
就把我的一些processing的一些過程把它列出來。
那EEG我們會在,對不同的通道我們去做一個re-referencing,
就是說我們會,我們這邊我們是取那個,
就是所有通道,所有通道的EEG都去減掉他們整體的平均。
那這部分就是可以去掉一些雜訊。
然後我們做bandpass filtering,
因為腦波他可以量到有意義的平台其實有限,
就是大概是50赫茲以下的能量。
那但是有一些低頻的飄動可能是來自於一些動來動去,
或是他device本身造成的雜訊。
所以我們會用一個通常就是用1到50赫茲,
或者差不多這個平台去把這個,
那個腦波濾一遍,
然後得到的就是比較真的像腦波的東西。
但是還是會有很多artifact。
然後我們會downsampling,就是減少我們運算的時間。
然後我們再去做subbandpass filtering,
就是說我們把腦波再分成不同平台的腦波,
就是像剛剛前面有show的,
就是比較快的震盪跟比較慢的震盪。
那他們就是從delta、theta、alpha到beta的腦波。
然後我們去取他的能量,
然後做一樣我們做一個smoothing,
就是對應我們剛剛RT做的smoothing,
我們現在也用90秒的moving window去對腦波做一個,
腦波能量的特性去做smoothing,
然後得到我們的theta。
所以我們現在有腦波的能量,
然後我們剛剛也有alertness的index,
所以我們現在就把這兩個東西拿來做一個對照。
那這個每一張小圖呢,
他的y表示的是EEG的能量,
然後x表示的是剛剛那個alertness deficit index。
所以x往右邊的話,
就是他反應時間越來越慢,
然後y軸往上的話,
就是EEG那個平台的能量越來越強。
所以這邊有delta、theta、alpha、beta,
就不同的平台。
然後我是把幾個通道秀出來,
就是有frontal比較前面的,
然後central,
那z就是midline的部分,
就是中間,
就是前額的中間,
然後中央的中間,
parietal的中間,
然後後面,最後面的中間。
那在這幾個位置上呢,
他不同平台,
然後他的EEG的能量變化都跟alertness
有一些相關性。
像delta的部分,
他是一個正相關,
像這個0.77就有相關係數。
那像alpha這邊我們可以看到
他是有一個負相關,
他是負0.28,
那就是變成說是當你alertness下降之後,
alpha的平台會減少。
然後這部分,
先說就是他其實是有一個變異性的,
就是每一個人每一次做,
他這個相關性的情況會不太一樣。
所以我們,
這邊我是用一個相關係數的一個分佈圖,
去看說某一次實驗,
腦波跟alertness的關係。
那這邊就是用顏色去show他的相關係數。
紅色是正相關,
藍色是負相關。
所以delta大部分都是正相關,
不管是在哪一個位置。
那beta這邊有一些負相關。
所以這一個圖,
就表示了這次實驗,
我們得到的腦波跟alertness的結果。
那這個圖他是會隨時間,
然後隨不同的人,
都會變化會蠻大的。
這邊要先講。
就是一個應該是neuroscience 101,
那個如果腦波,
你把它拿去做頻譜啊,
他的頻譜是在這個alpha,beta,theta,delta,
會有四個peak嗎?
還是說他是一個那種smooth的,
連續的一個的頻譜?
他是一個,
就是如果你是看頻率的話,
他會有一個1 over f的一個分布。
1 over f的分布長得就有點像是一個,
一個下降的一個曲線。
就是腦波他還是低頻的能量強一點,
高頻的能量弱一點。
所以切這個alpha,beta,theta,delta的那個band,
基本上只是把一個連續的一個頻譜,
把他切成四節這樣子嗎?
是,但是有時候他會有一些peak,
就剛剛講的,
雖然他是一個1 over f,
整體是一個1 over f的一個分布。
我們是叫他叫pain noise,
就是其中一種noise。
然後,
但是有時候他這個整體的分布,
他有時候會有一些小peak出來。
因為有時候他大腦,
他可以在某個頻帶上有一個很強的震盪。
比如說alpha是最常見的,
就alpha就是你只要閉眼睛,
然後你的,
尤其是後面的部分,
他就會開始有那個10赫茲左右的震盪。
那那個時候呢,
就是在你的這個1 over f的這個曲線上,
然後有一個小小的peak在10赫茲上面。
他長得會有點像這樣。
我在想的東西是這樣,
就是如果你的spectrum沒有,
就是你的energy spectrum,
就是頻譜沒有出peak的話,
你把它切成4節,
然後再分成這4組data丟machine learning,
其實我不覺得會enhance
你的machine learning的效果。
因為他可能,
可能在那個你切的那個band的範圍的邊邊在migrate。
所以可是,
如果你今天是會在alpha出peak,
那你把alpha獨立出來跟其他的,
然後再分開丟你的machine learning的training的話,
就會有,
我覺得會有比較明顯的效果。
所以我才問這個問題。
OK,
所以你大概了解你的意思。
所以你覺得如果說,
用一些比較真的有意義的平台,
把它特別拿出來,
然後去做training,
去做machine learning,
這樣效果會。
效果會比較好。
對,
我同意你這個說法,
就是全部丟,
你一定把很多雜訊丟進去。
對,
但是因為我後面要解決的問題,
就是說,
怎麼講,
就是我不能捨棄每一個,
因為每一個他,
因為有變異性的問題,
所以每一個有時候都會變成是最好用的feature,
會出現在上面。
所以,
所以就是沒有辦法,
就是再縮小範圍到某一個更好的feature去用。
就是我目前就是必須要去這麼多的feature去用。
是這樣的情況。
OK,
謝謝。
OK,
然後我這邊就講我的machine learning的部分,
它是一個regression的問題,
因為我想要從腦波的data,
然後去估計,
去有沒有辦法預測說這個alertness,
deficit index的這個變化,
它是一個連續的值,
然後再0到1之間。
所以我model的output必須是一個連續的數值,
然後要去貼近這個值。
那就剛剛有一些處理,
我就這邊是一樣的,
然後我就把這個腦波的能量,
跟我們實驗所錄到的那個反應時間,
再經過處理得到的alertness的index,
然後就送進這個model,
然後我就去train,
然後就可以得到一個regression model,
然後它就會可以把腦波轉成我們所估計的alertness index。
但是有一個問題,
就是剛剛我一直先講的,
就是human variability。
human variability這邊我們會分成inter-subject或intra-subject,
就是subject,subject間,
跟subject自己本身都有一些variability。
我這邊想請大家做個活動,
就是你現在看到這個舞者,
他是順時針轉,
就出個聲音就好。
我兩邊都可以看得到。
所以是一下看到這樣,
一下看到那樣。
就是我想要看到什麼情況,
我就可以看到什麼情況。
這個圖我這輩子看超多次,
我永遠只能看到同一邊。
真的嗎?
對啊,我不知道為什麼,
我超級想要看到另外一邊。
對,就是有些人看到逆時針,
有些人看到順時針,
然後有些人是想,
對,就像少年想看這樣,
就可以看到那樣。
那我的話也是就是,
就是想像他往那邊,
然後我再去看,
他就會順著我的預先的假設去轉。
然後這部分就是反映說,
同樣的刺激給我們不同的人,
那我們的大腦的處理什麼什麼,
最後的得到反應會不一樣。
那這只是一個例子,
就是告訴大家說,
我們的每個人大腦都不一樣。
其實我們大腦在不同時間內,
我們對同樣的刺激,
最後得到反應一樣都不一樣。
那所以反應在剛剛的,
跟Alertness相關的腦波變化上,
其實也是同樣的,
就是都不一樣,
不同人不一樣,
然後一個人他不同天,
做那個實驗也都不一樣。
然後這邊我把我的Data,
舉了一個例子,
就是剛剛我說要用這個,
Correlation的分布的圖,
當作某一次實驗,
腦波跟Alertness的關係。
那這邊我有一個,
這個S5之一就是第五個Subject,
他第一次來做,
做剛剛那個Driving,
下車的那個實驗。
然後我們得到的相關性是這樣,
就是你看到這邊有三個紅,
就是從Theta到Alpha到Beta,
都是正相關。
然後但是這個是他第二次來做,
Subject 5第二次來做,
我們看到完全不一樣,
他的Delta變正相關,
然後剩下三個相關性變小,
甚至Alpha變負相關。
所以如果我們用他第一次實驗,
去Train我們的Model,
然後我們第二次就會發現,
完完全全就會,
效果會很差。
但是我們做了很多實驗,
我們錄了很多人,
然後我們看到說,
比方說第四十一個Subject,
他第五次做的時候,
他有這樣子的Pattern,
然後跟Subject 5很像。
所以說不同的人,
他可能在我們這個要看的腦波上面,
他們有相似的反應。
那如果這樣的話就變成說,
我可以把Subject 41第五次的這個Data,
拿去Train一個Model,
然後我們如果用在Subject 5的第二次的話,
那這樣效果就會很好。
那當然這個是我們事後才有辦法,
知道說這次跟這個Session,
跟這個Session很像。
但是我們沒有辦法就是,
當這個Subject 5他來的時候,
我們就有辦法知道說,
我們要用這個Subject 41的Model去給他。
那就是一個工程上的挑戰,
或是科學上的挑戰,
就是我們要怎麼樣去做到這一點。
我想要問一個問題喔,不好意思。
我想要問一個問題,
那這些Subject他們每次做實驗的時候的時間,
大概都是固定的,
就是像你說是吃完午飯之後。
對,吃完午飯之後。
就是時間大致上都是固定的這樣。
是,是。
因為這看起來,
看起來有點像,
就我剛剛一開始提的問題就是,
他有可能不一樣的Factor,
那不同Session之間造成那個,
就是你的Brain Activity的Factor可能不太一樣。
對,對。
對,那所以譬如說你想像一下,
假設你們現在是要量Drowsiness,
你的第五個Subject的第二個Session,
跟第四十一個Subject的第五個Session,
量到的東西是類似的。
對。
那換句話來說,
如果說你可以有另一個Task,
或者是,
不知道Subjective Report還是什麼之類的東西,
來驗證他在每個Session裡面,
到底發生了什麼事情,
你有可能就可以退回去說,
那這個腦波其實比較像是,
A這個東西呢?
還是B這個東西?
還是C這個東西?
對,這是我想做的,
就是說有沒有很,
有沒有別的東西我們量,
然後可以很,
比較快一點的量到,
然後我們就可以知道說,
這個應該是跟某一個,
我們前面錄過的Session比較像,
然後就可以發動來用。
接下來我就是,
就是發展這個東西。
嗯,OK。
因為實際操作上,
有可能比這個更複雜。
換句話說就是,
我的Drowsiness的腦活化,
跟你的Mind Wandering腦活化有點類似,
就是它有一個交互之間的關係,
有可能會是這樣,
就是有可能每個人,
都有不一樣的Brain state嘛,
那Brain state,
當然我有現在的這個,
心智活動的時候,
會對應到一個Brain state,
但不代表那個Brain state可能會,
大家都有點類似這樣。
但我不知道,
那是可能是實際上的困難,
這感覺是一個可以做的主。
對對對。
當然我們如果可以,
再更精確的分析說,
是怎樣的狀態,
造成怎樣的變化,
那是很好。
但是因為我們這個實驗,
它目前我們可以分析的,
就沒有辦法去分析,
有沒有其他因素,
這比較可惜。
這邊我接下來,
我就是完全用,
用Data driven的方式,
去處理。
OK,謝謝。
我有問題,
對,就是這一頁,
就是我想問,
就是你現在畫這一個,
一個圓形的圖啊,
然後上面那些黑點,
就是你戴那個,
那個帽子的那個,
每一個相對應的Probe嘛,
可是你那個帽子,
其實是一個球面的空間分佈,
不是一個平的2D的圓餅。
對對對。
那你這個圖,
是怎麼從那樣子的,
一個球面分佈,
投影到你現在看到的,
你現在畫的這個圖,
還是這是一個示意圖?
它只是一個投影,
就像那個地圖投影一樣。
所以你有preserve,
就是說每一點之間的距離嗎?
就是說某一種特定的,
像畫地圖的投影,
還是說這就是一對一,
你把它排一排這樣子?
這個其實只有用在Visualization,
所以它那個關係,
如果被扭曲什麼,
就是沒有太大的影響。
因為我Machine Learning,
還是都只取那個,
exactly那個位置上面的。
哦,OK。
像這個是30個Channel,
所以我就只有那30個Channel的Data,
然後它中間發生什麼事,
那都是Visualization,
他們去內插,
然後去再投影,
然後想要跟你說這個。
哦,因為我剛才在想的是,
如果你先把Data,
就是process成這樣,
然後再丟的話,
聽起來有點像是,
你會rewrite每一個Data的效果,
然後可能會,
就是smear掉,
physically happening in your brain的事情。
你知道我意思嗎?
這個我懂你的意思,對。
OK,好,了解了解。
就是純粹只有Visualization。
好,謝謝。
就像你剛剛說的,
其實有人真的會把這個Mapping,
拿去當Data用,
然後我是蠻討厭這樣的做法,
因為就像你所問的問題。
然後,
好,所以剛剛講到說,
我們怎麼樣去找那個Database裡面,
跟新的人比較像的Model。
對,那這個的好處是什麼呢?
就我們如果有這個,
我們把它叫Subject Transfer,
就是把Model從一個人,
transfer到另一個人身上。
那這個好處就是說,
我們以前可能是要說,
我們對一個人,
我們盡量去收集他,
就是每一個人的Data,
就是腦波跟那個行為,
然後我們盡量收集多一點Data,
然後我們去建一個Model,
然後我們相信說對同一個人,
會有一個很好的Performance。
我們叫Self Decoding。
那因為有一些Variability的問題,
所以其實這樣子通常會,
還是會有一些,
還是有常常會Fail,
所以我們想要用那個Subject Transfer,
然後我們用一個少量的Data,
當作一個指標,
當作一個可能就是Brain Signature,
那我們就可以去從我們的Database裡面,
找出適合的Model,
然後拿來用,
然後就可以直接對這個新的人,
去開始運作,
開始去監測他的Learnance程度。
那這個比較小的,
比較少量的Data,
應該要用什麼呢?
就是我目前講到的,
就是用Baseline Activity。
Baseline Activity它是一個基準狀態,
那通常也可以,
就Baseline Activity它也可以,
講說是Resting Activity,
或是Task Free Activity,
就是說,
就是這個Subject沒在做什麼事情,
然後跟你的Task無關的時候,
然後那個時候的大腦活動。
那過去有很多研究,
去看說你大腦沒有在做什麼時候的,
那些大腦的固有的活動,
那跟你真的給他一個Task,
去做了之後,
特定的活動,
那是不是有一些關聯性?
那在腦波上呢,
就是我們發現說,
你從Resting Data,
你去用ICA,
然後去看他的一些,
分解出來的Component Activity,
然後你用那個就可以幫助他,
在動作想像這一個特定的Task上面,
你就可以從Resting的Data,
就可以找到他動作想像的時候,
的那個Pattern出來。
變成說你一個人,
沒有在做動作想像的時候,
其實他的Data,
就可以告訴你,
他在做動作想像的時候,
他的那個Pattern是長什麼樣子。
然後另外有用Resting的Data,
去預測說就是,
腦機介面的效能怎麼樣,
因為不是每一個人都可以,
很好地去掌握去運用腦機介面,
那Resting Data,
就可以大概的告訴你說,
這個人適不適合用腦機介面。
那還有一個Study是,
他就從Resting,
那這個是MRI的Data,
FMRI的Data,
然後他就直接從Resting的FMRI,
去預測說,
在特定的認知的Task下面,
他的Activation的Mapping長什麼樣子。
那所以就是有很多證據顯示說,
你的Resting的Data,
跟你Task關的Data,
會有一些關聯性。
那所以剛剛那個,
回到剛剛那個,
我們怎麼去選適當的Model,
那我就想說,
是不是用一小段Resting的Data,
我們就可以去找到正確的Model,
給新的人用。
所以這邊我想的一個架構就是說,
我有很多的Model,
就是從過去的那個實驗,
累積下來的Data,
我去都建好很多個Model,
然後新的人我們叫Target Subject,
然後我們就去錄他一段Baseline,
然後這是在Alert的情況下去錄到的。
那就是說這個人他在我們那個,
這個那個,
模擬駕駛裡面,
模擬的車子上面,
他沒有在動,
他沒有在轉方向盤,
沒有在幹嘛的時候,
就是車子直線的前進,
然後他什麼事都行,
都不用做的時候,
那段時間的Data,
我們就把他當作一個Friend Signature,
那我們用這個去估計說,
這個新的人跟原來的,
Database裡面的誰的Model比較像,
那我們就去對這個Model做一個排序,
然後做一個Fusion,
就是把那些Model Output結合在一起,
那當然是會給一些不同的權重,
那我們最後還要再經過一個Recalibration,
因為有時候他有一些Offset,
然後我們最後就是,
可以直接給這個Subject,
去估計他的Awareness,
這邊有什麼問題嗎?
你可以稍微再解釋一下,
那個配對的過程嗎?
好,對。
就是你怎麼找一個,
你是,
就是你怎麼找一個跟你配對的那個人,
還有那個Session?
OK,好,
然後我這邊,
我就Backup Slides,
就是新的人,
我會有他的那個Base Line的Data,
那他是,
就是他的不同頻帶的,
然後在不同位置的能量,
然後我們用這個去跟我Database裡面,
所有其他人的這個部分的Data,
去做比對,
然後我去估計他的相似性,
然後我用這個相似性,
我就可以去,
我就假設說,
如果他在這個Base Line的狀態下,
這兩個人的這個Pattern像,
那我就相信他們的那個,
EEG Awareness的那個Model會很像,
所以我就是這樣去做。
OK,所以換句話說,
你剛剛給我們看的,
某一個人的第幾個Session,
跟另一個人的某一個Session,
按照這個Model的假設,
他們的就是Default Baseline Activity,
應該會非常類似這樣。
對對對,這就是我的假設。
OK,謝謝。
然後所以我這邊有一個事後的分析,
就是說我們用Baseline Activity,
去預測出來的相似性,
是不是真的就是他們的相似性,
那我這邊真實的相似性,
我就是把那個某一個Session的Model,
某一個人某一個Session的Model,
直接去對另一個人的Data去用,
然後去看他們,
事後去看他們的Performance,
就有一個Offline得到一個真實的相似性,
然後我另外就是用Baseline Activity,
去估計他們的Subject-Subject相似性之後呢,
然後我去預測出來的,
我去預測之後,
然後我可以得到的Performance,
然後就發現說這兩個是還是蠻相關的,
就是這邊可以看到一個對應,
就是我實際上跟我預測的,
那是有一個準確性在這邊。
那運用這個的話,
我就可以做我剛剛的事情,
代表說我剛剛的假設,
至少有一部分是對的。
那因為這樣,
所以我們就可以去看我們預估,
去看我們預測出來的結果,
那這邊呢,
我們是黑線是代表剛剛那個Learners Index,
所以整個實驗裡面隨著時間的變化,
就是一個黑線,
那我們預測出來的結果,
就是要去貼近這個黑線,
那我們就可以看說不同區間的相關係數,
就可以表達說我們預測的準不準,
然後這邊藍色的部分是用傳統的方法,
就是每一個Subject,
用他自己前面已經錄到的Data,
去Train一個Model,
然後去看他的預測的結果。
那紅線的話,
就是我們我剛剛新提出來的方法,
就是說我們新的人,
去看他一小段Baseline Activity,
然後我們去用其他人的Model,
然後預測他的Learners,
然後你可以發現說在這個例子上面,
紅色表現比黑色還好,
那這邊是他們區間,
他們跟實際Ground Truth的相關係數,
是在這邊。
所以在這個例子上面,
那個Subject Transfer,
這個方法是表現的略為好一點。
我有一個小問題,
這概念上其實有點像捐血對不對?
假設你可以找到一群人,
他的某一個東西,
譬如說Genotype,
或者是某一個型,
跟你是很類似的,
那用你這個方法,
你其實可以利用他們的Data,
來跟你的Data配對。
對。
OK,
所以換句話說,
因為你同一個人,
他頂多只能做幾個小時的實驗,
可是如果利用這個方法,
合理來講,
你幾乎有無限大的Data可以用,
因為如果你Recruit很多人,
那這個人有很多人可以配對,
你的Data pool就會一直上升。
概念上是這樣,
沒錯吧?
沒錯沒錯。
OK,
謝謝。
我有一個問題,
就是前一頁那個圖啊,
就是Actual就是Actual嗎?
不不不,
下一頁。
下一頁,
對對對,
就是你這個等於是不同的方法去做,
然後你現在畫一條線,
可是如果那個,
就是你把你的Data稍微分一分,
然後做有點像是重複五百次,
或重複一千次同樣的事情,
然後你的Prediction,
會稍微有一點點每次都不一樣,
那你就可以把你的,
比如說紅色的條線,
畫成一個紅色的Band,
你知道我的意思嗎?
啊,
有一個Error。
對,
那個Band的範圍基本上就是,
你這個Model的可能的Uncertainty的範圍。
OK,
那我。
所以每一次跑,
你是不是有點不一樣?
你聽到嗎?
對,
因為你剛剛說,
所以每一次跑會有一點不一樣。
對啊,
所以我比較好奇的是,
除了你現在秀出來的這一條線之外,
那這每一條線它背後所代表的,
它的Certainty,
可能也不一定一樣,
比如說Predictability,
在這個Specific Case上特別好的,
它可能其實是Fluctuate Up,
剛剛好,
可是它其實那個Band很寬,
所以它不一定特別好。
哦,
我覺得是這樣,
就是Error Bar。
這是一個很好的問題,
對,
因為通常你如果Plot這個Prediction的話,
你會Plot 95% Confidence Interval,
它其實就是在說這個東西,
你應該把這個東西Plot出來。
OK,
了解,
對,
但是我看那個圖很多了,
我大概也會覺得說,
那應該沒什麼好爭論,
它應該就是有效果,
可是。
對,
如果很接近的時候,
我就會比較好奇說,
那我現在要判斷說,
這個比這個好,
或這個比那個差,
我可能就會想要看到Error Bar。
哦,
了解,
對,
這不錯,
我應該可以把那個,
那個Confidence Interval也一起畫進來。
對,
因為我這邊只是想要比它們的Correlation,
然後我就只是把那個線畫出來。
所以如果我把那個區間也畫出來,
我可以有更好的那個,
更好的比那相關係數更好的那個Measure,
去看它們的Performance嗎?
對啊,
我是這樣想,
因為我覺得如果你有Error Bar的話,
你就可以很明確的說,
這個好,
這個比較不好,
你知道嗎?
對,
可是如果你只是要Show Feature的話,
我現在看起來是,
就它們都Work,
而且都Work pretty good,
我覺得啦。
哦,
OK,
了解。
對啊。
因為我現在這邊比的方法,
我就是說,
每一次我去Testing的時候,
我去看那個不同方法的相關係數,
然後我不同人的話,
我就是把它們相關係數平均起來看,
然後最後去結論說,
我哪個方法比較好。
對,
我目前的做法是這樣,
比較簡單一點的,
但是可能不是最好的。
喂?
對,
如果有更好的方法,
我再跟你們請教一下。
好,
我們之後可以討論,
我們之後可以討論。
好,
謝謝,
好,
那我先繼續。
OK,
然後,
對,
剛剛就是我用相關係數去看說,
不同的方法,
它的整體的Performance,
那這邊我就是把所有我Testing的那個Subject都整體一起來看,
然後剛剛那個少敏提到說,
我的Data增加就是會不錯,
然後對,
所以我就去測試說,
這邊我的剛剛那個Data,
那個Database的Size如果不一樣大的話,
那我是,
我做的方式是說,
我把我的Database,
把它砍掉一些Data,
隨機的去砍掉一些Data,
以Subject為單位,
然後我去看說,
我Subject增加的時候,
我的那個方法的Performance會不會增加,
然後歪軸就是看平均的Correlation Coefficient,
然後這邊藍色是傳統的方法,
就是用自己的Data Train Model,
然後用在自己身上,
然後紅色的話就是我們的Subject Transfer的方法,
那灰色的話就是一樣是Subject Transfer,
但是沒有用我們的Baseline Activity,
去好好選那些Model,
然後你可以看到說,
我們的方法它會隨著你Database的那個Size增加而增加,
對,
然後,
但是你如果沒有用Baseline的校正的話,
它就是會稍微差一點,
會差一點,
差一截,
然後再繼續講下一張圖,
這個是我去比較說,
就是我們這樣子做的話,
它的Calibration Time有沒有減少,
就是傳統的話就是你要自己Data,
那因為Alertness,
我們要錄到它變Drowsy的話,
其實都要很花時間,
所以傳統上都要花一段時間,
才可以得到需要的Data,
那這個就是會造成就是Calibration Time很長,
那我們新的方法,
因為是取用Baseline Activity,
那Baseline Activity很好取得,
就不要動就可以了,
所以你大概不到兩分鐘的Data,
就可以達到過去的方法,
過去的方法大概18分鐘的效能,
就是它們是沒有顯出差異,
所以我這邊就是結論就是說,
我可以從18分鐘減少到不到兩分鐘,
在Calibration的減少上,
Subject Transfer可以給我們這樣的效益,
那這樣的話對我們未來真的要用腦波去預估,
Alertness這件事它的方便性就會比以前好很多。
然後另外有一個問題,
就是大家常常會問的說,
這個帽子長這樣,
這個沒有人會想戴,
那我們有沒有辦法用更好的方式去測量到我們腦波?
那我就在想說,
就是我們測量腦波的時候,
其實頭髮是一個很大的問題,
那如果我們避開頭髮的話,
我們其實可以用一些比較簡單的Device,
然後還有用一些,
甚至像貼在皮膚上的這些Sensor,
然後就可以,
如果用這些就可以量到腦波的話,
那這樣就更多人願意用,
就不用弄壞你的頭髮,
然後也不會不舒服這樣。
所以我就去測試說,
如果我今天只用前額跟耳朵旁邊的這幾個Channel,
只有六個Channel,
那我用這六個Channel可不可以跟整個頭,
用三十個Channel所達到的效能去做一個比較。
那我最後發現說,
你只用沒有頭髮覆蓋的這些Channel,
所得到的分類正確率,
可以跟所有Channel一起進來的分類,
有相似的,
就是沒有顯著差異。
所以就變成說,
我們其實可以把Alertness,
用在Alertness上面的PCI,
我們其實可以用,
非頭髮覆蓋的這些Channel去錄就好。
那這樣就是我們的Device,
我們的量測方式可以變得更方便。
然後就是後面這邊就是講一些,
就是我們在真的要應用的時候,
需要解決的問題。
那前面一個是用Subject Transferring,
去減少它的Calibration Time,
那後面這邊我們是去驗證說,
我們可以不需要用那麼多Channel,
我們可以用比較好的量測方式,
更方便的去做這件事。
那這邊是給大家一個示意說,
我們未來這個系統會怎麼運作。
就是剛剛我們講到說,
我們是用Response Time,
去當作我們Alertness的一個Ground Truth。
那更精準的來說,
我是打算用Response Time的Distribution,
去當作Alertness,
去定義我們的Alertness。
所以說你的Distribution如果比較尖,
然後它的Peak在比較時間比較短的情況,
就是這個Y軸是反應時間,
然後單位是秒。
所以如果這個是很窄的一個分布的話,
那就是比較好的Alertness。
那如果它這個分布很寬的話,
就是它比較容易有一些長一點的Response Time出現,
那就是比較糟的Alertness,High跟Low。
然後這邊就是一個展示說,
我的黑線是我的現在,
然後我就用這個現在之前的腦波的資料,
然後去預設說,
從現在開始到90秒內,
它的Response Time的機率分布。
那這個機率分布,
就是一個隨時間會變的一個東西。
然後我這個時間過去的時候,
我可以用一些,
我有一些Offline的測試,
然後去看說我的Response Time,
是不是真的落在比較機率高的地方。
那這些白點就是我們每一次測偏移,
它做反應所花的Response Time。
然後我這邊可以稍微播放一下。
OK,所以大家可以看到說,
現在這個是它的Distribution比較窄,
然後所以這邊顏色也比較明顯。
然後這邊是我們真實錄到的Response Time,
它就比較容易落在這個範圍內。
然後這個是比較,
Learning狀態比較好的情況下。
然後隨著時間過去,
我們可以看到這個人,
他的這個分布就是一直飄來飄去,
然後最後變得比較寬,
那就是代表說他開始狀況不太行了。
開始有一點打瞌睡。
好,那像這邊就是,
那像這邊就是,
大概是這裡。
就像這邊它的分布已經變得比較寬,
然後這邊也糊掉了。
那你也可以看到說,
有一些長的反應時間出現,
那就代表說我們的預測,
大致上有真實的資料去佐證說,
這個預測是有它的正確性的。
然後它就會一直起起伏伏。
那這是有點像天氣預報一樣,
我們去對它的Learnings做一個預報。
請問大家這邊有什麼問題嗎?
不好意思,這個預報是幾秒之前?
我剛剛可能miss掉了。
OK,這個黑線是現在,
所以我是往前預測90秒,
那這90秒內,
它的機率分布是在這裡。
那所以我們就看說,
我前面這樣預測,
那它後面真的反應時間是不是就落在
剛剛我預測的那個。
比如說我剛剛預測的分布。
那我就是打算說再繼續往下做,
那就是希望說,
這個東西可以真的應用在很多用途上。
那除了開車這件事以外,
很多工作只要是需要注意力專注的職業,
可能都可以用到這個東西。
那另外我也想要用這個東西去看說,
有沒有辦法去即時的,
看我們在學習的過程中,
我們大腦是不是用Alertness的變化,
去看它學習的效果,
看是不是跟學習效果有一些關係。
那或者是我們可以再去看說像ADHD,
或是其他的精緻的一些比較特別的人,
他們是不是在Alertness這個部分,
跟正常人有一些差異。
把Alertness當作一個工具。
看說是不是不同的群體有不同的差異。
這邊感謝我很多人,
還有實驗室,
還有Funding,
主要是陸軍所贊助的。
謝謝大家。
謝謝謝謝。
還有掌聲,太棒了。
大家有什麼問題嗎?
可以現在先問一下。
有問題。
還有一些Common。
首先第一個是小問題,
你說是陸軍贊助的,是美國嗎?
對。
美國陸軍贊助的Project。
對。
我只是好奇啦,
那你是美國籍嗎?
不是,
它這個Project它是沒有敏感性的。
哦。
所以它可以,
它就是有一個Project,
它是有很多學校一起,
然後幫陸軍做東西這樣。
它錢撒給很多學校,
然後所有很多學校幫它做事。
它這個計畫就是主要想看那個,
腦機介面還有包括很多,
就是怎麼樣把生命科學用在,
用在一些情境上面。
哦,I see。
因為至少在物理或是天文相關的,
如果是就是有軍方贊助,
就是軍方的Sponsorship的話,
通常就他們的毛都很多,
就是你這個國籍是誰啊,
你這個國籍是什麼啊,
背景是什麼啊。
對,他們有分,
他們很多Project就是一定要公民,
像那個,
對,給我們錢的那個單位就是你要,
你一定要公民才能在裡面工作,
就連PR都不行。
I see。
然後我會有一個覺得有趣的東西,
就是這個研究啊,
就是我覺得要是我接下去做,
我會想要做個東西就是,
因為比如說這個人已經開始恍神,
然後我們都有這樣的經驗就是說,
你旁邊,
你坐在副駕駛座,
然後駕駛開始恍神,
你就誒,
不要睡了,
結果那個白癡,
他做的第一件事情就是驚醒,
然後踩煞車,
其實也非常危險。
所以我覺得awakening的反應,
也會是這個研究,
接下去要讓這個東西整個變成是一個完整,
而且有用的東西,
很重要的一環,
我覺得啊。
對,對,說得好。
對,我們也有看他那個,
如果是睡覺的過程,
然後如果被我們,
我們之前用聲音去吵他,
然後看說我們吵了之後有沒有用。
對,但是我們沒有真的看到,
像你說的那個亂踩煞車,
對,但我覺得是有可能的,
對,這個建議嗎?
我有兩個問題。
好,我有兩個問題。
第一個問題是跟你的硬體有相關,
但你在裡面有講到,
其實如果你只用幾個channel,
頭髮沒有覆蓋到那幾個channel,
出來的效果也是一樣,
那那一些channel是不是,
你是用乾式的電極量訊號的嗎?
我那個研究裡面,
我全部都用同樣的電極,
都是10電極,
然後我純粹去看說,
不同位置給的結果是什麼樣子,
對,因為要比較的話,
所以我還是全部用同樣的量測方式,
這樣比較好。
因為我其實前幾年有去過San Diego,
有跟鍾老師碰過面,
當時他有給我們看,
他實驗室用交大發展的那個,
像棒球帽那個乾式電極。
棒球帽?
棒球帽是最原始的型態,
但是他們主要是把電極都變成乾式電極,
所以都不需要再打膠了。
所以我現在比較好奇的是,
以你們現在的實驗或目前來講,
還有人在用乾式電極嗎?
還是大部分都還是用有打膠的?
其實現在乾式電極越來越普及了,
因為大家發現它好用的地方,
就是做實驗很快,
然後subject也比較喜歡,
但是不一定比較舒服,
因為乾式電極它在頭髮的部分,
它通常要有一些特殊的設計才能穿過頭髮,
所以很多乾式電極它會做一些角、針角。
哦,比較長一點的頭髮。
對,那戴久了就會不舒服。
所以我專攻說沒有頭髮的部分,
是因為沒有頭髮的地方,
那個sensor的選擇就蠻多蠻多的,
因為不用處理頭髮的問題。
然後像那種貼片式的,
它對那個長時間量測會比較好一點,
因為乾式電極目前大部分的人,
就是戴一個小時之後就會開始覺得痛。
哦,好。
那我的第二個問題有一點點大哉問啦,
目前BCA我看到的大部分都是從大腦裡面截取訊號,
然後傳輸到電腦上面,
做相關的處理或是其他的應用。
但有沒有可能你覺得將來,
或是不曉得有沒有人現在已經在做,
就是另外有點像是相反,
是從電腦發出訊號或指令,
然後傳到人類的大腦裡面,
企圖去操控人類的行為?
有,就是有幾種非侵入的方式,
我就講非侵入的,
因為侵入的話就直接電刺激嘛。
那非侵入的話就是有那種,
有一種叫TMS,
就是穿耳磁刺激,
它會用很強的磁線圈,
然後去試圖引發你某個區域的大腦活動。
那那部分目前就是,
至少知道就是它可以就是,
就是那個醫生可以去找找找,
然後找看哪個位置,
它的刺激下去之後,
你的手就會動,
目前可以這樣。
但是這個東西它還沒有很完整的去研究過,
所以它到底可以造成什麼變化,
目前沒有很多相關的證據,
所以還在發展中。
我可以稍微講一下,
就是我們實驗室有人做這個,
我自己還沒有做過,
但是基本上它也會有,
剛剛接近於一對一的對應,
就譬如說,
如果你是刺激Visual Cortex,
就是Occipital這個地方,
有一些人會看到Closeting,
就是會看到閃光。
那像剛剛群樹說的,
如果你刺激Motor的話,
它會有地方會動,
而且是有可以對應的,
你可以找出來,
譬如說是哪一根手指會動,
就是你刺激某一個地方,
它會有Mapping這樣,
是大拇指動呢?
還是中指動呢?
還是哪裡動?
那聽覺,聽覺應該也是有人做,
所以應該說做的人相對稍微少一點,
跟譬如說EGYMRI比起來,
那其實也是有一群人在做TMS的研究,
那還有別的TDCS、TACS等等這樣。
對。
那大家還有其他問題嗎?
不然我要問問題囉。
等一下,等一下,不好意思。
我不是有問題啦,
我只是要說那個,
我要停止錄影喔。
那所以我們就可以隨便講話。
但是你們可以完全,
你們繼續,
我只是要停止錄影。
OK,OK,沒問題。
OK,不好意思。
可以問一些比較尖銳的問題。
