start	end	text
0	11000	謝謝大家早安晚安,謝謝大家今天來參加我來share我的screen。
11000	27000	我們今天人沒有很多,所以大家不用客氣,如果有問題隨時打斷我,或者是直接開,我覺得直接開麥克風應該也沒關係。
27000	35000	好,那今天我要講的這個題目其實是叫做Invisible Risk Data Sharing Activities of Data Brokers。
35000	44000	我的co-author是Aaron,是剛從Rutgers拿到PhD,他的PhD的peer好像也在這邊。
44000	51000	他之後要去California State University Fullerton,然後我另外一個老師是Rutgers的老師。
51000	63000	自我介紹一下,我的background其實是Accounting,然後我是CPA,然後我是Certified Internal Auditor,可是我的PhD是Management Information Systems。
63000	71000	我平常主要都是在教Data Analytics,Data Mining這種相關的課程,因為我的background的關係。
71000	88000	那我目前是在Fulbright Specialist的那個list上面,然後我是專門在做Curriculum Development,然後我之前也有在跟Computer Science那邊有合作,他們有個Task Force在講說Cyber Security的Curriculum要怎麼Design,所以我也在那個計畫裡面。
88000	109000	那我的research主要都是IT Management, Security Management,幾乎都是在這個方面的。那我經常在外面演講,那可能是大學啦,conference啦,然後或者是有一些professional organization的,然後之前有在Federal Reserve Bank當過panelist。
110000	124000	然後我上上禮拜,上上禮拜,三四個禮拜之前吧,有在McDonalds幫他們做Analytics的training,之前有幫California Department of Justice做一些training,然後也有在台灣的金管會幫他們演講過。
124000	141000	那我2018年的時候,我是KPMG就那很大的audit consulting firm,我在那邊當professor in residence,所以我其實跟他們一起在紐約工作了10個禮拜,然後我平常也有在跟公司做project,那目前已經做超過大概15個了吧。
141000	170000	好,那有關於這個paper,Data Broker其實已經出現很久了,只是他受到注意可能是過去這10年之內的事情,所以你看其實可以看到好多新聞都在講Data Broker,然後看到我這邊的這個最早期是2013年的,那最近其實是到今年。
171000	183000	呃,都還只有在看到,尤其是在那個Facebook的Cambridge Analytica的那個Scandal之後,新聞更多,那到底誰是Data Broker?呃,Data Broker其實。
184000	202000	不是我們平常一般會接觸到的那個那個organization,他其實是比如說我們去一個一個網站,我們在我們都知道說他會收集很多我們的資訊,我們也知道有些網站其實會把我們資訊拿去賣或拿去share,可Data Broker其實是躲在這些網站的後面的。
203000	218000	所以他在收集資料的時候,其實我們大概都不會知道,比如說,呃,我們手機有個免費的app,然後我們就去登入了,那其實這個app說是免費,他其實是背後其實是因為他這個有一個額外的information sharing的動作,所以他是免費的。
219000	244000	那或者是說,比如說我們去超級市場買東西,呃,我們所有的購買紀錄啊什麼,其實背後也通通都會被share出去喔,那或者是他可以到比如說Facebook啦,呃,什麼Instagram上面找我們的所有公開的資訊,所以我們發的相片啦,我們寫的東西啦,怎麼寫的啦,呃,是不是一個relationship啊,這些東西他全部都知道。
244000	259000	那還有一些public的source他也可以找得到,比如說在Illinois,呃,所有比如說誰繳了哪一間房子的property tax,那個全部都是看得到的,所以就是公開的註冊的資料其實都有。
259000	287000	然後,那這些公司就會把你這些資料全部收集起來,那如果不夠的話,他會去找其他的data broker一起分享,或者跟他們買,那買來之後整理完之後,其實我們每一個人就會有一個tag,他可以有一些inference可以做,比如說,喔,這個人是,呃,他們家最近最近會有會會有一個baby,或者是說,喔,這個人會有一個golf club的access。
288000	316000	然後或者是說,這個人是facebook的social media的influencer,他就可以都知道說,你有一些preferences啦,或者是你有一些特性,他通通都會知道,那這個東西,呃,最常見的就是這些marketing或advertising的data broker,那他們其實都可以做到很精準的,比如說,我之前在另外一間學校的時候,我的同事,他每次接到廣告信都是問他,你要不要買房子?
316000	336000	你要不要買一台車子?你要不要買一個新的車子?你要不要買一個新的船?然後他收到的都是這種,我收到的都是,你要不要借personal loan?你要不要借mortgage?你現在mortgage還有多少錢沒有還?所以你可以看到說,他可以知道說,你目前的財務狀況是什麼?他給你的那個advertisement通通都是不一樣的。
336000	364000	那另外還有兩種是,呃,比較常見的fraud detection跟risk mitigation是,比如說,你去銀行借錢的時候,他需要去確認你所給的資料是不是都正確的,那也是透過data broker,那這個部分就很重要嘛,那還有一些網站其實是,呃,讓你可以去找到其他人的網站,那他也是透過data broker去收集到這些人的資訊,所以你可以去判斷說,那個人是不是你想要看到的人。
365000	389000	那這些資料為什麼會有用呢?那其實是因為他如果能夠把很多顧客的資料全部收集起來,然後不管是線上的還是offline的,他全部找到之後呢,那這些資料他就有辦法重新去確認,比如說同樣的一件事情,我從好多個source都去找,我就把判斷說到底哪一個才是對的。
389000	415000	那就可以把那個data quality就會好非常多,所以他就有辦法用它來做一些prediction,那他不在意說我們每一個人到底發生什麼事,他要的是這個大量的aggregated資料,然後他就可以把它做prediction,那這prediction之後其實就很有用,原因是因為他就可以賣說,比如說這個人可能明年要換車子,他就有辦法跟這些人講說啊,你就可以send一個marketing的material去。
415000	423000	那或者是他可以跟其他data broker去買更有用的資料,來讓他的data更豐富。
423000	436000	所以你會看到各式各樣的data broker,那這邊這四個是比較大的,比如說action其實非常大的,那他其實是全部都是在做marketing campaign跟fraud detection的。
437000	459000	那後面這三個有人是專門是給business或government,比如說告訴你說啊,這些人的financial information是什麼啦,或者是說有人是告訴你說他的customer transaction到底都長什麼樣子啦,或者是說他可以告訴你說,我收集的這些資料不只是用來做marketing,financial service的product可以給。
460000	480000	那其實就是當你了解一個人所有的profile之後,他其實所有的資訊都是非常有用的。那他們到底收集了什麼樣的資料呢?呃,這有點模糊,因為這是一個screen shot。可是如果你們可以看到,他這邊其實告訴你說,Axiom這間很大的data broker,他是public traded company。
481000	501000	他既然有45years of historical data on name changes and residential history,過去45年的資料他通通都有,就是你這邊到底是誰,你的名字怎麼改,他全部都有。那性別啦,年齡啦,education level,這個都很簡單喔,對他們來講。
502000	519000	他也知道你比如說你目前手上的loan有哪一些,income level是什麼,車子是哪一台。然後當有這些資料的時候,他就有辦法做prediction,比如說你們的household是不是有人最近planning to have a baby,或者是planning to adopt a child。
519000	543000	對,或是你是不是都每年在美國是不是都每年4月有在報稅,然後或者是你是不是heavy Facebook user,或者是你是不是很容易被socially influenced,他都有辦法知道。你有沒有major medical insurance,這些全部通通都是知道的。然後surprisingly,他們既然有超過3000個不同的attributes。
543000	563000	所以在美國每一個人,如果他有收集到你的資訊的話,他既然有3000個不同的attributes去去描述這個人各式各樣的characteristics,所以他其實非常知道我們每一個人到底發生了什麼事情。有時候其實我們都不知道自己的preference,可是這些data broker都會知道。
563000	581000	那你們會發現說,這其實蠻恐怖的,原因是因為他不是我們直接會接觸到的那個organization,比如說我們去Amazon,我們知道Amazon,我們去Facebook,我們知道是他,可是他其實都是在後面behind the scene在做這些動作的。
581000	592000	所以在2014、2013的那個時候,美國的Federal Trade Commission,他們其實有兩個文章,通通都是在講這件事情的。
592000	615000	那他們這兩個文章主要在講的其實是說,他們對於data broker,他們覺得最大的問題是,我們不知道他到底在幹嘛,我們也不知道他到底收集了什麼資訊,我們也不曉得說他到底把我們資訊拿去做什麼了,怎麼分享的,怎麼賣的,賣給誰,其實通通都是不知道。
615000	638000	就是他整個practice其實都是一個black box,所以我們完全不知道說他們到底在做什麼。所以這個Federal Trade Commission在2013、14的時候就希望大家能夠regulators,能夠有一些動作去限制說,至少要讓我們更了解說這些data broker到底在做什麼事情。
638000	658000	那這是這兩篇主要的內容。那他們裡面提到一個很有趣的東西,就是data brokers他們其實是彼此之間是在互相競爭說他們那個data可以賣給誰的,所以這是沒問題的。可是他們其實不是互相競爭的關係,他們其實是互相合作也有可能。
658000	680000	比如說他們去問了9個data broker,然後他們就知道說每個data broker他們資料是從哪裡來的,比如說你是從政府單位收集來的那些公開資料,或者是說其他任何publicly available的source都有可能,那有可能是買來的commercial sources,或者是別家公司收集然後給你的。
680000	705000	你就會看到這9家其實他們收集的方法都非常的不一樣,有人是只有用commercial source,有人是什麼都在用。那最特別的是,雖然他們平常是在compete for client,就是到底誰可以買他們的data,可是你看到其實他們的data是會彼此互相share的,或者是說今天我收集到這個資料,然後你有需要我就賣給你。
705000	727000	你看到他們這是一個是很複雜的一個網路,那在這9個裡面其實只有第7個就是左邊下面這個,就第7個他是完全沒有跟其他的data broker有任何的data sharing的activities,那其他每一個人都有某種程度會買或賣,或者是從哪裡去share到通通都會有。
727000	756000	那這個東西對我們來講這個東西非常有趣,原因是因為如果他們不是只靠自己收集的,他們還會去拿別人的東西來一起用的話,如果今天hacker可以可以可以可以攻擊到其中某一個data broker,那其實就是像中大獎一樣,原因是因為你拿到的資料就不是只有他的,你拿到資料還有其他所有人他們彼此之間互相分享的所有訊息都有。
756000	777000	那其實這是我們的一個hypothesis,那只是我們後來發現說,其實還真的有這件事情,比如說,呃,很多年前的201118吧,aquifax有一個很大的bridge,他們裡面忘記去去去更新他們的更新他們的軟體,所以他們有一個很大的bridge。
778000	790000	那他們的bridge其實不是只有aquifax的資料被外流了,他們的除了aquifax之外,另外兩家很大的credit bureau就是experian跟transunion的資料其實也通通都外流了。
791000	804000	那其實我們去我們資料收集是從dark web去找的,所以我們其實有發現說,如果你去找到aquifax的data bridge的資料,其實你也可以看到其他兩家的資料,就其實全部通通都混在一起了。
804000	818000	那另外有一些,呃,像是anecdotal evidence吧,就是當他aquifax有bridge的時候,另外兩家去report credit fraud的資料也變多了,所以就是所有資料其實都通通是在leak的。
818000	830000	那如果我們去比如說google trend去看他們的那個fraud report的trend,你會發現這三家其實幾乎都是一模一樣的trend,就是一家有出事,另外兩家也通通都會有問題。
830000	843000	那我們就覺得說,那這個絕對是因為他們這種彼此彼此交換資訊之間之所以造成的影響,所以只要一個人有問題,就會所有的事情都會發生了。
843000	853000	那這很麻煩,所以你會看到其實在美國有很多的regulation的一些東西開始出現,從2013年就有了。
853000	865000	那早期的重點其實是說,呃,這些data broker應該要讓,呃,那些consumer知道說他們到底收集了什麼樣的資料。
865000	876000	所以在13年還14年的時候,Axiom其實會讓,呃,每一個使用者不管你是誰,你去登入你的資料,然後你就可以看到說他到底有你什麼資訊,都可以看得到。
876000	885000	那另外還有一些重點就是說,他們覺得說完全都是不是transparent的,你的practice到底是什麼,到底收集了什麼,賣給誰。
885000	903000	那到現在其實都還是black box,那這是早期的13、14的,那到了2018、19之後,就出現了兩個新的東西,就是在Vermont,呃,他有一個data broker law,他就講說,如果你是data broker,我們等一下會講他的definition。
903000	916000	如果你是data broker的話,你就應該要跟他的secretary of state要去註冊,那註冊簡單講就是每年1月底之前,你要到他網站,然後去把你的所有資料提供給他。
916000	928000	那提供的資料其實長得像這樣子,就是,呃,你是哪一家公司,你的網站是什麼,然後,呃,如果user不想要讓你收集資訊的話,能不能opt out,就是我不要讓你收集。
928000	943000	那要的話是怎麼做的,他其實整個disclosure都有細節喔,那或者是說,呃,你有沒有有關於,呃,任何關於這些opt out或data collection的statement啊什麼,其實都可以寫上去。
943000	958000	那這個例子是寫很多的,有的公司雖然說他有註冊,可是事實上你會看到其實根本沒有什麼訊息,他很多都只會講說啊,請見我們的網站,那你點過去,其實那邊也沒有什麼東西,你幾乎都看不到。
958000	970000	這是一個,第二個問題其實是,呃,data broker,就算他符合了這家,呃,符合了這個regulation的definition,他是data broker。
970000	988000	如果他沒有去註冊,那個penalty其實很低喔,呃,我忘記是vermont還是california state,他的,如果你不去註冊的話,一天只有罰你100美金而已,而且他是有上限的,就是我一直罰,罰到比如說,呃,10,000 US dollars就不能再罰了。
988000	1011000	那對於data broker來講,這個幾乎是nothing,他們可能一天就賺超過1萬美金,所以,呃,那個penalty的效果其實不太大,他不像GDPR那種,呃,在歐洲的privacy regulation的影響這麼大,就是如果你有一個violation,隨便下去就是幾個percent的annual sales revenue,所以這個東西的效果就沒有那麼好。
1012000	1032000	那他的定義其實很簡單,簡單講就是,一個,當一個企業你知道你有在蒐集資料,或者是你也知道你在賣,把你蒐集的資料拿出去賣,然後這樣其實就算data broker了,那只要你這個蒐集的資料跟賣的資料不是你直接面對那些顧客的話,他其實就算data broker了。
1033000	1056000	所以其實,呃,他定義其實還蠻大的,但是其實你要想過這個定義也很簡單,比如說,如果你只有蒐集資料,買資料來自己用的話,其實你不算data broker,或者是說你蒐集的資料其實是你的customer資料,比如說amazon,我蒐集的其實是跟我買東西的這些人的資料,然後把這些東西拿去賣,其實我也不算data broker。
1056000	1069000	所以他其實是有一些loophole在,所以這也會造成一些問題,就很多公司其實他應該是data broker,因為他其實是有買賣的動作的,但是,呃,照這個法令規定其實是看不到他的。
1069000	1089000	那California state一樣,呃,就是如果你去他attorney general的office,你也可以看到這個很大的這個register list,那,呃,幾乎所有要求的訊息都一模一樣,只是他是晚一年開始生效,他是2020年1月才開始生效的,那所有的定義都一樣,幾乎所有東西都一樣。
1089000	1118000	雖然,呃,加州對於privacy的regulation其實比較嚴格的,但這方面其實一樣的,那他要揭露的訊息其實也幾乎都是差不多的,所以,呃,如果你沒有機會去他們的網站上的話,你可以看到類似的東西,那好,那我們很快講一下,就是,呃,我們覺得說,為什麼他們這個互相彼此競爭又彼此在合作的關係,為什麼會覺得跟他們這個未來會發生?
1118000	1147000	Security breach或information會被人家偷走的這個狀態其實有關的原因,第一個很大的重點其實倒不是在這個competition或data sharing這件事,其實是因為他其實根本就是一個unregulated industry,他說他所有東西其實都是self regulated,他們自己有他們自己的privacy standard,他們自己有自己的norm,可是,呃,對我們來講,其實他們就是unregulated的,就是。
1149000	1169000	你拿你的資訊拿去share你的,呃,penalty到底是什麼,或者是什麼東西是可以分享,什麼東西是不可以分享的,他其實通通都是沒有任何的限制的,簡單講,所以如果有一個hacker,如果能夠發現到一個data broker,能夠把他的資料都拿走的話,影響就很大。
1170000	1191000	所以這就是為什麼像Aquifax這種主要的,其實主要就是一個data broker,那他的,如果他出現一個breach的話,他影響就會非常大,那這些資訊其實都是可以賣錢的,所以那這樣就影響就更大,所以他的誘因也更多,所以人家就更有可能會去想要去,呃,拿到你的資訊拿去賣。
1191000	1218000	我們這個這個paper還在非常rough的stage,但是我覺得說,呃,我們還是希望能夠present,然後希望能夠讓大家有一些awareness,或者是大家有一些額外的想法,尤其是在,呃,怎麼樣保護privacy protection方面,或者是怎麼樣去更更有效的去了解說他們到底在幹嘛,所以,呃,你會看到說,其實我們的hypothesis啊,其實所有東西都還是很rough的階段的,所以但是我們還是希望能夠多share一下。
1218000	1242000	那另外一個就是我們希望知道說這個registration到底有沒有任何的影響,呃,我們當然讓我們讓這些的broad data broker通通都是透明的,或者是大家知道他們是誰的時候,會不會說他們的practice就更好,他們就更transparent,或者是他們有一些壓力說他們不能夠那麼容易的會有security breach。
1242000	1243000	可是問題其實是在,不是這個regulation,其實是因為就算你不註冊的話,其實效果也不大,所以,呃,它變成是有點像是voluntary的一個建議你要去register的動作。那這邊有幾個是我們看到他們舉的例子說,如果你符合這些項目,你就可以不要不用去註冊,比如說,呃,你自己是一個專門做e-commerce的網站,你就可以不用,呃,那因為你資料一定會有,呃,那你就可以不用去註冊,比如說,呃,你自己是一個專門做e-commerce的網站,你就可以不用,呃,那因為你資料一定會有,呃,那你就可以不用去註冊,比如說,呃,你自己是一個專門做e-commerce的網站,你就可以不用,呃,那因為你資
1272000	1273000	那另外一個就是你就收集資料,然後你就建model,呃,你沒有把你收集的raw data拿去賣的話,這個也不算data broker,你賣model是沒關係的,但是你賣data的話就會算data broker,那另外一個第三個我是覺得有點誇張,就是如果你在你們網站上面有給user一個選項說do not sell my information的那個link,California很多公司都有了,如果你有那個link的話,你就不算data broker,因為你已經告訴人家說,呃,
1302000	1303000	這是有一個pre-collection的notice在,人家知道你在做這件事,好,那最後一個是,呃,這叫first party data holder,就是其實你就是,他們是你直接的customer,所以你本來就會收集他的資料,那如果你收集之後拿去賣的話,呃,你也不算data broker,好,那我們覺得registration其實是一個像signaling一樣,就是,呃,為什麼有些公司願意去收集,有些公司不願意,呃,呃,呃,呃,呃,呃,呃,呃,呃,呃,呃,呃,呃,呃,呃,呃,呃,呃,呃,呃,呃,呃,呃,呃,呃,呃,呃,呃,呃,呃,呃,呃,
1332000	1361500	呃,有一些公司願意去註冊,有一些公司不願意去註冊的原因就是,我們覺得他註冊那些公司其實是,呃,self-select去註冊的,他可能覺得說他的,呃,他本來就是transparent的,我本來就告訴大家說我到底在做什麼,所以有沒有去register其實根本沒影響,因為反正大家本來都知道,那或者是說其他security measure本來就比較好,我不可能出事,出事機率很低,那所以我去註冊也沒關係,
1361500	1384200	因為,呃,反正我本來就是比較好的那一群,那我讓大家知道反而是更好,大家就知道說,啊,其實我是比較好的那些data broker,那所以如果這個assumption是對的話,我們就會知道說那些不註冊的公司,其實出事的機會就比較高,所以你比較容易這樣看到說,有一些security breach啦,或者是information會被leak到其他的網站去喔。
1385200	1411900	那data collection,呃,data collection有點,有點複雜,原因是因為,呃,大部分的data broker其實都是private的,呃,我們根本不知道他們是誰,那我們的蒐集資料方法是,我們從vermont跟california state這兩個網站的註冊資料開始蒐集,所以他們有兩個很大的list,那我們後來發現其實這兩個list幾乎是大部分都是重疊的,都一模一樣,
1412400	1438400	那我們從這邊找到的是已經註冊的data broker,然後如果他有網站的話,我們就點進去,然後我們會找到說他有在告訴我們說他的公司到底在做什麼的,所以會有一些細節,我們是可以找得到的,好,那再來就是我們根據這兩,兩群很大群的,呃,registered list,我們每一家公司,我們到一個database叫mergent,
1438400	1468300	那mergent其實是,呃,有,有公開交易的公司在上面,或者是你是private的,很多公司也找得到,然後我們去上面收,蒐集他們的financial data,然後還有說他們的competitor是誰,所以我們可以看到說他們的competitor有哪些也是很大的一個list,那這些competitor不一定是data broker,這些competitor可能只是同一個industry裡面的人而已,所以我們之後還有一些data cleaning的動作去去identify這件事,
1469300	1490300	好,那這邊可以跟大家講說,我們從那個registry那邊找到的,其實有註冊只有270家,那可是我們從我們可以找到的competitor其實有2500家,然後最有趣的就是我標黃色這邊,註冊的這些公司裡面有將近一半的公司是連一個網站都沒有的,
1490300	1520240	所以說他有註冊,但是你想要去找他任何資料,他其實是什麼東西都沒有,他連網站都沒有,所以呃,還是一句話,就是我們根本不知道他們是誰,那更不用說我們沒有辦法發現說他們之間的關係是什麼,然後有37家,我們找不到任何的financial information,然後有68家,其實是他的名字,我們根本沒有辦法判斷說,呃,沒有辦法判斷,我們沒有辦法從其他的任何的呃,
1520260	1547940	資料來源去判斷說,這個講的這件事到底是不是這家公司,因為那個名字太常見了,所以根本就不知道他在講什麼,那所以最後我們其實可以用的sample其實只有49家而已,那registry那邊一樣喔,一模一樣的事情,最後可以用的sample其實只有1100家左右而已,所以我們發現說,呃,為什麼federal trade commission說這整個都是一個black box,就為什麼我們的title說叫invisible risk,
1547940	1577900	原因是因為就算已經register了,我們還是找不到他們任何的資訊,就是除了他們提供那很簡短的一兩句話之外,幾乎所有訊息都是,就是完全是不會不會對外揭露的喔,那我們怎麼知道他們到底有沒有在收集,有沒有在分享,有沒有在share呢,我們從他們每一家公司,我們剛收集到的about the company,還有他們的privacy statement裡面,我們可以知道說,呃,他的呃,
1578460	1605960	我們去找了一些特定的noun或subject,就是說我們有沒有在做什麼事情,或者experience有沒有在做什麼事情,這家公司有沒有在做什麼事情,那在做的事情是,呃,你有沒有在收集,你有沒有在賣,你有沒有在分享,或你有沒有在store這個information喔,那我們希望找到的就是,呃,分享什麼東西,比如說information,cookie,呃,你今天瀏覽網站的所有資訊,或者是我們有沒有在收集consumer behavior,
1605980	1630980	那這樣我們就知道說,呃,這些人他到底在做什麼,或者他講的東西到底是什麼,那這個是self-disclosed information,所以我們其實不知道說他們背後真正的action是什麼,就是說那張所有的information sharing之間的關係,或者是到底他們share了什麼information,collect了什麼,還是不知道,我們這邊只有self-disclosed information。
1630980	1651000	那根據這些self-disclosed information,我們可以看到其實大部分的這些data broker都是在做background check的,你給他一個information,呃,他就可以告訴你,比如說,呃,我們在找教職的時候,其實我們都有做background check,那就是其實就是找這些data broker去verify這些資訊的。
1651720	1669000	好,那我們找到了data broker是誰,我們找到了那些人之後,下一個東西是information leakage,或者是,呃,security breach要去哪裡找?呃,我們用的是,呃,dark web上面流流出來的資料。
1669000	1698020	那我們合作的對象其實是Rogers University,他們合作的對象是有一家公司叫做Dark Hour的,他們是專門幫美國的這些law enforcement agency在做monitoring的,比如說FBI啊,department of justice,呃,所以他們永遠都是在monitor這個dark web,那什麼是dark web呢?呃,我們平常在google上面可以找得到的所有東西,其實都是在surface web,就是最上面的這個iceberg,這個最上面的這一區。
1698760	1724780	那沒有辦法被google直接找到的,沒有index的這些東西呢,其實通通都是在這個下面,都叫deep web的部分,那deep web不是不好,deep web只是說,呃,我們可能要額外的authentication,你需要額外的link才能找得到,比如說,呃,我們很多學校都有intranet,intranet都是掛在deep web裡面,所以你用google直接去找intranet是找不到的。
1724780	1754760	所以你要有那個link,然後你要有學校的login的credential才進得去,那online banking的所有資料也是放在deep web,所以你google也是沒辦法進去的,那我們的medical的information也都是放在deep web,所以它相當於是另外一個,呃,像是一個hidden的place,那它其實是放在那邊,所以我們沒辦法直接從一般的search engine去去去去找到這部分的information,那這都算是deep web。
1754780	1755760	那dark web是,呃,它是故意去把這些東西藏起來的,那你需要access,你需要特別的website,呃,特別特別的web browser,比如說tor,呃,或者像你要特別的configuration,特定的ip,你才有辦法進得去喔,那它其實不見得是不好的事情,比如說在很多國家,它的所有的言論是有管制的,那你如果要講那樣政府的壞話的話,比如說,或者是你記者會的話,那你如果要講那樣政府的壞話的話,比如說,或者是你記者會的話,那你如果要講那樣政府的壞話的話,比如說,或者是你記者會的話,那你如果要講那樣政府的壞話的話,比如說,或者是你記者會的話,那你如果要講那樣政府的壞話的話,比如說,
1784780	1814780	或者是你要報導一些事情的話,你就必須要透過dark web,你才有辦法把一些事情的真相講出來喔,所以那個censorship的部分你就不會被控制到,那dark web為什麼會這麼紅的原因是因為過去幾年,呃,我們看到很多,比如說drug dealer啦,呃,賣武器的啦,賣軍火的啦,通通都是在那個上面,或者是hacker會在上面分享說,他們之前share,呃,hacker到的information,那所以他會有名是因為這些,
1814780	1830380	呃,額外的illegal的activity,所以讓他變得非常有名,所以大家都覺得說dark web其實裡面通通都是illegal的,他其實是,呃,都有,那其實就只是一個像是一個沒有辦法被你這麼直接access到的的地方喔,
1830880	1859180	那這家third party的monitoring company,他其實有所有dark web的資料喔,那比如說,如果我們跟他問說,我們要Aquifax的bridge,你就可以看到上面有個hacker的,呃,post的地方,然後他就可以有一個post就寫說,就是Aquifax的data bridge的資料,然後他上面就會有,呃,所有bridge的information啊,比如說什麼時候,這是哪一天發生的,然後你這個data set長什麼樣子,欄位有哪些喔,
1859780	1884780	那我們就從這邊,我們就可以找到兩件事情,第一件事情是,我們到底有多少個post是在講說Aquifax的這個information leak的,我們每個post進去找,我們就可以看到這個東西,那另外一個是,我們可以看到有多少的post是說,除了Aquifax之外,他還有其他公司的名字也都被列在上面,比如說我們這個例子是Aquifax Experian TransUnion,
1884780	1910180	好,那我們就知道有三家公司,那這個我們叫做co-leakage,就是不是只有我們自己在leak,其他的跟你同產業公司資訊其實也被洩漏了,那我們就這樣去找每一間,呃,每一間我們剛剛找到的data broker,我們去match說,他在dark web上面,我們可不可以找到相關的data bridge的資料,好,那有或沒有,
1910780	1935580	那其實我們analysis很簡單,然後我們能夠收集的資料也很有限,因為這是private,但其實我們還有額外資料,我們希望繼續收,那可以看到說有註冊跟沒註冊的公司,他們其實的,他們的characteristics差很多,大小差很多,呃,是不是公開交易的資料也差很多,他們有多少的competitor也差非常多,
1935580	1965140	所以,呃,這兩群其實就是完全不一樣的organization,簡單講,那我們的結果其實是說,呃,如果你有,你有越多的這種資料分享的這些過程的話,你就最容易更容易去看到說,你在dark web上面有information leakage,好,那這是一部分,那另外一個就是說,呃,有註冊公司相對相對於沒有註冊的公司,那些沒有註冊公司,呃,
1965140	1994900	出事的,或者是他們的資料會被發現在dark web上面機會就更多,好,所以這跟我們當初想的就是,但是願意去註冊公司,他其實是有一些self selection的,就是他真的是,呃,可能比如說security measure比較好,或者是比較transparent,所以他們才會願意做這件事,那這個是一部分的結果,我們其實還有一部分的結果是,我們一直還沒有另外share的,其實就share過一次而已,還有這些東西其實是在講說,
1995500	2020820	我們希望去看說,他的資料的收集是不是都跟別人不一樣,所以我們從剛剛那個他在講的他的disclosure是什麼,他的privacy statement是什麼,我們從那邊去判斷說,他今天到底收集了什麼類型的資料,然後我們就可以去把每一家data broker做分類,然後我們就可以知道說,比如說data broker A有80%的東西,其實都跟大家都是重疊的,
2021140	2045540	那如果大家都重疊的話,其實就算information有leak的話,其實我們知道說,他leak出去的東西就是大家都有的,所以不管你是買得到的,還是從dark web找到的,其實都沒差,因為反正大家都有,那我們比較在意的是說,如果他還有收集一部分是別人都沒有的,別人都沒有的那一部分,如果也有leakage的話,那影響就會更大,
2045540	2075500	所以我們希望看說,那是不是有unique data set這群人是不是更容易有information leakage,那第一部分是跟剛剛一樣,如果你是沒有註冊的話,你是比較容易有這些security breach的,或者是你比較容易你的information可以在dark web上面被找到的,那另外一個就是說,如果你的data uniqueness的話,這個其實是我們最擔心,就是你是unique,但是你其實你的bridge的資料,其實還是很多被洩漏在外面,
2076540	2104540	也就是說,如果我有辦法從dark web上找到這些unique data set,然後我另外再去找其他data broker去買到所有人都有的話,其實我就可以拼出來一個很完整的profile,那這個profile其實就是unique,就是其實大家都沒有的,那這樣子的情況下,其實對於大家的privacy的影響就是更嚴重的,那時間差不多,
2104540	2134300	那我們的conclusion其實是說,呃,這個research其實很rough,那其實是這是一個ongoing的project,其實我們一直希望繼續往下做,那我們今天present的重點,其實是我們想要提高大家對於data broker這個awareness,或者是希望鼓勵大家說,如果大家有興趣的話,可以join這種project,所以我們可以想想說,到底要怎麼樣才有辦法,呃,更準確或者是更有效的去知道說,
2134300	2153060	這些data broker的data collection跟sharing的practices到底是什麼,那這個才會對於,呃,我們現在一直在講的privacy protection才會更有幫助了,那另外還有一些東西就是,呃,我們希望其實能有一些privacy的regulation的implication,
2153060	2174820	所以如果有law school的朋友,或者是專門在做law related或regulation related,我們也希望知道說,呃,如果我們今天要提供建議的話,什麼樣的建議才是有效的,就可以讓這個regulation更更完善,或者是才是真的enforceable,讓可以讓他這個information的transparency的效果更好。
2175540	2185780	那這樣子大概是今天我的talk,那我們現在如果有任何的問題再麻煩大家發問,我現在可以stop sharing。
2187420	2190380	謝謝大家,有什麼問題嗎?
2191180	2198980	嗯,我只要想,我想,我想對這個,沒有說很了解,但是我覺得這是一個非常好的問題。
2199940	2210620	我只要想,我想,我想對這個,沒有說很了解,但是我覺得這是一個非常重要的一個議題。那我想知道說,以一個就是一般民眾要怎麼去保護自己的身體。
2210620	2218180	我只要想,我想,我想對這個,沒有說很了解,但是我覺得這是一個非常重要的議題。那我想知道說,以一個就是一般民眾要怎麼去保護自己的身體。
2218180	2244980	嗯,我只要想,我想對這個,沒有說很了解,但是我覺得這是一個非常重要的一個議題。那我想知道說,以一個就是一般民眾要怎麼去保護自己的資料,才譬如說,因為你你網站現在用都會有什麼cookie啊,然後你就要去accept或是reject,然後就有什麼事情是我們可以做可以保護,還是已經too late,我們的profile已經全部大家都知道。
2245660	2265020	我們發現其實大部分資料都已經在外面了。然後我們,我現在有在試的東西是,呃,網站的cookie就是,比如說我今天連到Wall Street Journal,我今天連到Amazon,它背後到底有哪些東西在在在收集我們的資料或者是activity,呃,我們發現其實。
2265860	2275820	我沒有辦法控制在一個upper bound跟lower bound中間,upper bound就是說,呃,我今天Google是在sign in的狀況下,所以Chrome知道說我是誰。
2275820	2305780	在那個狀況下的話,其實他們收集資料非常多,還蠻驚人的多的,但是如果我在完全沒有login的狀態下,我的browser又是開在private mode的話,那個可以限制到量就差很多,所以那個是另外一個辦法,就是你盡量關到都不行,那還有一些cookie其實是比較麻煩的是,呃,雖然他跟你講說你要不要接受,但其實不管你接受還是沒有接受,其實就是就是那樣子嘛。
2305820	2329100	對,他其實你看不到任何效果,那有些網站可以讓你願意讓你去選說,呃,不同的cookie,那個時候就是有,但是有一些其實是關不掉的,因為他一定要知道你是誰啊,你不然你沒辦法瀏覽的網站嗎?對,所以,呃,還是有一些限制啦,對,但是,呃,你就會知道說,其實他們已經收集到非常多資料,其實大概都知道我們是誰,我們在幹嘛?
2330060	2330960	嗯。
2332340	2359060	嗯,很可怕,對,那,呃,我有另外一篇跟一個computer science在做的之前,我們其實可以從,呃,使用者在social media上面的post,我們就把predict,呃,買衣服或者是買配件的preference,然後還有,那我們可以知道說,那你下一季喜歡穿什麼樣的衣服,顏色啊,brand啊,而且那個prediction,accuracy,
2359060	2371860	大概已經超過90%了,那,呃,那這個都麻煩的事情是說,我們只是自己做,只是我們自己收集的,我們資料就很小一部分,我們都可以做到這麼好,就可以知道說,他們要做其實是更更容易的。
2373300	2381540	那你會認為說,盡量不要post自己的一些,太多自己私人的事情,或者喜好之類的嗎?
2382260	2411500	一個我覺得我們還有一個問題,呃,我覺得是這樣子,這是有一個preference的,呃,我們如果不share這個information的話,我們不可能有那些customize的service,我們的search就會很糟,呃,幾乎都不是你要的,對,所以如果我們要特定服務的,你沒辦法,你一定要share,對不對,但是其實這是一個preference,所以我會再講說,他們之前像google講的那個才是比較正確,就是你的privacy到底是什麼樣的,
2412020	2423500	其實是你自己決定的,其實從零到一百,我到底要share到多少,就看你喜歡什麼樣子的東西,那其實不一定是壞事了,嗯,那我們有一個問題。
2423500	2453460	對,你是我,呃,我叫陳佩穎,我現在在伊利安納大學念information science,雖然我不做data privacy相關的議題,但因為這是現在很紅嘛,所以我就想說來聽一下演講,我覺得的確也收穫非常多,就特別是這種data broker的角色,好像在至少在我們的領域,這種投資資訊相關領域其實是比較少被提的,大家基本上都是針對單一個網站。
2453500	2470660	本身的這種,呃,資料隱私在做討論,那我的問題是說,既然這是data broker,嗯,就怎麼講,他們非常的critical,他們手上有這麼多資料,為什麼他們會這麼輕易的讓自己的資料給外洩出去呢?
2470660	2491940	就他們本身的這種privacy,他們的data security這件事情,而且因為他們一旦外洩了,就假設我是一個,我手上有那個data set,但是我被害了,這個資料就某種程度上他就是在大會上面是available,對啊,那他不是一個應該去防止這樣的事情發生嗎?
2492380	2512060	對,對,所以這個我們就覺得很,這是我們覺得最奇怪的事情了,而且你看有這麼多competitor,代表說其實這是一個非常profitable的business,所以才會有上千家公司其實在做這件事情,但他們的information又是大家都有的,但他還是有辦法繼續在賣。
2512780	2542040	所以為什麼我們希望能夠多知道說他們到底在幹嘛的,還有到底發生了什麼事情,可是問題是他們其實都是hidden player,就是連他們是誰都不知道,那或者是公司名字,像有的公司名字其實根本就是不make sense,像是亂取的,像是我們自己上課在亂講的,所以根本就也找不到他們到底是誰,所以如果有更多人可以跳進來想辦法知道說他們是誰,他們在做什麼,
2542040	2569420	的話,那應該會非常有幫助,security measure是我們會很想知道,因為那個影響會非常大嘛,因為就像比如說amazon或google,他們其實都是坐在一座data的山上面的,那如果我們能夠知道他們的security measure的話,會很有用,那像amazon其實他就他把他的socket report,就是就是他們information system security control的那些audit report全部都share在網站上了,
2569920	2575420	所以他們就很confident說我們很厲害,那但是這些人其實是完全是空白的。
2575420	2593420	嗯,那那比如說他們既然有去登記,然後雖然沒有url,他們會不會至少要提供一個就實體的地址,就是說我的公司地址是開在某個地方這樣子,有,他們有個實體的地址,像註冊地址跟電話都有。
2593420	2610420	嗯,那有什麼比較明確的地理分佈嗎?還是其實都沒有,我總覺得,呃,我們看不出任何特定的現象吧,因為他們收資料,其實根本也沒有限制特定的state或什麼的。
2610420	2639420	是,因為比如說,可是對,因為畢竟你可以傳到另外一個server上,因為我知道他們美國他們會有一些分佈,比如說,哎,我是一個需要,我記得好像是google的amazon,他們就會必須去找那種就是資源,各種自然資源非常豐沛的地方,我要有足夠的電力水力,我要確保他斷電啊,恆溫啊,巴拉巴拉巴拉巴拉的這樣子,可是這些事情事實上對這些公司也並不是一個。
2640420	2651420	嗯,就不是他們facebook上面必須要就是並不必然的相關,他們公司可能非常小吧,因為他們其重點根本都不是坐在辦公室的那些人。
2652420	2672420	嗯,對,那我們之前我之前在講這件事情,有人講說,我們有沒有辦法知道歐洲的data broker是誰,因為歐洲因為那個GDPR那個privacy law的關係,他管制應該會更嚴格,所以如果我們辦法找到他們的話,說不定他們的資料會更多,就比較容易知道他們在做什麼。
2673420	2687420	但是還是不曉得,就是我們那個data source要從哪裡去找,其實我們都還不知道。所以這才有趣的,我們覺得啦,這才真的像research在做的事情,都不知道。
2688420	2698420	那你覺得就是一個非常有趣的關係,因為就像你說的,就是學校聘人,他依然去找這些公司,就是拿你的background做background check。
2698420	2713420	所以我總覺得這裡面其實還隱藏著某種資訊不對的,就是你說學校資訊處,你要不要就找個人去direct上面找一找唄,可能也找得到,但是可能基於各種成本的考量,老子就跟這些公司買你的資料就好了。
2713420	2735420	所以這裡面是有一個,沒有到互利共生,但我覺得這中間事實上有一個共生的關係,就為什麼這些人,雖然我們覺得他們做著一些很secret的事情,可是事實上你們這些,就是你public,因為是學校這樣的機構,他還是仰賴,仰賴這些broker去提供一些資訊。
2736420	2763420	那像financial institution,我們去申請比如說mortgage什麼,他也是跟這些人去交換資訊,去確認我們的,我們給的東西是不是對的嗎?那只是這邊比較,這邊是compliance,這邊比較highly regulated,比如說有一個東西叫什麼fair credit act嗎?類似這種的,就是說我們可以去review我們的credit score,萬一有東西有錯我們可以叫他改啊什麼,那邊就有。
2763420	2778420	可是像其他的這種data broker,如果他資訊有錯的話,其實我們根本不知道他資訊哪裡有錯,或者是錯在哪裡,對不對?那如果人家用這個來verify我們是誰的話,萬一通通都是不一樣的,那問題就大了。
2778420	2801420	嗯,對,這是另外一個問題就是說,他們的有這麼多competitor,那他們自己,他們的niche,他們的selling point到底是什麼?我現在都還是只能想到就只是你利用某種資訊不對等,去賺取那種利益。因為假設我知道有個公司可以提供更,就是究竟所謂的more accurate這件事情,要怎麼被定義呢?
2802420	2818920	對,那或者是誰的influence model更好,然後或者是誰有,我在猜是他們應該有一些data broker,真的是有一些很特別的資料是別人都沒有,他們永遠不拿出來賣的。因為我覺得那才是competitive advantage嘛,就你有一些真的別人都沒有的。
2818920	2829920	了解,所以他們其實不是賣real data,他們不是說我就提供你一個這個人所有的分數,就是說我賣給你基於我們的模型所預測出來的這些customer的喜好。
2830920	2848920	兩種都有像,呃,如果是那種fraud detection的,那種就是我是賣data給你的,就比如說這個人的annual income大概是多少,他家住哪裡,那種就是一筆一筆在賣的。那如果是賣marketing的話,我就是賣influence model。
2848920	2859920	好吧,可能只能確定就是這些人,就是他們的員工可能都還蠻聰明的這樣子。
2860920	2878920	有可能全部都是自動化的啊,就跟youtube一樣,沒有,youtube其實所有的process都是自動的。那但還是一樣,就像FTC說的,他們到底在幹嘛,其實到現在還是沒有人知道。就算大家一直講說啊,他們怎樣怎樣,但是都都沒有任何的訊息。
2879920	2884920	太神秘了,好像有個法律專家可以解答。
2884920	2888920	就他們在法律上面沒有任何的規範嗎?
2889920	2903920	我跟我有一個學生是illinois的state的senator,我跟他講說,你下一個下一個assembly的時候,你提一下這個regulation,我們管制一下data broker,然後他說好,他就想一下到底要怎麼弄。
2903920	2920920	因為之前我跟他講,你知道illinois有一個AI的interview act,就是如果你是用machine去讀job applicants的interview video的話,你要disclose啊什麼的,這個東西也全部是從我們的課上講出來的。
2920920	2941920	因為他在上我的課,然後我跟他講,他就去提,然後就這樣過了。所以他常常會問我說,有沒有什麼有趣的topic是我覺得應該要他們要重視的,我跟他們提data broker。那就看怎麼處理而已,因為這都不好,所以都有一些controversial的issue在的。
2941920	2945920	好,感謝感謝謝謝。
2972920	2994920	剛剛你們提到,想快速分享一下就是那個資訊錯誤的問題,因為之前在申請那個房貸,然後那個資訊其實是有的資訊是錯誤的,就是已經就是不對的,對到不同的人,然後因此而你的credit score就是比較低,然後就不能申請房貸,所以那問題就就蠻麻煩的。
2994920	2997920	那問題就很大嘛,對。
2997920	3000920	但你不能,你不知道跟誰去講說這個。
3000920	3010920	對,在在美國的,呃,如果是credit score下面,你看得到那些public,他們抓的那些information,如果有錯,你都可以叫他們更正。
3010920	3022920	可是,呃,那你要,你有看到說有錯才行,不然還是很麻煩。那如果他們找data broker,你就不知道他看到的是什麼。
3023920	3034920	也許唯一的辦法,知道說data broker怎麼運作,是自己成為data broker。嗯,我還有時間可以問個問題嗎?可以。
3034920	3046920	嗯,我想問一下就是那個background check的問題啊,就是在美國你要找很多工作,其實他們都會經過一個background check,我只是很好奇說他們這種background check到底去收到什麼樣的資料?
3046920	3062920	那像就是我們之前我現在是來這裡找工作發現,哎,都找不到資料,因為他之前在臺灣住太久了,那可是怎麼會有可能會收不到資料?如果這種東西都一直存在的話,怎麼會有可能收不到資料?
3062920	3084920	呃,剛搬進來的是在這邊記錄是空白的,你是收不到,因為他他應該是沒有跨國在收那個資料的。可是他是美國公民,他是他是美國公民,他是空白的。對,所以我們就覺得很好奇,怎麼會有這種事情發生?他就說他找不到background check,找不到任何資料。
3085920	3107920	這也太奇怪了,呃,我們學校最常做的是,呃,那個什麼criminal record,不管多輕多重的全部都要查,嗯,很多學校都是這樣子。他會有連線的憲政,我說那種data broker,他們會說有多少年之後就會把之前的資料都清除掉嗎?會有這種情形嗎?
3108920	3125920	更是一個好問題,他們到底怎麼去處理這個?像剛剛那一家Axiom,他說他有超過45年的所有name change跟residential information對不對?那之後到底有沒有,不知道。他們要存多久,就是這些資料他們會儲存多久,很好奇。
3125920	3136920	對我來講,越久越有用啊,所以。因為大概再過個,比如說再過50年,那可能就是你唯一,你是唯一一個有這個資料的人。
3137920	3156920	所以代表那一家公司他在做background check,他可能那一家公司收的資料不夠好,有可能是這樣嗎?也有可能,因為像,呃,照他們那個FTC的資料,他們講說,其實data broker應該有幾乎所有美國所有人的資料。
3157920	3167920	謝謝你。對,我只是覺得這也是另外一個因素,到底是誰有誰沒有啊?為什麼會有人沒有?
3167920	3189920	嗯,那還有什麼,還有問題嗎?不然我們今天的演講就到此結束。那我先謝謝David給我們這麼精彩的演講,我覺得他都學到很多,然後有替有更多的awareness這樣子。
3189920	3204920	然後,那希望希望在下次可以再來演講,然後告訴我們說,你接下來這個project的後後來的發展怎麼樣?好,看看一年後有沒有進度,然後感謝大家感謝。
3204920	3225920	謝謝,然後再來就是我有,如果大家還沒有成為會員的話,我想要post一個link,就是你可以在這邊,就是加入他,就是就是一個free的那個的一個會員membership這樣子。你可以持續接收到我們每個就大概每個禮拜都會有一個演講,然後不同在不同主題上這樣子。
3225920	3237920	那謝謝大家,謝謝David,謝謝大家,謝謝你,拜拜,拜拜,拜拜。
