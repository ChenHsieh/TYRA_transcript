好,那很欢迎大家来到今天的Taiwan Talk,今天是1月8号,我们今天很高兴呢,到张翰,他目前呢是在台湾大学服务,他的PhD是在美国University of Massachusetts Amherst,然后PhD后来呢他在Boston进了一家生技产业,
然后后来呢又到了Boston University,就是BU的医学院,就是School of Medicine,做博士后研究,然后在2021年的时候呢他回到台湾大学,在医材影像所担任助理教授,今天呢我们很高兴有他来演讲。
那Taiwan的小小的传统就是呢,我们会请大家把麦克风打开,然后拍手,欢迎我们的讲者,那现在欢迎我们的讲者张翰老师。
好的,那可以share screen了。
有看到吗?
有看到吗?
可以看到了。
好,那也谢谢您介绍。大家好,我是张翰。
我刚刚所说,我是2016年博士班毕业的,然后之后是辗转几个单位,就是有一些新创公司要去博士后,然后我是去年2021年的时候回到台大做助理教授。
我记得Tara一开始申请,我记得表格说什么会员有每年一次报告研究之义务,然后我这件事情一直记在心里。
我回台湾之后基本上就很少上线,因为都起不来,所以想说还是要贡献一下。
今天也没全省,不过就是来跟大家聊聊。主要目的还是跟大家分享一下,另外也是如果大家对回台湾的环境有什么问题的话,我们等一下可以再讨论一下。
我自己实验室是做号称AI影像的分析,我本来做博士后的时候是做肌肉骨骼影像,主要治疗标的是退化性关节炎,另一方面就是回台湾之后又找一些其他的合作项目,包括脑科学跟线外影像等等。
等一下我有时间的话会稍微讲一下。AI这件事情可能是大家听演讲,每两周就会听到一次,所以介绍性的话我就很快带过去了。
大家知道AI在过去的五年、十年大概发展很快,很多影像辨识、分类、政策等等的表现超过人的标准,大概是最近几年发生的事情。
如果你看脑科学的话,比较旧的Letter,他们都会说图像辨识、人脑、电脑这些超过,可是假设你们再看一下Letter,可能五年内的话他们就会改口。
所以这个改变是最近几年的事情,可能大家都在自己的领域会感受到了。
在艺术影像上,影像上的modality是一个非常非常缓慢的过程。大家可能听过Hobart有一个Gordon Center,Gordon Center是影像中心合作PathGen的发明人,就是Gordon跟Charles。
他们做的是PathGen的前身,基本上原理其实是差不多的。他们的影像解析度的lower boundary是跟现在是一样的。
所以在艺术影像上的modality是一个非常非常慢的过程,通常都是几十年。通常都是几十年的adaptation要implement,然后被定创大规模使用。
所以有时候这一个领域或者AI有兴趣,不是因为,是不得不然,是因为发展太慢了。所以看到新的工具就赶快想利用看看,看到什么改变机会。
基本上Machine Learning或Deep Learning这些东西,它的功能就是找一个function,好比说我们可以做一个function去看图像,可以做分类。假设自然影像的话,分类就是分车子,分猫狗之类的。
马上就有人想说,我可不可以做诊断,所以分类在艺术影像的对应就是诊断嘛,好比说一把子hammer,就是calculation。像detection,大家做生物实验的话就发现鼠细胞这件事情是非常古老的labor。
那detection的话,假设自驾车的话,就是数行人,数别车等等。基本上一样的idea就是做一个function,然后放进slide,就会数细胞等等,这是侦测。
最后就是切割,切割就是在艺术影像上面也是使用关节的各部分,或者把器官切割出来。基本上就是你有想做的function,你有一个input,你有一个output。Machine Learning就是用自我最佳化的方式去把这个function找出来。
我自己做的题目是ulcerocytes,就是退化性关节炎。这是很老的疾病,就是老人的疾病。大家可能听到第一波的AMS,可能听到比较有名的,好比说糖尿病DMD影像,好比说oncology,就是癌症的肿瘤分割政策,还有cardiovascular。
这些当然就是因为这些疾病在美国是大课,假设我们数致死率的话,最前面是oncology和cardiovascular,就是因为需求而产生的这些情绪。我自己做ulcerocytes,它是退化性关节炎,它没有什么直接致死的passway。
如果你看美国第一名造成失能,disability的话,第一名就是ulcerocytes,就是一切关节炎。那里面大概三分之二是ulcerocytes,其他是免疫性关节炎。
第二名通常是背痛,我们国外很常会背痛,所以背痛也大大造成是很常见的。所以基本上这些肌肉骨骼病病人在造成disability在美国是非常非常常见的。
如果我们看开刀又花钱的话,通常数一数二的就是第一个是spine infusion,就是治疗脊椎,第二个就是replacement。
所以基本上这些肌肉骨骼的疾病,它如果不开刀的话就造成很多的失能。假设它开刀的话就会有很大的花费。
我们大家知道台湾是老化社会,这是第一个特性。第二个是台湾什么事情美国发生,台湾五年后就会发生。
这些事情对社会成本和社会健保的负担是会一增加一增加的增加。数数字就知道了,不需要看什么forecast,数数字就会负不起。
比方台湾的话,像这个new placement在美国也算是蛮贵的手术,成功率很高。台湾也算是一个一定要付但是非常昂贵的手术。
所以怎么用一些方式可以让病人不需要进入到社会分解的pathway其实是蛮重要的。
基本上,如果我们想说什么样的原因会造成病人需要换吸管,基本上就是疼痛难当,就是疼痛无法忍受就会换吸管。
大部分人都会忍受自己失能,就好比说这个关节炎有好几个symptom,可能一开始会活动能力受限,要conquer stiffness,最后可能会疼痛。
那其实stiffness或是活动能力受限很多人可以忍受,大家在美国大家知道吧,可能坐这个代步车就可以走一走去了。
那疼痛是无法忍受的。所以病人为什么最后会做开刀的决定,通常都是有一个pain spike,就是在要开刀之前,如果我们回顾他每年的function是怎么发生的话,都会有一年或两年前是突然疼痛增加了。
疼痛一增加,然后无法忍受,就跑去开刀了。如果疼痛是慢慢增加的话,大家知道耐痛是可以慢慢习惯的,反而还可以撑比较久。如果有一个pain spike的话,通常就跑去开刀了。
那会造成什么原因造成疼痛增加呢?如果我们直接画那个coalition是一个OA的定程,它叫KO grid,是一个OA的rheographic,就是X光上面的平分的话,那基本上跟疼痛是没有什么关系的。
很多人,好比说大家听到的那个NBA球员,有人没有软骨,然后还是可以打球,然后有人是膝盖正常,但很疼痛,所以基本上传统上的rheographic的关节点的平分跟疼痛没有关系。
所以先假设我们要研究这个OA是什么造成疼痛的话,传统上我们就是找到那边的人,可能像美国的话就OA付钱做trial,然后把这些MRI都拍下来,然后接下来要找医生去做grading,大家都很熟悉嘛。
基本上OA这些影像判读是需要有经验的医生,专门要看膝盖和关节炎的,所以成本很贵。
主持人员:"不好意思,不好意思,我小孩在重庆诶,不好意思。我请他妈来救援一下。
所以基本上你得到的资料都是非常少,也不一定一致,因为这些grading工作很慢,所以大部分都是很多routing center协作完成的,所以每个人的标准不太一样。
所以有时候统计分析的话,基本上过去效果都很差。所以这时候我们就讲到,有时候是需求决定了为什么要导入这些新的技术,是不得不然的。
所以我们既然用传统方式的grading很困难,又很花时间,那我们就导入AI,直接就最后一步,我们就完全放弃了这些所谓的影像特征的grading,
我们直接把你看到这些OA病变的MRI输到先进网络里面去,然后我们用的outcome就是我们想要看的地方。
好比说以这个project而言的话,它的outcome就是疼痛,病人有多少疼痛,再加上疼痛有没有突然增加。
所以这就是一个不再无法得知,或者本来就对什么样的病变造成疼痛不太清楚的状况下,使用这个方式。
好处大家知道吗,就是它很一致,它是同一个模型去看一些东西,所以特别适合这种clinical trial,就假设你有一个很一致的cohort,全部资料都是用同样的方式拍的话,
它标准的非常一致,它是自动的,所以只有你训练成功,它就没有成本。
那这个处理这个图像的基本上deep learning的网络就是convolutional neural network,大家很常听过,就是全机神经网络。
那它原理大概述下来,就是用一层一层的filter,大家做影像处理可能用filter,filter就是抓不同的特征,影像特征这样子。
那因为我不知道什么样的特征是比较重要的,我就让它自己optimize,自我更新。
那它就会照着这些方式层层更新,然后把这些影像处理成一些对结果的特征这样子。
那通常这个trivial neural network有一个重大的缺点,就是它很难控制confounder。
我们知道在医学上面,所有的事情都是影像加上confounder。
比如说这个人会不会,可能会恶化,是他的影像加上体重,加上他的生活情况,加上这些人有没有受伤等等。
所以我们做这个影像分析的时候,如果你把病人全部资料都丢进去,那虽然你想看到的是病人本身的影像,你想在影像上找到重要的特征。
可是只要neural network有任何读到confounder的方式的话,它就会随着pathway过去。
所以假设你的膝盖比较大,显然是体重比较重。
那neural network看膝盖比较大的事情,如果它可以跟outcome有关联的话,它就看膝盖比较大,它就忽略其他一些因素。
所以基本上deep learning的模型对confounder有很大的bias。
其中一个最简单的方式就是对冲。
你可以找两个有一样confounder的subject,然后让它互相抵消掉。
比如说我可以选一批评论者,他可能是疼痛增加前或增加后。
他同一个subject,所以他有类似的confounder。
所以如果我把一个网络同时参考两个incidence的话,他们confounder就互相消掉了。
另一个可能就是所谓的cross lateral,左右膝盖。
有些人在刚恶化的时候,一个膝盖会先恶化。
那通常久了之后另一个膝盖也会带长,也会追上来。
可是是有一些incidence,你是可以抓在一瞬间就这些不平等的现象,那这时候你可以把左右膝盖当对照。
这还有好处就是说,其实疼痛是主观因素。
我们疼痛,大家可能去看过牙医,然后常常会填笑脸图。
就是绿色的笑脸是0,然后黄色的是0。
然后医生问你有多痛,然后你讲不出来。
然后他问你说,如果是0到10,你有多痛,那你也讲不出来。
这很奇怪,但是基本上这是一个主观回报的事情。
但是如果同一个病人,他回报两边膝盖的话,他两边都是主观的嘛,他对疼痛的耐受程度是一样的。
然后另一个可能是,假如他疼痛并不来自膝盖,就有蛮多病人,他们的症状是来自我们说的neurosystem,那这也是confounder。
可是如果他同时回报说两个膝盖中有差异的话,那他回报就是疼痛的差异而不是疼痛。
这件事也是一个控制主观因素的方法。
所以我本来就有工作是拿这些疼痛跟不痛的膝盖,拿来做这些所谓的contracted learning,就是对照性的学习。
然后想要把症状有差异的一边预测出来,显然结果就是比用医生传统判断方式好很多。
大概多10%的AUC,AUC就是一个二分类的评分架构,通常本来就是60-70,用的方法可以做到85-90,所以其实本质就有差别。
那另一个事情是说,Fockin常听到所谓的可解释性AI,是一个buzzword,所以SAI,Explainable AI,这是一个buzzword,其实你自己看定义什么的话其实很难讲。
我们所谓Explainable就是对使用者是Explainable,就是那个使用人觉得是合理的,他就是可解释。
所以基本上使用人想要什么,他就是什么。
那传统上我们在医学影像上我们认为我们的使用者其实是医生嘛,所以表示我们模型要做出一件决定,那这个决定想要把它传达让医生觉得说它是合理的。
那现在大部分的differentiate方式都是用saliency map,热区图,有很多争议,一般人认为热区图上面的热区,指向的地方没有太夸张的话,就表示它可能没有错太离谱,它可解释力没有错太离谱。
那基本上这是一个很弱的条件啦,就是如果它热区图很离谱的话就可以排除,但是它如果对的话,也不一定是因为正确原因做正确的事情,它可能就是重叠在那边。
基本上这些saliency map只有未知资讯而已。
我们今天做的一些工作是想法改进这些热区图的解析度,可以让这些图可以把个别的病变分出来。
这时候再回头问医生说,我们指出这些病变的位置有没有跟你图片中想的疼痛的位置是有可能的,可以用这个方法来探讨说是什么样的病变最有可能造成疼痛,然后跟医生的想法有没有合理这样子。
不过这种方式有它的很大的限制,第一个它逻辑对不对大家都还在讨论,这种热区图方式能不能解释它是可解释的,大家都还在讨论。
第二个,你这个也很难拿来定量,大家如果看热区图的话,它毕竟是interpreter来的,所以它形状其实没什么意义,它就是这些点做一个interpreter,然后就变成区域。
可是你仔细看这些形状跟region形状有没有直接对应,其实是有问题的,所以你直接把这些高亮度的地方划成counter来统计,其实是无法定量的。
假如不要夸张一点的话,假如看到一些脑肿瘤的热区图,那可能肿瘤在脑的边边,那热区就会一半在脑内一半在脑外在背景上面,所以它定位能力其实是很有问题的,有它的限制。
有什么比较直观的方式可以做这些feature的运造工作呢?
我大概想一下,如果有看医学影像的话,我们常做的事情就是比较。好比说一病人做疾病在追踪,医生可能看了他的新的影像,他恶化的话,那就是拿前一张影像来比较。
假设他是做治疗的话,可能是本身的一张影像变好了,然后他也会拿旧的影像做比较。所以比较影像这件事情是人脑会自动拟合出来,这是人脑很神奇的功能。
那其实我们今天对单张影像可以分析得很好,但是影像比较这件事情,其实人脑是有它独特的mechanism,然后我们电脑都还没有办法完全追上。
今天假设说好,我今天有一个病人,他会有一个症状突然发生,所以一开始症状是进展比较慢,突然就恶化了。
如果你是医生的话,你合理的做法是说,我看一下pain spike前后发生什么事情,所以就会把两张影像调出来。
然后医生放左边跟放右边,脑中就自动拟合出两边的差异在哪里。那我们要怎么教电脑做这件事情?
传统上的话,像我们刚刚做的所谓的判别式模型,是想法把左边跟右边这两个有疼痛跟没疼痛的影像区分出来。
比较合理的方式是做这种比较式模型。
大家可能还记得,也差14年了。
所以我们看了这两个pair,就马上可以想说哪边是正常,哪边是不正常的老化。
就显然左边是不正常老化,这不正常,这正常。
所以人脑有神奇的功能,就是它可以看到影像的改变。
然后我们脑中第一件事情,我们有两个pre-test。
第一个是我们知道它同一个subject,这很重要,因为假设你不跟人说这个跟这个同一个subject的话,
没人会拿来一起比较,他以为是两个不同的人。
所以你刚刚说的是同一个subject。
第二个事情是,你脑中对正常老化有一个概念,你知道说14年人大概会变成什么样子。
那我们也可以用同样的方式去观察说,改变前跟改变后的医学影像。
到底什么样的变化是正常变化,什么样的变化不是正常变化。
这变化可以有很多种,你可以是ten-tone的progression。
假设我们用一个统计模型来看说这个人未来开刀几率基于影像的话,
那我们也可以问说,假设同一个病人他的toA跟toB突然他的开刀几率变很高了,
那是什么样的事情造成他这样的差异。
所以是一个比较差异的framework。
所以就是,这件事情会成功,就是他从subject,脑中有一个所谓的正常的reference。
那我们在做这件事情的时候,脑中是有正常的reference,所以你没有感受到,
但人脑是很神奇的,会自动在背后处理。
那我们今天要把这个用deep learning来拟合这件事情的话,
那最直接的方式就是所谓的商场对抗网络。
那大家可能也听过,商场对抗网络就是好比说,
很多合成脸、合成video、合成声音等等的模型都是根据这些技术,是同一个family。
它逻辑就是说,我今天有一个叫生成器,
它生成器是可以拿图片当成它的condition,
那生成器图片进去之后,它就会出来一张以input图片当成条件的图片,
那它跟它之间有点对应的关系。
那它生成条件是什么?
它生成条件就是,你拿这个真的reference图片,
然后它会拿这个当参考,
所以整个结论是说,你的生成器会拿一部图片,
生成一张跟reference图片很像的真的图片。
所以我们的做法可以说,我们可以把要比较的对比的reference,
就是real healthy,
好比说,左右膝盖的话,你就是不要不痛的膝盖当成reference,
不要痛的膝盖当成real disease,
然后我们去合成出一个假的healthy。
那这个差值就是比较差异嘛,
虚拟同样的造型,它如果不痛的话会长什么样子?
那在定义上我们叫counterfactual,
就是假设性的一个case,
这两个差异就会是我们想要看到的改变部分。
另一部分就是所谓的healthy reference,
就是我们脑中比较知道什么样的膝盖变化是正常的。
那大概讲说我们要比较的这些reference应该不是18岁健康的膝盖,
我们的OA是不可,是老化的疾病。
所谓老化的疾病就是说,所有人都很老,
所以有些影像上面的改变是正常的,我们需要接受,
好比说我们看做那个Azheimer影像的话,
这个老人的Azheimer影像都会有脑缩,
可是脑缩是老人就会缩啊,
并不是Azheimer他会缩。
所以像Azheimer这个研究的话,
很大一部分的目的就是要想要把这些正常老化跟不正常老化,
所谓的Azheimer倒转老化来区分出来。
那所以我们OA也是一样,
我们并不是要把这些膝盖还原到18岁的完美状况,
我们也没有这些影像,因为18岁不会去拍MRI。
那我们要,我们的reference应该是正常老化,
它是50,60,70,就该那样子,老就是会老,
但是它要是function或是什么东西还正常的。
所以像我们的话,我们就选说假设这些病人都是0致命OA,
或是preclinical,就是还没有进入临床上的OA,
然后也不会开刀,
所以这些人我们就定义成他是所谓的健康老化嘛。
那我们要,那我们的reference就是定义到把图拉到这些健康老化的状况上面,
而不是一个真空中完全健康完美的膝盖这样子。
所以这个好比说治疗前治疗后,
然后好比说这个pain spike,control incidence,
然后好比说不同的modality,
这种比较性概念是一个很强的framework,
因为我觉得这个在医学影像上,
很多时候我们是凭借这个比较这些事情来处理资讯的,
那基本上如果你去看诊的时候,
要看医生做什么,
其实很常这样发生的,
就是左边一张右边一张,
然后用比较来决定死因发生,
所以这是一个很泛用的framework,
并不只是在这个我目前做的topic上面。
所以我们先拿一个正常的disease,
然后产生说fit healthy,
然后产生real healthy,
那我们用一个回归器的方式,
我们可以训练一个回归器,
它就跟一般做回归一样,
用图像做回归,
那它目的就是要观察这些健康老化的器材,
然后要观察说它的年龄长什么样子,
因为这些也是健康老化的,
所以它的预测出来的年龄就会是它本身的年龄。
那做完之后如果拿这些同样的模型,
去观察一些不健康老化的病人的话,
就发现他的实际年龄会小于他膝盖的appearance age。
那这个concept其实大家可能听过脑灵嘛,
这个在其他分析中也常用到,
或者说大家可能听过脑灵检测等等,
就是有些人的脑看起来就是比他实际年龄老,
这个脑灵检测,
那其实也可以用同样的逻辑来做嘛,
就是拿一个不同年龄的模型去看健康老化的老人,
然后再回来看一些不同的病人。
那有关脑灵这部分的话,
台湾也有人做,
国外也有人做,
那还发现说不同的neurological disorders,
还有不同的,
就是他的年龄会有不同的shift,
他的shift pattern还不一样。
那又好比说大家看医生的时候,
如果大家去见检的话,
常常被问说,
你看起来不像年轻人,
这件事情也是一样的嘛,
就是你的appearance跟你的实际不如预期,
不如预期这件事情本身就是一个spell marker,
所以病人会跟你说,
你看起来不太好,
但是你跟五十岁比起来还不错啦,
就不会这样子嘛,
比起来是跟你的健康年龄该怎么样,
如果差异的话就表示有问题嘛,
所以这个比较脑灵,
比较年龄这些事情是很有意义的。
所以我们今天就拿这个,
把这个healthy reference这些事情来结合起来,
所以我们怎么做,
我们有真的disease,
然后我们产生一个fake healthy,
然后我们这个fake healthy还有一个condition,
就是fake healthy经过健康年龄的regression年龄的话,
要是本来的年龄,
所以我们不会生成出一个很假膝盖的样子,
我们生成出一个他该怎么年龄就怎么年龄的膝盖,
对,
就是一个拟合出他这个年龄上该有的状况的样子,
所以他生出来的模型都不会是完美的,
如果本来有大脊椎的话,
那可能就是小脊椎,
本来假设软骨有全掉的话,
可能就变掉三层,
都不会是完美的膝盖,
可是这个差异就是我们认为是造成有疾病的medication的原因。
所以基本上,
这个GAN技术目前非常有用,
当然看到一些生成VDR等等,
已经可以很愉快的控制它们,
所以目前假设我们有一些MRM想要找各种条件,
比如说把疼痛疾病移除掉,
都可以很愉快的做到,
它就会有类似的anachronism形状,
所以同个subject,
但是疾病的一些feature就消失掉了。
我们对这种GAN生成影像的最大的抗拒就是,
它是假的吗?
这些影像并不真的存在吗?
到底要怎么知道这些影像是可信还是不可信呢?
在医学上很困难,
因为这些都是假设性的,
不能重拍,
所以很难说到底是真的还是假的。
好比说我今天要预测一个tumor会不会有progression,
这很难知道,
因为它可能有progression,
可能没有progression,
如果它有progression,
它预测的方式可以有很多种,
它可以往某地方转移,
或者它的扩散有什么样的扩散,
所以progression这件事情很难讲,
因为未来是有很多种。
但是从病变变回健康这件事情,
其实有一个逻辑在那边,
它逻辑就是说,
健康的状态应该是都很类似的,
不健康的状态应该都是很不类似的,
大家有听过这个,
安娜·卡赖里娜,
她的第一句就是说,
happy families are all alike,
就是所有高薪的家庭都是一样的,
都类似的,
everyone's happy family is happy in its own way,
那这个在科学上有很多,
这是principle在科学上有很多应用,
主要想法就是说,
一个健康的状况应该是都很类似的,
所有的条件都很好的健康状况,
开始病变之后,
它就会往各处发散,
就会变得很不一样,
所以你要从健康预测不健康是比较困难的,
这样不健康反推回来是比较容易的,
因为健康状况应该是类似的,
其他我不敢讲,
但在膝盖影像上面,
健康的膝盖骨头,
软骨,
半夜半,
这都是有天生的形状,
所以健康状况是,
其实我们知道应该长什么样子,
所以假如你要画成群剧图的话,
你有一坨白色的健康状况,
都应该蛮类似的,
然后它的病变开始之后就慢慢发散,
所以你要从健康推到不健康,
其实蛮困难的,
因为你很难验证说,
你推断对不对,
但你从不健康的图片反推回来的话,
是比较容易的,
然后你有很多工具可以验证,
比如说你可以验证软骨的,
或是半夜半的形状等等,
有没有正常。
那最后一点是说,
我们刚讲比较性是拿,
有疼痛跟没有疼痛比较嘛,
那有疼痛跟没有疼痛是一个binary,
是我们自己把它变成binary嘛,
但其中其实没有可能嘛,
因为很多事情变成binary,
是我们人为的因素嘛,
好比说我今天病人照那个0到10的疼痛表,
来回报疼痛,
那他可能说左边是3,右边是7,
然后下来病人说左边是1,右边是5,
那差值都是4,
然后我做研究,
所以我要强迫变binary,
我说这是4,所以是一样的,
其实是不一样的嘛,
那或是说差是1到8,
或是1到6,
那差值是一大一小,
可是我做binary,
我binaryize,
那我会觉得是一样的,
可是这些一样,
其实是人为的解释嘛,
大家想要知道就是,
这些人为把一些事情做二本法,
其实是一个很常用的工具,
但是并不代表说二本法的边界有任何特别的地方,
这举个例子好了,
假如说有常人来台湾的话,
很常听说8是量表嘛,
8量表就是一个二本法嘛,
就是我觉得量表的左边就是不需要看护,
右边是需要看护,
那这个线的左边右边有什么magical thing happen,
它变不一样嘛,
其实没有,
所以二本法其实是很confusing,
我们在医学上知道它有很多人为设出来的边界,
或是人为设出来的binary,
这举个例子好了,
但其实是没有意义的,
所以很大的困难就是怎么把这些binary的资讯,
再让还原回去交给你的模型,
以这个project为例的话,
我们就是,
我们至少让模型知道说,
healthy跟painful,
跟healthy跟very unpainful要分开了,
所以假如说0到3的话,
差异很少,
我们让模型知道说这差异很小,
假如0到9的话,
差异很多,
我让它知道说差异很多,
幸好这些用模型可以解决,
我们是可以把这些差异,
encode之后放进去这个模型的生成的部分里面去,
所以它就照你想要给它的距离,
相比的差异,
所以就是数值差比较少会差比较少,
差比较多会差比较多,
那当然这个传统差异只是小部分,
所以这个比较类似像是一个demo一样,
证明说我们可以control这些事情,
当然是有更多更多的因素在里面,
所以可以想办法加进去,
所以基本上训练成功之后,
你就会得到一个连续的膝盖分布,
连续膝盖分布最左边就会是你本来的膝盖,
最右边就会是你疼痛的高低的膝盖,
那根据它们两个疼痛的scoring的差异,
它就会拉近会拉远,
所以并不是说左边是不疼痛膝盖,
右边是疼痛膝盖,中间都是垃圾,
它是一个连续的空间,
连续的空间它的分布其实是你可以控制的,
那我们之前有做过一些自动切割,
自动切割在一平衡上算是一个比较好解决的工作,
基本上结论就是说你只要有研究生,
只要有处理他就把你用手标完,
然后就解决掉,
所以其实基本上一平衡上自动切割算是单一,
比较困难是在单一data set,
多data set你会有差异,
但如果是在同一data set,
然后有标记的话,
你有光处的话,
就是我们这种所谓叫做有切割的光处,
就是切割的标记嘛,
那这种叫做监督式学习,
如果是survival的话,
基本上还蛮好解决的,
所以已经不是新的东西了,
那我们做deep learning的话,
有一个功能就是帮助这些,
本来就可以做的事情,
把自动化,
就好比说这些膝盖骨头切割,
那其实其实不是很难嘛,
因为医生都可以切,
然后也有些postdoc,
或者有些研究生都会切,
但是本来手法是非常非常非常慢,
那在近期的话,
可能用一些统计的statistical shape model,
去拟合出这些膝盖形状,
总之要花时间嘛,
但deep learning有一个很好的好处,
就是它可以自动化,
所以刚刚说过,
只要是survival能力做切割,
其实不是很难,
所以我们之前做的模型,
就是把这些手动标记,
转成一个自动切割化模型,
那一下子你会分析很多,
很多不同的资料,
那它科学上有新的东西吗?
其实没有,
它只是自动化而已,
但是生物学上的很多丢零,
就是最大的困难嘛,
所以它并不是新的功能,
但是只是把同样的事情,
给别人做一倍,
然后我会做一百倍,
那就很有价值。
那今天在我们这个case上面来说的话,
我没想要做自动切割,
为什么呢?
有一种特别的region是,
我们特别想要看的,
所谓的Bone Marrow Region,
它就是在骨髓内的,
在骨头区里面的所有的,
所有的hyperintensity,
都是被认为是Bone Marrow Region,
那它问题是这样子,
我们这个医学影像,
好多MRI好了,
每个MRI是拍的功能不太一样,
好比说像这个左边是High Definition,
就是它的骨头跟人肉之间的contrast很明显,
右边是看发炎的,
就是这个Weighted T2 Sequence,
所以它看到发炎,
可是它的骨头跟人肉之间的边界不是很明显,
那你可能想说,
我就把左边做自动切割,
然后搬到右边来就好了嘛,
可问题是即使是同一位病人,
它拍的时候也不会是完全align的,
像你膝盖的眼花稍微角做Man Spread就不一样了,
就已经3D形状就不一样了,
所以基本上,
这是Clinical是这样拍的,
这是Clinical Trial,
所以至少是同时拍的,
所以是有蛮多病人是重合没错,
但是至少一半是Man Spreading,
所以拍的3D的剖面不一样了,
假设如果是Follow Up的话,
基本上看起来就不太一样了,
所以基本上,
你有一些切割的资讯,
想要转到发炎资讯上面去,
你要怎么转呢?
然后再讲说,
为什么不能直接套用?
大家知道Neural Network有另一个重大缺点,
就是它很难套用在Core Data Stack,
最有名的例子是说,
Source跟Target其实差不多,
但是节度就差很多,
所以我们可以用这些Gate方式,
把一个模型转到另一个模型上面去,
那你就可以在想拍发炎资讯上去,
把这些去切割下来,
我花了超多时间,
所以我就讲快点好了,
我们最后结果是说,
我们可以拿这些切割模型,
在本来这个结病改变的图上面做定量,
那我们可以把这些Bomel Region,
很敏感的定量下来,
那最后我们就做这些统计分析,
等于是用后验的统计分析,
那根据传统的画Contour方式来比的话,
就发现如果计算,
还有未来会开到的Out Ratio,
就还好蛮多的,
所以大概这样子,
我之后本来要讲,
先这样子好了,
那我就直接讲,
我conclusion,
那我是回台湾之后,
大家知道我们做影像都会找合适的Collaborator,
我在美国的时候跟台湾的时候就不太一样,
那我在台湾的时候就做一个分支,
就是做脑影像研究,
大家可能知道说,
可能听过了,
Neural Network的本质就是,
一开始学脑会怎么function,
它是拟合一个脑细胞,
把很多资讯综结在一起,
然后用一个Activation Function,
然后往前输送这样子,
脑装滑,
偷别人的Video,
每颗脑神经都有几百个接收源,
然后再把这些神经连回去,
基本上,
这些神经集合在这边的Circuit,
就变回路,
回路就会做各种行为,
记忆等等,
所谓的脑科学的Holy Grail,
就是这个回路结合起来变Conscious,
我们是谁,
这我就不知道了,
因为我们对脑科学的认知,
非常非常地开始了,
像这些回路结合起来,
会变成怎么看东西,
这种东西我们都不知道,
第一步就是怎么把这些回路区分出来,
还是做不到,
除非是做电子显微镜,
不然解析度是不够的,
但你可以做光学显微镜,
解析度是不够,
但是会快很多,
电子显微镜基本上扫人脑,
所以有部分的,
怎么用AI技术来,
回头来分析这些脑科学影像,
想法先把这些脑神经,
一颗一颗重新连接,
重现出来,
我们才拿这些东西来,
建立一个模型来预测,
它的行为被怎么调控,
所以基本上就是一个,
我想问一下,
我问你,
左边右边,
差别是什么?
右边是原图影像,
左边是,
左边是米禾出的CNET,
就是,
左边是,
脑神经,
每颗发散的地方,
叫CNET,
左边是把CNET强化出来,
它有在,
它是两个神经的边界,
可能是,
这些,
每一线的终点,
是两个神经的边界,
它觉得不是同一个神经细胞,
有可能是CNET在交换资讯,
这结果不是很翻用来子,
但是,
但是,
目的就是说,
怎么把,
怎么把每颗脑神经,
然后,
然后把这些看起来是一条线的地方,
把它区分出来,
哪些是受理脑理,
哪些是在地脑理,
理论上这些CNET的位置,
就会是传递资讯的地方,
如果全部都做完,
然后很整的话,
你就可以利用一些theory,
graph theory,
去重现出这些会录长什么样子,
因为我同事有做这些,
Cognitive的测量,
并不是很大动物,
对,
但他们过于,
已经被训练说有些行为,
他们是要怎样,他们是要怎样,
他们做完行为之后,
他们再来拍摄这样子,
所以他们是可以知道说,
哪些会录如果有出现或没有出现的话,
可以跟某些方式联系在一起,
对,
所以,
那你可以做一些影像强化等等,
等等,
影像强化,
去噪音,去模糊化等等,
显微镜影像是非常常用的课题,
就可以拿来做,
基本上就是一个,
Light Emitting Art,
Art Emitting Light的过程,
就是当初是,
脑科学启发了AI的研究,
现在AI又会来做这个脑科学,
所以就会慢慢,
回旋就会收敛,
就会出现Terminated,
不过就大概这样子,
那我今天就,
在讲这边。
好,谢谢,
那,
现在我们就再感谢张涵,
谢谢。
现场有没有,
有问题,然后现在,
可以直接开麦克风,直接问。
你好,我想请教一下,
我对你刚提到那个,
不好意思,
那个可以先自我介绍一下。
对不起,对不起,我叫石清华,
我现在在Rochester,
New York,
那我对你那个脑神经,
那部分其实有点感兴趣,
因为其实在,
大概在一两个月前,
有一个,
有一个Research,
他应该还没有完全Publish,
他就是基本上是把,
脑神经,
有脑细胞养在一些Culture里头,
然后用一些Training,
然后配上AI的技术之后,
可以让他玩Video Game,
他可以玩乒乓,
这样子,
就是比较,
对,他是一个人,
我看了那篇Paper之后,
我觉得,
对,就是别人的Research已经到天上,
但我还在地上爬这样子。
那我只是好奇,
我只是好奇,
像你在你这边的那个,
如果有办法说,
用类似的Model,
然后对,
比如说你可以记住Action Potential,
或者是有办法,
荧光可以
侦测他Action Potential的,
然后类似的Pattern,
你就可以看到脑回路的反应,
或神经回路的反应,
针对他的Response这样子。
那,
而且因为这样东西,
呃,
我猜想,
就是说可以做到,
你可以比较,
Simplify一些Circuit,
然后可以做到比较,
呃,
比较High Resolution,
然后去Detect他的那个,
回路的Pattern,
那我不晓得说,
这个东西会不会在未来,
会变得很有趣,
或者是会变得是非常,
他相对于,
佐瑟菲亚的Brain来讲,
更小,因为他只有几百几千个细胞而已,
所以比那个佐瑟菲亚的Brain更小,
所以我觉得他可能,
说不定是一个很神奇的东西。
是是。
好,谢谢。
这个我可能要质疑一下我的同事,
我先说我们这个是,
这个是一个蛮大的Team,
然后主要是
清化脑科中心,
那我这边做影像分析,
那我主要一开始做的是,
这个,
是荧光行为镜影像嘛,
所以这是解剖完的染色或影像,
但是其实是有另外一个Branch,
是做Live Imaging,
就是,
就是是
Real Time的Function影像,
所以是有可能的,
是有可能的,
那我们现在其实,
又开始做分析,
是做这个,
就是这个,
类器官的体外培养的神经元,
原因也是一样,
就是你可以控制好,
然后是可以,
可以,
比较好地做一些,
就是这些,
你做解构或是
方便分析,
然后跟这些控制条件做比较,
但是这个Brain Cell可以,
我先找影片,
就是这个,
Brain Cell可以Play Pong,
可以Play乒乓球,
这是我是第一次知道,
我刚刚学习在那个Chat里头,
就是那个,
有看到,
我也是刚知道,
其实我们在看那个,
其实我们在看那个人脑培养的那个,
Ocrelinoid的脑细胞的时候,
就常常想说,
它有没有Conscious,
它有有Conscious的话就很可怕,
就很可怕,
有没有Conscious我是不知道,
可是它就可以Play Pong,
就已经有点可怕,
我一直觉得是我们的,
这完全是我自己的猜想,
就是我觉得我们的function,
或我们的意识其实是一个Module,
就是各种Module最后组成出来的效果,
所以各自的Module,
可能没有所谓的Conscious,
但是组合起来就可能有了,
是,
说得非常好,
就是,
就是,
我们同样的方式是可以分析,
人脑的一点点,
或者是生物的全体,
那像现在的光绘行为,
基本上可以做,
好比说很小的生物,好比说果蠅,
或者大体可能是猪脑,
猪脑可能可以做,
可能就花好几个礼拜,果蠅脑是一天两天这样子,
那假设就是说,
它假设是一样的,
它假设是全脑的事情,
而不是一块块的事情,
所以,
如果要看,
就是从,
从脑组织切片,
就这个我们有做啦,
就是从脑切片区域里面出来,
那要看,
比较high level的方面,
其实是不可能看到的,
所以今天会做的这么多AI分析,
其实目的就是为了搭配一件事情,
就是我们要很快可以处理整个脑的资讯,
那在,
那在影像技术上面的话,
电子显微镜是可以拍到
那个神经的那个,
每个神经的形状,
是可以扫得清楚的,
但像这个果蠅脑的话,
大家可以去搜那个,
Generia吧,
就美国有一个很大的这个,
这个果蠅脑的电子显微镜计划,
它扫了,
扫了两年吧,扫了半颗脑,
然后可能花了,
我不知道多少钱,
总之台湾是不可能付得起的钱,
然后这种扫描你也,
你也没办法跟,
好比说果蠅的行为,
做那个,
做比较吧,
因为扫太久了,
然后就一颗而已,
你也没办法这个,
看它行为然后做比较的样子,
那轻大他们做的事情就是,
然后他们也可以,
跟方选做对应,
因为他们可以做非常多颗,
所以他们知道这个果蠅,
他们生前有这种行为,
然后有没有记忆啊,
有没有等等等等,
所以他们有一个platform,
是可以把这些脑啊,
放大等等,
然后自动扫描下来,
然后接起来的样子,
那插了一块就是,
自动影像分析嘛,
就把这些影像放在那边了,
那第一个它是很小块的影像,
就一定你的view有限,
自动组合在一起,
然后自动,
自动,
自动接在一起,
然后还要知道说,
这些fiber长什么样子,
什么样的fiber是独立属于哪个神经,
然后最后才有可能说,
推断说这些东西怎么运作,
所以所以说没错就是,
就是这目的其实都是为了,
那大家觉得说,
这唯一solution就是需要,
需要用这些方式嘛,
那像像国外的话,
这些东西都跟,
跟Google合作等等,
那我们台湾就,
就做我们的事情,
就我们就想要把,
国外的智能智能影像,
先用AI可以分析出来,
然后那或许之后就可以跟,
function这东西搭配起来,
那不过这些都是,
这些都是生前跟生后的影像,
生前的行为跟,
跟结果后的影像对应啊,
那像你刚刚说这个live,
这个这个,
然后他做某些方面,
或者说play pump的话,
我觉得,
可能蛮有可能的,
如果成功的话,
可能对人类会很shock,
我觉得有可能,
有可能会很shock,
我真的不知道这件事情,
我常常看一些稀奇古怪的,
那个research news,
所以刚好看到这个,
oh my god,
我赶快同时讲,谢谢,
那,
这个,
我现在,
那我们今天就先到这边,
反正就是这个,
我现在要关这个,
感谢最后,
最后感谢那个张翰,
谢谢,
OK
