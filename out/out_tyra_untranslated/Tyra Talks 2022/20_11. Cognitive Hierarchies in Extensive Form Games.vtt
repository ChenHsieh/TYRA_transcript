WEBVTT

00:00.000 --> 00:03.000
整理&字幕由 Amara.org 社群提供

00:30.000 --> 00:47.880
我們先開始講解一下題目,首先第一個是我們在做的是Games,所以這個就是賽局,我想先用幾分鐘簡單介紹一下賽局理論到底是一個什麼樣的東西,算是一個比較科普版的介紹。

00:48.600 --> 01:04.940
首先先介紹到底什麼是一個賽局。大家看到Games就可能想到說是線上遊戲、桌遊、像我們日常生活中的剪刀石頭布之類的遊戲,其實這些都包含在這個範圍裡面。

01:05.220 --> 01:19.460
對我們來說,賽局其實就是一個數學方法來描述我們現在正在人與人互動中的策略環境,就像剛剛說的,它其實包含了非常多各式各樣的情況。

01:19.460 --> 01:37.040
就像它可以描述我們日常生活中,我們出去吃飯,不知道吃什麼的時候,就用剪刀石頭布來決定,這種也可以被描述。又或者更複雜一點的,可能像是一盤圍棋,可能像一天都不一定下得完的一盤棋,它其實也可以用這樣的賽局理論來描述。

01:37.480 --> 01:45.400
它其實非常非常地包山包海,不過我們說的所有遊戲裡面,它其實基本上可以分為兩大類。

01:46.220 --> 01:53.720
首先第一大類就是Normal Form,我不太確定中文應該叫什麼,可能叫正規表達式吧,不過我就姑且叫Normal Form。

01:53.720 --> 02:03.960
在Normal Form裡面,所有的玩家,在參與這個遊戲裡面的人,所有人是同時出招的,就很像是剪刀石頭布就算是這一類的環境。

02:03.960 --> 02:12.920
所以如果說等一下提到Normal Form,如果說你不太知道說到底我在講什麼的話,就可以想像一下就是剪刀石頭布的環境就好,所有人同時出招。

02:13.320 --> 02:29.520
那另外一個情況就是今天要講的Extensive Form,這個就是所有玩家是輪流出招的情況,這就像是圍棋,就是每個人下一手,然後我下完之後換另外一個人下,所以基本上就是賽局可以分為這兩大類。

02:30.120 --> 02:43.360
然後我現在開始介紹這兩類的基本上的數學定義是什麼。以下的兩頁投影片有一點點乾燥,如果有問題的話,有看不懂數學符號或者是什麼之類的,都可以馬上問我,沒有問題的。

02:43.960 --> 02:54.840
首先我們先來看Normal Form,就是所有人同時出招的情況。在這樣的一個情況,其實在數學上我們可以用三個東西來把它定義出來。

02:55.680 --> 03:09.440
首先第一個就是,我們需要有一個集合,去說現在到底有多少個玩家,就像是兩個人,就像我跟高賢在玩剪刀石頭布,那這個N就是1跟2,1是我,2是高賢。

03:10.440 --> 03:30.840
接下來我們需要描述的是,到底每個人可以出幾招。所以這個時候,對於每一個玩家I來說,我會用SI這個集合來表達說他能夠出的招,就像在剪刀石頭布裡面的話,就是每個人有三招,就是剪刀、石頭或布,所以這個set就是有三個東西。

03:31.840 --> 03:45.440
接下來,我們把所有人可以出的招,我們把它收集起來,變成一個項量,就像是這個N個人的話,我就把它收集成A1到AN,那我們就把它叫做是一個策略組合。

03:46.440 --> 04:15.140
接下來,第三件事情是,我知道有哪些策略組合了,那我知道有多少個人玩,接下來就是我要決定到底誰輸誰贏,那這樣子的話,我們需要用一個函數來表達,那我們這個時候把它叫做一個Payoff Function,對於每個玩家I來說,這個UI它其實就是一個從大家出的招的組合,到你可以拿到多少報酬的一個函數,就像剪刀石頭布的話,

04:15.140 --> 04:30.640
就應該說,我跟高賢在玩,我出剪刀,他出布的話,那這樣子我就贏了,所以在這個策略組合下,我所拿到的就是1,那高賢拿到的就是0,大概就像這樣,就是用這三個元素就可以來表達一個同時出招的一個策略環境。

04:31.640 --> 05:00.620
那我們在數學上,我們想要去預測說,在這樣的情況下,人到底會玩出什麼樣的結果,那我們提出來的數學預測呢,其實基本上是我們去想,最有可能玩出來的結果應該是一個最穩定的結果,所以在這個時候,我們使用的是一個叫均衡的概念來講說,到底什麼是最有可能出現的結果,那均衡的概念其實就是說,它是定義在一個策略組合上,我們會說,

05:01.120 --> 05:14.860
某一個策略組合它是一個均衡,就代表說對於每一個玩家來說,假設我知道他出什麼招,那我也不願意去變招,所以在這樣的情況下,就代表說這是一個均衡。

05:14.860 --> 05:44.840
所以如果是用數學上來表達的話,我們說一個策略組合A,它是一個單純策略均衡的話,就代表說對於每一個玩家,他用了這個A-I,就代表說是其他除了I之外玩家用的招,所以在這個情況下就代表說,player I他使用A-I這一招,他其實是比其他任何一招給他的報酬都還要好,那如果這樣對每一個玩家都成立的話,那我們就說這個是一個單純策略均衡。

05:44.860 --> 06:14.820
呃,我想先稍微停個幾秒鐘,就是大家有任何問題嗎?如果沒有的話,我會繼續講另外一個部分,OK,好,那我就繼續下去囉,那我們接下來,就剛剛已經講完了就是normal form,那接下來我們來講的是extensive form,就是大家輪流出招的情況,所以這個時候呢,就是你就想,它其實在數學上的結構,其實跟前面的normal form是非常像的,就一樣是有一個

06:14.860 --> 06:44.820
集合來描述有多少個玩家,另外我們還需要的是,就是有一個集合來描述每個人可能可以出的招,不過現在因為是大家輪流出招,所以現在需要描述的事情就剩下呃三件事,第一個就是誰在什麼地方做什麼事,所以這樣的話就等於是我們必須要描述所有可能出現的情況,然後跟在這個情況下誰來動作,然後他能夠做哪些事,那有關這一點的話就是

06:44.860 --> 07:14.820
呃,其實有有幾種不同的數學表達的方法,不過這邊的話我就用一個就是比較常見的數學表達來描述我剛剛說的這些事情,首先就是呃,在用在講這些notation的時候,就是如果說覺得數學符號有點多,你可以心理想像,就是這是一盤圍棋,現在n就是一跟二,就是有黑棋跟白棋,然後s呢,就是所有可能下的地方,所以如果是19成19的棋盤,你就有361個可能下的點

07:15.580 --> 07:44.580
那接下來首先第一個是我們在描述所有可能出現的情況,他其實就是所有還在進行中的棋譜,就是你可能下到一半的棋譜或者已經下完的棋譜,我們這些都把它用在呃,用一個set叫做h,他其實就代表是歷史,這個集合來描述說這所有可能的情況,也就是說說下到一半的棋譜啊什麼的,我全部的把它收集在這個集合裡面,所以這個集合其實非常的大,然後

07:44.580 --> 08:03.580
這個集合裡面每一個元素呢,他其實代表說就是前面所經歷過的,呃,已經下過的順序,舉例來說,黑棋先下的第一步在天元,那這樣這是一個,這是在history中的一個元素,那現在白棋下了另外一手,那這樣子就依序下來,這些東西都會被收集在這個歷史裡面。

08:04.580 --> 08:18.980
那在這個歷史集合裡面呢,有一個比較小的幾何字,我們把這個叫做所有terminal history,所以這個就是呢,所有已經下完的棋譜,我就把它放在這個裡面,因為到時候我們的報酬是背上這個幾何來定的。

08:18.980 --> 08:47.980
那接下來第二件事情,我們要定的就是誰在什麼情況下做什麼事?那首先是誰呢?就是說他其實是一個函數p,然後這個函數呢,是從所有可能的棋譜還沒下完的棋譜中所印到,就是就就印射到就是玩家的集合,就代表說現在這一步棋應該是輪到黑棋下還白棋下,所以這個就是p這個函數在在幫助我們的事。

08:48.980 --> 09:11.980
那接下來第三件事就是what?就是在每個情況下,我知道這個人現在輪到黑棋做事,那他到底有哪些動作可以做呢?那我就用row這個correspondence來描述,那他這邊印射到的是從歷史集合,印射到一個可以動作的集合的一個子集合,就代表這在描述說就是我現在能夠做哪些事情?

09:12.980 --> 09:37.980
那接下來就是我們的怎麼決定誰輸誰贏呢?就一樣是用這個我們的熟悉的UI來表示,像這個東西呢,就是從一個最後的outcome Z打到十數線的一個函數,所以舉例來說,就像如果在圍棋裡面的話,就是我看著我說下完的棋譜,如果說誰的d比較大,那誰就贏了,這個就是我們如何來描述extensible game。

09:38.980 --> 09:49.980
那在這個情況下,我們一樣是有理論預測,那我們這邊的理論預測呢,其實就是用一個概念,也是用均衡,不過他其實是叫做完美子賽局均衡。

09:49.980 --> 10:12.980
那在這個情況下呢,就是每一個人的策略,他其實是在每一個你可以動作的情況,就代表說是從每一個H,然後那個是輪到player I在做動作的情況,印射到說你在這邊可以做的動作,所以一個策略等於是告訴我說,在每一次輪到我在動的時候,我要做什麼動作。

10:13.980 --> 10:30.980
那當我知道每一個人的策略是什麼之後,我說一個策略幾何是完美子賽局均衡,就代表說他在每一個H,他都是均衡,那這樣的話這個是比前面的均衡稍微再更強一點點的數學概念。

10:31.980 --> 10:48.980
好,我非常知道就是前面這幾分鐘其實是非常的枯燥,因為他其實就只是在定義數學,不過等一下可能會變得比較有趣一點,因為我開始會講一些比較真實世界會發生的遊戲了,不過就是想在這邊稍微停個幾秒鐘,想再確認一下就是聽眾有沒有任何的問題。

10:49.980 --> 10:53.980
如果沒有問題的話,那我就繼續往下囉。

10:53.980 --> 11:07.980
那剛剛講完的其實就是一個十分鐘版本的賽局理論的crash course,那接下來我要講的事情是behavioral game theory,也就是說我們去想,這個賽局到底預測人的行為到底好或不好。

11:08.980 --> 11:18.980
那基本上就是我們在想,均衡他到底能不能很好的去預測人的行為,這個是在behavioral game theory最重要的一個問題。

11:19.980 --> 11:34.980
在這個時候呢,我們可以先考慮一個遊戲,這個叫做選美比賽。那這個遊戲其實是凱因斯經濟學的凱因斯,他在一九三幾年的時候提出來的一個環境。

11:35.980 --> 11:54.980
在這個時候可以想像一下,就是在當時有辦選美比賽,然後就是想像一下這個時候選美比賽最後決賽,有還剩下六個嘉莉,然後就是他們會把,就是在可能決賽前就為了要宣傳這個選美比賽,所以他們就把六個嘉莉的照片都印在報紙上,然後就發出去了。

11:54.980 --> 12:14.980
然後這個時候呢,就是為了要增加大家的曝光度,所以報紙就辦了一個抽獎。那這個抽獎呢,就是說,你看著這六個嘉莉的照片,請你選出來誰會是這次抽獎裡面的人氣王,就是誰是最多人票選說,最多人投票給他的人。

12:15.980 --> 12:36.980
所以這個時候,如果你在參加抽獎的話,你其實在腦子裡在想的事情,並不是說到底哪一個嘉莉是最帥或最美的,而你在想的事情是,別人會怎麼覺得哪一個是最帥或最美的。所以這個等於是說,你不是在思考她絕對到底是評審怎麼看,而是你同時在思考別人怎麼想。

12:36.980 --> 13:04.980
那同時呢,就是當你會這樣想之後,別人也會想說,噢,你會這樣想我,那我是不是也會應該要基於這件事情來去想說,噢,那我應該再多想一層,那別人到底應該怎麼想我。所以這個是凱因斯拿來描述說,就是股票市場其實就有點像是這個樣子,就是所有人在買賣股票的時候,他並不是真的care這家公司它到底本質到底有多好,而是在care的事情呢,就是其他人怎麼評價這些公司。

13:04.980 --> 13:28.980
那我能夠賺錢的就是,噢,其他人評價這家公司還不錯的話,那我是不是就應該考慮在這個時候做買賣呢?大概是這樣子。那接下來我要講的是一個遊戲版本,所以就是等一下聽眾可以跟我一起玩這個遊戲。那我們先想像就是,我們現在這個聊天室裡面有11個人,所以想像我們一起玩這個遊戲就是n等於11。

13:28.980 --> 13:49.980
那接下來這個遊戲的過程是,每一個人呢,同時選一個從0到100的整數。那這個遊戲的贏家呢,是你所選的數字最接近所有人選的數字的平均的三分之二。那這個數字最接近的人就是這個遊戲的贏家。

13:50.980 --> 14:04.980
雖然我看不到大家,不過如果大家有興趣的話,可以拿個紙跟筆,我給大家幾秒鐘稍微想一下。如果說我們在這邊一起玩這個遊戲的話,你會想要選什麼數字?反正就是大家稍微想一下,然後我再講說理論預測會是什麼。

14:04.980 --> 14:25.980
嗯,好,我想大家應該都已經想得差不多了。那我現在就先來講一下,反正大家就心裡先想好說就是,你是怎麼樣去思考這個遊戲的,然後你選的數字是多少。

14:26.980 --> 14:51.980
那我們接下來看看就是理論預測他到底會預測什麼。那在這個情況下呢,就是理論預測他其實會做出一個非常非常極端的預測,就是他會預測說這個遊戲的均衡是所有玩家都應該要選0。那這個會是一個均衡,就是因為說你去想,我去檢查這個事情是一個均衡,就代表說我要去檢查,假設我知道說其他人都選0的話,我應該要選什麼?

14:52.980 --> 15:19.980
假設我今天不選0,我去改選一個數字x的話,那這樣的話,整個所有加總的平均就變成是x除上11,然後再乘上三分之二,最接近這個數字的人才會贏。那很明顯在這個情況下,0會比x還要再接近這個,這個我的目標的這個數字,所以代表說我選任何數字都只會讓我從平手變成是輸,所以代表說就是我也要選0。

15:19.980 --> 15:37.980
那如果說你經過一些數學檢查的話,你會發現這個均衡其實是這個遊戲裡面唯一的均衡,那所以這個其實基本上算是一個非常非常極端的一個理論預測。那我們接下來就來看看說就是,實際上就是大家玩的到底怎麼樣?

15:37.980 --> 16:06.980
就這個是1995年就是Rosemary Nagel,她算是第一個做出這個實驗的人,然後她就發現了這張算是一個我覺得還算是蠻改變就是整個behavioral game theory的一張圖吧,就這個是第一個就是剛剛描述的實驗的實驗資料,然後你可以看到說就是在這個,這個是就是實際上資料的分佈,然後發現說在這個情況下居然沒有任何一個人選了0。

16:08.980 --> 16:23.980
這代表說就是理論預測的這個0這個地方其實並不是一個非常好能夠解釋資料的模型,然後你們還可以看到說就是其實在這邊就是有一些特別的突出的點,就像這邊有33跟22都是一些特別突出的一些數字。

16:23.980 --> 16:45.980
那這些個就是這個實驗資料其實從1995年開始已經被不斷replicate過,在世界各個地方都已經不斷replicate過,就是這是一個非常非常穩定的一個結果,就在任何地方你都可以看到說基本上沒有什麼人會去選0,然後呢你可以看到說很多人都選50啊3322或者是10這種數字。

16:46.980 --> 17:02.980
那所以大家就想說,欸那這樣均衡可能不是一個很好描述這樣的資料的一個情況,所以呢也因為這樣的資料,所以我們就算是啟發了另外一個替取而代之來解釋行為的模型,這個模型叫做level k。

17:02.980 --> 17:28.980
那level k模型呢它其實是假設說每個人他只能想一定的次數,就只能想幾成而已,那這個模型呢就想說假設說每個人可以想的層次是不一樣的,那一切的開始就是level 0的人,level 0的人就代表說他在看到這個遊戲他就傻了,他根本不知道說這個遊戲我應該要選什麼數字。

17:28.980 --> 17:38.980
那所以呢這個模型就假設說這些人他就在0到100隨機的挑一個數字,就反正就是完全不策略的他就是反正就隨便挑一個。

17:38.980 --> 18:07.980
那level 1的人呢他會想說ok,其他人他會假設說其他人都是level 0,那所以他今天他要最適的去回應其他玩家都是level 0的人,那這個時候他就會去算ok,在這個情況下如果說其他人都是level 0,那我的期望值的平均就我對於其他人選的數字的期望值應該就是50,那所以這樣的話我要選50的三分之二也就是33這個數字。

18:08.980 --> 18:21.980
那接下來呢level 2的人他會去假設其他人都是level 1,那所以呢其他人他都會選33,那我就要選33的三分之二也就是22,所以這樣子一直類推下去。

18:22.980 --> 18:47.980
所以也因為這樣子就是level k模型就是可以基本上解釋就是現在這邊出現的這個資料,就在這邊的話就是你可以看到很多人就是可能比較矮的地方比較矮的密度很有可能就是level的uniform的選出來的,然後可以看到說就是在這邊就是這個33這邊有一個peak就代表說很多人可能是level 1,那接下來在22的附近也有一個也有很大的密度就可能是他們是想兩層的人。

18:47.980 --> 19:05.980
請問,可是為什麼比如說我是一個level n的人,我為什麼一定要假設所有人都是完全一樣的是比我低一階的,我不能假設我distribution嗎?

19:06.980 --> 19:12.980
主持人問的問題非常好,因為這個是我們這篇文章要處理的另外一件事情,馬上就會講到了,不過謝謝。

19:15.980 --> 19:22.980
不過這個只是單純的介紹整個文獻發展的過程,這個是第一版本的模型。

19:23.980 --> 19:42.980
不過接下來就是就拿著這個模型,雖然是像剛剛彥永提到的,就是這個模型他其實怎麼講呢,就是他做了一些很強的假設,就像是選n層的人,居然假設全部人都選n-1,但是呢,至少這個模型他其實還蠻能解釋很多normal form情況下的策略行為。

19:43.980 --> 19:58.980
不過呢,如果說你重新回到在想像一開始就是extensive form的情況下,輪流出招的情況,就是從1995年到現在,還沒有出現任何一個模型是類似的,就是hierarchical thinking的模型。

19:59.980 --> 20:10.980
那這篇文章,我們的目標就是在提出一個同樣的解的概念,只是在extensive form上面,就也是一個層次性思考的一個模型。

20:10.980 --> 20:22.980
這個大概就是我的introduction,然後就除了剛剛彥永的問題馬上就回答到,然後就其他聽眾有任何問題嗎?如果沒有的話,那我就繼續囉。

20:23.980 --> 20:26.980
好,接下來開始進到我們的模型。

20:26.980 --> 20:37.980
所以我們現在來就先設想一下,到底為什麼level k模型如果直接套到extensive form上面會發生什麼事?

20:38.980 --> 20:58.980
所以這個時候我們就想,因為level k模型它是定義在所有人同時出招的情況,也就是說原本的level k模型它並沒有考慮到說,我看到別人做的過去的行為,我應該更新我自己對別人的想法這件事情,它是並沒有把它build in到這個模型裡面的。

20:58.980 --> 21:17.980
所以也就是說,當你面臨到一個同時出招的情況,那這個模型可以用,可是當你面臨到別人輪流出招的情況,那這樣子level k模型的預測就是,所有人對別人有多聰明的評價是完全固定的,那它會固定across the whole game。

21:17.980 --> 21:29.980
那我們接下來會發生到的邏輯上的問題,我們可以從這個簡單的例子來看,然後我先用這個數來簡單解釋一下,再重新回復一下extensive form game它的一些定義。

21:29.980 --> 21:50.980
所以基本上我們有一個在定義所有的棋譜就是h,那h它在這邊其實就是描述整棵樹的情況,那在這邊就是每一個頂點,就是告訴說每一個需要決策的地方,那p這個函數就告訴我說,在每一個頂點上到底是輪到誰來做事情。

21:51.980 --> 22:08.980
那所以假設現在這個情況是我跟高賢在玩這個遊戲,然後高賢是第二個玩家,然後我是第一個玩家,不好意思主持人一直被我cue,不過也沒關係,如果說今天高賢是一個可以想四層的人,然後他就會覺得說,欸,博軒可能就是想三層嘛,就從頭到尾他都是這樣想的。

22:08.980 --> 22:36.980
那如果說你去解出來,你發現說,OK,想一層跟兩層的博軒,他會在一開始的時候選左邊這裡,選a,如果想三層的博軒他會選b,那所以這個時候你試想一下,如果說今天是可以想四層的高賢,他就覺得說,OK,我假設博軒一定是想三層的,所以在這個情況下我一定會到,他一定會下b,走b這個選擇。

22:36.980 --> 22:55.980
那我一定會到右邊這個branch。可是如果說你今天發現,欸,糟糕,博軒居然選了a,那這樣這件事情就發生了一個算是對別人想幾層的評價上跟你實際觀察到的行為,是一個不compatible的情況。

22:55.980 --> 23:15.980
這代表說就是因為,我現在覺得博軒想三層,那我一定要在右邊啊,可是今天居然發生了左邊了,那這個是如果說你今天直接用level k模型套用到Extensible Game上可能會發生的問題。那如果說你去仔細去看這個incompatibility的話,你會發現說他其實是有兩個問題所在的。

23:15.980 --> 23:38.980
首先第一個就是剛剛彥永講到的,就是所有的玩家他都假設別人比他少一級,這代表說就是,他沒有去想,就是高賢想四層,他沒有去想其他的可能性是博軒可能沒有那麼聰明啊,他可能不一定只有想三層,他可能只有想兩層或一層而已啊,所以這個是原本模型的一個問題,所以他沒有辦法直接被套用到Extensible Game上。

23:39.980 --> 24:03.980
然後再來另外一個問題是,當你看到別人做的動作的時候,你應該要去更新你對別人的評價。這舉例來說,在這個遊戲裡面,如果說高賢看到左邊,就我選的左邊,那他應該要馬上察覺到一件事就是,博軒絕對不是想三層的人。那可是這個行為呢,就是在原本的靜態模型下也是沒有被building的。

24:04.980 --> 24:15.980
所以這兩件事情呢,就是我們這篇模型想要去突破的這兩個點,就同時要處理這兩個問題。那接下來呢,就是開始講我們的模型。

24:16.980 --> 24:31.980
那首先這個就是完全是彥永提到的一個地方,就是我們怎麼處理第一點。那第一點呢,就是Cognitive Hierarchy Approach,現在在這兩個字出來之後,終於把整個題目在做什麼事情,終於全部串起來了。

24:31.980 --> 24:54.980
那這個Cognitive Hierarchy Approach,它算是一個進階版的Level K模型,就是在Level K出現九年之後才被提出來。那在這個模型的運作過程是如下,就是每一個玩家在一開始的時候,他也是會有一個Level。然後呢,這個Level,他是每一個人是獨立的抽的,從這個機率分配裡面抽出來。

24:55.980 --> 25:10.980
那Level K的人,他這個時候不再完全假設所有人都只是Level K-1,他假設說每一個人可能是從,可能是Level 0,可能是Level 1,也可能是就O的位到Level K-1,所以這些都是有可能的。

25:11.980 --> 25:38.980
那接下來呢,就是Level K的玩家,他雖然會錯誤的覺得所有人都是從Level 0到Level K-1,不過呢,他們對別人的評價其實沒有那麼錯,就是呢,他們的評價至少在有一個地方是正確的,就是我對於所有比我想的沒有我多成的人呢,他們的在跟實際分配上,他的relative的proportion是對的。

25:38.980 --> 26:07.980
那所以接下來就是,呃,從數學上語言來說的話,我們可以用,我們用μij來表示,呃,這件事情。所以這個μ這個東西呢,是一個機率密度。所以這個是對於Player i,對於Player j的評價。那所以今天這個,頭上這個K就代表說,Level K,Player i,他對於Player j的評價。那所以這個時候就是L就是,如果說Player j是L的機率是多少?

26:07.980 --> 26:27.980
那所以今天如果L大於等於K的話,就代表說,別人是不是跟我至少能夠想到一樣的層次,或比我還聰明?那在這個模型下呢,就是覺得,噢,如果你是玩家,你是Level K的玩家,你會覺得說,沒有,其他人沒有辦法想得比你還聰明。所以這個時候我就放機率密度是0在這裡。

26:27.980 --> 26:44.980
但是如果說L是嚴格小於K的話呢,那其實就是,這個機率密度,你看,分子的話,它其實跟真實的機率分布是一樣的。那唯一不一樣的地方只是,我重新把它renormalize過了,就是用Level 0到Level K-0的情況,來重新renormalize。

26:44.980 --> 27:07.980
所以這個時候就想說,這些玩家他其實在我們的模型裡面,他沒有那麼聰明去想到說,每一個人是所有的聰明才智的情況都有可能發生。他其實會假設說就是,別人都比你還……想得沒有你那麼多。那可是呢,別人的想法也沒有那麼錯,就是因為說,別人的對於整體的分布上其實是對的。

27:07.980 --> 27:27.980
那我們這個時候我們說,就是玩家他們有truncated rational expectation。那所以你在這邊你可以觀察說,當我們很直接的一個exercise,就是當K受到無限大,就當你是無限量聰明的人,你也可以看到說,在這個表達式下,這個分子會受益到1,因為就是你的機率分布全部加起來就是,機率是1。

27:27.980 --> 27:43.980
所以這樣的話等於是,你可以有完全正確的評價,所以這個時候就是fully rational expectation。可是如果說是,你可能只能講case的話,你就只有一個是部分對別人想法的一個評價。

27:43.980 --> 28:07.980
那有關於就是,如果說你對於這個,這樣的設定就是有可能像是,為什麼要這樣設定的一些問題,我們之後可以會後再討論,不過就是,這是,呃,這篇文章就是,是這樣子想的,就是算是一個level k的一個延伸的一個模型。那我們用這樣子就可以來處理,就是第一個問題,就是別人,呃,每一個玩家對於其他玩家的level的想法都是一個固定的點。

28:08.980 --> 28:30.980
那接下來呢,就有關於處理,就是怎麼更新訊息。這個時候我們就假設說,每一個玩家,他在每一個history下,他都會更新他的事後機率,然後是用貝斯法則來更新事後機率。所以這樣的話就等於是,我可以不斷的去更新我對於別人的評價,然後我是用別人過去的行為來更新我的評價。

28:30.980 --> 28:59.980
那當你做了這個假設之後,你馬上會面臨到的一個問題就是,事後機率,它是不是well-defined?就是因為說,如果說,我們大家都知道說是事後機率,你就是probability A,然後一槓,然後後面一個B嘛,所以就是如果說,B它是一個機率為0的事件的話,那這樣這個事後機率,它其實不會是well-defined,那其實在就是extensive game的,呃,的文獻上,其實就是有,有非常非常多的文章就在處理事後機率是0的事情。

29:00.980 --> 29:23.980
那不過呢,就是在我們這篇文章,就是我們這個模型下,完全不會有這樣的問題,就是理由是這樣,就是因為,我們首先看第一點,不論你是哪一個level的人,你都會有一定的機率去覺得對方是level0的人,那level0的人呢,他在每一個地方,輪到他做事情的時候,他都會隨便選。

29:23.980 --> 29:50.980
那也因為這樣子呢,你在每一個歷史,你都會覺得這個事情是可能發生的,因為至少有level0,他會選到那裡,那也就是說,我的事後機率是永遠都是well-defined,那也因為這樣子,就是我的belief system是完全是well-defined,那所有的玩家,他其實就單純只是在,就是對於,呃,我的信仰去做,呃,最正確的回應。

29:50.980 --> 30:19.980
就這個是,就如果說你這邊聽得懂的話,那基本上就是我們這篇模型你已經都聽懂了,那為了再稍微複習一下,我們再回到剛剛的那個例子,就一樣是我跟高賢在玩的遊戲,在這個時候呢,我們來看看高賢他腦子裡在,到底在想什麼,如果是可以想4層的高賢呢,我們現在用這樣的一個vector來表示說,呃,他對於我的評價,因為他現在覺得我可能是level0,level1,level2,level3,所以就是我們4個元素就夠表達了。

30:19.980 --> 30:48.980
呃,這個機率密度了,那所以今天當高賢看到我在一開始選A之後呢,在每個模型,我們現在就用來比較一下三個模型他到底給了我們什麼,首先第一個就是一開始一樣提到的,就是最天真的levelK,他這邊假設的是所有人,如果說高賢可以想4層,那他就覺得博軒一定是想3層,所以無論如何,他都只放機率密度是1,在level3的地方。

30:49.980 --> 31:18.980
這樣子,所以你就可以看到,馬上可以看到說,就是不compatible的問題,那現在我們來看就是,如果是用就是2004年的那個那個模型,他會帶給我什麼,那在這個時候呢,我們可以看到說,因為這是2004年的CH model,他也是一個靜態的模型,所以呢,他的對於別人的評價是不會更新的,他永遠都覺得別人就是用truncated rational expectation來做事,所以他事後的評價就永遠都是呃。

31:18.980 --> 31:34.980
假設別人是level0到level3,所以他的分母就是0到0加到3,然後呢,他的分子就剛好就是0123,所以這個只是從真實的分配出發,不過呢,我是重新renormalize,假設別人只有0到3的可能。

31:34.980 --> 31:57.980
那接下來介紹的是,在我們的模型下,他的事後機率會長成什麼樣子?那首先呢,在我們的模型下,當想4層的高軒看到我選了A,那他這邊會選擇的事情,他就會開始去想,欸,到底為什麼我會選A?他就會想說,哦,有幾種可能。

31:58.980 --> 32:23.980
第一個是,博軒他其實是一個level0,根本是在胡鬧的,所以如果說是level0的話呢,那在一開始這邊,我有一半的機率會選左邊,一半的機率會選右邊,所以ok,所以假設我是level0,那我就一半的機率選左邊。那我另外還有可能是,博軒他可能是level1或level2啊,那所以這個就是,所有可能出現左邊的機率就放在分母,就1 2的P0加上P1加P2。

32:23.980 --> 32:50.980
那接下來上面的話,就是貝斯法則告訴我們的。然後另外你可以觀察我們的事後機率,我們就知道說,哦,他在這個subgame下,高軒可以馬上排除博軒是level3的可能,就是因為說,如果是level3,我一定會在另外一個subgame,不過呢,我現在居然在這裡,所以代表說就是我在計算事後機率的時候會完全把這個殺掉。

32:51.980 --> 33:05.980
好,所以這個啊,這邊是,就基本上是我們整個模型的illustration,就稍微,可以稍微停一下下,就是大家有任何問題嗎?我剛剛看到聊天室有個,有個問題,或者我稍微看一下哦,嗯。

33:06.980 --> 33:31.980
哦,在這邊的話是,呃,呃,這邊這邊謝謝,謝謝義歐陽他問了一個問題,那他在這邊問的問題是說,就是我們這邊在機率密度上做了什麼假設?我們其實,呃,我們其實假設的是full support,就是每一個PK都大於0,那這個東西其實是一個,呃,without loss of generality,對謝謝,不過這邊我們做的假設是,呃,就是有full support。

33:32.980 --> 33:52.980
OK,好,那,那我先就繼續嘍,嗯,非常謝謝提問,那接下來就是我在,因為這邊就這個就有一點technical,不過我就稍微就是介紹一下,就是在這樣的模型設定下,我們可以導出哪些,呃,一般性的一些法則。

33:53.980 --> 34:21.980
首先第一個定理就是說,在任何的extensible game下,呃,假設今天有很多個人,假設今天還是我跟高賢,然後再加一個神秘玩家X,假設有三個人在玩,那這樣這個定理告訴我們說,如果今天有超過超過,呃,超過兩個人的話,那這樣子我在每一個地方的事後機率,那其實是一個我對於高賢跟玩家X的有多聰明的一個聯合機率。

34:21.980 --> 34:43.980
那這個定理告訴我們說,不論你在哪裡,你的事後的聯合機率,它都會是,呃,對於每一個玩家都是各自獨立的,這也代表說呢,別人做了什麼事,就像X做了什麼事,不會影響我對於高賢的評價,跟高賢做了什麼事情,不會影響我對於X的評價。

34:44.980 --> 35:09.980
然後再來第二個定理呢,其實我們從剛剛的illustration可以看到,當這個遊戲變得越來越長的時候呢,我會有更多的證據去看,去知道說,到底我是哪一個層級的人,那所以接下來呢,我對於就是,呃,我會放,我覺得對方是多少呃,多少層的可能性會越來越少,這代表說,當歷史變長的話,我的support會越來越小。

35:10.980 --> 35:35.980
那接下來第三個就是,呃,我們去想說就是,在這個模型下,呃,有提出了一個模型的解。那這樣子呢,就是,因為你可以看到說,當K受到無限大的時候,其實人是有fully rational expectation的,那在這個情況下,大家就會自然的去問說,我們的模型是不是當K受到無限大的時候,在level無限大的人,會不會選到均衡?

35:36.980 --> 35:58.980
那其實答案是,呃,不一定,就也就是說就是,我們的模型解,跟完美子賽局均衡,它其實是沒有邏輯的包含關係的,也就是說我們可以找到一個例子去說就是,它會受用到均衡,然後也可以找到例子是,它絕對不會受用到均衡。所以這個是比較一般性的定義,就是這個是比較稍微technical的結果,不過,我就只是列在這,我就不特別多說。

35:59.980 --> 36:26.980
那接下來就是,因為以上它其實比較接近,呃,在我臉上比較像接近就是純數學模型,不過我覺得,呃,呃,就是,就是大家對於科學這件事情,就是其實有很多種很多種不同的想法,不過至少在在在在我的我的看法中啊,就是,如果說真的一個是一個模型是說好的模型的話,它是能要能夠能夠被實際資料去去檢視或者是否證的。

36:26.980 --> 36:51.980
那在現在目前這個情況下,目前我們所有所導出來的東西,它其實都是一個數學上的解,而且它有點太過於一般性,所以我們沒有辦法去找出來一些更更否證的的的的的理論預測。那所以在接下來,為了得到一些我們可以在實驗上檢測的預測,我們現在考慮以下這個非常非常特定的決策情況。

36:52.980 --> 37:08.980
好,我們現在考慮這個以下這個遊戲,這邊有兩個人,假設今天是我們來換換一個人好了,換我跟我跟我跟晏永來玩,好,我們兩個來玩遊戲,然後呢?今天這個遊戲是輪流出招,我跟你輪流出。

37:09.980 --> 37:21.980
在一開始呢,你可以把它想像成是一個投資遊戲,我們要一起來養一個,舉例來說,你可以說是西瓜南瓜或者是電子雞都可以,不過一開始那個大小是一單位。

37:22.980 --> 37:46.980
那接下來每一天,我們輪流去給他餵食、澆花、灑水或者是投資。輪流在每一天呢,每個人可以做兩個動作,一個是我決定我要take,我要把這隻雞給拿了,或者我要把這個南瓜給採收了,那我決定採收的話呢,決定採收的人可以分到比較大的一個部分,然後被採收的人可能只能拿到比較小的部分。

37:47.980 --> 38:09.980
那同時呢,每天你有另外一個選項,就是我可以投資C塊錢到這個裡面,像是你給這個南瓜澆水,讓他今天長大。然後呢,如果說你今天決定要採收這個南瓜,或者你決定要拿這個電子雞的話,那這樣這個遊戲就結束了,就依照我們所說好的這個分配來分這個東西。

38:09.980 --> 38:33.980
不過如果說,你決定投資的話,那這樣這個其實是一個有策略風險的一個動作。就是因為說,你在選擇去投資的話,你有一個好處是,你可以讓這個東西變大。那可是你的缺點就是,你在隔天是輪到別人來決定,別人要決定拿,或者說他要繼續投資。

38:33.980 --> 38:49.980
所以如果當別人,你去想,如果說別人要投資的話,你很有可能會覺得,那我乾脆今天來投資。可是如果說你覺得今天來拿,如果你覺得明天要拿的話,那你可能覺得今天要拿,就是因為別人拿的話,別人在明天會拿到一個更大的部分,你會拿到一個比較小的部分。

38:49.980 --> 39:00.980
那所以這邊的話,就是有一個 trade-off 在這邊。不過我們這只是講一個遊戲的大概念,不過等一下會有一個更細節的介紹。那這個遊戲呢,其實被我們叫做是無攻賽局。

39:00.980 --> 39:21.980
好,我在介紹無攻賽局之前,我再稍微回應一下這個易歐陽的提問。對,這個是 common knowledge,就是所有人都知道那個機率分配。好,謝謝提問。那我先繼續講,這是這個無攻賽局。

39:22.980 --> 39:43.980
為什麼這個東西被叫做無攻賽局呢?就是因為你如果把它畫成樹狀圖的話,它長得就跟無攻一樣,就只是因為這樣子。這個樹狀圖的看法是這樣,在一開始是 player 1 做事情,如果他在一開始就決定要拿的話,他拿 1,別人拿 0,那在第一天他也可以決定要傳。

39:43.980 --> 40:01.980
如果傳的話呢,這個東西就變大 C,就增加 C 個單位,所以是如果說第二天就輪到 player 2 來決定說他要傳還是拿,如果他拿的話,player 1 就只能拿 C,然後 player 2 可以拿 1 加 C,那一樣,player 2 可以決定傳或拿。

40:01.980 --> 40:22.980
如果 player 2 決定傳的話,那輪到第三天換我做。所以你可以想像說,這個在第三天如果拿的話,我的報酬就變 1 加 2 C,然後別人,諺詠就只能拿 2 C。那所以這樣子的話,我們這邊假設說,我們總共有 2 S 篇,所以每一個人可以做 S 個動作。

40:23.980 --> 40:40.980
好,這邊就只是一些 technical assumption,在這邊我們假設,就是每一次增加的 C,他在三分之一到一之間,這個假設他,這並不是一個很嚴格的假設,我們只是單純讓這件事情就是,讓這個問題變成是一個有趣的問題。

40:40.980 --> 41:00.980
那就是,你可以想像說,如果說 C 太大的話,那這樣大家都會一直傳下去,所以這樣就不有趣了。如果說 C 太小的話,大家可能就覺得說,可能就直接拿就好,太 trivial,所以我們就是考慮一個比較有趣的 range。

41:00.980 --> 41:26.980
那在這些假設下,我們可以去看說就是,到底均衡解是預測這個遊戲大家會怎麼玩。那在這邊呢,就是均衡的預測是,所有人只要他能夠做動作的時候,他都要拿。所以這個時候我們可以回去檢查一下,就是均衡的定義到底長什麼樣子。就是說,每一個人,他在每一個歷史下,他都要做最佳的行為。所以這個時候我們就一個一個歷史往回看。

41:26.980 --> 41:54.980
我們看最後一天,最後一天輪到第二個人來做事情。他就可以看說,哦,OK,我就去想說,我到底要拿還是我要傳。我這個時候我拿的話,我可以拿 1 加上 2s-1 乘上 C。可是如果說我決定傳的話,我是 2s C。那所以在 C 比,嚴格比 1 小的情況下呢,他其實是,對於最後一天來說,Player 2 他其實是想要拿的,拿的比較 profitable。

41:54.980 --> 42:11.980
那所以同樣的道理就是,如果說回到最後一天的倒數前一天,假設 Player 1 知道 Player 2 隔天要拿,那經過同樣的運算,Player 1 他也會覺得拿比較好。那如果在倒數第二天的話,又輪到 Player 2,Player 2 也會覺得拿比較好。

42:11.980 --> 42:30.980
所以就一路倒推回來,就發現說,就是我們的完美子賽局均衡就預測了一個非常極端的結果,就是這個遊戲不論你多長,然後不論 C 有多大,就在三分之一到一之間的話,你永遠要拿,在第一天就會拿。所以這個遊戲不論多長,他都不會延續下去。

42:31.920 --> 42:59.760
請問一下,這個東西你說你現在想要做實驗,可是其實你剛剛就是理論的部分講完的時候我就想要問了,就是你們有先寫個 Monte Carlo 跑一跑,看看它的狀況到底會,就是比如說對於有幾個人玩啊,C 是多少啊,有幾個人,他的 FaceSpace 會長怎麼樣之類的。

42:59.760 --> 43:16.360
你問的問題真的非常的好,因為你根本是我肚子裡的蛔蟲,這個是馬上過幾頁投影片就會出現的東西,各位聽眾,不好意思啊,我的蛔蟲又在講話了。我跟他就蠻熟的,所以他都知道我要講什麼。

43:16.560 --> 43:32.360
對,所以我只先介紹一下我們這個遊戲環境而已,就單純介紹環境。那麼接下來我們再來看看,為什麼要挑 Centipede Game?首先第一個就是,這一個……啊,OK,不好意思,我剛剛笑場了。

43:32.360 --> 43:45.920
就是,這個蜈蚣賽局呢,它之所以有趣的地方是,它其實已經被做實驗做了三十年了,然後呢,我們就想說,你應該找一個現有的理論是不好的嘛,這才有新的理論發展的空間。

43:46.840 --> 44:15.560
那我們現在來看看,對於其他比較不熟悉這個實驗的朋友的話,想要先稍微解釋一下這個實驗的資料會長什麼樣子。假設我們現在是基數,就不太好,假設我們只有十個人好了,那假設十個人的話,我們來做實驗,實驗者會隨機的兩個人配一隊,兩個人配一隊,所以這邊總共有五隊,那所以每一隊開始玩這個遊戲之後呢,就一隊玩家會產生一個觀察值。

44:15.680 --> 44:45.000
就是他們到底在哪一天做了,就決定要拿了,所以這個是觀察值,就是我的terminal period。那接下來呢,我們的均衡預測呢,就是是一個degenerate的一個distribution,就是所有的機率密度都會放在第一天,第一天所有人都會拿,那可是在實際資料上,就是在1992年,就是這是我老闆他做的第一個實驗,就發現呢,實際上只有1%的人會選在均衡上,

44:45.000 --> 45:14.480
這代表說均衡在這個情況下並不是一個很好的預測,呃,其實應該是非常相當糟糕的一個預測,那就首先第一個理由就是因為就是實際行為上就是離現有的均衡理論就是呃,非常非常的遠,所以我們才會去想說啊,那這樣子可能我們的理論有施展全角的空間,那接下來我們同時呃,就是我們在處理這個環境,其實還有一個一魚兩吃的一個目的,就是說因為在過去三十年呢,

45:14.480 --> 45:43.920
就是這個蜈蚣賽局,他其實已經被重複做了好多次了,那可是在實驗上有兩種可能的做法,一種呢,是用extensive form,就是我依次問大家說,噢,今天你要拿還是你要傳,然後再問其他人說,假設你知道別人要傳了,那你要拿還是傳,所以這樣子就是我依次依序去問,可是同樣的實驗,你也可以去問另外一個問題,就是說噢,我另外一個做法是我直接

45:44.480 --> 46:13.720
去問說,你要在第幾天拿,跟我問另外一個人說,你要在第幾天拿,那所以這兩個東西呢,就是很多人在argue說,到底哪一個,到底是兩個問法是不是在行為上是一樣的,那所以這個東西呢,就是還是在under debate,那所以因為這樣呢,就是我們接下來就馬上要講的理論預測,就他不只是實驗可測的,而且呢,我們還同時想要去解決這個在實驗經濟學上方法論上一個很大的debate

46:14.960 --> 46:41.040
這是為什麼我們要挑蜈蚣賽局的原因,那接下來在開始講我的理論預測之前呢,我再稍微再簡單講一下,就是這兩種方法他到底長什麼樣子,就首先這邊你可以看到說,這個例子是一個就是六隻腳的蜈蚣,就一樣是兩個人,所以這邊有六個stage,所以在extensive form的話,就可以看上面這張圖,我就只是單純就問說,第一個人,你要拿還是傳,然後我再問第二個人,你要拿還是傳,這樣一路問到第六天

46:41.040 --> 47:11.000
那同時呢,我也可以去,有另外一個方法去問他是說,就是我同時去問兩個人說,你要在第幾個你的決策的時候去決定拿,所以對於player 1來說的話,第一個選項,take the first time,就代表說,我要在第一天就拿,那take the second time的意思就是說,我第一天我要傳,第二天我才拿,也就是我要在第三,對不起,第二個選擇我才要拿,也就是我在第三天的時候拿,所以第三個選項代表是我要在第五天的時候拿,或者我永遠都要傳,

47:12.040 --> 47:39.000
所以這樣的話就是,兩個,對於兩個玩家來說,他們都有四個選擇,所以這兩個東西呢,就在這兩種方法上,均衡的預測是,這兩種方法是策略上是均等的,而且理論預測呢就是,不論你用哪一種形式去玩這個遊戲,他都要在第一天就拿,所以說就是,在這兩個方法下,理論預測就是,就是一樣都是degenerate的distribution,所有的機率密度都放在第一天,

47:39.000 --> 48:08.960
但是呢,我們的模型預測,這兩個方法玩出來的結果,會是不一樣的,那以下呢就是,我們這篇文章算是,算最不好證的一個定理,那這個定理的敘述如下,就是對於任何的sensitivity game,就是,因為你看在現在我們的sensitivity game下,你有兩個參數就可以決定這個sensitivity game,第一個就是c,就是這個,這個sensitivity到底有,每一次增加的話,他到底可以增加多肥,

48:09.000 --> 48:38.560
第二個是這個s,就是這個sensitivity有多少隻腳,那我們現在這個定理是,對於任何的c跟s,然後再來第二件事情是,對於任何的,就是,呃,我對於level的,的,的,的prior,現在我假設我今天去做實驗,我去randomize,就是我的表現方,就玩實驗的方法,我去randomize說,有一些人,我是用同時玩的,就是用normal form來玩,有一些人,我去用extensive form來玩,

48:38.560 --> 49:05.760
那我玩出來的結果是,在normal form下,我可以找到一個機率密度函數,然後也可以去算成,呃,累積機率密度函數,然後我在extensive form下也可以去找出來,實際上的累積機率密度函數,那麼接下來的理論預測是,在normal form下的累積機率密度函數,會first order stochastically dominate,呃,就是你在extensive form下的機率密度,呃,的累積機率密度,

49:05.760 --> 49:06.760
那這個定理是,我能先介紹一下,什麼是FOSD,呃,這個東西,就是我在演講前,我稍微思考了一下,到底要怎麼講這件事,後來我想到一個例子,我覺得還不錯,我自己覺得啦,如果大家不喜歡,可以,可以在留言區湊我,也是沒有問題的,就大家都講說,就是那個,有時候講,大家考大學就說,今年的聯考比去年的難,或者比去年的簡單,如果說我們今年,那這樣大家就想說,哦,到底簡單有多簡單,難有多難,那所以說,這個時候就有一種比法,就是如果說今年的聯考比去年的難,或者比去年的簡單,如果說我們今年,那這樣大家就想說,哦,到底簡單有多簡單,難有多難,那所以說,這個時候就有一種比法,就是如果說今年的聯考比去年的

49:35.760 --> 49:36.760
first order stochastically dominate的簡單的話,就代表說,我在看頂標、前標、均標、後標、底標,我的頂標,假設去年是70分,我今年變80分,我的前標去年是,like,65分,今年變成70分,所以我就比每一個標,其實是每一個PR值所對應出來的分數,今年的分數如果都比去年的高的話,那我就說今年的是比較簡單的,in the sense of FOSD,就代表說,我在看頂標、前標、均標、後標、底標,我的頂標,假設去年是70分,我今年變80分,我的前標去年是,like,65分,今年變成70分,所以我就比每一個標,其實是每一個PR值所對應出來的分數,今年的分數如果都比去年的高的話,那我就說

50:06.760 --> 50:29.760
所以如果說你換成累積機率密度的話,你會長出來是像這個樣子,就是紅色的線,如果說FOSD藍色的線,代表說紅的線會一直被壓在藍色的線下面,或者說紅色的線會是在藍色的線的右邊,那接下來這邊就是剛剛彥永所提到的問題,就是說,到底我們的理論預測會在這個情況下長什麼樣子?

50:30.760 --> 50:58.760
那我們這邊是一個簡單的例子,就是假設你有兩隻腳,呃,對不起,四隻腳,所以這樣的話就是你可能的terminal node就是第一天、第二天、第三天、第四天,或者到最後一天就是fair2還是傳,所以就是第五天,所以總共有五種可能,那藍色的呢,是我們DynamicCH預測下的結果,那紅色的虛線這條呢,就是假設,喔,對不起,藍色的線其實就是我們用我們的理論說的,就在extensive form下的結果,

50:58.760 --> 51:27.760
那紅色的線呢,就是用normal form下玩出來的結果,那我們的理論預測呢,就是不論你在哪裡玩,不論你的C跟S長什麼樣子,你永遠會看到這樣的關係,就是藍色的線是在紅色的線的上面,所以今天呢,就是不論你的,呃,distribution of levels長什麼樣子,你所移動的只是藍色線跟紅色的線的相對位置,呃,的絕對位置,但是相對來說,藍色的線永遠要在紅色的線上面。

51:28.760 --> 51:56.760
所以這個是我們的理論預測,如果說用直觀上來說的話,就是每一個玩家,就假設說我今天是用extensive form game給你玩的話,他會更接近均衡,in a sense that就是他們會更早的決定去take,那所以就是我在這邊我要再稍微再講一下,就是就是為什麼這個東西就是第一個是為什麼他實驗可測,就是因為說當我現在做實驗,我在同一個受試者群體,我去randomize,

51:56.760 --> 52:09.760
我可以,呃,就是一部分的人用normal form玩,一部分人用extensive form game玩的話,這條藍色的線跟紅色的線就直接是我們理論所就直接是資料所看到的東西。

52:10.760 --> 52:23.760
接下來,當我們看到這個之後,我們就是有很多的,呃,呃,呃,就統計工具就可以說,藍色的線是不是跟紅色的線是有顯著的差異,而且我們可以看的說是,他們兩個是不是有FOSD的這個差異。

52:24.760 --> 52:52.760
所以這個是為什麼我們說,就是我們的實驗結果是可測的,然後在第二件事情是,這個理論預測為什麼他對於實驗學家非常的好,同時也對我們來說的理論來說是一個壓力測試,就是因為這個理論他一開始他雖然就是有很多parameter在裡面,可是最後我們的statement居然是parameter free的,就是不牽涉於任何的函數,不牽涉於任何的參數,所以唯一的要求就是我在同一個受試者群體下我做randomization。

52:52.760 --> 53:07.760
這就代表說,你身為一個實驗者,你可以隨便的挑一個C跟S,所以這個時候你可以挑說,我可能武功我要十隻腳,我要二十隻腳,那我的C我想要挑今天是0.5,就一次長半個,我也可以挑0.7、0.8。

53:08.760 --> 53:22.760
在這些情況下,唯一改變的就只是藍色跟紅色的形狀,可是他們還是那個相對位置,永遠都在這裡,永遠都是藍色的線在紅色的線上面,所以代表說對於實驗者來說他有很大的自由度。

53:22.760 --> 53:37.760
而且再來是因為他是對於每一個distribution都對,就代表說我這個實驗我拿到台灣做,或在歐洲做,或在美國做,他都要看到這個,所以也就是說我們理論提供了一個非常強的理論預測。

53:38.760 --> 53:57.760
那他雖然非常非常就是說,在任何一個地方他如果做錯的話,就沒有辦法呈現我們的結果的話,可能就否證了我們的理論,可是換句話說是,如果說我做這個實驗,我可以發現這個FOSD,就是居然可以驗證我這個強的假數的話,代表說對我們這個理論又是一個,算是一個非常非常大的支持了。

53:57.760 --> 54:20.760
那所以這個的話就是,這個算是,這個我們在paper裡面有不同的statement,不過這個是一個比較一般化版本的一個statement。那接下來因為我想時間差不多了,所以我可能就稍微總結一下,那我可能就稍微總結一下,然後我們就再留點時間QA好嗎?如果說大家有問題的話,我們可以在會後,就五分鐘之後我們可以稍微聊一下。

54:20.760 --> 54:41.760
那接下來稍微我們結論一下,就是我們這顆模型到底做了什麼事?就最重要的一個訊息就是說,當你看到別人過去做的行為的時候,他其實除了告訴你現在遊戲進程到哪裡,他其實還告訴你別人可能他到底能夠想幾層,這個訊息其實也被藏在別人的過去的行為裡面。

54:42.760 --> 55:00.760
那接下來如果說,我們直接套用任何的靜態模型,不論是level K或者是CH模型的話,他其實會發現就是,我們的想法跟我們所看到的行為可能會發現不吻合的情況。那所以這個時候呢,我們就使用了我們的,我們提供了新的模型,來解決這個incompatibility的問題。

55:00.760 --> 55:15.760
那對於就是如果說這邊有做CS計算的人的話,我們可以去想說,這是這可能腦子裡面可以直接想到的問題是,我們這個東西到底好不好解?那其實我的回應是,就是我們的模型是在對電腦來說是一個非常非常好解的東西。

55:15.760 --> 55:34.760
理由是,他的code其實是可以用一個for loop重新寫的。就等於是說,我在每一個level的人,他其實是用同樣的法則在做事情。我在解這個模型就是,我先想level 1的人,他假設所有人都是level 0,然後我就去解level 1會最好做什麼事情。

55:34.760 --> 55:51.760
那接下來level 2的人,他會看著level 0跟level 1在做什麼事,然後我說ok,我就先解說這些人在做什麼事,然後我去更新我的belief,然後我就挑說我在每一個地方最好的行為是什麼。那接下來level 3的人,就假設別人是level 0、level 1、level 2,然後做一樣的事。

55:51.760 --> 56:15.120
所以說他其實是一個recursive的定義方法,在數學上是非常非常好解的,在電腦上是非常非常好算的。可是相對於均衡模型的話,他其實在解一個固定點的問題,因為你所有人必須要同時respond to each other。所以這個時候就等於是,你很像是有好幾條方程在解。所以這個時候就是,你可能一開始其實條件選得不好,你可能收斂性就會有問題。

56:15.120 --> 56:22.400
可是在我們的模型的話,in general它是唯一的,而且它存在,而且它非常非常好解。所以這是一些比較好的property。

56:23.360 --> 56:34.080
我們在文章的另外一個部分是,提出了一個非常強的,而且在實驗上是可以被否證的一個理論預測。

56:34.080 --> 56:55.840
就是說,我們假設說,在同一個數字的群體,你用extensible game玩,或者是normal form game玩,這個無攻賽局,我們會發現說,extensible下,所有的玩家應該會拿得比較早,而且是in the sense of FOSD。這個地方是對的,任何sensibility game都要對,而且是在任何地方都要對。

56:55.920 --> 57:05.600
所以這是一個非常強的假設,當這個假設是能夠的理論預測,所以當這個預測是能夠被證明的話,那代表說對於我們的理論是一個非常非常大的支持。

57:05.600 --> 57:21.120
那最後面就是一些未來的展望,跟可能可以接下來的延伸。首先第一個就是實驗,就是現在就是我正在跟我的老師,然後還有台大的王道宇老師正在思考說,我們怎麼去設計一個實驗來驗證我們這個很強的prediction。

57:21.360 --> 57:35.440
那接下來理論的話就是,至少第二點就是理論是我現在正在寫的第二episode,就是有關於同樣的模型的情況。那這邊的話,在第二篇文章我可以稍微簡單講一下,不過時間不多,我就不能多講。

57:35.760 --> 57:59.360
在這邊我們還可以再更深刻的去思考一件事就是,假設今天在這個遊戲,你會有一個不完全的資訊,就很像是玩德州撲克的話,你所有的資訊就是你手上的兩張手牌跟桌上的盒牌是什麼,可是你並不知道玩家的手牌是什麼。

57:59.680 --> 58:11.680
所以在一般的賽局理論下,我們只會預測說,當我在別人權利要過,或者說決定要加注的時候,我去更新別人的手牌,到底長什麼樣子。

58:12.560 --> 58:31.200
那可是呢,如果說今天是在我們的理論下,在別人要加注,或者說是要決定要fold的時候,你可不可以同時去update別人到底是不是一個很高配的玩家。所以如果說別人沒事就亂加注,你很有可能就知道說,哎,我根本不用管他的底牌,反正這個應該是一個level 0。

58:31.280 --> 58:52.560
所以有關這件事情的話,在現在的理論,它其實是已經有building在裡面,不過它其實並不太tractable。所以現在我正在寫一個更新版的理論去討論這件事情,然後預計是再過兩個月要用這篇,要用第二個blueprint去考我的候選人,然後接下來還有其他的application。

58:53.280 --> 59:12.720
其實我們這個理論是一個非常非常general的設定,它其實可以被應用到很多的地方,舉例來說像social learning,像這個可能就是像進家財是做的東西。像social learning可能就像說,你每次都經過一家餐廳,你從來沒有進去吃過,然後你也不確定這個餐廳到底好吃還難吃,你只有看到的是永遠都是有一群人在排隊。

59:12.880 --> 59:38.080
像這個時候,一般的理論可能就像說,哦,別人在排隊,那可能我只用別人在排隊這件行為來更新說,這家餐廳到底好不好。可是很有可能是,如果說你看到這家餐廳的情況,就是每次都在排隊,可是你自己有去看yelp的情況,就是,欸,可是很多人都說不太理想啊,那所以這個時候你是不是要更新你的belief說,那些在排隊的人很有可能是level 0的去找吃飯的人。

59:38.080 --> 59:53.080
這就表示說,他們的行為其實並沒有想太多,就是在排隊,別人跟風排,就不見得說真的是這個東西有多好吃。所以這個時候,如果說當我們的模型應用到像social learning的情況,可能會有這樣的類似的情境發生。

59:53.080 --> 01:00:14.960
那接下來當然也可以應用到政治學的情況,就像是投票,比方說你可能在看到一個候選人出來,那候選人其實很像是跟選民在玩一個game,就候選人不斷的去提政見,然後最後voter決定說到底要投他還是投給另外一個人。所以很有可能是在過了他提出一些政見之後,你去update說,欸,這個候選人他可能其實是一個level 0的候選人,大概是這樣。

01:00:14.960 --> 01:00:33.160
然後接下來還有可能像應用在談判的情況啊,所以就是blah blah blah blah blah,任何當時要輪流出招的game下,就是我們的理論其實都適用。好,我想我今天就先講到這裡,就非常謝謝大家今天的參與,然後就是大家可以就是email我,就是有任何問題的話都可以找我聯繫。

01:00:33.160 --> 01:00:55.440
然後呢,就是因為這篇文章其實已經算是寫完了,然後現在正在就是,就已經preprint了,所以就是要看draft的話,就是可以在我的網站上可以找到,然後就是這個投影片的話我也會分享給大家,就我也會放到網站上,所以大家可以去看。然後接下來這個,因為這個演講是有錄影的,所以在projectira上也可以找到錄影,所以就今天先講到這邊,就謝謝大家。

01:00:56.440 --> 01:01:11.440
謝謝國勳,非常精彩的演講,尤其是你提供了非常具象化的解釋,幫助我確立自己的邏輯,然後我想應該,不知道是我錄影嗎?還是就是那個麥克風有點回音回音的?

01:01:11.440 --> 01:01:17.440
回音嗎?現在還有嗎?我不知道,其他人有嗎?我是聽不太清楚。

01:01:17.440 --> 01:01:19.440
聽起來很像變形金剛啊。

01:01:19.440 --> 01:01:21.440
好的,我先拿掉麥克風。

01:01:26.440 --> 01:01:30.440
好,現在應該有比較好一點。

01:01:30.440 --> 01:01:51.440
好,對,好,那我再重新講一次,就是非常謝謝國勳的演講,尤其是你提供很具象化的解釋,幫助我理解你的理論模型,那我想因為我們剛剛在過程之中其實有開放一些QA的回答,所以我們現在因為還在錄影中,所以我們可以再開放幾個問題。

01:01:52.440 --> 01:02:01.440
我想QA的時間我們就分成兩個部分,第一個部分就是維持在錄影,第二個部分我們會把錄影關掉,然後我們就會閒聊時間。

01:02:01.440 --> 01:02:09.440
所以現在在錄影的過程中,不知道有沒有觀眾想要提一些問題,那就可以自己看麥克風。

01:02:10.440 --> 01:02:19.440
剛剛這邊也有人在留言區問到說,你說是In-N-Out漢堡嗎?我說是,我的回答就是是。好,謝謝,謝謝你的提問。

01:02:20.440 --> 01:02:32.440
我也提一個問題好了,刷一下存在感,就是我覺得你提了很多具象化的解釋,所以真的很幫助我。

01:02:32.440 --> 01:02:44.440
那我其實有一個問題就是你剛剛在最前面講到的那個猜數字的遊戲,那其實在那個猜數字的遊戲裡面,我感覺它的本質好像有點像是Player之間其實是沒有競爭關係的。

01:02:44.440 --> 01:03:08.440
那在後面的這個蜈蚣遊戲,我說的沒有競爭關係,只是說我只要努力的去猜到正確的數字就好了嘛。那其實後面的那個遊戲,蜈蚣遊戲的話,它就是有競爭關係的了嘛,就變成是我一定要猜到你不會拿到,你不想要在這一局收網,你還足夠貪心。

01:03:09.240 --> 01:03:18.440
所以我覺得這兩個遊戲之間好像有一些本質上的差異,所以我不太確定,這可能是一個clarification的問題啦。

01:03:18.440 --> 01:03:31.440
不過其實,非常非常謝謝你的提問,這兩個遊戲其實確實是有一些不一樣的地方。首先第一個就是,一個是無光字輪流出招嘛,然後猜數字的話它是同時出招的,那首先這是第一個點。

01:03:31.440 --> 01:03:51.440
然後再第二個是,確實就是說,因為當你是同時出招的情況下,它的競爭要說不是那麼激烈也可以,不過最後贏家還是誰最接近誰就贏嘛,某種程度上也是一個最接近的人才贏。

01:03:51.440 --> 01:04:14.440
不過它的問題是這樣,它的payoff不會因為你做了什麼事情而payoff長大,贏就贏,輸就輸。可是你在無光裡的話,如果說當你們兩個一起去傳,就你們兩個決定去……某種程度上是先說好的,我們先一起傳個十天,然後再開始玩這個遊戲的話,確實某部分上是可能合作,不過也有人可能會作弊說,我就決定先投拿了。

01:04:14.440 --> 01:04:22.440
所以確實就是,某種程度上在兩個遊戲下的思維可能會不太一樣,不過就非常謝謝您的提問。

01:04:23.440 --> 01:04:40.440
主持人問道:"對,因為感覺好像前面的猜數字遊戲,它的解答是固定的嘛,那後面的那個無光賽局遊戲,它的解答不是固定的,它是隨時隨地跟著另外一個人在更動的嘛,所以我覺得我不知道這兩個差異會不會對你的模型的設定上面是有影響的?"

01:04:40.440 --> 01:04:52.440
其實不是很會,因為我們模型是定在非常general的情況。不過講到這個解的這件事,如果大家有興趣的話,可以在下面留言區刷一排,你所選的數字嘛。

01:04:52.440 --> 01:04:59.440
害羞也沒關係,我們也可以在錄影結束之後再來聊說你選了什麼數字,我是蠻好奇的啦。

01:05:22.960 --> 01:05:41.940
主持人問道:"問題是這樣,你做一個假設,這個假設就是在參與這個遊戲的人,他們都會做最理性最佳的選擇,那他真正的限制條件就是他不夠聰明,或是說我們講他思考的深度有限,

01:05:41.940 --> 01:06:01.320
可是就像高雄人講的,你怎麼知道當你真的要implement這個實驗給一群人的時候,不會有來惡搞的壞份子,或是他故意要不遵守規則,或者是他昨天家裡出事了,所以他的行為選擇很奇怪,之類之類的。

01:06:01.840 --> 01:06:18.400
這個東西會不會是一個有趣的probe?可不可以拿你想要implement的實驗來反之,如果我今天測到了與理論不合的,我可以去probe說,這群人可能遭受了比如說他家打仗之類的,或是一些選擇行為的probe?"

01:06:19.400 --> 01:06:46.780
主持人問:「那我先第二個回答,非常感謝您的問題,聽起來有點鬧,不過它其實是非常非常認真的問題,首先第一個就是,我們的理論其實並沒有說,你可以姑且說它可能是設定上的缺失,或者說是模型的feature,就是說我們的唯一的限制就是在說,唯一他選不到那個地方的程度並不是因為他出錯,而是因為他的腦子沒有辦法想那麼多。

01:06:47.020 --> 01:07:10.160
所以今天當遇到說,可能有像其他情況是,他有些人是故意在武功裡面不斷一直傳下去,那很有可能在我們的模型裡面他是一個level0的人,不過當然就是說,你也可以去寫說,就是有另外一種type的人,他就是喜歡一直傳下去,所以他的決策行為就是不斷的傳,遇到哪裡就傳,所以就是我們這個模型它其實比較像是一個方法論,

01:07:10.160 --> 01:07:25.460
所以當然可以延伸說,我可以加入其他這種比較瘋狂的類型的人到裡面的話,我們這個模型也是適用的,就是單純重新改寫說到底有多少type而已,我們這個模型比較像是一個方法論上的突破,所以這個是可以的。

01:07:25.460 --> 01:07:52.560
剛才有關於detect他們到底是出什麼錯的情況下,其實我可以稍微講一下,其實在實驗經濟學上是有人在思考這件事的,有人在思考說,我是不是可以用一些舉例來說,我們有一個遊戲叫做獨裁者遊戲,像今天我跟你玩遊戲,我有一百塊可以分,我決定我要分給你多少錢,就是你沒得說,就是我給你多少錢就多少錢。

01:07:52.720 --> 01:08:21.900
我們可以某種程度上用這樣子,就是他去分多少錢給對方,去看說他到底是對於其他人的other guiding preference怎麼樣,就是對於社會公平的程度的偏好長怎麼樣子,就可能是有用其他的環境去,確實有想要去量說他對於這件事情,就是試著去detect說他對於社會的偏好長怎麼樣子,又或者說是可能像是說,像另外還有一個遊戲叫做最後通牒的賽局。

01:08:21.900 --> 01:08:51.880
比方說可能是,這個遊戲非常一樣,比方說第一個人還是決定說,我有一百塊,我要給你多少錢,那第二個人就決定說,他要接受這個offer,或者是不要。那所以這個時候就是,如果說他不要的話,就是每個人都不拿東西,那如果說他接受的話,那就用這樣的分法,所以我們也可以用說,就是在這樣的遊戲下,他到底會分給別人多少錢,跟別人到底會不會接受這件事情,來去看說他對於別人的想法到底長什麼樣子,就確實就是說,至少在無功賽局的話,可能不是一個這樣子類型的一個遊戲。

01:08:51.900 --> 01:09:10.060
不過確實是有其他遊戲是試著要去detect說,就是他們除了策略性思考之外,其他的偏好長什麼樣子。先聊到這兒,不過感謝提問,還有其他問題嗎?或者說我們可以就是不錄影之後,事後閒聊也可以。

01:09:22.300 --> 01:09:51.320
你好,我是劍橋大學的黃飛揚,我是在做神經經濟學。我有兩個問題,第一個比較像是說,應該算是你的延伸,就是說因為看起來你的模型會取決於,好像就是假設說這個人他很明確知道自己是level級,那有沒有一種可能是他不確定他自己是level級,然後甚至是一個distribution,聽起來應該也是可以有這樣的延伸。

01:09:51.400 --> 01:10:18.200
因為我自己會感覺,實際上的受試者他也有可能不確定自己在哪裡,這是第一個問題。第二個問題是比較technical,實際上的問題就是,你的預測是預測說,extensive game他都會比normal form的game來得早拿嘛,那我想問的是說,實際上在實驗上你要怎麼證明FOSD?

01:10:18.200 --> 01:10:35.780
因為你就算窮局,你也只能approach,就猜他可能是接近FOSD,因為你找不到反例也不代表他不存在嘛,所以實驗上要怎麼樣的程度會讓你確定說你的推論是正確的?

01:10:36.780 --> 01:10:59.980
好,首先這兩個問題都非常好,非常謝謝你的提問,我們先一個一個來好了。第一個,第一個就是,你講的那個technical的點是,我覺得完全同意你,因為畢竟我們現在這個東西算是在extensive form裡面算是第一篇這樣子的做法的一個東西,所以確實我覺得現在的延伸是,這個是完全可行的。

01:10:59.980 --> 01:11:29.960
那這樣子,其實我所知道的就是,像有些人在normal form game下的做法,現在比較新的做法比較像是這樣,就是說,每個人他雖然他可能他在每個遊戲下他玩出來的level他是不一定的,就是他確實可能是在每個遊戲下玩的是不一樣的,可是每個人他最後有一個capacity,就是說,不論我多聰明,可是我就是還是玩到一個程度,可是就是基於不同的遊戲,然後可能玩到不同的人,就對到不同的對手的話,我有不同的belief。

01:11:30.480 --> 01:11:59.040
那這樣的話,就是我可能展現出來的level是不一樣的,所以這個是一種,另外一種延伸,不過像像你剛剛提到的是另外一種做法,就是說,就是我可能不太確定說,我今天我的level到底是多少,所以等於是說,你在玩遊戲的過程,你同時會學到好幾件事情,第一個就是你會學到你自己到底有多聰明,第二個是別人到底有多聰明,然後再來是如果說有不完全的資訊的話,就是別人的不完全的資訊到底長什麼樣子。

01:11:59.040 --> 01:12:28.900
所以如果說今天是這樣的話,就是這在你的模型設定下,是可能會學到很多的事情,不過我覺得是會完全是可行的,對,就是我覺得這是一個非常非常有趣的延伸,不過因為這邊就像剛說的,就是只是因為是example的第一篇了,所以就我們只是想先先demonstrate說,就是我們這樣做是是數學上是可行的,對,不過非常謝謝你的第一個提問,然後接下來,呃,聊一下第二個,第二個的話是,呃,就有關於實驗上,我覺得你講的雖然是,呃。

01:12:29.820 --> 01:12:54.520
呃,怎麼講呢?算是對的,就是說我們確實就是只能再說就是給定,就是我們算這個FOSD這個關係是在,呃,怎麼講呢?就是說,再給定一個無攻賽局的話,就是會對,應該說給定任何一個無攻賽局下都會對,可是就是我們能做的可能就只是是,呃,確實啊,你要說窮局,當然也不一定對,可是某種程度上是我們可以去想說。

01:12:55.240 --> 01:13:23.160
去挑些比較極端一點的case,就像說,如果說很接近三分之一或者很接近一的話,那這樣的話就是,就是我們只能,我們確實就是只能做的事情是,就是我們盡力的去挑一些很極端的case,如果說在這些case下,他都有展現出來,就是就至少我們看到那個實際上,因為藍色線和紅色線這兩個CDF是是實驗上可以直接觀察到的一個經過,所以如果說我們在不論在各種極端情況下,呃。

01:13:23.160 --> 01:13:53.120
呃,不不論在各種情況下,極端情況下,我們都看到藍色線和紅色線有這樣子這樣子上下的關係的話,那或許我們可以就只能說我們只滿足了一個必要條件,但這並不代表是一個充分條件,我想我想你說的是一個像這樣的東西,就確實我們就只是單純是在就是我們挑了一個C或S的話,那單純就這個只是驗證說,哦,這個必要條件滿足了,那充分條件不一定會對,可是就是我們能做的就在實驗,實驗上我們最好做的最好就是說。

01:13:53.160 --> 01:14:23.120
去很像是去怎麼講,去試著否證我們的模型,就如果說我們自己盡全力都沒有辦法否證的話,或許可以說就是我們的模型是對的,不過到底有多對,就是確實是需要更多更多的的怎麼講呢?去說明嗎?因為畢竟你在很多情況下就是你在驗證模型的時候,你只是在驗證他能夠被test的prediction嘛,所以這樣的話就是你很某種程度上都是在去基於模型導出來的一些結果,然後去看說他到底會不會滿足這件事情,就很像在驗說他的他的必要條件。

01:14:23.360 --> 01:14:43.360
如果這件事情不對,那模型者被反制。不過我覺得你問的問題都都非常好,我不確定我回答的到底好不好啦,就非常不好意思,不過非常謝謝你的提問,我不知道有回答到你嗎?還是,對,非常非常謝謝,如果說如果回答的不好,可以在在事後再跟我再跟我聊,沒問題,謝謝,謝謝提問。

01:14:43.360 --> 01:15:04.000
主持人:「謝謝博軒,那我馬上就關錄影了,那在關錄影之前,博軒你有沒有想要做最後的correctification,因為其實可能會有未來的潛在觀眾會看你的影片,所以你有沒有想要做最後的詮釋或concluding remark?」

01:15:04.320 --> 01:15:25.640
博軒:「哦,我覺得好像,謝謝給我這個機會,不過我覺得我好像都,聊的好像都差不多了,因為主要是,對,我覺得我聊的都差不多了,對對對,對,不過就謝謝,如果說有未來的觀眾要看的話,就非常非常謝謝,然後就是,對,就非常謝謝你的收看,沒有,沒有,沒有必要。」

01:15:25.640 --> 01:15:27.880
主持人:「謝謝博軒,那我現在就關錄影。」

