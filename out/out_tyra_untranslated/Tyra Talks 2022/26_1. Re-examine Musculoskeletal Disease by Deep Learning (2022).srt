1
00:00:00,000 --> 00:00:25,000
好,那很欢迎大家来到今天的Taiwan Talk,今天是1月8号,我们今天很高兴呢,到张翰,他目前呢是在台湾大学服务,他的PhD是在美国University of Massachusetts Amherst,然后PhD后来呢他在Boston进了一家生技产业,

2
00:00:25,000 --> 00:00:45,000
然后后来呢又到了Boston University,就是BU的医学院,就是School of Medicine,做博士后研究,然后在2021年的时候呢他回到台湾大学,在医材影像所担任助理教授,今天呢我们很高兴有他来演讲。

3
00:00:45,000 --> 00:01:01,000
那Taiwan的小小的传统就是呢,我们会请大家把麦克风打开,然后拍手,欢迎我们的讲者,那现在欢迎我们的讲者张翰老师。

4
00:01:05,000 --> 00:01:09,000
好的,那可以share screen了。

5
00:01:15,000 --> 00:01:17,000
有看到吗?

6
00:01:35,000 --> 00:01:37,000
有看到吗?

7
00:01:37,000 --> 00:01:39,000
可以看到了。

8
00:01:39,000 --> 00:01:44,000
好,那也谢谢您介绍。大家好,我是张翰。

9
00:01:45,000 --> 00:02:02,000
我刚刚所说,我是2016年博士班毕业的,然后之后是辗转几个单位,就是有一些新创公司要去博士后,然后我是去年2021年的时候回到台大做助理教授。

10
00:02:02,000 --> 00:02:12,000
我记得Tara一开始申请,我记得表格说什么会员有每年一次报告研究之义务,然后我这件事情一直记在心里。

11
00:02:12,000 --> 00:02:22,000
我回台湾之后基本上就很少上线,因为都起不来,所以想说还是要贡献一下。

12
00:02:22,000 --> 00:02:42,000
今天也没全省,不过就是来跟大家聊聊。主要目的还是跟大家分享一下,另外也是如果大家对回台湾的环境有什么问题的话,我们等一下可以再讨论一下。

13
00:02:43,000 --> 00:03:09,000
我自己实验室是做号称AI影像的分析,我本来做博士后的时候是做肌肉骨骼影像,主要治疗标的是退化性关节炎,另一方面就是回台湾之后又找一些其他的合作项目,包括脑科学跟线外影像等等。

14
00:03:09,000 --> 00:03:25,000
等一下我有时间的话会稍微讲一下。AI这件事情可能是大家听演讲,每两周就会听到一次,所以介绍性的话我就很快带过去了。

15
00:03:25,000 --> 00:03:43,000
大家知道AI在过去的五年、十年大概发展很快,很多影像辨识、分类、政策等等的表现超过人的标准,大概是最近几年发生的事情。

16
00:03:44,000 --> 00:04:02,000
如果你看脑科学的话,比较旧的Letter,他们都会说图像辨识、人脑、电脑这些超过,可是假设你们再看一下Letter,可能五年内的话他们就会改口。

17
00:04:02,000 --> 00:04:10,000
所以这个改变是最近几年的事情,可能大家都在自己的领域会感受到了。

18
00:04:10,000 --> 00:04:30,000
在艺术影像上,影像上的modality是一个非常非常缓慢的过程。大家可能听过Hobart有一个Gordon Center,Gordon Center是影像中心合作PathGen的发明人,就是Gordon跟Charles。

19
00:04:31,000 --> 00:04:45,000
他们做的是PathGen的前身,基本上原理其实是差不多的。他们的影像解析度的lower boundary是跟现在是一样的。

20
00:04:45,000 --> 00:05:00,000
所以在艺术影像上的modality是一个非常非常慢的过程,通常都是几十年。通常都是几十年的adaptation要implement,然后被定创大规模使用。

21
00:05:00,000 --> 00:05:17,000
所以有时候这一个领域或者AI有兴趣,不是因为,是不得不然,是因为发展太慢了。所以看到新的工具就赶快想利用看看,看到什么改变机会。

22
00:05:17,000 --> 00:05:33,000
基本上Machine Learning或Deep Learning这些东西,它的功能就是找一个function,好比说我们可以做一个function去看图像,可以做分类。假设自然影像的话,分类就是分车子,分猫狗之类的。

23
00:05:33,000 --> 00:05:51,000
马上就有人想说,我可不可以做诊断,所以分类在艺术影像的对应就是诊断嘛,好比说一把子hammer,就是calculation。像detection,大家做生物实验的话就发现鼠细胞这件事情是非常古老的labor。

24
00:05:51,000 --> 00:06:06,000
那detection的话,假设自驾车的话,就是数行人,数别车等等。基本上一样的idea就是做一个function,然后放进slide,就会数细胞等等,这是侦测。

25
00:06:06,000 --> 00:06:29,000
最后就是切割,切割就是在艺术影像上面也是使用关节的各部分,或者把器官切割出来。基本上就是你有想做的function,你有一个input,你有一个output。Machine Learning就是用自我最佳化的方式去把这个function找出来。

26
00:06:30,000 --> 00:06:54,000
我自己做的题目是ulcerocytes,就是退化性关节炎。这是很老的疾病,就是老人的疾病。大家可能听到第一波的AMS,可能听到比较有名的,好比说糖尿病DMD影像,好比说oncology,就是癌症的肿瘤分割政策,还有cardiovascular。

27
00:06:54,000 --> 00:07:19,000
这些当然就是因为这些疾病在美国是大课,假设我们数致死率的话,最前面是oncology和cardiovascular,就是因为需求而产生的这些情绪。我自己做ulcerocytes,它是退化性关节炎,它没有什么直接致死的passway。

28
00:07:20,000 --> 00:07:38,000
如果你看美国第一名造成失能,disability的话,第一名就是ulcerocytes,就是一切关节炎。那里面大概三分之二是ulcerocytes,其他是免疫性关节炎。

29
00:07:39,000 --> 00:07:53,000
第二名通常是背痛,我们国外很常会背痛,所以背痛也大大造成是很常见的。所以基本上这些肌肉骨骼病病人在造成disability在美国是非常非常常见的。

30
00:07:54,000 --> 00:08:04,000
如果我们看开刀又花钱的话,通常数一数二的就是第一个是spine infusion,就是治疗脊椎,第二个就是replacement。

31
00:08:05,000 --> 00:08:19,000
所以基本上这些肌肉骨骼的疾病,它如果不开刀的话就造成很多的失能。假设它开刀的话就会有很大的花费。

32
00:08:20,000 --> 00:08:30,000
我们大家知道台湾是老化社会,这是第一个特性。第二个是台湾什么事情美国发生,台湾五年后就会发生。

33
00:08:31,000 --> 00:08:46,000
这些事情对社会成本和社会健保的负担是会一增加一增加的增加。数数字就知道了,不需要看什么forecast,数数字就会负不起。

34
00:08:46,000 --> 00:09:00,000
比方台湾的话,像这个new placement在美国也算是蛮贵的手术,成功率很高。台湾也算是一个一定要付但是非常昂贵的手术。

35
00:09:01,000 --> 00:09:11,000
所以怎么用一些方式可以让病人不需要进入到社会分解的pathway其实是蛮重要的。

36
00:09:12,000 --> 00:09:24,000
基本上,如果我们想说什么样的原因会造成病人需要换吸管,基本上就是疼痛难当,就是疼痛无法忍受就会换吸管。

37
00:09:25,000 --> 00:09:43,000
大部分人都会忍受自己失能,就好比说这个关节炎有好几个symptom,可能一开始会活动能力受限,要conquer stiffness,最后可能会疼痛。

38
00:09:43,000 --> 00:09:55,000
那其实stiffness或是活动能力受限很多人可以忍受,大家在美国大家知道吧,可能坐这个代步车就可以走一走去了。

39
00:09:55,000 --> 00:10:18,000
那疼痛是无法忍受的。所以病人为什么最后会做开刀的决定,通常都是有一个pain spike,就是在要开刀之前,如果我们回顾他每年的function是怎么发生的话,都会有一年或两年前是突然疼痛增加了。

40
00:10:18,000 --> 00:10:33,000
疼痛一增加,然后无法忍受,就跑去开刀了。如果疼痛是慢慢增加的话,大家知道耐痛是可以慢慢习惯的,反而还可以撑比较久。如果有一个pain spike的话,通常就跑去开刀了。

41
00:10:33,000 --> 00:10:50,000
那会造成什么原因造成疼痛增加呢?如果我们直接画那个coalition是一个OA的定程,它叫KO grid,是一个OA的rheographic,就是X光上面的平分的话,那基本上跟疼痛是没有什么关系的。

42
00:10:50,000 --> 00:11:07,000
很多人,好比说大家听到的那个NBA球员,有人没有软骨,然后还是可以打球,然后有人是膝盖正常,但很疼痛,所以基本上传统上的rheographic的关节点的平分跟疼痛没有关系。

43
00:11:07,000 --> 00:11:29,000
所以先假设我们要研究这个OA是什么造成疼痛的话,传统上我们就是找到那边的人,可能像美国的话就OA付钱做trial,然后把这些MRI都拍下来,然后接下来要找医生去做grading,大家都很熟悉嘛。

44
00:11:29,000 --> 00:11:41,000
基本上OA这些影像判读是需要有经验的医生,专门要看膝盖和关节炎的,所以成本很贵。

45
00:11:59,000 --> 00:12:20,000
主持人员:"不好意思,不好意思,我小孩在重庆诶,不好意思。我请他妈来救援一下。

46
00:12:21,000 --> 00:12:38,000
所以基本上你得到的资料都是非常少,也不一定一致,因为这些grading工作很慢,所以大部分都是很多routing center协作完成的,所以每个人的标准不太一样。

47
00:12:39,000 --> 00:12:51,000
所以有时候统计分析的话,基本上过去效果都很差。所以这时候我们就讲到,有时候是需求决定了为什么要导入这些新的技术,是不得不然的。

48
00:12:51,000 --> 00:13:07,000
所以我们既然用传统方式的grading很困难,又很花时间,那我们就导入AI,直接就最后一步,我们就完全放弃了这些所谓的影像特征的grading,

49
00:13:07,000 --> 00:13:21,000
我们直接把你看到这些OA病变的MRI输到先进网络里面去,然后我们用的outcome就是我们想要看的地方。

50
00:13:22,000 --> 00:13:36,000
好比说以这个project而言的话,它的outcome就是疼痛,病人有多少疼痛,再加上疼痛有没有突然增加。

51
00:13:36,000 --> 00:13:51,000
所以这就是一个不再无法得知,或者本来就对什么样的病变造成疼痛不太清楚的状况下,使用这个方式。

52
00:13:51,000 --> 00:14:05,000
好处大家知道吗,就是它很一致,它是同一个模型去看一些东西,所以特别适合这种clinical trial,就假设你有一个很一致的cohort,全部资料都是用同样的方式拍的话,

53
00:14:05,000 --> 00:14:11,000
它标准的非常一致,它是自动的,所以只有你训练成功,它就没有成本。

54
00:14:11,000 --> 00:14:23,000
那这个处理这个图像的基本上deep learning的网络就是convolutional neural network,大家很常听过,就是全机神经网络。

55
00:14:23,000 --> 00:14:37,000
那它原理大概述下来,就是用一层一层的filter,大家做影像处理可能用filter,filter就是抓不同的特征,影像特征这样子。

56
00:14:37,000 --> 00:14:43,000
那因为我不知道什么样的特征是比较重要的,我就让它自己optimize,自我更新。

57
00:14:43,000 --> 00:14:53,000
那它就会照着这些方式层层更新,然后把这些影像处理成一些对结果的特征这样子。

58
00:14:53,000 --> 00:15:03,000
那通常这个trivial neural network有一个重大的缺点,就是它很难控制confounder。

59
00:15:04,000 --> 00:15:14,000
我们知道在医学上面,所有的事情都是影像加上confounder。

60
00:15:14,000 --> 00:15:23,000
比如说这个人会不会,可能会恶化,是他的影像加上体重,加上他的生活情况,加上这些人有没有受伤等等。

61
00:15:23,000 --> 00:15:42,000
所以我们做这个影像分析的时候,如果你把病人全部资料都丢进去,那虽然你想看到的是病人本身的影像,你想在影像上找到重要的特征。

62
00:15:42,000 --> 00:15:48,000
可是只要neural network有任何读到confounder的方式的话,它就会随着pathway过去。

63
00:15:48,000 --> 00:15:54,000
所以假设你的膝盖比较大,显然是体重比较重。

64
00:15:54,000 --> 00:16:03,000
那neural network看膝盖比较大的事情,如果它可以跟outcome有关联的话,它就看膝盖比较大,它就忽略其他一些因素。

65
00:16:03,000 --> 00:16:09,000
所以基本上deep learning的模型对confounder有很大的bias。

66
00:16:09,000 --> 00:16:15,000
其中一个最简单的方式就是对冲。

67
00:16:15,000 --> 00:16:21,000
你可以找两个有一样confounder的subject,然后让它互相抵消掉。

68
00:16:21,000 --> 00:16:27,000
比如说我可以选一批评论者,他可能是疼痛增加前或增加后。

69
00:16:27,000 --> 00:16:30,000
他同一个subject,所以他有类似的confounder。

70
00:16:30,000 --> 00:16:37,000
所以如果我把一个网络同时参考两个incidence的话,他们confounder就互相消掉了。

71
00:16:37,000 --> 00:16:42,000
另一个可能就是所谓的cross lateral,左右膝盖。

72
00:16:42,000 --> 00:16:47,000
有些人在刚恶化的时候,一个膝盖会先恶化。

73
00:16:47,000 --> 00:16:54,000
那通常久了之后另一个膝盖也会带长,也会追上来。

74
00:16:54,000 --> 00:17:03,000
可是是有一些incidence,你是可以抓在一瞬间就这些不平等的现象,那这时候你可以把左右膝盖当对照。

75
00:17:04,000 --> 00:17:07,000
这还有好处就是说,其实疼痛是主观因素。

76
00:17:07,000 --> 00:17:12,000
我们疼痛,大家可能去看过牙医,然后常常会填笑脸图。

77
00:17:12,000 --> 00:17:16,000
就是绿色的笑脸是0,然后黄色的是0。

78
00:17:16,000 --> 00:17:19,000
然后医生问你有多痛,然后你讲不出来。

79
00:17:19,000 --> 00:17:24,000
然后他问你说,如果是0到10,你有多痛,那你也讲不出来。

80
00:17:24,000 --> 00:17:30,000
这很奇怪,但是基本上这是一个主观回报的事情。

81
00:17:30,000 --> 00:17:40,000
但是如果同一个病人,他回报两边膝盖的话,他两边都是主观的嘛,他对疼痛的耐受程度是一样的。

82
00:17:40,000 --> 00:17:51,000
然后另一个可能是,假如他疼痛并不来自膝盖,就有蛮多病人,他们的症状是来自我们说的neurosystem,那这也是confounder。

83
00:17:51,000 --> 00:17:57,000
可是如果他同时回报说两个膝盖中有差异的话,那他回报就是疼痛的差异而不是疼痛。

84
00:17:57,000 --> 00:18:01,000
这件事也是一个控制主观因素的方法。

85
00:18:01,000 --> 00:18:13,000
所以我本来就有工作是拿这些疼痛跟不痛的膝盖,拿来做这些所谓的contracted learning,就是对照性的学习。

86
00:18:13,000 --> 00:18:21,000
然后想要把症状有差异的一边预测出来,显然结果就是比用医生传统判断方式好很多。

87
00:18:21,000 --> 00:18:38,000
大概多10%的AUC,AUC就是一个二分类的评分架构,通常本来就是60-70,用的方法可以做到85-90,所以其实本质就有差别。

88
00:18:39,000 --> 00:18:56,000
那另一个事情是说,Fockin常听到所谓的可解释性AI,是一个buzzword,所以SAI,Explainable AI,这是一个buzzword,其实你自己看定义什么的话其实很难讲。

89
00:18:56,000 --> 00:19:04,000
我们所谓Explainable就是对使用者是Explainable,就是那个使用人觉得是合理的,他就是可解释。

90
00:19:04,000 --> 00:19:09,000
所以基本上使用人想要什么,他就是什么。

91
00:19:09,000 --> 00:19:25,000
那传统上我们在医学影像上我们认为我们的使用者其实是医生嘛,所以表示我们模型要做出一件决定,那这个决定想要把它传达让医生觉得说它是合理的。

92
00:19:26,000 --> 00:19:45,000
那现在大部分的differentiate方式都是用saliency map,热区图,有很多争议,一般人认为热区图上面的热区,指向的地方没有太夸张的话,就表示它可能没有错太离谱,它可解释力没有错太离谱。

93
00:19:46,000 --> 00:20:01,000
那基本上这是一个很弱的条件啦,就是如果它热区图很离谱的话就可以排除,但是它如果对的话,也不一定是因为正确原因做正确的事情,它可能就是重叠在那边。

94
00:20:01,000 --> 00:20:04,000
基本上这些saliency map只有未知资讯而已。

95
00:20:04,000 --> 00:20:14,000
我们今天做的一些工作是想法改进这些热区图的解析度,可以让这些图可以把个别的病变分出来。

96
00:20:14,000 --> 00:20:32,000
这时候再回头问医生说,我们指出这些病变的位置有没有跟你图片中想的疼痛的位置是有可能的,可以用这个方法来探讨说是什么样的病变最有可能造成疼痛,然后跟医生的想法有没有合理这样子。

97
00:20:35,000 --> 00:20:46,000
不过这种方式有它的很大的限制,第一个它逻辑对不对大家都还在讨论,这种热区图方式能不能解释它是可解释的,大家都还在讨论。

98
00:20:46,000 --> 00:21:01,000
第二个,你这个也很难拿来定量,大家如果看热区图的话,它毕竟是interpreter来的,所以它形状其实没什么意义,它就是这些点做一个interpreter,然后就变成区域。

99
00:21:01,000 --> 00:21:16,000
可是你仔细看这些形状跟region形状有没有直接对应,其实是有问题的,所以你直接把这些高亮度的地方划成counter来统计,其实是无法定量的。

100
00:21:16,000 --> 00:21:37,000
假如不要夸张一点的话,假如看到一些脑肿瘤的热区图,那可能肿瘤在脑的边边,那热区就会一半在脑内一半在脑外在背景上面,所以它定位能力其实是很有问题的,有它的限制。

101
00:21:37,000 --> 00:21:51,000
有什么比较直观的方式可以做这些feature的运造工作呢?

102
00:21:51,000 --> 00:22:09,000
我大概想一下,如果有看医学影像的话,我们常做的事情就是比较。好比说一病人做疾病在追踪,医生可能看了他的新的影像,他恶化的话,那就是拿前一张影像来比较。

103
00:22:09,000 --> 00:22:25,000
假设他是做治疗的话,可能是本身的一张影像变好了,然后他也会拿旧的影像做比较。所以比较影像这件事情是人脑会自动拟合出来,这是人脑很神奇的功能。

104
00:22:25,000 --> 00:22:45,000
那其实我们今天对单张影像可以分析得很好,但是影像比较这件事情,其实人脑是有它独特的mechanism,然后我们电脑都还没有办法完全追上。

105
00:22:46,000 --> 00:22:59,000
今天假设说好,我今天有一个病人,他会有一个症状突然发生,所以一开始症状是进展比较慢,突然就恶化了。

106
00:23:00,000 --> 00:23:10,000
如果你是医生的话,你合理的做法是说,我看一下pain spike前后发生什么事情,所以就会把两张影像调出来。

107
00:23:11,000 --> 00:23:21,000
然后医生放左边跟放右边,脑中就自动拟合出两边的差异在哪里。那我们要怎么教电脑做这件事情?

108
00:23:22,000 --> 00:23:37,000
传统上的话,像我们刚刚做的所谓的判别式模型,是想法把左边跟右边这两个有疼痛跟没疼痛的影像区分出来。

109
00:23:37,000 --> 00:23:42,000
比较合理的方式是做这种比较式模型。

110
00:24:08,000 --> 00:24:11,000
大家可能还记得,也差14年了。

111
00:24:12,000 --> 00:24:20,000
所以我们看了这两个pair,就马上可以想说哪边是正常,哪边是不正常的老化。

112
00:24:20,000 --> 00:24:24,000
就显然左边是不正常老化,这不正常,这正常。

113
00:24:25,000 --> 00:24:30,000
所以人脑有神奇的功能,就是它可以看到影像的改变。

114
00:24:31,000 --> 00:24:34,000
然后我们脑中第一件事情,我们有两个pre-test。

115
00:24:34,000 --> 00:24:44,000
第一个是我们知道它同一个subject,这很重要,因为假设你不跟人说这个跟这个同一个subject的话,

116
00:24:44,000 --> 00:24:46,000
没人会拿来一起比较,他以为是两个不同的人。

117
00:24:46,000 --> 00:24:48,000
所以你刚刚说的是同一个subject。

118
00:24:48,000 --> 00:24:58,000
第二个事情是,你脑中对正常老化有一个概念,你知道说14年人大概会变成什么样子。

119
00:24:59,000 --> 00:25:07,000
那我们也可以用同样的方式去观察说,改变前跟改变后的医学影像。

120
00:25:07,000 --> 00:25:12,000
到底什么样的变化是正常变化,什么样的变化不是正常变化。

121
00:25:12,000 --> 00:25:19,000
这变化可以有很多种,你可以是ten-tone的progression。

122
00:25:19,000 --> 00:25:25,000
假设我们用一个统计模型来看说这个人未来开刀几率基于影像的话,

123
00:25:25,000 --> 00:25:32,000
那我们也可以问说,假设同一个病人他的toA跟toB突然他的开刀几率变很高了,

124
00:25:32,000 --> 00:25:34,000
那是什么样的事情造成他这样的差异。

125
00:25:34,000 --> 00:25:38,000
所以是一个比较差异的framework。

126
00:25:38,000 --> 00:25:51,000
所以就是,这件事情会成功,就是他从subject,脑中有一个所谓的正常的reference。

127
00:25:52,000 --> 00:25:57,000
那我们在做这件事情的时候,脑中是有正常的reference,所以你没有感受到,

128
00:25:57,000 --> 00:26:01,000
但人脑是很神奇的,会自动在背后处理。

129
00:26:01,000 --> 00:26:08,000
那我们今天要把这个用deep learning来拟合这件事情的话,

130
00:26:08,000 --> 00:26:12,000
那最直接的方式就是所谓的商场对抗网络。

131
00:26:12,000 --> 00:26:15,000
那大家可能也听过,商场对抗网络就是好比说,

132
00:26:15,000 --> 00:26:24,000
很多合成脸、合成video、合成声音等等的模型都是根据这些技术,是同一个family。

133
00:26:24,000 --> 00:26:28,000
它逻辑就是说,我今天有一个叫生成器,

134
00:26:28,000 --> 00:26:34,000
它生成器是可以拿图片当成它的condition,

135
00:26:34,000 --> 00:26:41,000
那生成器图片进去之后,它就会出来一张以input图片当成条件的图片,

136
00:26:41,000 --> 00:26:44,000
那它跟它之间有点对应的关系。

137
00:26:44,000 --> 00:26:46,000
那它生成条件是什么?

138
00:26:46,000 --> 00:26:54,000
它生成条件就是,你拿这个真的reference图片,

139
00:26:54,000 --> 00:26:57,000
然后它会拿这个当参考,

140
00:26:57,000 --> 00:27:03,000
所以整个结论是说,你的生成器会拿一部图片,

141
00:27:03,000 --> 00:27:09,000
生成一张跟reference图片很像的真的图片。

142
00:27:09,000 --> 00:27:14,000
所以我们的做法可以说,我们可以把要比较的对比的reference,

143
00:27:14,000 --> 00:27:16,000
就是real healthy,

144
00:27:16,000 --> 00:27:21,000
好比说,左右膝盖的话,你就是不要不痛的膝盖当成reference,

145
00:27:21,000 --> 00:27:24,000
不要痛的膝盖当成real disease,

146
00:27:24,000 --> 00:27:27,000
然后我们去合成出一个假的healthy。

147
00:27:27,000 --> 00:27:32,000
那这个差值就是比较差异嘛,

148
00:27:32,000 --> 00:27:36,000
虚拟同样的造型,它如果不痛的话会长什么样子?

149
00:27:37,000 --> 00:27:39,000
那在定义上我们叫counterfactual,

150
00:27:39,000 --> 00:27:41,000
就是假设性的一个case,

151
00:27:41,000 --> 00:27:46,000
这两个差异就会是我们想要看到的改变部分。

152
00:27:50,000 --> 00:27:53,000
另一部分就是所谓的healthy reference,

153
00:27:53,000 --> 00:28:02,000
就是我们脑中比较知道什么样的膝盖变化是正常的。

154
00:28:02,000 --> 00:28:07,000
那大概讲说我们要比较的这些reference应该不是18岁健康的膝盖,

155
00:28:07,000 --> 00:28:10,000
我们的OA是不可,是老化的疾病。

156
00:28:10,000 --> 00:28:14,000
所谓老化的疾病就是说,所有人都很老,

157
00:28:14,000 --> 00:28:18,000
所以有些影像上面的改变是正常的,我们需要接受,

158
00:28:18,000 --> 00:28:21,000
好比说我们看做那个Azheimer影像的话,

159
00:28:21,000 --> 00:28:25,000
这个老人的Azheimer影像都会有脑缩,

160
00:28:25,000 --> 00:28:27,000
可是脑缩是老人就会缩啊,

161
00:28:27,000 --> 00:28:31,000
并不是Azheimer他会缩。

162
00:28:31,000 --> 00:28:33,000
所以像Azheimer这个研究的话,

163
00:28:33,000 --> 00:28:37,000
很大一部分的目的就是要想要把这些正常老化跟不正常老化,

164
00:28:37,000 --> 00:28:40,000
所谓的Azheimer倒转老化来区分出来。

165
00:28:40,000 --> 00:28:42,000
那所以我们OA也是一样,

166
00:28:42,000 --> 00:28:47,000
我们并不是要把这些膝盖还原到18岁的完美状况,

167
00:28:47,000 --> 00:28:51,000
我们也没有这些影像,因为18岁不会去拍MRI。

168
00:28:51,000 --> 00:28:56,000
那我们要,我们的reference应该是正常老化,

169
00:28:56,000 --> 00:29:00,000
它是50,60,70,就该那样子,老就是会老,

170
00:29:00,000 --> 00:29:06,000
但是它要是function或是什么东西还正常的。

171
00:29:06,000 --> 00:29:12,000
所以像我们的话,我们就选说假设这些病人都是0致命OA,

172
00:29:12,000 --> 00:29:16,000
或是preclinical,就是还没有进入临床上的OA,

173
00:29:16,000 --> 00:29:18,000
然后也不会开刀,

174
00:29:18,000 --> 00:29:21,000
所以这些人我们就定义成他是所谓的健康老化嘛。

175
00:29:21,000 --> 00:29:28,000
那我们要,那我们的reference就是定义到把图拉到这些健康老化的状况上面,

176
00:29:28,000 --> 00:29:32,000
而不是一个真空中完全健康完美的膝盖这样子。

177
00:29:32,000 --> 00:29:37,000
所以这个好比说治疗前治疗后,

178
00:29:37,000 --> 00:29:40,000
然后好比说这个pain spike,control incidence,

179
00:29:40,000 --> 00:29:44,000
然后好比说不同的modality,

180
00:29:44,000 --> 00:29:47,000
这种比较性概念是一个很强的framework,

181
00:29:47,000 --> 00:29:51,000
因为我觉得这个在医学影像上,

182
00:29:51,000 --> 00:29:57,000
很多时候我们是凭借这个比较这些事情来处理资讯的,

183
00:29:57,000 --> 00:30:01,000
那基本上如果你去看诊的时候,

184
00:30:01,000 --> 00:30:03,000
要看医生做什么,

185
00:30:03,000 --> 00:30:05,000
其实很常这样发生的,

186
00:30:05,000 --> 00:30:07,000
就是左边一张右边一张,

187
00:30:07,000 --> 00:30:13,000
然后用比较来决定死因发生,

188
00:30:13,000 --> 00:30:15,000
所以这是一个很泛用的framework,

189
00:30:15,000 --> 00:30:19,000
并不只是在这个我目前做的topic上面。

190
00:30:19,000 --> 00:30:26,000
所以我们先拿一个正常的disease,

191
00:30:26,000 --> 00:30:28,000
然后产生说fit healthy,

192
00:30:28,000 --> 00:30:29,000
然后产生real healthy,

193
00:30:29,000 --> 00:30:36,000
那我们用一个回归器的方式,

194
00:30:36,000 --> 00:30:39,000
我们可以训练一个回归器,

195
00:30:39,000 --> 00:30:42,000
它就跟一般做回归一样,

196
00:30:42,000 --> 00:30:44,000
用图像做回归,

197
00:30:44,000 --> 00:30:48,000
那它目的就是要观察这些健康老化的器材,

198
00:30:48,000 --> 00:30:54,000
然后要观察说它的年龄长什么样子,

199
00:30:54,000 --> 00:30:55,000
因为这些也是健康老化的,

200
00:30:55,000 --> 00:31:01,000
所以它的预测出来的年龄就会是它本身的年龄。

201
00:31:01,000 --> 00:31:06,000
那做完之后如果拿这些同样的模型,

202
00:31:06,000 --> 00:31:08,000
去观察一些不健康老化的病人的话,

203
00:31:08,000 --> 00:31:16,000
就发现他的实际年龄会小于他膝盖的appearance age。

204
00:31:16,000 --> 00:31:21,000
那这个concept其实大家可能听过脑灵嘛,

205
00:31:21,000 --> 00:31:24,000
这个在其他分析中也常用到,

206
00:31:24,000 --> 00:31:27,000
或者说大家可能听过脑灵检测等等,

207
00:31:27,000 --> 00:31:31,000
就是有些人的脑看起来就是比他实际年龄老,

208
00:31:31,000 --> 00:31:32,000
这个脑灵检测,

209
00:31:32,000 --> 00:31:36,000
那其实也可以用同样的逻辑来做嘛,

210
00:31:36,000 --> 00:31:40,000
就是拿一个不同年龄的模型去看健康老化的老人,

211
00:31:40,000 --> 00:31:43,000
然后再回来看一些不同的病人。

212
00:31:43,000 --> 00:31:46,000
那有关脑灵这部分的话,

213
00:31:46,000 --> 00:31:47,000
台湾也有人做,

214
00:31:47,000 --> 00:31:48,000
国外也有人做,

215
00:31:48,000 --> 00:31:53,000
那还发现说不同的neurological disorders,

216
00:31:53,000 --> 00:31:54,000
还有不同的,

217
00:31:54,000 --> 00:31:56,000
就是他的年龄会有不同的shift,

218
00:31:56,000 --> 00:31:58,000
他的shift pattern还不一样。

219
00:31:58,000 --> 00:32:03,000
那又好比说大家看医生的时候,

220
00:32:03,000 --> 00:32:09,000
如果大家去见检的话,

221
00:32:09,000 --> 00:32:10,000
常常被问说,

222
00:32:10,000 --> 00:32:12,000
你看起来不像年轻人,

223
00:32:12,000 --> 00:32:14,000
这件事情也是一样的嘛,

224
00:32:14,000 --> 00:32:18,000
就是你的appearance跟你的实际不如预期,

225
00:32:18,000 --> 00:32:21,000
不如预期这件事情本身就是一个spell marker,

226
00:32:21,000 --> 00:32:25,000
所以病人会跟你说,

227
00:32:25,000 --> 00:32:26,000
你看起来不太好,

228
00:32:26,000 --> 00:32:28,000
但是你跟五十岁比起来还不错啦,

229
00:32:28,000 --> 00:32:30,000
就不会这样子嘛,

230
00:32:30,000 --> 00:32:33,000
比起来是跟你的健康年龄该怎么样,

231
00:32:33,000 --> 00:32:36,000
如果差异的话就表示有问题嘛,

232
00:32:36,000 --> 00:32:38,000
所以这个比较脑灵,

233
00:32:38,000 --> 00:32:41,000
比较年龄这些事情是很有意义的。

234
00:32:41,000 --> 00:32:44,000
所以我们今天就拿这个,

235
00:32:44,000 --> 00:32:48,000
把这个healthy reference这些事情来结合起来,

236
00:32:48,000 --> 00:32:49,000
所以我们怎么做,

237
00:32:49,000 --> 00:32:50,000
我们有真的disease,

238
00:32:50,000 --> 00:32:52,000
然后我们产生一个fake healthy,

239
00:32:52,000 --> 00:32:56,000
然后我们这个fake healthy还有一个condition,

240
00:32:56,000 --> 00:33:01,000
就是fake healthy经过健康年龄的regression年龄的话,

241
00:33:01,000 --> 00:33:03,000
要是本来的年龄,

242
00:33:03,000 --> 00:33:09,000
所以我们不会生成出一个很假膝盖的样子,

243
00:33:09,000 --> 00:33:14,000
我们生成出一个他该怎么年龄就怎么年龄的膝盖,

244
00:33:14,000 --> 00:33:15,000
对,

245
00:33:15,000 --> 00:33:21,000
就是一个拟合出他这个年龄上该有的状况的样子,

246
00:33:21,000 --> 00:33:25,000
所以他生出来的模型都不会是完美的,

247
00:33:26,000 --> 00:33:27,000
如果本来有大脊椎的话,

248
00:33:27,000 --> 00:33:29,000
那可能就是小脊椎,

249
00:33:29,000 --> 00:33:32,000
本来假设软骨有全掉的话,

250
00:33:32,000 --> 00:33:34,000
可能就变掉三层,

251
00:33:34,000 --> 00:33:35,000
都不会是完美的膝盖,

252
00:33:35,000 --> 00:33:43,000
可是这个差异就是我们认为是造成有疾病的medication的原因。

253
00:33:45,000 --> 00:33:47,000
所以基本上,

254
00:33:49,000 --> 00:33:53,000
这个GAN技术目前非常有用,

255
00:33:53,000 --> 00:33:57,000
当然看到一些生成VDR等等,

256
00:33:57,000 --> 00:34:01,000
已经可以很愉快的控制它们,

257
00:34:01,000 --> 00:34:08,000
所以目前假设我们有一些MRM想要找各种条件,

258
00:34:08,000 --> 00:34:11,000
比如说把疼痛疾病移除掉,

259
00:34:11,000 --> 00:34:13,000
都可以很愉快的做到,

260
00:34:13,000 --> 00:34:15,000
它就会有类似的anachronism形状,

261
00:34:15,000 --> 00:34:17,000
所以同个subject,

262
00:34:17,000 --> 00:34:20,000
但是疾病的一些feature就消失掉了。

263
00:34:24,000 --> 00:34:30,000
我们对这种GAN生成影像的最大的抗拒就是,

264
00:34:30,000 --> 00:34:32,000
它是假的吗?

265
00:34:32,000 --> 00:34:34,000
这些影像并不真的存在吗?

266
00:34:34,000 --> 00:34:39,000
到底要怎么知道这些影像是可信还是不可信呢?

267
00:34:39,000 --> 00:34:42,000
在医学上很困难,

268
00:34:42,000 --> 00:34:44,000
因为这些都是假设性的,

269
00:34:44,000 --> 00:34:45,000
不能重拍,

270
00:34:45,000 --> 00:34:47,000
所以很难说到底是真的还是假的。

271
00:34:48,000 --> 00:34:54,000
好比说我今天要预测一个tumor会不会有progression,

272
00:34:54,000 --> 00:34:57,000
这很难知道,

273
00:34:57,000 --> 00:34:59,000
因为它可能有progression,

274
00:34:59,000 --> 00:35:00,000
可能没有progression,

275
00:35:00,000 --> 00:35:01,000
如果它有progression,

276
00:35:01,000 --> 00:35:03,000
它预测的方式可以有很多种,

277
00:35:03,000 --> 00:35:05,000
它可以往某地方转移,

278
00:35:05,000 --> 00:35:07,000
或者它的扩散有什么样的扩散,

279
00:35:07,000 --> 00:35:10,000
所以progression这件事情很难讲,

280
00:35:10,000 --> 00:35:12,000
因为未来是有很多种。

281
00:35:12,000 --> 00:35:16,000
但是从病变变回健康这件事情,

282
00:35:16,000 --> 00:35:18,000
其实有一个逻辑在那边,

283
00:35:18,000 --> 00:35:19,000
它逻辑就是说,

284
00:35:19,000 --> 00:35:22,000
健康的状态应该是都很类似的,

285
00:35:22,000 --> 00:35:25,000
不健康的状态应该都是很不类似的,

286
00:35:25,000 --> 00:35:28,000
大家有听过这个,

287
00:35:28,000 --> 00:35:29,000
安娜·卡赖里娜,

288
00:35:29,000 --> 00:35:30,000
她的第一句就是说,

289
00:35:30,000 --> 00:35:31,000
happy families are all alike,

290
00:35:31,000 --> 00:35:34,000
就是所有高薪的家庭都是一样的,

291
00:35:34,000 --> 00:35:35,000
都类似的,

292
00:35:35,000 --> 00:35:38,000
everyone's happy family is happy in its own way,

293
00:35:38,000 --> 00:35:42,000
那这个在科学上有很多,

294
00:35:42,000 --> 00:35:45,000
这是principle在科学上有很多应用,

295
00:35:45,000 --> 00:35:46,000
主要想法就是说,

296
00:35:46,000 --> 00:35:50,000
一个健康的状况应该是都很类似的,

297
00:35:50,000 --> 00:35:53,000
所有的条件都很好的健康状况,

298
00:35:53,000 --> 00:35:55,000
开始病变之后,

299
00:35:55,000 --> 00:35:58,000
它就会往各处发散,

300
00:35:58,000 --> 00:36:00,000
就会变得很不一样,

301
00:36:00,000 --> 00:36:04,000
所以你要从健康预测不健康是比较困难的,

302
00:36:04,000 --> 00:36:07,000
这样不健康反推回来是比较容易的,

303
00:36:07,000 --> 00:36:09,000
因为健康状况应该是类似的,

304
00:36:09,000 --> 00:36:12,000
其他我不敢讲,

305
00:36:12,000 --> 00:36:14,000
但在膝盖影像上面,

306
00:36:14,000 --> 00:36:17,000
健康的膝盖骨头,

307
00:36:17,000 --> 00:36:18,000
软骨,

308
00:36:18,000 --> 00:36:19,000
半夜半,

309
00:36:19,000 --> 00:36:20,000
这都是有天生的形状,

310
00:36:20,000 --> 00:36:22,000
所以健康状况是,

311
00:36:22,000 --> 00:36:25,000
其实我们知道应该长什么样子,

312
00:36:25,000 --> 00:36:29,000
所以假如你要画成群剧图的话,

313
00:36:29,000 --> 00:36:32,000
你有一坨白色的健康状况,

314
00:36:32,000 --> 00:36:33,000
都应该蛮类似的,

315
00:36:33,000 --> 00:36:36,000
然后它的病变开始之后就慢慢发散,

316
00:36:36,000 --> 00:36:39,000
所以你要从健康推到不健康,

317
00:36:39,000 --> 00:36:41,000
其实蛮困难的,

318
00:36:41,000 --> 00:36:44,000
因为你很难验证说,

319
00:36:44,000 --> 00:36:46,000
你推断对不对,

320
00:36:46,000 --> 00:36:49,000
但你从不健康的图片反推回来的话,

321
00:36:49,000 --> 00:36:50,000
是比较容易的,

322
00:36:50,000 --> 00:36:52,000
然后你有很多工具可以验证,

323
00:36:52,000 --> 00:36:55,000
比如说你可以验证软骨的,

324
00:36:55,000 --> 00:36:57,000
或是半夜半的形状等等,

325
00:36:57,000 --> 00:36:58,000
有没有正常。

326
00:37:03,000 --> 00:37:05,000
那最后一点是说,

327
00:37:05,000 --> 00:37:08,000
我们刚讲比较性是拿,

328
00:37:08,000 --> 00:37:10,000
有疼痛跟没有疼痛比较嘛,

329
00:37:10,000 --> 00:37:13,000
那有疼痛跟没有疼痛是一个binary,

330
00:37:13,000 --> 00:37:16,000
是我们自己把它变成binary嘛,

331
00:37:16,000 --> 00:37:17,000
但其中其实没有可能嘛,

332
00:37:17,000 --> 00:37:19,000
因为很多事情变成binary,

333
00:37:19,000 --> 00:37:21,000
是我们人为的因素嘛,

334
00:37:21,000 --> 00:37:27,000
好比说我今天病人照那个0到10的疼痛表,

335
00:37:27,000 --> 00:37:29,000
来回报疼痛,

336
00:37:29,000 --> 00:37:31,000
那他可能说左边是3,右边是7,

337
00:37:31,000 --> 00:37:34,000
然后下来病人说左边是1,右边是5,

338
00:37:34,000 --> 00:37:35,000
那差值都是4,

339
00:37:35,000 --> 00:37:38,000
然后我做研究,

340
00:37:38,000 --> 00:37:39,000
所以我要强迫变binary,

341
00:37:39,000 --> 00:37:41,000
我说这是4,所以是一样的,

342
00:37:41,000 --> 00:37:43,000
其实是不一样的嘛,

343
00:37:43,000 --> 00:37:46,000
那或是说差是1到8,

344
00:37:46,000 --> 00:37:47,000
或是1到6,

345
00:37:47,000 --> 00:37:50,000
那差值是一大一小,

346
00:37:50,000 --> 00:37:51,000
可是我做binary,

347
00:37:51,000 --> 00:37:52,000
我binaryize,

348
00:37:52,000 --> 00:37:54,000
那我会觉得是一样的,

349
00:37:54,000 --> 00:37:56,000
可是这些一样,

350
00:37:56,000 --> 00:37:58,000
其实是人为的解释嘛,

351
00:37:58,000 --> 00:38:00,000
大家想要知道就是,

352
00:38:00,000 --> 00:38:02,000
这些人为把一些事情做二本法,

353
00:38:02,000 --> 00:38:04,000
其实是一个很常用的工具,

354
00:38:04,000 --> 00:38:08,000
但是并不代表说二本法的边界有任何特别的地方,

355
00:38:08,000 --> 00:38:10,000
这举个例子好了,

356
00:38:10,000 --> 00:38:13,000
假如说有常人来台湾的话,

357
00:38:13,000 --> 00:38:14,000
很常听说8是量表嘛,

358
00:38:14,000 --> 00:38:16,000
8量表就是一个二本法嘛,

359
00:38:16,000 --> 00:38:20,000
就是我觉得量表的左边就是不需要看护,

360
00:38:20,000 --> 00:38:21,000
右边是需要看护,

361
00:38:21,000 --> 00:38:25,000
那这个线的左边右边有什么magical thing happen,

362
00:38:25,000 --> 00:38:26,000
它变不一样嘛,

363
00:38:26,000 --> 00:38:27,000
其实没有,

364
00:38:27,000 --> 00:38:30,000
所以二本法其实是很confusing,

365
00:38:30,000 --> 00:38:34,000
我们在医学上知道它有很多人为设出来的边界,

366
00:38:34,000 --> 00:38:36,000
或是人为设出来的binary,

367
00:38:36,000 --> 00:38:37,000
这举个例子好了,

368
00:38:37,000 --> 00:38:38,000
但其实是没有意义的,

369
00:38:38,000 --> 00:38:45,000
所以很大的困难就是怎么把这些binary的资讯,

370
00:38:45,000 --> 00:38:47,000
再让还原回去交给你的模型,

371
00:38:47,000 --> 00:38:49,000
以这个project为例的话,

372
00:38:49,000 --> 00:38:50,000
我们就是,

373
00:38:50,000 --> 00:38:52,000
我们至少让模型知道说,

374
00:38:52,000 --> 00:38:54,000
healthy跟painful,

375
00:38:54,000 --> 00:38:56,000
跟healthy跟very unpainful要分开了,

376
00:38:56,000 --> 00:38:58,000
所以假如说0到3的话,

377
00:38:58,000 --> 00:38:59,000
差异很少,

378
00:38:59,000 --> 00:39:02,000
我们让模型知道说这差异很小,

379
00:39:02,000 --> 00:39:04,000
假如0到9的话,

380
00:39:04,000 --> 00:39:05,000
差异很多,

381
00:39:05,000 --> 00:39:07,000
我让它知道说差异很多,

382
00:39:07,000 --> 00:39:10,000
幸好这些用模型可以解决,

383
00:39:10,000 --> 00:39:13,000
我们是可以把这些差异,

384
00:39:13,000 --> 00:39:18,000
encode之后放进去这个模型的生成的部分里面去,

385
00:39:18,000 --> 00:39:22,000
所以它就照你想要给它的距离,

386
00:39:22,000 --> 00:39:24,000
相比的差异,

387
00:39:24,000 --> 00:39:27,000
所以就是数值差比较少会差比较少,

388
00:39:27,000 --> 00:39:29,000
差比较多会差比较多,

389
00:39:29,000 --> 00:39:33,000
那当然这个传统差异只是小部分,

390
00:39:33,000 --> 00:39:36,000
所以这个比较类似像是一个demo一样,

391
00:39:36,000 --> 00:39:38,000
证明说我们可以control这些事情,

392
00:39:38,000 --> 00:39:41,000
当然是有更多更多的因素在里面,

393
00:39:41,000 --> 00:39:43,000
所以可以想办法加进去,

394
00:39:43,000 --> 00:39:48,000
所以基本上训练成功之后,

395
00:39:48,000 --> 00:39:52,000
你就会得到一个连续的膝盖分布,

396
00:39:52,000 --> 00:39:56,000
连续膝盖分布最左边就会是你本来的膝盖,

397
00:39:56,000 --> 00:40:00,000
最右边就会是你疼痛的高低的膝盖,

398
00:40:00,000 --> 00:40:06,000
那根据它们两个疼痛的scoring的差异,

399
00:40:06,000 --> 00:40:09,000
它就会拉近会拉远,

400
00:40:09,000 --> 00:40:12,000
所以并不是说左边是不疼痛膝盖,

401
00:40:12,000 --> 00:40:14,000
右边是疼痛膝盖,中间都是垃圾,

402
00:40:14,000 --> 00:40:16,000
它是一个连续的空间,

403
00:40:16,000 --> 00:40:19,000
连续的空间它的分布其实是你可以控制的,

404
00:40:19,000 --> 00:40:24,000
那我们之前有做过一些自动切割,

405
00:40:24,000 --> 00:40:27,000
自动切割在一平衡上算是一个比较好解决的工作,

406
00:40:27,000 --> 00:40:31,000
基本上结论就是说你只要有研究生,

407
00:40:31,000 --> 00:40:34,000
只要有处理他就把你用手标完,

408
00:40:34,000 --> 00:40:35,000
然后就解决掉,

409
00:40:35,000 --> 00:40:39,000
所以其实基本上一平衡上自动切割算是单一,

410
00:40:39,000 --> 00:40:41,000
比较困难是在单一data set,

411
00:40:41,000 --> 00:40:44,000
多data set你会有差异,

412
00:40:44,000 --> 00:40:46,000
但如果是在同一data set,

413
00:40:46,000 --> 00:40:48,000
然后有标记的话,

414
00:40:48,000 --> 00:40:49,000
你有光处的话,

415
00:40:49,000 --> 00:40:52,000
就是我们这种所谓叫做有切割的光处,

416
00:40:52,000 --> 00:40:53,000
就是切割的标记嘛,

417
00:40:53,000 --> 00:40:55,000
那这种叫做监督式学习,

418
00:40:56,000 --> 00:40:57,000
如果是survival的话,

419
00:40:57,000 --> 00:40:59,000
基本上还蛮好解决的,

420
00:40:59,000 --> 00:41:01,000
所以已经不是新的东西了,

421
00:41:01,000 --> 00:41:06,000
那我们做deep learning的话,

422
00:41:06,000 --> 00:41:09,000
有一个功能就是帮助这些,

423
00:41:09,000 --> 00:41:11,000
本来就可以做的事情,

424
00:41:11,000 --> 00:41:12,000
把自动化,

425
00:41:12,000 --> 00:41:14,000
就好比说这些膝盖骨头切割,

426
00:41:14,000 --> 00:41:17,000
那其实其实不是很难嘛,

427
00:41:17,000 --> 00:41:18,000
因为医生都可以切,

428
00:41:18,000 --> 00:41:19,000
然后也有些postdoc,

429
00:41:19,000 --> 00:41:21,000
或者有些研究生都会切,

430
00:41:21,000 --> 00:41:23,000
但是本来手法是非常非常非常慢,

431
00:41:23,000 --> 00:41:25,000
那在近期的话,

432
00:41:25,000 --> 00:41:28,000
可能用一些统计的statistical shape model,

433
00:41:28,000 --> 00:41:30,000
去拟合出这些膝盖形状,

434
00:41:30,000 --> 00:41:32,000
总之要花时间嘛,

435
00:41:32,000 --> 00:41:34,000
但deep learning有一个很好的好处,

436
00:41:34,000 --> 00:41:35,000
就是它可以自动化,

437
00:41:35,000 --> 00:41:37,000
所以刚刚说过,

438
00:41:37,000 --> 00:41:38,000
只要是survival能力做切割,

439
00:41:38,000 --> 00:41:40,000
其实不是很难,

440
00:41:40,000 --> 00:41:42,000
所以我们之前做的模型,

441
00:41:42,000 --> 00:41:44,000
就是把这些手动标记,

442
00:41:44,000 --> 00:41:45,000
转成一个自动切割化模型,

443
00:41:45,000 --> 00:41:47,000
那一下子你会分析很多,

444
00:41:47,000 --> 00:41:50,000
很多不同的资料,

445
00:41:51,000 --> 00:41:53,000
那它科学上有新的东西吗?

446
00:41:53,000 --> 00:41:54,000
其实没有,

447
00:41:54,000 --> 00:41:55,000
它只是自动化而已,

448
00:41:55,000 --> 00:41:58,000
但是生物学上的很多丢零,

449
00:41:58,000 --> 00:42:00,000
就是最大的困难嘛,

450
00:42:00,000 --> 00:42:02,000
所以它并不是新的功能,

451
00:42:02,000 --> 00:42:04,000
但是只是把同样的事情,

452
00:42:04,000 --> 00:42:06,000
给别人做一倍,

453
00:42:06,000 --> 00:42:07,000
然后我会做一百倍,

454
00:42:07,000 --> 00:42:08,000
那就很有价值。

455
00:42:13,000 --> 00:42:16,000
那今天在我们这个case上面来说的话,

456
00:42:16,000 --> 00:42:18,000
我没想要做自动切割,

457
00:42:18,000 --> 00:42:19,000
为什么呢?

458
00:42:19,000 --> 00:42:21,000
有一种特别的region是,

459
00:42:21,000 --> 00:42:22,000
我们特别想要看的,

460
00:42:22,000 --> 00:42:23,000
所谓的Bone Marrow Region,

461
00:42:23,000 --> 00:42:25,000
它就是在骨髓内的,

462
00:42:25,000 --> 00:42:27,000
在骨头区里面的所有的,

463
00:42:27,000 --> 00:42:31,000
所有的hyperintensity,

464
00:42:31,000 --> 00:42:33,000
都是被认为是Bone Marrow Region,

465
00:42:33,000 --> 00:42:38,000
那它问题是这样子,

466
00:42:38,000 --> 00:42:39,000
我们这个医学影像,

467
00:42:39,000 --> 00:42:41,000
好多MRI好了,

468
00:42:41,000 --> 00:42:43,000
每个MRI是拍的功能不太一样,

469
00:42:44,000 --> 00:42:48,000
好比说像这个左边是High Definition,

470
00:42:48,000 --> 00:42:51,000
就是它的骨头跟人肉之间的contrast很明显,

471
00:42:51,000 --> 00:42:53,000
右边是看发炎的,

472
00:42:53,000 --> 00:42:56,000
就是这个Weighted T2 Sequence,

473
00:42:56,000 --> 00:42:58,000
所以它看到发炎,

474
00:42:58,000 --> 00:43:01,000
可是它的骨头跟人肉之间的边界不是很明显,

475
00:43:01,000 --> 00:43:04,000
那你可能想说,

476
00:43:04,000 --> 00:43:06,000
我就把左边做自动切割,

477
00:43:06,000 --> 00:43:07,000
然后搬到右边来就好了嘛,

478
00:43:07,000 --> 00:43:10,000
可问题是即使是同一位病人,

479
00:43:10,000 --> 00:43:12,000
它拍的时候也不会是完全align的,

480
00:43:12,000 --> 00:43:16,000
像你膝盖的眼花稍微角做Man Spread就不一样了,

481
00:43:16,000 --> 00:43:18,000
就已经3D形状就不一样了,

482
00:43:18,000 --> 00:43:20,000
所以基本上,

483
00:43:20,000 --> 00:43:22,000
这是Clinical是这样拍的,

484
00:43:22,000 --> 00:43:24,000
这是Clinical Trial,

485
00:43:24,000 --> 00:43:26,000
所以至少是同时拍的,

486
00:43:26,000 --> 00:43:28,000
所以是有蛮多病人是重合没错,

487
00:43:28,000 --> 00:43:33,000
但是至少一半是Man Spreading,

488
00:43:33,000 --> 00:43:37,000
所以拍的3D的剖面不一样了,

489
00:43:37,000 --> 00:43:39,000
假设如果是Follow Up的话,

490
00:43:39,000 --> 00:43:41,000
基本上看起来就不太一样了,

491
00:43:41,000 --> 00:43:44,000
所以基本上,

492
00:43:44,000 --> 00:43:47,000
你有一些切割的资讯,

493
00:43:47,000 --> 00:43:49,000
想要转到发炎资讯上面去,

494
00:43:49,000 --> 00:43:51,000
你要怎么转呢?

495
00:43:51,000 --> 00:43:54,000
然后再讲说,

496
00:43:54,000 --> 00:43:56,000
为什么不能直接套用?

497
00:43:56,000 --> 00:44:01,000
大家知道Neural Network有另一个重大缺点,

498
00:44:01,000 --> 00:44:04,000
就是它很难套用在Core Data Stack,

499
00:44:04,000 --> 00:44:06,000
最有名的例子是说,

500
00:44:06,000 --> 00:44:10,000
Source跟Target其实差不多,

501
00:44:10,000 --> 00:44:13,000
但是节度就差很多,

502
00:44:13,000 --> 00:44:16,000
所以我们可以用这些Gate方式,

503
00:44:16,000 --> 00:44:18,000
把一个模型转到另一个模型上面去,

504
00:44:18,000 --> 00:44:24,000
那你就可以在想拍发炎资讯上去,

505
00:44:24,000 --> 00:44:26,000
把这些去切割下来,

506
00:44:26,000 --> 00:44:30,000
我花了超多时间,

507
00:44:30,000 --> 00:44:32,000
所以我就讲快点好了,

508
00:44:32,000 --> 00:44:34,000
我们最后结果是说,

509
00:44:34,000 --> 00:44:36,000
我们可以拿这些切割模型,

510
00:44:36,000 --> 00:44:40,000
在本来这个结病改变的图上面做定量,

511
00:44:40,000 --> 00:44:44,000
那我们可以把这些Bomel Region,

512
00:44:44,000 --> 00:44:46,000
很敏感的定量下来,

513
00:44:46,000 --> 00:44:48,000
那最后我们就做这些统计分析,

514
00:44:48,000 --> 00:44:51,000
等于是用后验的统计分析,

515
00:44:51,000 --> 00:44:53,000
那根据传统的画Contour方式来比的话,

516
00:44:53,000 --> 00:44:55,000
就发现如果计算,

517
00:44:55,000 --> 00:44:59,000
还有未来会开到的Out Ratio,

518
00:44:59,000 --> 00:45:01,000
就还好蛮多的,

519
00:45:02,000 --> 00:45:04,000
所以大概这样子,

520
00:45:04,000 --> 00:45:06,000
我之后本来要讲,

521
00:45:06,000 --> 00:45:09,000
先这样子好了,

522
00:45:09,000 --> 00:45:11,000
那我就直接讲,

523
00:45:11,000 --> 00:45:13,000
我conclusion,

524
00:45:13,000 --> 00:45:16,000
那我是回台湾之后,

525
00:45:16,000 --> 00:45:22,000
大家知道我们做影像都会找合适的Collaborator,

526
00:45:22,000 --> 00:45:24,000
我在美国的时候跟台湾的时候就不太一样,

527
00:45:24,000 --> 00:45:26,000
那我在台湾的时候就做一个分支,

528
00:45:26,000 --> 00:45:28,000
就是做脑影像研究,

529
00:45:28,000 --> 00:45:30,000
大家可能知道说,

530
00:45:30,000 --> 00:45:32,000
可能听过了,

531
00:45:32,000 --> 00:45:34,000
Neural Network的本质就是,

532
00:45:34,000 --> 00:45:36,000
一开始学脑会怎么function,

533
00:45:36,000 --> 00:45:38,000
它是拟合一个脑细胞,

534
00:45:38,000 --> 00:45:40,000
把很多资讯综结在一起,

535
00:45:40,000 --> 00:45:44,000
然后用一个Activation Function,

536
00:45:44,000 --> 00:45:46,000
然后往前输送这样子,

537
00:45:46,000 --> 00:45:48,000
脑装滑,

538
00:45:48,000 --> 00:45:50,000
偷别人的Video,

539
00:45:50,000 --> 00:45:55,000
每颗脑神经都有几百个接收源,

540
00:45:55,000 --> 00:45:59,000
然后再把这些神经连回去,

541
00:45:59,000 --> 00:46:01,000
基本上,

542
00:46:01,000 --> 00:46:03,000
这些神经集合在这边的Circuit,

543
00:46:03,000 --> 00:46:05,000
就变回路,

544
00:46:05,000 --> 00:46:09,000
回路就会做各种行为,

545
00:46:09,000 --> 00:46:11,000
记忆等等,

546
00:46:11,000 --> 00:46:14,000
所谓的脑科学的Holy Grail,

547
00:46:14,000 --> 00:46:16,000
就是这个回路结合起来变Conscious,

548
00:46:16,000 --> 00:46:18,000
我们是谁,

549
00:46:18,000 --> 00:46:20,000
这我就不知道了,

550
00:46:20,000 --> 00:46:22,000
因为我们对脑科学的认知,

551
00:46:23,000 --> 00:46:25,000
非常非常地开始了,

552
00:46:25,000 --> 00:46:27,000
像这些回路结合起来,

553
00:46:27,000 --> 00:46:29,000
会变成怎么看东西,

554
00:46:29,000 --> 00:46:31,000
这种东西我们都不知道,

555
00:46:31,000 --> 00:46:35,000
第一步就是怎么把这些回路区分出来,

556
00:46:35,000 --> 00:46:37,000
还是做不到,

557
00:46:37,000 --> 00:46:39,000
除非是做电子显微镜,

558
00:46:39,000 --> 00:46:41,000
不然解析度是不够的,

559
00:46:41,000 --> 00:46:43,000
但你可以做光学显微镜,

560
00:46:43,000 --> 00:46:46,000
解析度是不够,

561
00:46:46,000 --> 00:46:48,000
但是会快很多,

562
00:46:48,000 --> 00:46:50,000
电子显微镜基本上扫人脑,

563
00:46:51,000 --> 00:46:53,000
所以有部分的,

564
00:46:53,000 --> 00:46:57,000
怎么用AI技术来,

565
00:46:57,000 --> 00:47:00,000
回头来分析这些脑科学影像,

566
00:47:00,000 --> 00:47:02,000
想法先把这些脑神经,

567
00:47:02,000 --> 00:47:04,000
一颗一颗重新连接,

568
00:47:04,000 --> 00:47:06,000
重现出来,

569
00:47:06,000 --> 00:47:08,000
我们才拿这些东西来,

570
00:47:08,000 --> 00:47:10,000
建立一个模型来预测,

571
00:47:10,000 --> 00:47:12,000
它的行为被怎么调控,

572
00:47:12,000 --> 00:47:14,000
所以基本上就是一个,

573
00:47:14,000 --> 00:47:16,000
我想问一下,

574
00:47:16,000 --> 00:47:18,000
我问你,

575
00:47:18,000 --> 00:47:20,000
左边右边,

576
00:47:20,000 --> 00:47:22,000
差别是什么?

577
00:47:26,000 --> 00:47:28,000
右边是原图影像,

578
00:47:28,000 --> 00:47:30,000
左边是,

579
00:47:30,000 --> 00:47:32,000
左边是米禾出的CNET,

580
00:47:32,000 --> 00:47:34,000
就是,

581
00:47:34,000 --> 00:47:36,000
左边是,

582
00:47:36,000 --> 00:47:38,000
脑神经,

583
00:47:38,000 --> 00:47:40,000
每颗发散的地方,

584
00:47:40,000 --> 00:47:42,000
叫CNET,

585
00:47:42,000 --> 00:47:44,000
左边是把CNET强化出来,

586
00:47:44,000 --> 00:47:46,000
它有在,

587
00:47:46,000 --> 00:47:48,000
它是两个神经的边界,

588
00:47:48,000 --> 00:47:50,000
可能是,

589
00:47:50,000 --> 00:47:52,000
这些,

590
00:47:52,000 --> 00:47:54,000
每一线的终点,

591
00:47:54,000 --> 00:47:56,000
是两个神经的边界,

592
00:47:56,000 --> 00:47:58,000
它觉得不是同一个神经细胞,

593
00:47:58,000 --> 00:48:00,000
有可能是CNET在交换资讯,

594
00:48:02,000 --> 00:48:04,000
这结果不是很翻用来子,

595
00:48:04,000 --> 00:48:06,000
但是,

596
00:48:06,000 --> 00:48:08,000
但是,

597
00:48:08,000 --> 00:48:10,000
目的就是说,

598
00:48:10,000 --> 00:48:12,000
怎么把,

599
00:48:12,000 --> 00:48:14,000
怎么把每颗脑神经,

600
00:48:14,000 --> 00:48:16,000
然后,

601
00:48:16,000 --> 00:48:18,000
然后把这些看起来是一条线的地方,

602
00:48:18,000 --> 00:48:20,000
把它区分出来,

603
00:48:20,000 --> 00:48:22,000
哪些是受理脑理,

604
00:48:22,000 --> 00:48:24,000
哪些是在地脑理,

605
00:48:24,000 --> 00:48:26,000
理论上这些CNET的位置,

606
00:48:26,000 --> 00:48:28,000
就会是传递资讯的地方,

607
00:48:28,000 --> 00:48:30,000
如果全部都做完,

608
00:48:30,000 --> 00:48:32,000
然后很整的话,

609
00:48:32,000 --> 00:48:34,000
你就可以利用一些theory,

610
00:48:34,000 --> 00:48:36,000
graph theory,

611
00:48:36,000 --> 00:48:38,000
去重现出这些会录长什么样子,

612
00:48:38,000 --> 00:48:40,000
因为我同事有做这些,

613
00:48:40,000 --> 00:48:42,000
Cognitive的测量,

614
00:48:42,000 --> 00:48:44,000
并不是很大动物,

615
00:48:44,000 --> 00:48:46,000
对,

616
00:48:46,000 --> 00:48:48,000
但他们过于,

617
00:48:48,000 --> 00:48:50,000
已经被训练说有些行为,

618
00:48:50,000 --> 00:48:52,000
他们是要怎样,他们是要怎样,

619
00:48:52,000 --> 00:48:54,000
他们做完行为之后,

620
00:48:54,000 --> 00:48:56,000
他们再来拍摄这样子,

621
00:48:56,000 --> 00:48:58,000
所以他们是可以知道说,

622
00:48:58,000 --> 00:49:00,000
哪些会录如果有出现或没有出现的话,

623
00:49:00,000 --> 00:49:02,000
可以跟某些方式联系在一起,

624
00:49:02,000 --> 00:49:04,000
对,

625
00:49:04,000 --> 00:49:06,000
所以,

626
00:49:06,000 --> 00:49:08,000
那你可以做一些影像强化等等,

627
00:49:08,000 --> 00:49:10,000
等等,

628
00:49:10,000 --> 00:49:12,000
影像强化,

629
00:49:12,000 --> 00:49:14,000
去噪音,去模糊化等等,

630
00:49:14,000 --> 00:49:16,000
显微镜影像是非常常用的课题,

631
00:49:16,000 --> 00:49:18,000
就可以拿来做,

632
00:49:18,000 --> 00:49:20,000
基本上就是一个,

633
00:49:20,000 --> 00:49:22,000
Light Emitting Art,

634
00:49:22,000 --> 00:49:24,000
Art Emitting Light的过程,

635
00:49:24,000 --> 00:49:26,000
就是当初是,

636
00:49:26,000 --> 00:49:28,000
脑科学启发了AI的研究,

637
00:49:28,000 --> 00:49:30,000
现在AI又会来做这个脑科学,

638
00:49:30,000 --> 00:49:32,000
所以就会慢慢,

639
00:49:32,000 --> 00:49:34,000
回旋就会收敛,

640
00:49:34,000 --> 00:49:36,000
就会出现Terminated,

641
00:49:36,000 --> 00:49:38,000
不过就大概这样子,

642
00:49:38,000 --> 00:49:40,000
那我今天就,

643
00:49:40,000 --> 00:49:42,000
在讲这边。

644
00:49:44,000 --> 00:49:46,000
好,谢谢,

645
00:49:46,000 --> 00:49:48,000
那,

646
00:49:48,000 --> 00:49:50,000
现在我们就再感谢张涵,

647
00:49:50,000 --> 00:49:52,000
谢谢。

648
00:49:54,000 --> 00:49:56,000
现场有没有,

649
00:49:56,000 --> 00:49:58,000
有问题,然后现在,

650
00:49:58,000 --> 00:50:00,000
可以直接开麦克风,直接问。

651
00:50:02,000 --> 00:50:04,000
你好,我想请教一下,

652
00:50:04,000 --> 00:50:06,000
我对你刚提到那个,

653
00:50:06,000 --> 00:50:08,000
不好意思,

654
00:50:08,000 --> 00:50:10,000
那个可以先自我介绍一下。

655
00:50:10,000 --> 00:50:12,000
对不起,对不起,我叫石清华,

656
00:50:12,000 --> 00:50:14,000
我现在在Rochester,

657
00:50:14,000 --> 00:50:16,000
New York,

658
00:50:16,000 --> 00:50:18,000
那我对你那个脑神经,

659
00:50:18,000 --> 00:50:20,000
那部分其实有点感兴趣,

660
00:50:20,000 --> 00:50:22,000
因为其实在,

661
00:50:22,000 --> 00:50:24,000
大概在一两个月前,

662
00:50:24,000 --> 00:50:26,000
有一个,

663
00:50:26,000 --> 00:50:28,000
有一个Research,

664
00:50:28,000 --> 00:50:30,000
他应该还没有完全Publish,

665
00:50:30,000 --> 00:50:32,000
他就是基本上是把,

666
00:50:32,000 --> 00:50:34,000
脑神经,

667
00:50:34,000 --> 00:50:36,000
有脑细胞养在一些Culture里头,

668
00:50:36,000 --> 00:50:38,000
然后用一些Training,

669
00:50:38,000 --> 00:50:40,000
然后配上AI的技术之后,

670
00:50:40,000 --> 00:50:42,000
可以让他玩Video Game,

671
00:50:42,000 --> 00:50:44,000
他可以玩乒乓,

672
00:50:44,000 --> 00:50:46,000
这样子,

673
00:50:46,000 --> 00:50:48,000
就是比较,

674
00:50:48,000 --> 00:50:50,000
对,他是一个人,

675
00:50:50,000 --> 00:50:52,000
我看了那篇Paper之后,

676
00:50:52,000 --> 00:50:54,000
我觉得,

677
00:50:54,000 --> 00:50:56,000
对,就是别人的Research已经到天上,

678
00:50:56,000 --> 00:50:58,000
但我还在地上爬这样子。

679
00:50:58,000 --> 00:51:00,000
那我只是好奇,

680
00:51:00,000 --> 00:51:02,000
我只是好奇,

681
00:51:02,000 --> 00:51:04,000
像你在你这边的那个,

682
00:51:04,000 --> 00:51:06,000
如果有办法说,

683
00:51:06,000 --> 00:51:08,000
用类似的Model,

684
00:51:08,000 --> 00:51:10,000
然后对,

685
00:51:10,000 --> 00:51:12,000
比如说你可以记住Action Potential,

686
00:51:12,000 --> 00:51:14,000
或者是有办法,

687
00:51:14,000 --> 00:51:16,000
荧光可以

688
00:51:16,000 --> 00:51:18,000
侦测他Action Potential的,

689
00:51:18,000 --> 00:51:20,000
然后类似的Pattern,

690
00:51:20,000 --> 00:51:22,000
你就可以看到脑回路的反应,

691
00:51:22,000 --> 00:51:24,000
或神经回路的反应,

692
00:51:24,000 --> 00:51:26,000
针对他的Response这样子。

693
00:51:26,000 --> 00:51:28,000
那,

694
00:51:28,000 --> 00:51:30,000
而且因为这样东西,

695
00:51:30,000 --> 00:51:32,000
呃,

696
00:51:32,000 --> 00:51:34,000
我猜想,

697
00:51:34,000 --> 00:51:36,000
就是说可以做到,

698
00:51:36,000 --> 00:51:38,000
你可以比较,

699
00:51:38,000 --> 00:51:40,000
Simplify一些Circuit,

700
00:51:40,000 --> 00:51:42,000
然后可以做到比较,

701
00:51:42,000 --> 00:51:44,000
呃,

702
00:51:44,000 --> 00:51:46,000
比较High Resolution,

703
00:51:46,000 --> 00:51:48,000
然后去Detect他的那个,

704
00:51:48,000 --> 00:51:50,000
回路的Pattern,

705
00:51:50,000 --> 00:51:52,000
那我不晓得说,

706
00:51:52,000 --> 00:51:54,000
这个东西会不会在未来,

707
00:51:54,000 --> 00:51:56,000
会变得很有趣,

708
00:51:56,000 --> 00:51:58,000
或者是会变得是非常,

709
00:51:58,000 --> 00:52:00,000
他相对于,

710
00:52:00,000 --> 00:52:02,000
佐瑟菲亚的Brain来讲,

711
00:52:02,000 --> 00:52:04,000
更小,因为他只有几百几千个细胞而已,

712
00:52:04,000 --> 00:52:06,000
所以比那个佐瑟菲亚的Brain更小,

713
00:52:06,000 --> 00:52:08,000
所以我觉得他可能,

714
00:52:08,000 --> 00:52:10,000
说不定是一个很神奇的东西。

715
00:52:10,000 --> 00:52:12,000
是是。

716
00:52:12,000 --> 00:52:14,000
好,谢谢。

717
00:52:14,000 --> 00:52:16,000
这个我可能要质疑一下我的同事,

718
00:52:16,000 --> 00:52:18,000
我先说我们这个是,

719
00:52:18,000 --> 00:52:20,000
这个是一个蛮大的Team,

720
00:52:20,000 --> 00:52:22,000
然后主要是

721
00:52:22,000 --> 00:52:24,000
清化脑科中心,

722
00:52:24,000 --> 00:52:26,000
那我这边做影像分析,

723
00:52:26,000 --> 00:52:28,000
那我主要一开始做的是,

724
00:52:28,000 --> 00:52:30,000
这个,

725
00:52:30,000 --> 00:52:32,000
是荧光行为镜影像嘛,

726
00:52:32,000 --> 00:52:34,000
所以这是解剖完的染色或影像,

727
00:52:34,000 --> 00:52:36,000
但是其实是有另外一个Branch,

728
00:52:36,000 --> 00:52:38,000
是做Live Imaging,

729
00:52:38,000 --> 00:52:40,000
就是,

730
00:52:40,000 --> 00:52:42,000
就是是

731
00:52:42,000 --> 00:52:44,000
Real Time的Function影像,

732
00:52:44,000 --> 00:52:46,000
所以是有可能的,

733
00:52:46,000 --> 00:52:48,000
是有可能的,

734
00:52:48,000 --> 00:52:50,000
那我们现在其实,

735
00:52:50,000 --> 00:52:52,000
又开始做分析,

736
00:52:52,000 --> 00:52:54,000
是做这个,

737
00:52:54,000 --> 00:52:56,000
就是这个,

738
00:52:56,000 --> 00:52:58,000
类器官的体外培养的神经元,

739
00:52:58,000 --> 00:53:00,000
原因也是一样,

740
00:53:00,000 --> 00:53:02,000
就是你可以控制好,

741
00:53:02,000 --> 00:53:04,000
然后是可以,

742
00:53:04,000 --> 00:53:06,000
可以,

743
00:53:06,000 --> 00:53:08,000
比较好地做一些,

744
00:53:08,000 --> 00:53:10,000
就是这些,

745
00:53:10,000 --> 00:53:12,000
你做解构或是

746
00:53:12,000 --> 00:53:14,000
方便分析,

747
00:53:14,000 --> 00:53:16,000
然后跟这些控制条件做比较,

748
00:53:16,000 --> 00:53:18,000
但是这个Brain Cell可以,

749
00:53:18,000 --> 00:53:20,000
我先找影片,

750
00:53:20,000 --> 00:53:22,000
就是这个,

751
00:53:22,000 --> 00:53:24,000
Brain Cell可以Play Pong,

752
00:53:24,000 --> 00:53:26,000
可以Play乒乓球,

753
00:53:26,000 --> 00:53:28,000
这是我是第一次知道,

754
00:53:28,000 --> 00:53:32,000
我刚刚学习在那个Chat里头,

755
00:53:32,000 --> 00:53:34,000
就是那个,

756
00:53:34,000 --> 00:53:36,000
有看到,

757
00:53:36,000 --> 00:53:38,000
我也是刚知道,

758
00:53:38,000 --> 00:53:40,000
其实我们在看那个,

759
00:53:40,000 --> 00:53:42,000
其实我们在看那个人脑培养的那个,

760
00:53:42,000 --> 00:53:44,000
Ocrelinoid的脑细胞的时候,

761
00:53:44,000 --> 00:53:46,000
就常常想说,

762
00:53:46,000 --> 00:53:48,000
它有没有Conscious,

763
00:53:48,000 --> 00:53:50,000
它有有Conscious的话就很可怕,

764
00:53:50,000 --> 00:53:52,000
就很可怕,

765
00:53:54,000 --> 00:53:56,000
有没有Conscious我是不知道,

766
00:53:56,000 --> 00:53:58,000
可是它就可以Play Pong,

767
00:53:58,000 --> 00:54:00,000
就已经有点可怕,

768
00:54:00,000 --> 00:54:02,000
我一直觉得是我们的,

769
00:54:02,000 --> 00:54:04,000
这完全是我自己的猜想,

770
00:54:04,000 --> 00:54:06,000
就是我觉得我们的function,

771
00:54:06,000 --> 00:54:08,000
或我们的意识其实是一个Module,

772
00:54:08,000 --> 00:54:10,000
就是各种Module最后组成出来的效果,

773
00:54:10,000 --> 00:54:12,000
所以各自的Module,

774
00:54:12,000 --> 00:54:14,000
可能没有所谓的Conscious,

775
00:54:14,000 --> 00:54:16,000
但是组合起来就可能有了,

776
00:54:16,000 --> 00:54:18,000
是,

777
00:54:18,000 --> 00:54:20,000
说得非常好,

778
00:54:20,000 --> 00:54:22,000
就是,

779
00:54:22,000 --> 00:54:24,000
就是,

780
00:54:24,000 --> 00:54:26,000
我们同样的方式是可以分析,

781
00:54:26,000 --> 00:54:28,000
人脑的一点点,

782
00:54:28,000 --> 00:54:30,000
或者是生物的全体,

783
00:54:30,000 --> 00:54:32,000
那像现在的光绘行为,

784
00:54:32,000 --> 00:54:34,000
基本上可以做,

785
00:54:34,000 --> 00:54:36,000
好比说很小的生物,好比说果蠅,

786
00:54:36,000 --> 00:54:38,000
或者大体可能是猪脑,

787
00:54:38,000 --> 00:54:40,000
猪脑可能可以做,

788
00:54:40,000 --> 00:54:42,000
可能就花好几个礼拜,果蠅脑是一天两天这样子,

789
00:54:42,000 --> 00:54:44,000
那假设就是说,

790
00:54:44,000 --> 00:54:46,000
它假设是一样的,

791
00:54:46,000 --> 00:54:48,000
它假设是全脑的事情,

792
00:54:48,000 --> 00:54:50,000
而不是一块块的事情,

793
00:54:50,000 --> 00:54:52,000
所以,

794
00:54:52,000 --> 00:54:54,000
如果要看,

795
00:54:54,000 --> 00:54:56,000
就是从,

796
00:54:56,000 --> 00:54:58,000
从脑组织切片,

797
00:54:58,000 --> 00:55:00,000
就这个我们有做啦,

798
00:55:00,000 --> 00:55:02,000
就是从脑切片区域里面出来,

799
00:55:02,000 --> 00:55:04,000
那要看,

800
00:55:04,000 --> 00:55:06,000
比较high level的方面,

801
00:55:06,000 --> 00:55:08,000
其实是不可能看到的,

802
00:55:08,000 --> 00:55:10,000
所以今天会做的这么多AI分析,

803
00:55:10,000 --> 00:55:12,000
其实目的就是为了搭配一件事情,

804
00:55:12,000 --> 00:55:14,000
就是我们要很快可以处理整个脑的资讯,

805
00:55:14,000 --> 00:55:16,000
那在,

806
00:55:16,000 --> 00:55:18,000
那在影像技术上面的话,

807
00:55:18,000 --> 00:55:20,000
电子显微镜是可以拍到

808
00:55:20,000 --> 00:55:22,000
那个神经的那个,

809
00:55:22,000 --> 00:55:24,000
每个神经的形状,

810
00:55:24,000 --> 00:55:26,000
是可以扫得清楚的,

811
00:55:26,000 --> 00:55:28,000
但像这个果蠅脑的话,

812
00:55:28,000 --> 00:55:30,000
大家可以去搜那个,

813
00:55:32,000 --> 00:55:34,000
Generia吧,

814
00:55:34,000 --> 00:55:36,000
就美国有一个很大的这个,

815
00:55:36,000 --> 00:55:38,000
这个果蠅脑的电子显微镜计划,

816
00:55:40,000 --> 00:55:42,000
它扫了,

817
00:55:42,000 --> 00:55:44,000
扫了两年吧,扫了半颗脑,

818
00:55:44,000 --> 00:55:46,000
然后可能花了,

819
00:55:46,000 --> 00:55:48,000
我不知道多少钱,

820
00:55:48,000 --> 00:55:50,000
总之台湾是不可能付得起的钱,

821
00:55:50,000 --> 00:55:52,000
然后这种扫描你也,

822
00:55:52,000 --> 00:55:54,000
你也没办法跟,

823
00:55:54,000 --> 00:55:56,000
好比说果蠅的行为,

824
00:55:56,000 --> 00:55:58,000
做那个,

825
00:55:58,000 --> 00:56:00,000
做比较吧,

826
00:56:00,000 --> 00:56:02,000
因为扫太久了,

827
00:56:02,000 --> 00:56:04,000
然后就一颗而已,

828
00:56:04,000 --> 00:56:06,000
你也没办法这个,

829
00:56:06,000 --> 00:56:08,000
看它行为然后做比较的样子,

830
00:56:08,000 --> 00:56:10,000
那轻大他们做的事情就是,

831
00:56:10,000 --> 00:56:12,000
然后他们也可以,

832
00:56:12,000 --> 00:56:14,000
跟方选做对应,

833
00:56:14,000 --> 00:56:16,000
因为他们可以做非常多颗,

834
00:56:16,000 --> 00:56:18,000
所以他们知道这个果蠅,

835
00:56:18,000 --> 00:56:20,000
他们生前有这种行为,

836
00:56:20,000 --> 00:56:22,000
然后有没有记忆啊,

837
00:56:22,000 --> 00:56:24,000
有没有等等等等,

838
00:56:24,000 --> 00:56:26,000
所以他们有一个platform,

839
00:56:26,000 --> 00:56:28,000
是可以把这些脑啊,

840
00:56:28,000 --> 00:56:30,000
放大等等,

841
00:56:30,000 --> 00:56:32,000
然后自动扫描下来,

842
00:56:32,000 --> 00:56:34,000
然后接起来的样子,

843
00:56:34,000 --> 00:56:36,000
那插了一块就是,

844
00:56:36,000 --> 00:56:38,000
自动影像分析嘛,

845
00:56:38,000 --> 00:56:40,000
就把这些影像放在那边了,

846
00:56:40,000 --> 00:56:42,000
那第一个它是很小块的影像,

847
00:56:42,000 --> 00:56:44,000
就一定你的view有限,

848
00:56:44,000 --> 00:56:46,000
自动组合在一起,

849
00:56:46,000 --> 00:56:48,000
然后自动,

850
00:56:48,000 --> 00:56:50,000
自动,

851
00:56:50,000 --> 00:56:52,000
自动接在一起,

852
00:56:52,000 --> 00:56:54,000
然后还要知道说,

853
00:56:54,000 --> 00:56:56,000
这些fiber长什么样子,

854
00:56:56,000 --> 00:56:58,000
什么样的fiber是独立属于哪个神经,

855
00:56:58,000 --> 00:57:00,000
然后最后才有可能说,

856
00:57:00,000 --> 00:57:02,000
推断说这些东西怎么运作,

857
00:57:02,000 --> 00:57:04,000
所以所以说没错就是,

858
00:57:04,000 --> 00:57:06,000
就是这目的其实都是为了,

859
00:57:06,000 --> 00:57:08,000
那大家觉得说,

860
00:57:08,000 --> 00:57:10,000
这唯一solution就是需要,

861
00:57:10,000 --> 00:57:12,000
需要用这些方式嘛,

862
00:57:12,000 --> 00:57:14,000
那像像国外的话,

863
00:57:14,000 --> 00:57:16,000
这些东西都跟,

864
00:57:16,000 --> 00:57:18,000
跟Google合作等等,

865
00:57:18,000 --> 00:57:20,000
那我们台湾就,

866
00:57:20,000 --> 00:57:22,000
就做我们的事情,

867
00:57:22,000 --> 00:57:24,000
就我们就想要把,

868
00:57:24,000 --> 00:57:26,000
国外的智能智能影像,

869
00:57:26,000 --> 00:57:28,000
先用AI可以分析出来,

870
00:57:28,000 --> 00:57:30,000
然后那或许之后就可以跟,

871
00:57:30,000 --> 00:57:32,000
function这东西搭配起来,

872
00:57:32,000 --> 00:57:34,000
那不过这些都是,

873
00:57:34,000 --> 00:57:36,000
这些都是生前跟生后的影像,

874
00:57:36,000 --> 00:57:38,000
生前的行为跟,

875
00:57:38,000 --> 00:57:40,000
跟结果后的影像对应啊,

876
00:57:40,000 --> 00:57:42,000
那像你刚刚说这个live,

877
00:57:42,000 --> 00:57:44,000
这个这个,

878
00:57:44,000 --> 00:57:46,000
然后他做某些方面,

879
00:57:46,000 --> 00:57:48,000
或者说play pump的话,

880
00:57:48,000 --> 00:57:50,000
我觉得,

881
00:57:50,000 --> 00:57:52,000
可能蛮有可能的,

882
00:57:52,000 --> 00:57:54,000
如果成功的话,

883
00:57:54,000 --> 00:57:56,000
可能对人类会很shock,

884
00:57:56,000 --> 00:57:58,000
我觉得有可能,

885
00:57:58,000 --> 00:58:00,000
有可能会很shock,

886
00:58:00,000 --> 00:58:02,000
我真的不知道这件事情,

887
00:58:02,000 --> 00:58:04,000
我常常看一些稀奇古怪的,

888
00:58:04,000 --> 00:58:06,000
那个research news,

889
00:58:06,000 --> 00:58:08,000
所以刚好看到这个,

890
00:58:08,000 --> 00:58:10,000
oh my god,

891
00:58:10,000 --> 00:58:12,000
我赶快同时讲,谢谢,

892
00:58:16,000 --> 00:58:18,000
那,

893
00:58:18,000 --> 00:58:20,000
这个,

894
00:58:22,000 --> 00:58:24,000
我现在,

895
00:58:24,000 --> 00:58:26,000
那我们今天就先到这边,

896
00:58:26,000 --> 00:58:28,000
反正就是这个,

897
00:58:28,000 --> 00:58:30,000
我现在要关这个,

898
00:58:30,000 --> 00:58:32,000
感谢最后,

899
00:58:32,000 --> 00:58:34,000
最后感谢那个张翰,

900
00:58:34,000 --> 00:58:36,000
谢谢,

901
00:58:36,000 --> 00:58:38,000
OK

