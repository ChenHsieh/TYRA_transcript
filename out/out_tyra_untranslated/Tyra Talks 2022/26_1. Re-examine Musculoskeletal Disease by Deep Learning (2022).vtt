WEBVTT

00:00.000 --> 00:25.000
好,那很欢迎大家来到今天的Taiwan Talk,今天是1月8号,我们今天很高兴呢,到张翰,他目前呢是在台湾大学服务,他的PhD是在美国University of Massachusetts Amherst,然后PhD后来呢他在Boston进了一家生技产业,

00:25.000 --> 00:45.000
然后后来呢又到了Boston University,就是BU的医学院,就是School of Medicine,做博士后研究,然后在2021年的时候呢他回到台湾大学,在医材影像所担任助理教授,今天呢我们很高兴有他来演讲。

00:45.000 --> 01:01.000
那Taiwan的小小的传统就是呢,我们会请大家把麦克风打开,然后拍手,欢迎我们的讲者,那现在欢迎我们的讲者张翰老师。

01:05.000 --> 01:09.000
好的,那可以share screen了。

01:15.000 --> 01:17.000
有看到吗?

01:35.000 --> 01:37.000
有看到吗?

01:37.000 --> 01:39.000
可以看到了。

01:39.000 --> 01:44.000
好,那也谢谢您介绍。大家好,我是张翰。

01:45.000 --> 02:02.000
我刚刚所说,我是2016年博士班毕业的,然后之后是辗转几个单位,就是有一些新创公司要去博士后,然后我是去年2021年的时候回到台大做助理教授。

02:02.000 --> 02:12.000
我记得Tara一开始申请,我记得表格说什么会员有每年一次报告研究之义务,然后我这件事情一直记在心里。

02:12.000 --> 02:22.000
我回台湾之后基本上就很少上线,因为都起不来,所以想说还是要贡献一下。

02:22.000 --> 02:42.000
今天也没全省,不过就是来跟大家聊聊。主要目的还是跟大家分享一下,另外也是如果大家对回台湾的环境有什么问题的话,我们等一下可以再讨论一下。

02:43.000 --> 03:09.000
我自己实验室是做号称AI影像的分析,我本来做博士后的时候是做肌肉骨骼影像,主要治疗标的是退化性关节炎,另一方面就是回台湾之后又找一些其他的合作项目,包括脑科学跟线外影像等等。

03:09.000 --> 03:25.000
等一下我有时间的话会稍微讲一下。AI这件事情可能是大家听演讲,每两周就会听到一次,所以介绍性的话我就很快带过去了。

03:25.000 --> 03:43.000
大家知道AI在过去的五年、十年大概发展很快,很多影像辨识、分类、政策等等的表现超过人的标准,大概是最近几年发生的事情。

03:44.000 --> 04:02.000
如果你看脑科学的话,比较旧的Letter,他们都会说图像辨识、人脑、电脑这些超过,可是假设你们再看一下Letter,可能五年内的话他们就会改口。

04:02.000 --> 04:10.000
所以这个改变是最近几年的事情,可能大家都在自己的领域会感受到了。

04:10.000 --> 04:30.000
在艺术影像上,影像上的modality是一个非常非常缓慢的过程。大家可能听过Hobart有一个Gordon Center,Gordon Center是影像中心合作PathGen的发明人,就是Gordon跟Charles。

04:31.000 --> 04:45.000
他们做的是PathGen的前身,基本上原理其实是差不多的。他们的影像解析度的lower boundary是跟现在是一样的。

04:45.000 --> 05:00.000
所以在艺术影像上的modality是一个非常非常慢的过程,通常都是几十年。通常都是几十年的adaptation要implement,然后被定创大规模使用。

05:00.000 --> 05:17.000
所以有时候这一个领域或者AI有兴趣,不是因为,是不得不然,是因为发展太慢了。所以看到新的工具就赶快想利用看看,看到什么改变机会。

05:17.000 --> 05:33.000
基本上Machine Learning或Deep Learning这些东西,它的功能就是找一个function,好比说我们可以做一个function去看图像,可以做分类。假设自然影像的话,分类就是分车子,分猫狗之类的。

05:33.000 --> 05:51.000
马上就有人想说,我可不可以做诊断,所以分类在艺术影像的对应就是诊断嘛,好比说一把子hammer,就是calculation。像detection,大家做生物实验的话就发现鼠细胞这件事情是非常古老的labor。

05:51.000 --> 06:06.000
那detection的话,假设自驾车的话,就是数行人,数别车等等。基本上一样的idea就是做一个function,然后放进slide,就会数细胞等等,这是侦测。

06:06.000 --> 06:29.000
最后就是切割,切割就是在艺术影像上面也是使用关节的各部分,或者把器官切割出来。基本上就是你有想做的function,你有一个input,你有一个output。Machine Learning就是用自我最佳化的方式去把这个function找出来。

06:30.000 --> 06:54.000
我自己做的题目是ulcerocytes,就是退化性关节炎。这是很老的疾病,就是老人的疾病。大家可能听到第一波的AMS,可能听到比较有名的,好比说糖尿病DMD影像,好比说oncology,就是癌症的肿瘤分割政策,还有cardiovascular。

06:54.000 --> 07:19.000
这些当然就是因为这些疾病在美国是大课,假设我们数致死率的话,最前面是oncology和cardiovascular,就是因为需求而产生的这些情绪。我自己做ulcerocytes,它是退化性关节炎,它没有什么直接致死的passway。

07:20.000 --> 07:38.000
如果你看美国第一名造成失能,disability的话,第一名就是ulcerocytes,就是一切关节炎。那里面大概三分之二是ulcerocytes,其他是免疫性关节炎。

07:39.000 --> 07:53.000
第二名通常是背痛,我们国外很常会背痛,所以背痛也大大造成是很常见的。所以基本上这些肌肉骨骼病病人在造成disability在美国是非常非常常见的。

07:54.000 --> 08:04.000
如果我们看开刀又花钱的话,通常数一数二的就是第一个是spine infusion,就是治疗脊椎,第二个就是replacement。

08:05.000 --> 08:19.000
所以基本上这些肌肉骨骼的疾病,它如果不开刀的话就造成很多的失能。假设它开刀的话就会有很大的花费。

08:20.000 --> 08:30.000
我们大家知道台湾是老化社会,这是第一个特性。第二个是台湾什么事情美国发生,台湾五年后就会发生。

08:31.000 --> 08:46.000
这些事情对社会成本和社会健保的负担是会一增加一增加的增加。数数字就知道了,不需要看什么forecast,数数字就会负不起。

08:46.000 --> 09:00.000
比方台湾的话,像这个new placement在美国也算是蛮贵的手术,成功率很高。台湾也算是一个一定要付但是非常昂贵的手术。

09:01.000 --> 09:11.000
所以怎么用一些方式可以让病人不需要进入到社会分解的pathway其实是蛮重要的。

09:12.000 --> 09:24.000
基本上,如果我们想说什么样的原因会造成病人需要换吸管,基本上就是疼痛难当,就是疼痛无法忍受就会换吸管。

09:25.000 --> 09:43.000
大部分人都会忍受自己失能,就好比说这个关节炎有好几个symptom,可能一开始会活动能力受限,要conquer stiffness,最后可能会疼痛。

09:43.000 --> 09:55.000
那其实stiffness或是活动能力受限很多人可以忍受,大家在美国大家知道吧,可能坐这个代步车就可以走一走去了。

09:55.000 --> 10:18.000
那疼痛是无法忍受的。所以病人为什么最后会做开刀的决定,通常都是有一个pain spike,就是在要开刀之前,如果我们回顾他每年的function是怎么发生的话,都会有一年或两年前是突然疼痛增加了。

10:18.000 --> 10:33.000
疼痛一增加,然后无法忍受,就跑去开刀了。如果疼痛是慢慢增加的话,大家知道耐痛是可以慢慢习惯的,反而还可以撑比较久。如果有一个pain spike的话,通常就跑去开刀了。

10:33.000 --> 10:50.000
那会造成什么原因造成疼痛增加呢?如果我们直接画那个coalition是一个OA的定程,它叫KO grid,是一个OA的rheographic,就是X光上面的平分的话,那基本上跟疼痛是没有什么关系的。

10:50.000 --> 11:07.000
很多人,好比说大家听到的那个NBA球员,有人没有软骨,然后还是可以打球,然后有人是膝盖正常,但很疼痛,所以基本上传统上的rheographic的关节点的平分跟疼痛没有关系。

11:07.000 --> 11:29.000
所以先假设我们要研究这个OA是什么造成疼痛的话,传统上我们就是找到那边的人,可能像美国的话就OA付钱做trial,然后把这些MRI都拍下来,然后接下来要找医生去做grading,大家都很熟悉嘛。

11:29.000 --> 11:41.000
基本上OA这些影像判读是需要有经验的医生,专门要看膝盖和关节炎的,所以成本很贵。

11:59.000 --> 12:20.000
主持人员:"不好意思,不好意思,我小孩在重庆诶,不好意思。我请他妈来救援一下。

12:21.000 --> 12:38.000
所以基本上你得到的资料都是非常少,也不一定一致,因为这些grading工作很慢,所以大部分都是很多routing center协作完成的,所以每个人的标准不太一样。

12:39.000 --> 12:51.000
所以有时候统计分析的话,基本上过去效果都很差。所以这时候我们就讲到,有时候是需求决定了为什么要导入这些新的技术,是不得不然的。

12:51.000 --> 13:07.000
所以我们既然用传统方式的grading很困难,又很花时间,那我们就导入AI,直接就最后一步,我们就完全放弃了这些所谓的影像特征的grading,

13:07.000 --> 13:21.000
我们直接把你看到这些OA病变的MRI输到先进网络里面去,然后我们用的outcome就是我们想要看的地方。

13:22.000 --> 13:36.000
好比说以这个project而言的话,它的outcome就是疼痛,病人有多少疼痛,再加上疼痛有没有突然增加。

13:36.000 --> 13:51.000
所以这就是一个不再无法得知,或者本来就对什么样的病变造成疼痛不太清楚的状况下,使用这个方式。

13:51.000 --> 14:05.000
好处大家知道吗,就是它很一致,它是同一个模型去看一些东西,所以特别适合这种clinical trial,就假设你有一个很一致的cohort,全部资料都是用同样的方式拍的话,

14:05.000 --> 14:11.000
它标准的非常一致,它是自动的,所以只有你训练成功,它就没有成本。

14:11.000 --> 14:23.000
那这个处理这个图像的基本上deep learning的网络就是convolutional neural network,大家很常听过,就是全机神经网络。

14:23.000 --> 14:37.000
那它原理大概述下来,就是用一层一层的filter,大家做影像处理可能用filter,filter就是抓不同的特征,影像特征这样子。

14:37.000 --> 14:43.000
那因为我不知道什么样的特征是比较重要的,我就让它自己optimize,自我更新。

14:43.000 --> 14:53.000
那它就会照着这些方式层层更新,然后把这些影像处理成一些对结果的特征这样子。

14:53.000 --> 15:03.000
那通常这个trivial neural network有一个重大的缺点,就是它很难控制confounder。

15:04.000 --> 15:14.000
我们知道在医学上面,所有的事情都是影像加上confounder。

15:14.000 --> 15:23.000
比如说这个人会不会,可能会恶化,是他的影像加上体重,加上他的生活情况,加上这些人有没有受伤等等。

15:23.000 --> 15:42.000
所以我们做这个影像分析的时候,如果你把病人全部资料都丢进去,那虽然你想看到的是病人本身的影像,你想在影像上找到重要的特征。

15:42.000 --> 15:48.000
可是只要neural network有任何读到confounder的方式的话,它就会随着pathway过去。

15:48.000 --> 15:54.000
所以假设你的膝盖比较大,显然是体重比较重。

15:54.000 --> 16:03.000
那neural network看膝盖比较大的事情,如果它可以跟outcome有关联的话,它就看膝盖比较大,它就忽略其他一些因素。

16:03.000 --> 16:09.000
所以基本上deep learning的模型对confounder有很大的bias。

16:09.000 --> 16:15.000
其中一个最简单的方式就是对冲。

16:15.000 --> 16:21.000
你可以找两个有一样confounder的subject,然后让它互相抵消掉。

16:21.000 --> 16:27.000
比如说我可以选一批评论者,他可能是疼痛增加前或增加后。

16:27.000 --> 16:30.000
他同一个subject,所以他有类似的confounder。

16:30.000 --> 16:37.000
所以如果我把一个网络同时参考两个incidence的话,他们confounder就互相消掉了。

16:37.000 --> 16:42.000
另一个可能就是所谓的cross lateral,左右膝盖。

16:42.000 --> 16:47.000
有些人在刚恶化的时候,一个膝盖会先恶化。

16:47.000 --> 16:54.000
那通常久了之后另一个膝盖也会带长,也会追上来。

16:54.000 --> 17:03.000
可是是有一些incidence,你是可以抓在一瞬间就这些不平等的现象,那这时候你可以把左右膝盖当对照。

17:04.000 --> 17:07.000
这还有好处就是说,其实疼痛是主观因素。

17:07.000 --> 17:12.000
我们疼痛,大家可能去看过牙医,然后常常会填笑脸图。

17:12.000 --> 17:16.000
就是绿色的笑脸是0,然后黄色的是0。

17:16.000 --> 17:19.000
然后医生问你有多痛,然后你讲不出来。

17:19.000 --> 17:24.000
然后他问你说,如果是0到10,你有多痛,那你也讲不出来。

17:24.000 --> 17:30.000
这很奇怪,但是基本上这是一个主观回报的事情。

17:30.000 --> 17:40.000
但是如果同一个病人,他回报两边膝盖的话,他两边都是主观的嘛,他对疼痛的耐受程度是一样的。

17:40.000 --> 17:51.000
然后另一个可能是,假如他疼痛并不来自膝盖,就有蛮多病人,他们的症状是来自我们说的neurosystem,那这也是confounder。

17:51.000 --> 17:57.000
可是如果他同时回报说两个膝盖中有差异的话,那他回报就是疼痛的差异而不是疼痛。

17:57.000 --> 18:01.000
这件事也是一个控制主观因素的方法。

18:01.000 --> 18:13.000
所以我本来就有工作是拿这些疼痛跟不痛的膝盖,拿来做这些所谓的contracted learning,就是对照性的学习。

18:13.000 --> 18:21.000
然后想要把症状有差异的一边预测出来,显然结果就是比用医生传统判断方式好很多。

18:21.000 --> 18:38.000
大概多10%的AUC,AUC就是一个二分类的评分架构,通常本来就是60-70,用的方法可以做到85-90,所以其实本质就有差别。

18:39.000 --> 18:56.000
那另一个事情是说,Fockin常听到所谓的可解释性AI,是一个buzzword,所以SAI,Explainable AI,这是一个buzzword,其实你自己看定义什么的话其实很难讲。

18:56.000 --> 19:04.000
我们所谓Explainable就是对使用者是Explainable,就是那个使用人觉得是合理的,他就是可解释。

19:04.000 --> 19:09.000
所以基本上使用人想要什么,他就是什么。

19:09.000 --> 19:25.000
那传统上我们在医学影像上我们认为我们的使用者其实是医生嘛,所以表示我们模型要做出一件决定,那这个决定想要把它传达让医生觉得说它是合理的。

19:26.000 --> 19:45.000
那现在大部分的differentiate方式都是用saliency map,热区图,有很多争议,一般人认为热区图上面的热区,指向的地方没有太夸张的话,就表示它可能没有错太离谱,它可解释力没有错太离谱。

19:46.000 --> 20:01.000
那基本上这是一个很弱的条件啦,就是如果它热区图很离谱的话就可以排除,但是它如果对的话,也不一定是因为正确原因做正确的事情,它可能就是重叠在那边。

20:01.000 --> 20:04.000
基本上这些saliency map只有未知资讯而已。

20:04.000 --> 20:14.000
我们今天做的一些工作是想法改进这些热区图的解析度,可以让这些图可以把个别的病变分出来。

20:14.000 --> 20:32.000
这时候再回头问医生说,我们指出这些病变的位置有没有跟你图片中想的疼痛的位置是有可能的,可以用这个方法来探讨说是什么样的病变最有可能造成疼痛,然后跟医生的想法有没有合理这样子。

20:35.000 --> 20:46.000
不过这种方式有它的很大的限制,第一个它逻辑对不对大家都还在讨论,这种热区图方式能不能解释它是可解释的,大家都还在讨论。

20:46.000 --> 21:01.000
第二个,你这个也很难拿来定量,大家如果看热区图的话,它毕竟是interpreter来的,所以它形状其实没什么意义,它就是这些点做一个interpreter,然后就变成区域。

21:01.000 --> 21:16.000
可是你仔细看这些形状跟region形状有没有直接对应,其实是有问题的,所以你直接把这些高亮度的地方划成counter来统计,其实是无法定量的。

21:16.000 --> 21:37.000
假如不要夸张一点的话,假如看到一些脑肿瘤的热区图,那可能肿瘤在脑的边边,那热区就会一半在脑内一半在脑外在背景上面,所以它定位能力其实是很有问题的,有它的限制。

21:37.000 --> 21:51.000
有什么比较直观的方式可以做这些feature的运造工作呢?

21:51.000 --> 22:09.000
我大概想一下,如果有看医学影像的话,我们常做的事情就是比较。好比说一病人做疾病在追踪,医生可能看了他的新的影像,他恶化的话,那就是拿前一张影像来比较。

22:09.000 --> 22:25.000
假设他是做治疗的话,可能是本身的一张影像变好了,然后他也会拿旧的影像做比较。所以比较影像这件事情是人脑会自动拟合出来,这是人脑很神奇的功能。

22:25.000 --> 22:45.000
那其实我们今天对单张影像可以分析得很好,但是影像比较这件事情,其实人脑是有它独特的mechanism,然后我们电脑都还没有办法完全追上。

22:46.000 --> 22:59.000
今天假设说好,我今天有一个病人,他会有一个症状突然发生,所以一开始症状是进展比较慢,突然就恶化了。

23:00.000 --> 23:10.000
如果你是医生的话,你合理的做法是说,我看一下pain spike前后发生什么事情,所以就会把两张影像调出来。

23:11.000 --> 23:21.000
然后医生放左边跟放右边,脑中就自动拟合出两边的差异在哪里。那我们要怎么教电脑做这件事情?

23:22.000 --> 23:37.000
传统上的话,像我们刚刚做的所谓的判别式模型,是想法把左边跟右边这两个有疼痛跟没疼痛的影像区分出来。

23:37.000 --> 23:42.000
比较合理的方式是做这种比较式模型。

24:08.000 --> 24:11.000
大家可能还记得,也差14年了。

24:12.000 --> 24:20.000
所以我们看了这两个pair,就马上可以想说哪边是正常,哪边是不正常的老化。

24:20.000 --> 24:24.000
就显然左边是不正常老化,这不正常,这正常。

24:25.000 --> 24:30.000
所以人脑有神奇的功能,就是它可以看到影像的改变。

24:31.000 --> 24:34.000
然后我们脑中第一件事情,我们有两个pre-test。

24:34.000 --> 24:44.000
第一个是我们知道它同一个subject,这很重要,因为假设你不跟人说这个跟这个同一个subject的话,

24:44.000 --> 24:46.000
没人会拿来一起比较,他以为是两个不同的人。

24:46.000 --> 24:48.000
所以你刚刚说的是同一个subject。

24:48.000 --> 24:58.000
第二个事情是,你脑中对正常老化有一个概念,你知道说14年人大概会变成什么样子。

24:59.000 --> 25:07.000
那我们也可以用同样的方式去观察说,改变前跟改变后的医学影像。

25:07.000 --> 25:12.000
到底什么样的变化是正常变化,什么样的变化不是正常变化。

25:12.000 --> 25:19.000
这变化可以有很多种,你可以是ten-tone的progression。

25:19.000 --> 25:25.000
假设我们用一个统计模型来看说这个人未来开刀几率基于影像的话,

25:25.000 --> 25:32.000
那我们也可以问说,假设同一个病人他的toA跟toB突然他的开刀几率变很高了,

25:32.000 --> 25:34.000
那是什么样的事情造成他这样的差异。

25:34.000 --> 25:38.000
所以是一个比较差异的framework。

25:38.000 --> 25:51.000
所以就是,这件事情会成功,就是他从subject,脑中有一个所谓的正常的reference。

25:52.000 --> 25:57.000
那我们在做这件事情的时候,脑中是有正常的reference,所以你没有感受到,

25:57.000 --> 26:01.000
但人脑是很神奇的,会自动在背后处理。

26:01.000 --> 26:08.000
那我们今天要把这个用deep learning来拟合这件事情的话,

26:08.000 --> 26:12.000
那最直接的方式就是所谓的商场对抗网络。

26:12.000 --> 26:15.000
那大家可能也听过,商场对抗网络就是好比说,

26:15.000 --> 26:24.000
很多合成脸、合成video、合成声音等等的模型都是根据这些技术,是同一个family。

26:24.000 --> 26:28.000
它逻辑就是说,我今天有一个叫生成器,

26:28.000 --> 26:34.000
它生成器是可以拿图片当成它的condition,

26:34.000 --> 26:41.000
那生成器图片进去之后,它就会出来一张以input图片当成条件的图片,

26:41.000 --> 26:44.000
那它跟它之间有点对应的关系。

26:44.000 --> 26:46.000
那它生成条件是什么?

26:46.000 --> 26:54.000
它生成条件就是,你拿这个真的reference图片,

26:54.000 --> 26:57.000
然后它会拿这个当参考,

26:57.000 --> 27:03.000
所以整个结论是说,你的生成器会拿一部图片,

27:03.000 --> 27:09.000
生成一张跟reference图片很像的真的图片。

27:09.000 --> 27:14.000
所以我们的做法可以说,我们可以把要比较的对比的reference,

27:14.000 --> 27:16.000
就是real healthy,

27:16.000 --> 27:21.000
好比说,左右膝盖的话,你就是不要不痛的膝盖当成reference,

27:21.000 --> 27:24.000
不要痛的膝盖当成real disease,

27:24.000 --> 27:27.000
然后我们去合成出一个假的healthy。

27:27.000 --> 27:32.000
那这个差值就是比较差异嘛,

27:32.000 --> 27:36.000
虚拟同样的造型,它如果不痛的话会长什么样子?

27:37.000 --> 27:39.000
那在定义上我们叫counterfactual,

27:39.000 --> 27:41.000
就是假设性的一个case,

27:41.000 --> 27:46.000
这两个差异就会是我们想要看到的改变部分。

27:50.000 --> 27:53.000
另一部分就是所谓的healthy reference,

27:53.000 --> 28:02.000
就是我们脑中比较知道什么样的膝盖变化是正常的。

28:02.000 --> 28:07.000
那大概讲说我们要比较的这些reference应该不是18岁健康的膝盖,

28:07.000 --> 28:10.000
我们的OA是不可,是老化的疾病。

28:10.000 --> 28:14.000
所谓老化的疾病就是说,所有人都很老,

28:14.000 --> 28:18.000
所以有些影像上面的改变是正常的,我们需要接受,

28:18.000 --> 28:21.000
好比说我们看做那个Azheimer影像的话,

28:21.000 --> 28:25.000
这个老人的Azheimer影像都会有脑缩,

28:25.000 --> 28:27.000
可是脑缩是老人就会缩啊,

28:27.000 --> 28:31.000
并不是Azheimer他会缩。

28:31.000 --> 28:33.000
所以像Azheimer这个研究的话,

28:33.000 --> 28:37.000
很大一部分的目的就是要想要把这些正常老化跟不正常老化,

28:37.000 --> 28:40.000
所谓的Azheimer倒转老化来区分出来。

28:40.000 --> 28:42.000
那所以我们OA也是一样,

28:42.000 --> 28:47.000
我们并不是要把这些膝盖还原到18岁的完美状况,

28:47.000 --> 28:51.000
我们也没有这些影像,因为18岁不会去拍MRI。

28:51.000 --> 28:56.000
那我们要,我们的reference应该是正常老化,

28:56.000 --> 29:00.000
它是50,60,70,就该那样子,老就是会老,

29:00.000 --> 29:06.000
但是它要是function或是什么东西还正常的。

29:06.000 --> 29:12.000
所以像我们的话,我们就选说假设这些病人都是0致命OA,

29:12.000 --> 29:16.000
或是preclinical,就是还没有进入临床上的OA,

29:16.000 --> 29:18.000
然后也不会开刀,

29:18.000 --> 29:21.000
所以这些人我们就定义成他是所谓的健康老化嘛。

29:21.000 --> 29:28.000
那我们要,那我们的reference就是定义到把图拉到这些健康老化的状况上面,

29:28.000 --> 29:32.000
而不是一个真空中完全健康完美的膝盖这样子。

29:32.000 --> 29:37.000
所以这个好比说治疗前治疗后,

29:37.000 --> 29:40.000
然后好比说这个pain spike,control incidence,

29:40.000 --> 29:44.000
然后好比说不同的modality,

29:44.000 --> 29:47.000
这种比较性概念是一个很强的framework,

29:47.000 --> 29:51.000
因为我觉得这个在医学影像上,

29:51.000 --> 29:57.000
很多时候我们是凭借这个比较这些事情来处理资讯的,

29:57.000 --> 30:01.000
那基本上如果你去看诊的时候,

30:01.000 --> 30:03.000
要看医生做什么,

30:03.000 --> 30:05.000
其实很常这样发生的,

30:05.000 --> 30:07.000
就是左边一张右边一张,

30:07.000 --> 30:13.000
然后用比较来决定死因发生,

30:13.000 --> 30:15.000
所以这是一个很泛用的framework,

30:15.000 --> 30:19.000
并不只是在这个我目前做的topic上面。

30:19.000 --> 30:26.000
所以我们先拿一个正常的disease,

30:26.000 --> 30:28.000
然后产生说fit healthy,

30:28.000 --> 30:29.000
然后产生real healthy,

30:29.000 --> 30:36.000
那我们用一个回归器的方式,

30:36.000 --> 30:39.000
我们可以训练一个回归器,

30:39.000 --> 30:42.000
它就跟一般做回归一样,

30:42.000 --> 30:44.000
用图像做回归,

30:44.000 --> 30:48.000
那它目的就是要观察这些健康老化的器材,

30:48.000 --> 30:54.000
然后要观察说它的年龄长什么样子,

30:54.000 --> 30:55.000
因为这些也是健康老化的,

30:55.000 --> 31:01.000
所以它的预测出来的年龄就会是它本身的年龄。

31:01.000 --> 31:06.000
那做完之后如果拿这些同样的模型,

31:06.000 --> 31:08.000
去观察一些不健康老化的病人的话,

31:08.000 --> 31:16.000
就发现他的实际年龄会小于他膝盖的appearance age。

31:16.000 --> 31:21.000
那这个concept其实大家可能听过脑灵嘛,

31:21.000 --> 31:24.000
这个在其他分析中也常用到,

31:24.000 --> 31:27.000
或者说大家可能听过脑灵检测等等,

31:27.000 --> 31:31.000
就是有些人的脑看起来就是比他实际年龄老,

31:31.000 --> 31:32.000
这个脑灵检测,

31:32.000 --> 31:36.000
那其实也可以用同样的逻辑来做嘛,

31:36.000 --> 31:40.000
就是拿一个不同年龄的模型去看健康老化的老人,

31:40.000 --> 31:43.000
然后再回来看一些不同的病人。

31:43.000 --> 31:46.000
那有关脑灵这部分的话,

31:46.000 --> 31:47.000
台湾也有人做,

31:47.000 --> 31:48.000
国外也有人做,

31:48.000 --> 31:53.000
那还发现说不同的neurological disorders,

31:53.000 --> 31:54.000
还有不同的,

31:54.000 --> 31:56.000
就是他的年龄会有不同的shift,

31:56.000 --> 31:58.000
他的shift pattern还不一样。

31:58.000 --> 32:03.000
那又好比说大家看医生的时候,

32:03.000 --> 32:09.000
如果大家去见检的话,

32:09.000 --> 32:10.000
常常被问说,

32:10.000 --> 32:12.000
你看起来不像年轻人,

32:12.000 --> 32:14.000
这件事情也是一样的嘛,

32:14.000 --> 32:18.000
就是你的appearance跟你的实际不如预期,

32:18.000 --> 32:21.000
不如预期这件事情本身就是一个spell marker,

32:21.000 --> 32:25.000
所以病人会跟你说,

32:25.000 --> 32:26.000
你看起来不太好,

32:26.000 --> 32:28.000
但是你跟五十岁比起来还不错啦,

32:28.000 --> 32:30.000
就不会这样子嘛,

32:30.000 --> 32:33.000
比起来是跟你的健康年龄该怎么样,

32:33.000 --> 32:36.000
如果差异的话就表示有问题嘛,

32:36.000 --> 32:38.000
所以这个比较脑灵,

32:38.000 --> 32:41.000
比较年龄这些事情是很有意义的。

32:41.000 --> 32:44.000
所以我们今天就拿这个,

32:44.000 --> 32:48.000
把这个healthy reference这些事情来结合起来,

32:48.000 --> 32:49.000
所以我们怎么做,

32:49.000 --> 32:50.000
我们有真的disease,

32:50.000 --> 32:52.000
然后我们产生一个fake healthy,

32:52.000 --> 32:56.000
然后我们这个fake healthy还有一个condition,

32:56.000 --> 33:01.000
就是fake healthy经过健康年龄的regression年龄的话,

33:01.000 --> 33:03.000
要是本来的年龄,

33:03.000 --> 33:09.000
所以我们不会生成出一个很假膝盖的样子,

33:09.000 --> 33:14.000
我们生成出一个他该怎么年龄就怎么年龄的膝盖,

33:14.000 --> 33:15.000
对,

33:15.000 --> 33:21.000
就是一个拟合出他这个年龄上该有的状况的样子,

33:21.000 --> 33:25.000
所以他生出来的模型都不会是完美的,

33:26.000 --> 33:27.000
如果本来有大脊椎的话,

33:27.000 --> 33:29.000
那可能就是小脊椎,

33:29.000 --> 33:32.000
本来假设软骨有全掉的话,

33:32.000 --> 33:34.000
可能就变掉三层,

33:34.000 --> 33:35.000
都不会是完美的膝盖,

33:35.000 --> 33:43.000
可是这个差异就是我们认为是造成有疾病的medication的原因。

33:45.000 --> 33:47.000
所以基本上,

33:49.000 --> 33:53.000
这个GAN技术目前非常有用,

33:53.000 --> 33:57.000
当然看到一些生成VDR等等,

33:57.000 --> 34:01.000
已经可以很愉快的控制它们,

34:01.000 --> 34:08.000
所以目前假设我们有一些MRM想要找各种条件,

34:08.000 --> 34:11.000
比如说把疼痛疾病移除掉,

34:11.000 --> 34:13.000
都可以很愉快的做到,

34:13.000 --> 34:15.000
它就会有类似的anachronism形状,

34:15.000 --> 34:17.000
所以同个subject,

34:17.000 --> 34:20.000
但是疾病的一些feature就消失掉了。

34:24.000 --> 34:30.000
我们对这种GAN生成影像的最大的抗拒就是,

34:30.000 --> 34:32.000
它是假的吗?

34:32.000 --> 34:34.000
这些影像并不真的存在吗?

34:34.000 --> 34:39.000
到底要怎么知道这些影像是可信还是不可信呢?

34:39.000 --> 34:42.000
在医学上很困难,

34:42.000 --> 34:44.000
因为这些都是假设性的,

34:44.000 --> 34:45.000
不能重拍,

34:45.000 --> 34:47.000
所以很难说到底是真的还是假的。

34:48.000 --> 34:54.000
好比说我今天要预测一个tumor会不会有progression,

34:54.000 --> 34:57.000
这很难知道,

34:57.000 --> 34:59.000
因为它可能有progression,

34:59.000 --> 35:00.000
可能没有progression,

35:00.000 --> 35:01.000
如果它有progression,

35:01.000 --> 35:03.000
它预测的方式可以有很多种,

35:03.000 --> 35:05.000
它可以往某地方转移,

35:05.000 --> 35:07.000
或者它的扩散有什么样的扩散,

35:07.000 --> 35:10.000
所以progression这件事情很难讲,

35:10.000 --> 35:12.000
因为未来是有很多种。

35:12.000 --> 35:16.000
但是从病变变回健康这件事情,

35:16.000 --> 35:18.000
其实有一个逻辑在那边,

35:18.000 --> 35:19.000
它逻辑就是说,

35:19.000 --> 35:22.000
健康的状态应该是都很类似的,

35:22.000 --> 35:25.000
不健康的状态应该都是很不类似的,

35:25.000 --> 35:28.000
大家有听过这个,

35:28.000 --> 35:29.000
安娜·卡赖里娜,

35:29.000 --> 35:30.000
她的第一句就是说,

35:30.000 --> 35:31.000
happy families are all alike,

35:31.000 --> 35:34.000
就是所有高薪的家庭都是一样的,

35:34.000 --> 35:35.000
都类似的,

35:35.000 --> 35:38.000
everyone's happy family is happy in its own way,

35:38.000 --> 35:42.000
那这个在科学上有很多,

35:42.000 --> 35:45.000
这是principle在科学上有很多应用,

35:45.000 --> 35:46.000
主要想法就是说,

35:46.000 --> 35:50.000
一个健康的状况应该是都很类似的,

35:50.000 --> 35:53.000
所有的条件都很好的健康状况,

35:53.000 --> 35:55.000
开始病变之后,

35:55.000 --> 35:58.000
它就会往各处发散,

35:58.000 --> 36:00.000
就会变得很不一样,

36:00.000 --> 36:04.000
所以你要从健康预测不健康是比较困难的,

36:04.000 --> 36:07.000
这样不健康反推回来是比较容易的,

36:07.000 --> 36:09.000
因为健康状况应该是类似的,

36:09.000 --> 36:12.000
其他我不敢讲,

36:12.000 --> 36:14.000
但在膝盖影像上面,

36:14.000 --> 36:17.000
健康的膝盖骨头,

36:17.000 --> 36:18.000
软骨,

36:18.000 --> 36:19.000
半夜半,

36:19.000 --> 36:20.000
这都是有天生的形状,

36:20.000 --> 36:22.000
所以健康状况是,

36:22.000 --> 36:25.000
其实我们知道应该长什么样子,

36:25.000 --> 36:29.000
所以假如你要画成群剧图的话,

36:29.000 --> 36:32.000
你有一坨白色的健康状况,

36:32.000 --> 36:33.000
都应该蛮类似的,

36:33.000 --> 36:36.000
然后它的病变开始之后就慢慢发散,

36:36.000 --> 36:39.000
所以你要从健康推到不健康,

36:39.000 --> 36:41.000
其实蛮困难的,

36:41.000 --> 36:44.000
因为你很难验证说,

36:44.000 --> 36:46.000
你推断对不对,

36:46.000 --> 36:49.000
但你从不健康的图片反推回来的话,

36:49.000 --> 36:50.000
是比较容易的,

36:50.000 --> 36:52.000
然后你有很多工具可以验证,

36:52.000 --> 36:55.000
比如说你可以验证软骨的,

36:55.000 --> 36:57.000
或是半夜半的形状等等,

36:57.000 --> 36:58.000
有没有正常。

37:03.000 --> 37:05.000
那最后一点是说,

37:05.000 --> 37:08.000
我们刚讲比较性是拿,

37:08.000 --> 37:10.000
有疼痛跟没有疼痛比较嘛,

37:10.000 --> 37:13.000
那有疼痛跟没有疼痛是一个binary,

37:13.000 --> 37:16.000
是我们自己把它变成binary嘛,

37:16.000 --> 37:17.000
但其中其实没有可能嘛,

37:17.000 --> 37:19.000
因为很多事情变成binary,

37:19.000 --> 37:21.000
是我们人为的因素嘛,

37:21.000 --> 37:27.000
好比说我今天病人照那个0到10的疼痛表,

37:27.000 --> 37:29.000
来回报疼痛,

37:29.000 --> 37:31.000
那他可能说左边是3,右边是7,

37:31.000 --> 37:34.000
然后下来病人说左边是1,右边是5,

37:34.000 --> 37:35.000
那差值都是4,

37:35.000 --> 37:38.000
然后我做研究,

37:38.000 --> 37:39.000
所以我要强迫变binary,

37:39.000 --> 37:41.000
我说这是4,所以是一样的,

37:41.000 --> 37:43.000
其实是不一样的嘛,

37:43.000 --> 37:46.000
那或是说差是1到8,

37:46.000 --> 37:47.000
或是1到6,

37:47.000 --> 37:50.000
那差值是一大一小,

37:50.000 --> 37:51.000
可是我做binary,

37:51.000 --> 37:52.000
我binaryize,

37:52.000 --> 37:54.000
那我会觉得是一样的,

37:54.000 --> 37:56.000
可是这些一样,

37:56.000 --> 37:58.000
其实是人为的解释嘛,

37:58.000 --> 38:00.000
大家想要知道就是,

38:00.000 --> 38:02.000
这些人为把一些事情做二本法,

38:02.000 --> 38:04.000
其实是一个很常用的工具,

38:04.000 --> 38:08.000
但是并不代表说二本法的边界有任何特别的地方,

38:08.000 --> 38:10.000
这举个例子好了,

38:10.000 --> 38:13.000
假如说有常人来台湾的话,

38:13.000 --> 38:14.000
很常听说8是量表嘛,

38:14.000 --> 38:16.000
8量表就是一个二本法嘛,

38:16.000 --> 38:20.000
就是我觉得量表的左边就是不需要看护,

38:20.000 --> 38:21.000
右边是需要看护,

38:21.000 --> 38:25.000
那这个线的左边右边有什么magical thing happen,

38:25.000 --> 38:26.000
它变不一样嘛,

38:26.000 --> 38:27.000
其实没有,

38:27.000 --> 38:30.000
所以二本法其实是很confusing,

38:30.000 --> 38:34.000
我们在医学上知道它有很多人为设出来的边界,

38:34.000 --> 38:36.000
或是人为设出来的binary,

38:36.000 --> 38:37.000
这举个例子好了,

38:37.000 --> 38:38.000
但其实是没有意义的,

38:38.000 --> 38:45.000
所以很大的困难就是怎么把这些binary的资讯,

38:45.000 --> 38:47.000
再让还原回去交给你的模型,

38:47.000 --> 38:49.000
以这个project为例的话,

38:49.000 --> 38:50.000
我们就是,

38:50.000 --> 38:52.000
我们至少让模型知道说,

38:52.000 --> 38:54.000
healthy跟painful,

38:54.000 --> 38:56.000
跟healthy跟very unpainful要分开了,

38:56.000 --> 38:58.000
所以假如说0到3的话,

38:58.000 --> 38:59.000
差异很少,

38:59.000 --> 39:02.000
我们让模型知道说这差异很小,

39:02.000 --> 39:04.000
假如0到9的话,

39:04.000 --> 39:05.000
差异很多,

39:05.000 --> 39:07.000
我让它知道说差异很多,

39:07.000 --> 39:10.000
幸好这些用模型可以解决,

39:10.000 --> 39:13.000
我们是可以把这些差异,

39:13.000 --> 39:18.000
encode之后放进去这个模型的生成的部分里面去,

39:18.000 --> 39:22.000
所以它就照你想要给它的距离,

39:22.000 --> 39:24.000
相比的差异,

39:24.000 --> 39:27.000
所以就是数值差比较少会差比较少,

39:27.000 --> 39:29.000
差比较多会差比较多,

39:29.000 --> 39:33.000
那当然这个传统差异只是小部分,

39:33.000 --> 39:36.000
所以这个比较类似像是一个demo一样,

39:36.000 --> 39:38.000
证明说我们可以control这些事情,

39:38.000 --> 39:41.000
当然是有更多更多的因素在里面,

39:41.000 --> 39:43.000
所以可以想办法加进去,

39:43.000 --> 39:48.000
所以基本上训练成功之后,

39:48.000 --> 39:52.000
你就会得到一个连续的膝盖分布,

39:52.000 --> 39:56.000
连续膝盖分布最左边就会是你本来的膝盖,

39:56.000 --> 40:00.000
最右边就会是你疼痛的高低的膝盖,

40:00.000 --> 40:06.000
那根据它们两个疼痛的scoring的差异,

40:06.000 --> 40:09.000
它就会拉近会拉远,

40:09.000 --> 40:12.000
所以并不是说左边是不疼痛膝盖,

40:12.000 --> 40:14.000
右边是疼痛膝盖,中间都是垃圾,

40:14.000 --> 40:16.000
它是一个连续的空间,

40:16.000 --> 40:19.000
连续的空间它的分布其实是你可以控制的,

40:19.000 --> 40:24.000
那我们之前有做过一些自动切割,

40:24.000 --> 40:27.000
自动切割在一平衡上算是一个比较好解决的工作,

40:27.000 --> 40:31.000
基本上结论就是说你只要有研究生,

40:31.000 --> 40:34.000
只要有处理他就把你用手标完,

40:34.000 --> 40:35.000
然后就解决掉,

40:35.000 --> 40:39.000
所以其实基本上一平衡上自动切割算是单一,

40:39.000 --> 40:41.000
比较困难是在单一data set,

40:41.000 --> 40:44.000
多data set你会有差异,

40:44.000 --> 40:46.000
但如果是在同一data set,

40:46.000 --> 40:48.000
然后有标记的话,

40:48.000 --> 40:49.000
你有光处的话,

40:49.000 --> 40:52.000
就是我们这种所谓叫做有切割的光处,

40:52.000 --> 40:53.000
就是切割的标记嘛,

40:53.000 --> 40:55.000
那这种叫做监督式学习,

40:56.000 --> 40:57.000
如果是survival的话,

40:57.000 --> 40:59.000
基本上还蛮好解决的,

40:59.000 --> 41:01.000
所以已经不是新的东西了,

41:01.000 --> 41:06.000
那我们做deep learning的话,

41:06.000 --> 41:09.000
有一个功能就是帮助这些,

41:09.000 --> 41:11.000
本来就可以做的事情,

41:11.000 --> 41:12.000
把自动化,

41:12.000 --> 41:14.000
就好比说这些膝盖骨头切割,

41:14.000 --> 41:17.000
那其实其实不是很难嘛,

41:17.000 --> 41:18.000
因为医生都可以切,

41:18.000 --> 41:19.000
然后也有些postdoc,

41:19.000 --> 41:21.000
或者有些研究生都会切,

41:21.000 --> 41:23.000
但是本来手法是非常非常非常慢,

41:23.000 --> 41:25.000
那在近期的话,

41:25.000 --> 41:28.000
可能用一些统计的statistical shape model,

41:28.000 --> 41:30.000
去拟合出这些膝盖形状,

41:30.000 --> 41:32.000
总之要花时间嘛,

41:32.000 --> 41:34.000
但deep learning有一个很好的好处,

41:34.000 --> 41:35.000
就是它可以自动化,

41:35.000 --> 41:37.000
所以刚刚说过,

41:37.000 --> 41:38.000
只要是survival能力做切割,

41:38.000 --> 41:40.000
其实不是很难,

41:40.000 --> 41:42.000
所以我们之前做的模型,

41:42.000 --> 41:44.000
就是把这些手动标记,

41:44.000 --> 41:45.000
转成一个自动切割化模型,

41:45.000 --> 41:47.000
那一下子你会分析很多,

41:47.000 --> 41:50.000
很多不同的资料,

41:51.000 --> 41:53.000
那它科学上有新的东西吗?

41:53.000 --> 41:54.000
其实没有,

41:54.000 --> 41:55.000
它只是自动化而已,

41:55.000 --> 41:58.000
但是生物学上的很多丢零,

41:58.000 --> 42:00.000
就是最大的困难嘛,

42:00.000 --> 42:02.000
所以它并不是新的功能,

42:02.000 --> 42:04.000
但是只是把同样的事情,

42:04.000 --> 42:06.000
给别人做一倍,

42:06.000 --> 42:07.000
然后我会做一百倍,

42:07.000 --> 42:08.000
那就很有价值。

42:13.000 --> 42:16.000
那今天在我们这个case上面来说的话,

42:16.000 --> 42:18.000
我没想要做自动切割,

42:18.000 --> 42:19.000
为什么呢?

42:19.000 --> 42:21.000
有一种特别的region是,

42:21.000 --> 42:22.000
我们特别想要看的,

42:22.000 --> 42:23.000
所谓的Bone Marrow Region,

42:23.000 --> 42:25.000
它就是在骨髓内的,

42:25.000 --> 42:27.000
在骨头区里面的所有的,

42:27.000 --> 42:31.000
所有的hyperintensity,

42:31.000 --> 42:33.000
都是被认为是Bone Marrow Region,

42:33.000 --> 42:38.000
那它问题是这样子,

42:38.000 --> 42:39.000
我们这个医学影像,

42:39.000 --> 42:41.000
好多MRI好了,

42:41.000 --> 42:43.000
每个MRI是拍的功能不太一样,

42:44.000 --> 42:48.000
好比说像这个左边是High Definition,

42:48.000 --> 42:51.000
就是它的骨头跟人肉之间的contrast很明显,

42:51.000 --> 42:53.000
右边是看发炎的,

42:53.000 --> 42:56.000
就是这个Weighted T2 Sequence,

42:56.000 --> 42:58.000
所以它看到发炎,

42:58.000 --> 43:01.000
可是它的骨头跟人肉之间的边界不是很明显,

43:01.000 --> 43:04.000
那你可能想说,

43:04.000 --> 43:06.000
我就把左边做自动切割,

43:06.000 --> 43:07.000
然后搬到右边来就好了嘛,

43:07.000 --> 43:10.000
可问题是即使是同一位病人,

43:10.000 --> 43:12.000
它拍的时候也不会是完全align的,

43:12.000 --> 43:16.000
像你膝盖的眼花稍微角做Man Spread就不一样了,

43:16.000 --> 43:18.000
就已经3D形状就不一样了,

43:18.000 --> 43:20.000
所以基本上,

43:20.000 --> 43:22.000
这是Clinical是这样拍的,

43:22.000 --> 43:24.000
这是Clinical Trial,

43:24.000 --> 43:26.000
所以至少是同时拍的,

43:26.000 --> 43:28.000
所以是有蛮多病人是重合没错,

43:28.000 --> 43:33.000
但是至少一半是Man Spreading,

43:33.000 --> 43:37.000
所以拍的3D的剖面不一样了,

43:37.000 --> 43:39.000
假设如果是Follow Up的话,

43:39.000 --> 43:41.000
基本上看起来就不太一样了,

43:41.000 --> 43:44.000
所以基本上,

43:44.000 --> 43:47.000
你有一些切割的资讯,

43:47.000 --> 43:49.000
想要转到发炎资讯上面去,

43:49.000 --> 43:51.000
你要怎么转呢?

43:51.000 --> 43:54.000
然后再讲说,

43:54.000 --> 43:56.000
为什么不能直接套用?

43:56.000 --> 44:01.000
大家知道Neural Network有另一个重大缺点,

44:01.000 --> 44:04.000
就是它很难套用在Core Data Stack,

44:04.000 --> 44:06.000
最有名的例子是说,

44:06.000 --> 44:10.000
Source跟Target其实差不多,

44:10.000 --> 44:13.000
但是节度就差很多,

44:13.000 --> 44:16.000
所以我们可以用这些Gate方式,

44:16.000 --> 44:18.000
把一个模型转到另一个模型上面去,

44:18.000 --> 44:24.000
那你就可以在想拍发炎资讯上去,

44:24.000 --> 44:26.000
把这些去切割下来,

44:26.000 --> 44:30.000
我花了超多时间,

44:30.000 --> 44:32.000
所以我就讲快点好了,

44:32.000 --> 44:34.000
我们最后结果是说,

44:34.000 --> 44:36.000
我们可以拿这些切割模型,

44:36.000 --> 44:40.000
在本来这个结病改变的图上面做定量,

44:40.000 --> 44:44.000
那我们可以把这些Bomel Region,

44:44.000 --> 44:46.000
很敏感的定量下来,

44:46.000 --> 44:48.000
那最后我们就做这些统计分析,

44:48.000 --> 44:51.000
等于是用后验的统计分析,

44:51.000 --> 44:53.000
那根据传统的画Contour方式来比的话,

44:53.000 --> 44:55.000
就发现如果计算,

44:55.000 --> 44:59.000
还有未来会开到的Out Ratio,

44:59.000 --> 45:01.000
就还好蛮多的,

45:02.000 --> 45:04.000
所以大概这样子,

45:04.000 --> 45:06.000
我之后本来要讲,

45:06.000 --> 45:09.000
先这样子好了,

45:09.000 --> 45:11.000
那我就直接讲,

45:11.000 --> 45:13.000
我conclusion,

45:13.000 --> 45:16.000
那我是回台湾之后,

45:16.000 --> 45:22.000
大家知道我们做影像都会找合适的Collaborator,

45:22.000 --> 45:24.000
我在美国的时候跟台湾的时候就不太一样,

45:24.000 --> 45:26.000
那我在台湾的时候就做一个分支,

45:26.000 --> 45:28.000
就是做脑影像研究,

45:28.000 --> 45:30.000
大家可能知道说,

45:30.000 --> 45:32.000
可能听过了,

45:32.000 --> 45:34.000
Neural Network的本质就是,

45:34.000 --> 45:36.000
一开始学脑会怎么function,

45:36.000 --> 45:38.000
它是拟合一个脑细胞,

45:38.000 --> 45:40.000
把很多资讯综结在一起,

45:40.000 --> 45:44.000
然后用一个Activation Function,

45:44.000 --> 45:46.000
然后往前输送这样子,

45:46.000 --> 45:48.000
脑装滑,

45:48.000 --> 45:50.000
偷别人的Video,

45:50.000 --> 45:55.000
每颗脑神经都有几百个接收源,

45:55.000 --> 45:59.000
然后再把这些神经连回去,

45:59.000 --> 46:01.000
基本上,

46:01.000 --> 46:03.000
这些神经集合在这边的Circuit,

46:03.000 --> 46:05.000
就变回路,

46:05.000 --> 46:09.000
回路就会做各种行为,

46:09.000 --> 46:11.000
记忆等等,

46:11.000 --> 46:14.000
所谓的脑科学的Holy Grail,

46:14.000 --> 46:16.000
就是这个回路结合起来变Conscious,

46:16.000 --> 46:18.000
我们是谁,

46:18.000 --> 46:20.000
这我就不知道了,

46:20.000 --> 46:22.000
因为我们对脑科学的认知,

46:23.000 --> 46:25.000
非常非常地开始了,

46:25.000 --> 46:27.000
像这些回路结合起来,

46:27.000 --> 46:29.000
会变成怎么看东西,

46:29.000 --> 46:31.000
这种东西我们都不知道,

46:31.000 --> 46:35.000
第一步就是怎么把这些回路区分出来,

46:35.000 --> 46:37.000
还是做不到,

46:37.000 --> 46:39.000
除非是做电子显微镜,

46:39.000 --> 46:41.000
不然解析度是不够的,

46:41.000 --> 46:43.000
但你可以做光学显微镜,

46:43.000 --> 46:46.000
解析度是不够,

46:46.000 --> 46:48.000
但是会快很多,

46:48.000 --> 46:50.000
电子显微镜基本上扫人脑,

46:51.000 --> 46:53.000
所以有部分的,

46:53.000 --> 46:57.000
怎么用AI技术来,

46:57.000 --> 47:00.000
回头来分析这些脑科学影像,

47:00.000 --> 47:02.000
想法先把这些脑神经,

47:02.000 --> 47:04.000
一颗一颗重新连接,

47:04.000 --> 47:06.000
重现出来,

47:06.000 --> 47:08.000
我们才拿这些东西来,

47:08.000 --> 47:10.000
建立一个模型来预测,

47:10.000 --> 47:12.000
它的行为被怎么调控,

47:12.000 --> 47:14.000
所以基本上就是一个,

47:14.000 --> 47:16.000
我想问一下,

47:16.000 --> 47:18.000
我问你,

47:18.000 --> 47:20.000
左边右边,

47:20.000 --> 47:22.000
差别是什么?

47:26.000 --> 47:28.000
右边是原图影像,

47:28.000 --> 47:30.000
左边是,

47:30.000 --> 47:32.000
左边是米禾出的CNET,

47:32.000 --> 47:34.000
就是,

47:34.000 --> 47:36.000
左边是,

47:36.000 --> 47:38.000
脑神经,

47:38.000 --> 47:40.000
每颗发散的地方,

47:40.000 --> 47:42.000
叫CNET,

47:42.000 --> 47:44.000
左边是把CNET强化出来,

47:44.000 --> 47:46.000
它有在,

47:46.000 --> 47:48.000
它是两个神经的边界,

47:48.000 --> 47:50.000
可能是,

47:50.000 --> 47:52.000
这些,

47:52.000 --> 47:54.000
每一线的终点,

47:54.000 --> 47:56.000
是两个神经的边界,

47:56.000 --> 47:58.000
它觉得不是同一个神经细胞,

47:58.000 --> 48:00.000
有可能是CNET在交换资讯,

48:02.000 --> 48:04.000
这结果不是很翻用来子,

48:04.000 --> 48:06.000
但是,

48:06.000 --> 48:08.000
但是,

48:08.000 --> 48:10.000
目的就是说,

48:10.000 --> 48:12.000
怎么把,

48:12.000 --> 48:14.000
怎么把每颗脑神经,

48:14.000 --> 48:16.000
然后,

48:16.000 --> 48:18.000
然后把这些看起来是一条线的地方,

48:18.000 --> 48:20.000
把它区分出来,

48:20.000 --> 48:22.000
哪些是受理脑理,

48:22.000 --> 48:24.000
哪些是在地脑理,

48:24.000 --> 48:26.000
理论上这些CNET的位置,

48:26.000 --> 48:28.000
就会是传递资讯的地方,

48:28.000 --> 48:30.000
如果全部都做完,

48:30.000 --> 48:32.000
然后很整的话,

48:32.000 --> 48:34.000
你就可以利用一些theory,

48:34.000 --> 48:36.000
graph theory,

48:36.000 --> 48:38.000
去重现出这些会录长什么样子,

48:38.000 --> 48:40.000
因为我同事有做这些,

48:40.000 --> 48:42.000
Cognitive的测量,

48:42.000 --> 48:44.000
并不是很大动物,

48:44.000 --> 48:46.000
对,

48:46.000 --> 48:48.000
但他们过于,

48:48.000 --> 48:50.000
已经被训练说有些行为,

48:50.000 --> 48:52.000
他们是要怎样,他们是要怎样,

48:52.000 --> 48:54.000
他们做完行为之后,

48:54.000 --> 48:56.000
他们再来拍摄这样子,

48:56.000 --> 48:58.000
所以他们是可以知道说,

48:58.000 --> 49:00.000
哪些会录如果有出现或没有出现的话,

49:00.000 --> 49:02.000
可以跟某些方式联系在一起,

49:02.000 --> 49:04.000
对,

49:04.000 --> 49:06.000
所以,

49:06.000 --> 49:08.000
那你可以做一些影像强化等等,

49:08.000 --> 49:10.000
等等,

49:10.000 --> 49:12.000
影像强化,

49:12.000 --> 49:14.000
去噪音,去模糊化等等,

49:14.000 --> 49:16.000
显微镜影像是非常常用的课题,

49:16.000 --> 49:18.000
就可以拿来做,

49:18.000 --> 49:20.000
基本上就是一个,

49:20.000 --> 49:22.000
Light Emitting Art,

49:22.000 --> 49:24.000
Art Emitting Light的过程,

49:24.000 --> 49:26.000
就是当初是,

49:26.000 --> 49:28.000
脑科学启发了AI的研究,

49:28.000 --> 49:30.000
现在AI又会来做这个脑科学,

49:30.000 --> 49:32.000
所以就会慢慢,

49:32.000 --> 49:34.000
回旋就会收敛,

49:34.000 --> 49:36.000
就会出现Terminated,

49:36.000 --> 49:38.000
不过就大概这样子,

49:38.000 --> 49:40.000
那我今天就,

49:40.000 --> 49:42.000
在讲这边。

49:44.000 --> 49:46.000
好,谢谢,

49:46.000 --> 49:48.000
那,

49:48.000 --> 49:50.000
现在我们就再感谢张涵,

49:50.000 --> 49:52.000
谢谢。

49:54.000 --> 49:56.000
现场有没有,

49:56.000 --> 49:58.000
有问题,然后现在,

49:58.000 --> 50:00.000
可以直接开麦克风,直接问。

50:02.000 --> 50:04.000
你好,我想请教一下,

50:04.000 --> 50:06.000
我对你刚提到那个,

50:06.000 --> 50:08.000
不好意思,

50:08.000 --> 50:10.000
那个可以先自我介绍一下。

50:10.000 --> 50:12.000
对不起,对不起,我叫石清华,

50:12.000 --> 50:14.000
我现在在Rochester,

50:14.000 --> 50:16.000
New York,

50:16.000 --> 50:18.000
那我对你那个脑神经,

50:18.000 --> 50:20.000
那部分其实有点感兴趣,

50:20.000 --> 50:22.000
因为其实在,

50:22.000 --> 50:24.000
大概在一两个月前,

50:24.000 --> 50:26.000
有一个,

50:26.000 --> 50:28.000
有一个Research,

50:28.000 --> 50:30.000
他应该还没有完全Publish,

50:30.000 --> 50:32.000
他就是基本上是把,

50:32.000 --> 50:34.000
脑神经,

50:34.000 --> 50:36.000
有脑细胞养在一些Culture里头,

50:36.000 --> 50:38.000
然后用一些Training,

50:38.000 --> 50:40.000
然后配上AI的技术之后,

50:40.000 --> 50:42.000
可以让他玩Video Game,

50:42.000 --> 50:44.000
他可以玩乒乓,

50:44.000 --> 50:46.000
这样子,

50:46.000 --> 50:48.000
就是比较,

50:48.000 --> 50:50.000
对,他是一个人,

50:50.000 --> 50:52.000
我看了那篇Paper之后,

50:52.000 --> 50:54.000
我觉得,

50:54.000 --> 50:56.000
对,就是别人的Research已经到天上,

50:56.000 --> 50:58.000
但我还在地上爬这样子。

50:58.000 --> 51:00.000
那我只是好奇,

51:00.000 --> 51:02.000
我只是好奇,

51:02.000 --> 51:04.000
像你在你这边的那个,

51:04.000 --> 51:06.000
如果有办法说,

51:06.000 --> 51:08.000
用类似的Model,

51:08.000 --> 51:10.000
然后对,

51:10.000 --> 51:12.000
比如说你可以记住Action Potential,

51:12.000 --> 51:14.000
或者是有办法,

51:14.000 --> 51:16.000
荧光可以

51:16.000 --> 51:18.000
侦测他Action Potential的,

51:18.000 --> 51:20.000
然后类似的Pattern,

51:20.000 --> 51:22.000
你就可以看到脑回路的反应,

51:22.000 --> 51:24.000
或神经回路的反应,

51:24.000 --> 51:26.000
针对他的Response这样子。

51:26.000 --> 51:28.000
那,

51:28.000 --> 51:30.000
而且因为这样东西,

51:30.000 --> 51:32.000
呃,

51:32.000 --> 51:34.000
我猜想,

51:34.000 --> 51:36.000
就是说可以做到,

51:36.000 --> 51:38.000
你可以比较,

51:38.000 --> 51:40.000
Simplify一些Circuit,

51:40.000 --> 51:42.000
然后可以做到比较,

51:42.000 --> 51:44.000
呃,

51:44.000 --> 51:46.000
比较High Resolution,

51:46.000 --> 51:48.000
然后去Detect他的那个,

51:48.000 --> 51:50.000
回路的Pattern,

51:50.000 --> 51:52.000
那我不晓得说,

51:52.000 --> 51:54.000
这个东西会不会在未来,

51:54.000 --> 51:56.000
会变得很有趣,

51:56.000 --> 51:58.000
或者是会变得是非常,

51:58.000 --> 52:00.000
他相对于,

52:00.000 --> 52:02.000
佐瑟菲亚的Brain来讲,

52:02.000 --> 52:04.000
更小,因为他只有几百几千个细胞而已,

52:04.000 --> 52:06.000
所以比那个佐瑟菲亚的Brain更小,

52:06.000 --> 52:08.000
所以我觉得他可能,

52:08.000 --> 52:10.000
说不定是一个很神奇的东西。

52:10.000 --> 52:12.000
是是。

52:12.000 --> 52:14.000
好,谢谢。

52:14.000 --> 52:16.000
这个我可能要质疑一下我的同事,

52:16.000 --> 52:18.000
我先说我们这个是,

52:18.000 --> 52:20.000
这个是一个蛮大的Team,

52:20.000 --> 52:22.000
然后主要是

52:22.000 --> 52:24.000
清化脑科中心,

52:24.000 --> 52:26.000
那我这边做影像分析,

52:26.000 --> 52:28.000
那我主要一开始做的是,

52:28.000 --> 52:30.000
这个,

52:30.000 --> 52:32.000
是荧光行为镜影像嘛,

52:32.000 --> 52:34.000
所以这是解剖完的染色或影像,

52:34.000 --> 52:36.000
但是其实是有另外一个Branch,

52:36.000 --> 52:38.000
是做Live Imaging,

52:38.000 --> 52:40.000
就是,

52:40.000 --> 52:42.000
就是是

52:42.000 --> 52:44.000
Real Time的Function影像,

52:44.000 --> 52:46.000
所以是有可能的,

52:46.000 --> 52:48.000
是有可能的,

52:48.000 --> 52:50.000
那我们现在其实,

52:50.000 --> 52:52.000
又开始做分析,

52:52.000 --> 52:54.000
是做这个,

52:54.000 --> 52:56.000
就是这个,

52:56.000 --> 52:58.000
类器官的体外培养的神经元,

52:58.000 --> 53:00.000
原因也是一样,

53:00.000 --> 53:02.000
就是你可以控制好,

53:02.000 --> 53:04.000
然后是可以,

53:04.000 --> 53:06.000
可以,

53:06.000 --> 53:08.000
比较好地做一些,

53:08.000 --> 53:10.000
就是这些,

53:10.000 --> 53:12.000
你做解构或是

53:12.000 --> 53:14.000
方便分析,

53:14.000 --> 53:16.000
然后跟这些控制条件做比较,

53:16.000 --> 53:18.000
但是这个Brain Cell可以,

53:18.000 --> 53:20.000
我先找影片,

53:20.000 --> 53:22.000
就是这个,

53:22.000 --> 53:24.000
Brain Cell可以Play Pong,

53:24.000 --> 53:26.000
可以Play乒乓球,

53:26.000 --> 53:28.000
这是我是第一次知道,

53:28.000 --> 53:32.000
我刚刚学习在那个Chat里头,

53:32.000 --> 53:34.000
就是那个,

53:34.000 --> 53:36.000
有看到,

53:36.000 --> 53:38.000
我也是刚知道,

53:38.000 --> 53:40.000
其实我们在看那个,

53:40.000 --> 53:42.000
其实我们在看那个人脑培养的那个,

53:42.000 --> 53:44.000
Ocrelinoid的脑细胞的时候,

53:44.000 --> 53:46.000
就常常想说,

53:46.000 --> 53:48.000
它有没有Conscious,

53:48.000 --> 53:50.000
它有有Conscious的话就很可怕,

53:50.000 --> 53:52.000
就很可怕,

53:54.000 --> 53:56.000
有没有Conscious我是不知道,

53:56.000 --> 53:58.000
可是它就可以Play Pong,

53:58.000 --> 54:00.000
就已经有点可怕,

54:00.000 --> 54:02.000
我一直觉得是我们的,

54:02.000 --> 54:04.000
这完全是我自己的猜想,

54:04.000 --> 54:06.000
就是我觉得我们的function,

54:06.000 --> 54:08.000
或我们的意识其实是一个Module,

54:08.000 --> 54:10.000
就是各种Module最后组成出来的效果,

54:10.000 --> 54:12.000
所以各自的Module,

54:12.000 --> 54:14.000
可能没有所谓的Conscious,

54:14.000 --> 54:16.000
但是组合起来就可能有了,

54:16.000 --> 54:18.000
是,

54:18.000 --> 54:20.000
说得非常好,

54:20.000 --> 54:22.000
就是,

54:22.000 --> 54:24.000
就是,

54:24.000 --> 54:26.000
我们同样的方式是可以分析,

54:26.000 --> 54:28.000
人脑的一点点,

54:28.000 --> 54:30.000
或者是生物的全体,

54:30.000 --> 54:32.000
那像现在的光绘行为,

54:32.000 --> 54:34.000
基本上可以做,

54:34.000 --> 54:36.000
好比说很小的生物,好比说果蠅,

54:36.000 --> 54:38.000
或者大体可能是猪脑,

54:38.000 --> 54:40.000
猪脑可能可以做,

54:40.000 --> 54:42.000
可能就花好几个礼拜,果蠅脑是一天两天这样子,

54:42.000 --> 54:44.000
那假设就是说,

54:44.000 --> 54:46.000
它假设是一样的,

54:46.000 --> 54:48.000
它假设是全脑的事情,

54:48.000 --> 54:50.000
而不是一块块的事情,

54:50.000 --> 54:52.000
所以,

54:52.000 --> 54:54.000
如果要看,

54:54.000 --> 54:56.000
就是从,

54:56.000 --> 54:58.000
从脑组织切片,

54:58.000 --> 55:00.000
就这个我们有做啦,

55:00.000 --> 55:02.000
就是从脑切片区域里面出来,

55:02.000 --> 55:04.000
那要看,

55:04.000 --> 55:06.000
比较high level的方面,

55:06.000 --> 55:08.000
其实是不可能看到的,

55:08.000 --> 55:10.000
所以今天会做的这么多AI分析,

55:10.000 --> 55:12.000
其实目的就是为了搭配一件事情,

55:12.000 --> 55:14.000
就是我们要很快可以处理整个脑的资讯,

55:14.000 --> 55:16.000
那在,

55:16.000 --> 55:18.000
那在影像技术上面的话,

55:18.000 --> 55:20.000
电子显微镜是可以拍到

55:20.000 --> 55:22.000
那个神经的那个,

55:22.000 --> 55:24.000
每个神经的形状,

55:24.000 --> 55:26.000
是可以扫得清楚的,

55:26.000 --> 55:28.000
但像这个果蠅脑的话,

55:28.000 --> 55:30.000
大家可以去搜那个,

55:32.000 --> 55:34.000
Generia吧,

55:34.000 --> 55:36.000
就美国有一个很大的这个,

55:36.000 --> 55:38.000
这个果蠅脑的电子显微镜计划,

55:40.000 --> 55:42.000
它扫了,

55:42.000 --> 55:44.000
扫了两年吧,扫了半颗脑,

55:44.000 --> 55:46.000
然后可能花了,

55:46.000 --> 55:48.000
我不知道多少钱,

55:48.000 --> 55:50.000
总之台湾是不可能付得起的钱,

55:50.000 --> 55:52.000
然后这种扫描你也,

55:52.000 --> 55:54.000
你也没办法跟,

55:54.000 --> 55:56.000
好比说果蠅的行为,

55:56.000 --> 55:58.000
做那个,

55:58.000 --> 56:00.000
做比较吧,

56:00.000 --> 56:02.000
因为扫太久了,

56:02.000 --> 56:04.000
然后就一颗而已,

56:04.000 --> 56:06.000
你也没办法这个,

56:06.000 --> 56:08.000
看它行为然后做比较的样子,

56:08.000 --> 56:10.000
那轻大他们做的事情就是,

56:10.000 --> 56:12.000
然后他们也可以,

56:12.000 --> 56:14.000
跟方选做对应,

56:14.000 --> 56:16.000
因为他们可以做非常多颗,

56:16.000 --> 56:18.000
所以他们知道这个果蠅,

56:18.000 --> 56:20.000
他们生前有这种行为,

56:20.000 --> 56:22.000
然后有没有记忆啊,

56:22.000 --> 56:24.000
有没有等等等等,

56:24.000 --> 56:26.000
所以他们有一个platform,

56:26.000 --> 56:28.000
是可以把这些脑啊,

56:28.000 --> 56:30.000
放大等等,

56:30.000 --> 56:32.000
然后自动扫描下来,

56:32.000 --> 56:34.000
然后接起来的样子,

56:34.000 --> 56:36.000
那插了一块就是,

56:36.000 --> 56:38.000
自动影像分析嘛,

56:38.000 --> 56:40.000
就把这些影像放在那边了,

56:40.000 --> 56:42.000
那第一个它是很小块的影像,

56:42.000 --> 56:44.000
就一定你的view有限,

56:44.000 --> 56:46.000
自动组合在一起,

56:46.000 --> 56:48.000
然后自动,

56:48.000 --> 56:50.000
自动,

56:50.000 --> 56:52.000
自动接在一起,

56:52.000 --> 56:54.000
然后还要知道说,

56:54.000 --> 56:56.000
这些fiber长什么样子,

56:56.000 --> 56:58.000
什么样的fiber是独立属于哪个神经,

56:58.000 --> 57:00.000
然后最后才有可能说,

57:00.000 --> 57:02.000
推断说这些东西怎么运作,

57:02.000 --> 57:04.000
所以所以说没错就是,

57:04.000 --> 57:06.000
就是这目的其实都是为了,

57:06.000 --> 57:08.000
那大家觉得说,

57:08.000 --> 57:10.000
这唯一solution就是需要,

57:10.000 --> 57:12.000
需要用这些方式嘛,

57:12.000 --> 57:14.000
那像像国外的话,

57:14.000 --> 57:16.000
这些东西都跟,

57:16.000 --> 57:18.000
跟Google合作等等,

57:18.000 --> 57:20.000
那我们台湾就,

57:20.000 --> 57:22.000
就做我们的事情,

57:22.000 --> 57:24.000
就我们就想要把,

57:24.000 --> 57:26.000
国外的智能智能影像,

57:26.000 --> 57:28.000
先用AI可以分析出来,

57:28.000 --> 57:30.000
然后那或许之后就可以跟,

57:30.000 --> 57:32.000
function这东西搭配起来,

57:32.000 --> 57:34.000
那不过这些都是,

57:34.000 --> 57:36.000
这些都是生前跟生后的影像,

57:36.000 --> 57:38.000
生前的行为跟,

57:38.000 --> 57:40.000
跟结果后的影像对应啊,

57:40.000 --> 57:42.000
那像你刚刚说这个live,

57:42.000 --> 57:44.000
这个这个,

57:44.000 --> 57:46.000
然后他做某些方面,

57:46.000 --> 57:48.000
或者说play pump的话,

57:48.000 --> 57:50.000
我觉得,

57:50.000 --> 57:52.000
可能蛮有可能的,

57:52.000 --> 57:54.000
如果成功的话,

57:54.000 --> 57:56.000
可能对人类会很shock,

57:56.000 --> 57:58.000
我觉得有可能,

57:58.000 --> 58:00.000
有可能会很shock,

58:00.000 --> 58:02.000
我真的不知道这件事情,

58:02.000 --> 58:04.000
我常常看一些稀奇古怪的,

58:04.000 --> 58:06.000
那个research news,

58:06.000 --> 58:08.000
所以刚好看到这个,

58:08.000 --> 58:10.000
oh my god,

58:10.000 --> 58:12.000
我赶快同时讲,谢谢,

58:16.000 --> 58:18.000
那,

58:18.000 --> 58:20.000
这个,

58:22.000 --> 58:24.000
我现在,

58:24.000 --> 58:26.000
那我们今天就先到这边,

58:26.000 --> 58:28.000
反正就是这个,

58:28.000 --> 58:30.000
我现在要关这个,

58:30.000 --> 58:32.000
感谢最后,

58:32.000 --> 58:34.000
最后感谢那个张翰,

58:34.000 --> 58:36.000
谢谢,

58:36.000 --> 58:38.000
OK

