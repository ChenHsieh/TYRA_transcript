1
00:00:00,000 --> 00:00:02,000
這樣能看到嗎?

2
00:00:02,000 --> 00:00:04,000
可以

3
00:00:04,000 --> 00:00:06,000
OK

4
00:00:06,000 --> 00:00:08,000
大家好

5
00:00:08,000 --> 00:00:10,000
我是莊育南

6
00:00:10,000 --> 00:00:12,000
可以叫我Allen

7
00:00:12,000 --> 00:00:14,000
我現在是

8
00:00:14,000 --> 00:00:16,000
Rice University的PhD學生

9
00:00:16,000 --> 00:00:18,000
我讀的是

10
00:00:18,000 --> 00:00:20,000
Computer Science

11
00:00:20,000 --> 00:00:22,000
我現在是二年級

12
00:00:22,000 --> 00:00:24,000
我在做的研究就是

13
00:00:24,000 --> 00:00:26,000
像是剛才那個

14
00:00:26,000 --> 00:00:28,000
主持人提到的

15
00:00:28,000 --> 00:00:30,000
Predictable Machine Learning

16
00:00:30,000 --> 00:00:32,000
或者是這種Explainable

17
00:00:32,000 --> 00:00:34,000
Artificial Intelligence

18
00:00:34,000 --> 00:00:36,000
目的就是在

19
00:00:36,000 --> 00:00:38,000
介紹

20
00:00:38,000 --> 00:00:40,000
這個Machine Learning Model

21
00:00:40,000 --> 00:00:42,000
為什麼會做出這種Prediction

22
00:00:42,000 --> 00:00:44,000
你要去給他一個解釋

23
00:00:44,000 --> 00:00:46,000
讓人家去

24
00:00:46,000 --> 00:00:48,000
信服你說

25
00:00:48,000 --> 00:00:50,000
這個Prediction Result

26
00:00:50,000 --> 00:00:52,000
不是亂來的

27
00:00:52,000 --> 00:00:54,000
OK

28
00:00:54,000 --> 00:00:56,000
講一下我的

29
00:00:56,000 --> 00:00:58,000
自我介紹

30
00:00:58,000 --> 00:01:00,000
我以前在台灣念碩班

31
00:01:00,000 --> 00:01:02,000
我以前做的是

32
00:01:02,000 --> 00:01:04,000
推薦系統

33
00:01:04,000 --> 00:01:06,000
做推薦系統相關

34
00:01:06,000 --> 00:01:08,000
等下Q&A如果有推薦系統相關的問題

35
00:01:08,000 --> 00:01:10,000
也可以問我

36
00:01:10,000 --> 00:01:12,000
但我會盡量回答的出來

37
00:01:12,000 --> 00:01:14,000
OK

38
00:01:14,000 --> 00:01:16,000
我以前是

39
00:01:16,000 --> 00:01:18,000
大學的時候念數學

40
00:01:18,000 --> 00:01:20,000
我大學在四年級

41
00:01:20,000 --> 00:01:22,000
畢業以前我是不會寫Code

42
00:01:22,000 --> 00:01:24,000
我連一行Code都看不懂

43
00:01:24,000 --> 00:01:26,000
所以

44
00:01:26,000 --> 00:01:28,000
在這邊鼓勵

45
00:01:28,000 --> 00:01:30,000
還想學Code的人

46
00:01:30,000 --> 00:01:32,000
不要放棄

47
00:01:32,000 --> 00:01:34,000
都有機會

48
00:01:34,000 --> 00:01:36,000
努力練練練

49
00:01:36,000 --> 00:01:38,000
應該是大家都有機會

50
00:01:38,000 --> 00:01:40,000
可以去做這件事

51
00:01:40,000 --> 00:01:42,000
OK

52
00:01:42,000 --> 00:01:44,000
那今天的話主要是

53
00:01:44,000 --> 00:01:46,000
OK

54
00:01:46,000 --> 00:01:48,000
那個

55
00:01:48,000 --> 00:01:50,000
我只是想要講說

56
00:01:50,000 --> 00:01:52,000
這開頭太勵志了

57
00:01:52,000 --> 00:01:54,000
反正

58
00:01:54,000 --> 00:01:56,000
今天我不是什麼大師

59
00:01:56,000 --> 00:01:58,000
我只是一個

60
00:01:58,000 --> 00:02:00,000
普通的二年級的PhD學生

61
00:02:00,000 --> 00:02:02,000
所以你如果要打斷我的話

62
00:02:02,000 --> 00:02:04,000
你就直接開啟你的麥克風

63
00:02:04,000 --> 00:02:06,000
然後把我打斷都沒關係

64
00:02:06,000 --> 00:02:08,000
OK

65
00:02:08,000 --> 00:02:10,000
那我就開始吧

66
00:02:10,000 --> 00:02:12,000
OK

67
00:02:12,000 --> 00:02:14,000
今天的Outline會比較是

68
00:02:14,000 --> 00:02:16,000
著重在四個點

69
00:02:16,000 --> 00:02:18,000
第一個就是我來介紹一下

70
00:02:18,000 --> 00:02:20,000
什麼是XAI

71
00:02:20,000 --> 00:02:22,000
什麼是可解釋機器學習

72
00:02:22,000 --> 00:02:24,000
然後再來就是

73
00:02:24,000 --> 00:02:26,000
接下來就是比較偏向

74
00:02:26,000 --> 00:02:28,000
我的研究的部分

75
00:02:28,000 --> 00:02:30,000
在可解釋機器學習裡面

76
00:02:30,000 --> 00:02:32,000
主要會有兩種

77
00:02:32,000 --> 00:02:34,000
一種是模型的本身就有可解釋性

78
00:02:34,000 --> 00:02:36,000
舉個例子來說

79
00:02:36,000 --> 00:02:38,000
大家可能有聽過二分法術

80
00:02:38,000 --> 00:02:40,000
就是Decision Tree

81
00:02:40,000 --> 00:02:42,000
這種Decision Tree的話

82
00:02:42,000 --> 00:02:44,000
它在做Prediction

83
00:02:44,000 --> 00:02:46,000
我們可以看到它的決策過程

84
00:02:46,000 --> 00:02:48,000
那這種就是

85
00:02:48,000 --> 00:02:50,000
它本身就是具有可解釋性的

86
00:02:50,000 --> 00:02:52,000
Machine Learning Model

87
00:02:52,000 --> 00:02:54,000
那另外一種是像是

88
00:02:54,000 --> 00:02:56,000
你們比較常聽到的神經網路

89
00:02:56,000 --> 00:02:58,000
然後像是

90
00:02:58,000 --> 00:03:00,000
Deep Neural Network

91
00:03:00,000 --> 00:03:02,000
就是那種Fully Connected

92
00:03:02,000 --> 00:03:04,000
那種就是Black Box Model

93
00:03:04,000 --> 00:03:06,000
那它本身就不具有可解釋性

94
00:03:06,000 --> 00:03:08,000
因為你不知道它裡面的那些Learning Weight

95
00:03:08,000 --> 00:03:10,000
就是那些學習的那些Weight

96
00:03:10,000 --> 00:03:12,000
到底怎麼分布

97
00:03:12,000 --> 00:03:14,000
或是怎麼去讓這個Model

98
00:03:14,000 --> 00:03:16,000
學習的這個動作

99
00:03:16,000 --> 00:03:18,000
所以我們就需要一個

100
00:03:18,000 --> 00:03:20,000
事後的解釋

101
00:03:20,000 --> 00:03:22,000
就是我在模型學Prediction Model

102
00:03:22,000 --> 00:03:24,000
學完之後

103
00:03:24,000 --> 00:03:26,000
我再額外去Learn一個

104
00:03:26,000 --> 00:03:28,000
我們叫Explainer

105
00:03:28,000 --> 00:03:30,000
就是專門用來解釋的模型

106
00:03:30,000 --> 00:03:32,000
去解釋那個Prediction Model

107
00:03:32,000 --> 00:03:34,000
然後這種的學習方式叫做Post-Hoc

108
00:03:34,000 --> 00:03:36,000
就是After Prediction Process

109
00:03:36,000 --> 00:03:38,000
OK

110
00:03:38,000 --> 00:03:40,000
然後再來就是我來講完這個之後

111
00:03:40,000 --> 00:03:42,000
我來講一下

112
00:03:42,000 --> 00:03:44,000
這個XAI目前有什麼應用

113
00:03:44,000 --> 00:03:46,000
大家如果不是Computer Science

114
00:03:46,000 --> 00:03:48,000
背景的人可能也不要

115
00:03:48,000 --> 00:03:50,000
就是會覺得

116
00:03:50,000 --> 00:03:52,000
我到底學的有什麼用

117
00:03:52,000 --> 00:03:54,000
我講一下現在有什麼Open Source Package

118
00:03:54,000 --> 00:03:56,000
就是

119
00:03:56,000 --> 00:03:58,000
可以做這個

120
00:03:58,000 --> 00:04:00,000
Explainable Model

121
00:04:00,000 --> 00:04:02,000
那當然現在就是大家都用Python

122
00:04:02,000 --> 00:04:04,000
所以我就是講了兩個Python的

123
00:04:04,000 --> 00:04:06,000
Open Source Package

124
00:04:06,000 --> 00:04:08,000
然後跟大家說其實

125
00:04:08,000 --> 00:04:10,000
這個東西不是想像中的遙不可及

126
00:04:10,000 --> 00:04:12,000
就是每個人在每個人領域

127
00:04:12,000 --> 00:04:14,000
當你有Prediction Model

128
00:04:14,000 --> 00:04:16,000
你想要做Explainable

129
00:04:16,000 --> 00:04:18,000
那人人都可以有機會

130
00:04:18,000 --> 00:04:20,000
可以踏進這個領域

131
00:04:20,000 --> 00:04:22,000
OK好那接下來就來

132
00:04:22,000 --> 00:04:24,000
講一下什麼是

133
00:04:24,000 --> 00:04:26,000
什麼是XAI

134
00:04:26,000 --> 00:04:28,000
OK那就是

135
00:04:28,000 --> 00:04:30,000
人工智慧在

136
00:04:30,000 --> 00:04:32,000
在我們日常生活中

137
00:04:32,000 --> 00:04:34,000
已經有很多很多應用了

138
00:04:34,000 --> 00:04:36,000
像是這最近很

139
00:04:36,000 --> 00:04:38,000
前陣子比較流行的

140
00:04:38,000 --> 00:04:40,000
就是DeepMind不是

141
00:04:40,000 --> 00:04:42,000
就是去玩這個

142
00:04:42,000 --> 00:04:44,000
然後他可以下贏那個

143
00:04:44,000 --> 00:04:46,000
人類的Expert

144
00:04:46,000 --> 00:04:48,000
那前陣子

145
00:04:48,000 --> 00:04:50,000
還有DeepMind

146
00:04:50,000 --> 00:04:52,000
有給了一個叫Alpha Tensor

147
00:04:52,000 --> 00:04:54,000
跟Alpha那個叫

148
00:04:54,000 --> 00:04:56,000
算蛋白質的那個東西

149
00:04:56,000 --> 00:04:58,000
那其實上他們都是

150
00:04:58,000 --> 00:05:00,000
就是那種機器人

151
00:05:00,000 --> 00:05:02,000
強化學

152
00:05:02,000 --> 00:05:04,000
強化式學習的

153
00:05:04,000 --> 00:05:06,000
這種應用在日常生活

154
00:05:06,000 --> 00:05:08,000
領域當中

155
00:05:08,000 --> 00:05:10,000
像是一些Medical Diagnosis

156
00:05:10,000 --> 00:05:12,000
就是例如說我給你一個X光片

157
00:05:12,000 --> 00:05:14,000
然後你希望這個

158
00:05:14,000 --> 00:05:16,000
機器人的Model判斷你有沒有腦瘤

159
00:05:16,000 --> 00:05:18,000
那他就會說

160
00:05:18,000 --> 00:05:20,000
有或沒有類似這種

161
00:05:20,000 --> 00:05:22,000
或是甚至說你給今天一個

162
00:05:22,000 --> 00:05:24,000
機器人的Model說你今天有

163
00:05:24,000 --> 00:05:26,000
咳嗽有什麼症狀

164
00:05:26,000 --> 00:05:28,000
然後他幫你判斷你到底得了什麼病

165
00:05:28,000 --> 00:05:30,000
類似這種的Medical Diagnosis

166
00:05:30,000 --> 00:05:32,000
或是像是

167
00:05:32,000 --> 00:05:34,000
Tesla的Autopilot

168
00:05:34,000 --> 00:05:36,000
就是這種

169
00:05:36,000 --> 00:05:38,000
自動駕駛

170
00:05:38,000 --> 00:05:40,000
他不是會Detect

171
00:05:40,000 --> 00:05:42,000
就是有什麼物體

172
00:05:42,000 --> 00:05:44,000
然後他會給你一個最佳路徑

173
00:05:44,000 --> 00:05:46,000
讓你這個車子去開

174
00:05:46,000 --> 00:05:48,000
再來就是Voice Recognition

175
00:05:48,000 --> 00:05:50,000
像是Alexa

176
00:05:50,000 --> 00:05:52,000
不知道大家有沒有用過智慧音響

177
00:05:52,000 --> 00:05:54,000
你只要對這個音響講的時候

178
00:05:54,000 --> 00:05:56,000
他就會偵測你的

179
00:05:56,000 --> 00:05:58,000
語音然後把這個東西

180
00:05:58,000 --> 00:06:00,000
轉換成

181
00:06:00,000 --> 00:06:02,000
文字

182
00:06:02,000 --> 00:06:04,000
然後透過這個文字

183
00:06:04,000 --> 00:06:06,000
Online Server去Request

184
00:06:06,000 --> 00:06:08,000
或是像最近Meta有個很紅的

185
00:06:08,000 --> 00:06:10,000
Speech to Speech

186
00:06:10,000 --> 00:06:12,000
就是把台語轉換成英文

187
00:06:12,000 --> 00:06:14,000
那個也很神

188
00:06:14,000 --> 00:06:16,000
所以就類似這種AI的

189
00:06:16,000 --> 00:06:18,000
應用在日常生活中越來越常見

190
00:06:18,000 --> 00:06:20,000
OK

191
00:06:20,000 --> 00:06:22,000
那但是

192
00:06:22,000 --> 00:06:24,000
就是我們其實很難知道

193
00:06:24,000 --> 00:06:26,000
就是這些模型就為什麼會去

194
00:06:26,000 --> 00:06:28,000
做出這些判斷像是

195
00:06:28,000 --> 00:06:30,000
假設你去看一個醫生

196
00:06:30,000 --> 00:06:32,000
然後今天醫生推了一個

197
00:06:32,000 --> 00:06:34,000
然後你把

198
00:06:34,000 --> 00:06:36,000
你的病狀全部輸入這個

199
00:06:36,000 --> 00:06:38,000
模型他就說

200
00:06:38,000 --> 00:06:40,000
你今天只是感冒你信嗎

201
00:06:40,000 --> 00:06:42,000
為什麼就問你為什麼會做出這個

202
00:06:42,000 --> 00:06:44,000
判斷或者是

203
00:06:44,000 --> 00:06:46,000
今天Tesla給你一個

204
00:06:46,000 --> 00:06:48,000
最佳的

205
00:06:48,000 --> 00:06:50,000
自動駕駛

206
00:06:50,000 --> 00:06:52,000
路線規劃

207
00:06:52,000 --> 00:06:54,000
他給你給出來之後

208
00:06:54,000 --> 00:06:56,000
你真的按照他這樣開你真的覺得

209
00:06:56,000 --> 00:06:58,000
他不會出事嗎

210
00:06:58,000 --> 00:07:00,000
這個決策過程中

211
00:07:00,000 --> 00:07:02,000
如果能夠提供

212
00:07:02,000 --> 00:07:04,000
說今天是因為

213
00:07:04,000 --> 00:07:06,000
這個模型學到什麼什麼特徵

214
00:07:06,000 --> 00:07:08,000
或是他感知到了

215
00:07:08,000 --> 00:07:10,000
例如說有一個行人走過去他停下來

216
00:07:10,000 --> 00:07:12,000
或是他覺得他detect

217
00:07:12,000 --> 00:07:14,000
前方是綠燈

218
00:07:14,000 --> 00:07:16,000
這種感知的

219
00:07:16,000 --> 00:07:18,000
這種為什麼的這種過程

220
00:07:18,000 --> 00:07:20,000
如果提供給使用者的話

221
00:07:20,000 --> 00:07:22,000
那他其實上可以增加

222
00:07:22,000 --> 00:07:24,000
人們對這個模型

223
00:07:24,000 --> 00:07:26,000
對prediction model這種機器學習

224
00:07:26,000 --> 00:07:28,000
模型的這種可信度

225
00:07:28,000 --> 00:07:30,000
對吧

226
00:07:30,000 --> 00:07:32,000
所以整個這個xai

227
00:07:32,000 --> 00:07:34,000
他其實就是在做一件事

228
00:07:34,000 --> 00:07:36,000
他希望提供給使用者一個

229
00:07:36,000 --> 00:07:38,000
合理的原因

230
00:07:38,000 --> 00:07:40,000
例如說因為這個模型

231
00:07:40,000 --> 00:07:42,000
學了什麼特徵

232
00:07:42,000 --> 00:07:44,000
或是這個模型

233
00:07:44,000 --> 00:07:46,000
因為看到了什麼或是這個模型

234
00:07:46,000 --> 00:07:48,000
因為學習了某兩三個特徵

235
00:07:48,000 --> 00:07:50,000
而導致我做出這個prediction

236
00:07:50,000 --> 00:07:52,000
的結果

237
00:07:52,000 --> 00:07:54,000
那xai就是在

238
00:07:54,000 --> 00:07:56,000
把這個過程給完善

239
00:07:56,000 --> 00:07:58,000
像是左邊這個

240
00:07:58,000 --> 00:08:00,000
假設這個autopilot我剛才講過

241
00:08:00,000 --> 00:08:02,000
就是我們xai要做什麼

242
00:08:02,000 --> 00:08:04,000
其實就是想要提供

243
00:08:04,000 --> 00:08:06,000
就是為什麼這個autopilot

244
00:08:06,000 --> 00:08:08,000
會給你的

245
00:08:08,000 --> 00:08:10,000
autopilot做的路徑是安全的

246
00:08:10,000 --> 00:08:12,000
所以你就要跟使用者講說

247
00:08:12,000 --> 00:08:14,000
因為我偵測到模型

248
00:08:14,000 --> 00:08:16,000
我的模型偵測到人

249
00:08:16,000 --> 00:08:18,000
我的模型偵測到前方

250
00:08:18,000 --> 00:08:20,000
可能50米內沒有車子

251
00:08:20,000 --> 00:08:22,000
那再來就是例如說

252
00:08:22,000 --> 00:08:24,000
像是右邊這個圖

253
00:08:24,000 --> 00:08:28,000
這個醫療的診斷

254
00:08:28,000 --> 00:08:30,000
醫療診斷它其實就是要

255
00:08:30,000 --> 00:08:32,000
例如說你要說服這個醫生

256
00:08:32,000 --> 00:08:34,000
或是說服這個病人說

257
00:08:34,000 --> 00:08:36,000
因為我在你

258
00:08:36,000 --> 00:08:38,000
腦的X光片裡面

259
00:08:38,000 --> 00:08:40,000
看到某一塊是腦瘤

260
00:08:40,000 --> 00:08:42,000
我把它框起來

261
00:08:42,000 --> 00:08:44,000
所以我判斷你的腦瘤

262
00:08:44,000 --> 00:08:46,000
這個動作其實上

263
00:08:46,000 --> 00:08:48,000
看起來就是沒有這麼的

264
00:08:48,000 --> 00:08:50,000
在整個prediction的過程中

265
00:08:50,000 --> 00:08:52,000
看起來沒有這麼的

266
00:08:52,000 --> 00:08:54,000
這麼有需求

267
00:08:54,000 --> 00:08:56,000
但是如果你提供給使用者

268
00:08:56,000 --> 00:08:58,000
這個步驟的話

269
00:08:58,000 --> 00:09:00,000
就是為什麼這個步驟的話

270
00:09:00,000 --> 00:09:02,000
使用者其實會對於你的決策模型

271
00:09:02,000 --> 00:09:04,000
感到就是非常的

272
00:09:04,000 --> 00:09:06,000
例如說他可以放下心來去

273
00:09:06,000 --> 00:09:08,000
相信這個決策

274
00:09:08,000 --> 00:09:10,000
當然還有很多我沒有提到的應用

275
00:09:10,000 --> 00:09:12,000
像是例如做股市交易

276
00:09:12,000 --> 00:09:14,000
或是什麼的

277
00:09:14,000 --> 00:09:16,000
你今天股市說你就買50萬的Meta股票

278
00:09:16,000 --> 00:09:18,000
類似這樣

279
00:09:18,000 --> 00:09:20,000
Meta現在已經跌到

280
00:09:20,000 --> 00:09:22,000
骨折了

281
00:09:22,000 --> 00:09:24,000
他叫你賣掉

282
00:09:24,000 --> 00:09:26,000
你說為什麼他不會跌超過

283
00:09:26,000 --> 00:09:28,000
低於100塊

284
00:09:28,000 --> 00:09:30,000
這模型如果預測錯了

285
00:09:30,000 --> 00:09:32,000
他叫你趕快賣掉

286
00:09:32,000 --> 00:09:34,000
他說因為股票可能跌超過100塊

287
00:09:34,000 --> 00:09:36,000
類似這種東西

288
00:09:36,000 --> 00:09:38,000
你總要說服買賣的trader

289
00:09:38,000 --> 00:09:40,000
說因為我看到

290
00:09:40,000 --> 00:09:42,000
他的財報全部都不達標

291
00:09:42,000 --> 00:09:44,000
什麼什麼貴的

292
00:09:44,000 --> 00:09:46,000
這種檢測到特徵

293
00:09:46,000 --> 00:09:48,000
你才能說服使用者說

294
00:09:48,000 --> 00:09:50,000
這模型是可信的

295
00:09:50,000 --> 00:09:52,000
所以

296
00:09:52,000 --> 00:09:54,000
這種東西其實

297
00:09:54,000 --> 00:09:56,000
牽扯到幾個點

298
00:09:56,000 --> 00:09:58,000
第一個是我們剛才講到你要說服使用者

299
00:09:58,000 --> 00:10:00,000
然後再來就是你要提供安全

300
00:10:00,000 --> 00:10:02,000
還有一個很重要的東西就是

301
00:10:02,000 --> 00:10:04,000
就是一些法規的東西

302
00:10:04,000 --> 00:10:06,000
像是GDPR

303
00:10:06,000 --> 00:10:08,000
像是Facebook在前陣子

304
00:10:08,000 --> 00:10:10,000
就是Zack Scruber

305
00:10:10,000 --> 00:10:12,000
被叫去歐洲議會罵

306
00:10:12,000 --> 00:10:14,000
或是Google CEO

307
00:10:14,000 --> 00:10:16,000
被叫去美國的

308
00:10:16,000 --> 00:10:18,000
眾議院被叫去罵

309
00:10:18,000 --> 00:10:20,000
其實就是在說

310
00:10:20,000 --> 00:10:22,000
你們使用的

311
00:10:22,000 --> 00:10:24,000
這些privacy data

312
00:10:24,000 --> 00:10:26,000
或是你們使用的個人資料

313
00:10:26,000 --> 00:10:28,000
這些資料的使用

314
00:10:28,000 --> 00:10:30,000
你沒有提供給使用者

315
00:10:30,000 --> 00:10:32,000
一個合理或是讓他

316
00:10:32,000 --> 00:10:34,000
覺得安全幸福的這種

317
00:10:34,000 --> 00:10:36,000
使用方法的準則

318
00:10:36,000 --> 00:10:38,000
你不能就是無條件無上限

319
00:10:38,000 --> 00:10:40,000
去使用這些東西

320
00:10:40,000 --> 00:10:42,000
這些feature當作訓練模型的一個依據

321
00:10:42,000 --> 00:10:44,000
所以如果你今天能透過

322
00:10:44,000 --> 00:10:46,000
XAI的這些方法

323
00:10:46,000 --> 00:10:48,000
提供給這些使用者

324
00:10:48,000 --> 00:10:50,000
我今天是因為用了你

325
00:10:50,000 --> 00:10:52,000
這些feature

326
00:10:52,000 --> 00:10:54,000
然後導致我提供給你

327
00:10:54,000 --> 00:10:56,000
這些個人化的一些

328
00:10:56,000 --> 00:10:58,000
不管是推薦結果或是預測結果

329
00:10:58,000 --> 00:11:00,000
那其實使用者他在

330
00:11:00,000 --> 00:11:02,000
某種程度上他會比較安心說

331
00:11:02,000 --> 00:11:04,000
原來你是使用過這些東西

332
00:11:04,000 --> 00:11:06,000
縱使他是隱私資料

333
00:11:06,000 --> 00:11:08,000
但是總比就是完全關起門來

334
00:11:08,000 --> 00:11:10,000
然後做事然後就跟你講結果

335
00:11:10,000 --> 00:11:12,000
好得非常多

336
00:11:12,000 --> 00:11:14,000
這是XAI為什麼

337
00:11:14,000 --> 00:11:16,000
我不敢說這一兩年

338
00:11:16,000 --> 00:11:18,000
或是這三四年

339
00:11:18,000 --> 00:11:20,000
越來越多人關注的一個

340
00:11:20,000 --> 00:11:22,000
原因

341
00:11:22,000 --> 00:11:24,000
好

342
00:11:24,000 --> 00:11:26,000
再來就是

343
00:11:26,000 --> 00:11:28,000
剛才那些都是一些

344
00:11:28,000 --> 00:11:30,000
比較

345
00:11:30,000 --> 00:11:32,000
high level層面

346
00:11:32,000 --> 00:11:34,000
那我們現在就講一些

347
00:11:34,000 --> 00:11:36,000
比較

348
00:11:36,000 --> 00:11:38,000
科技層面的東西

349
00:11:38,000 --> 00:11:40,000
反正就是如果我們現在在做這種

350
00:11:40,000 --> 00:11:42,000
image classification

351
00:11:42,000 --> 00:11:44,000
就是我們這個圖片分類

352
00:11:44,000 --> 00:11:46,000
我們在判斷這個模型好不好

353
00:11:46,000 --> 00:11:48,000
就是我們單純做實驗我們要

354
00:11:48,000 --> 00:11:50,000
train一個我們要訓練一個

355
00:11:50,000 --> 00:11:52,000
圖片分類的模型

356
00:11:52,000 --> 00:11:54,000
這個圖片分類模型我們總不能

357
00:11:54,000 --> 00:11:56,000
說

358
00:11:56,000 --> 00:11:58,000
當然可以說就是prediction

359
00:11:58,000 --> 00:12:00,000
就是例如說我們去看它說

360
00:12:00,000 --> 00:12:02,000
預測準不準確就例如說看它

361
00:12:02,000 --> 00:12:04,000
accuracy好不好啊

362
00:12:04,000 --> 00:12:06,000
我有沒有成功的預測到屬於這樣圖的

363
00:12:06,000 --> 00:12:08,000
當然是可以這樣做

364
00:12:08,000 --> 00:12:10,000
你可以其實可以想一件事就是

365
00:12:10,000 --> 00:12:12,000
今天這張圖是一隻青蛙

366
00:12:12,000 --> 00:12:14,000
那

367
00:12:14,000 --> 00:12:16,000
今天這張圖是一隻青蛙那今天這個模型

368
00:12:16,000 --> 00:12:18,000
是真的學到青蛙的特徵嗎

369
00:12:18,000 --> 00:12:20,000
也就是說換句話說就是

370
00:12:20,000 --> 00:12:22,000
他真的學到青蛙這個頭嗎

371
00:12:22,000 --> 00:12:24,000
就是這個image classification

372
00:12:24,000 --> 00:12:26,000
這個模型真的學到這個青蛙

373
00:12:26,000 --> 00:12:28,000
沒有人知道他有可能是學

374
00:12:28,000 --> 00:12:30,000
假設後面有一個

375
00:12:30,000 --> 00:12:32,000
一個水塘然後上面有一個荷葉

376
00:12:32,000 --> 00:12:34,000
然後他就覺得

377
00:12:34,000 --> 00:12:36,000
大部分的青蛙圖片都是因為青蛙

378
00:12:36,000 --> 00:12:38,000
在水塘跟荷葉上面

379
00:12:38,000 --> 00:12:40,000
所以他就反而去抓那個水塘

380
00:12:40,000 --> 00:12:42,000
跟荷葉的特徵

381
00:12:42,000 --> 00:12:44,000
那這件事情不是我們樂見的為什麼

382
00:12:44,000 --> 00:12:46,000
那當今天有一個像是這種圖片的

383
00:12:46,000 --> 00:12:48,000
來那學到水塘跟青蛙

384
00:12:48,000 --> 00:12:50,000
的這種的圖片

385
00:12:50,000 --> 00:12:52,000
分類的這種的model

386
00:12:52,000 --> 00:12:54,000
是不是就會predict錯誤

387
00:12:54,000 --> 00:12:56,000
所以這個東西其實是我們不樂見

388
00:12:56,000 --> 00:12:58,000
所以透過這種XAI的方法

389
00:12:58,000 --> 00:13:00,000
就是我們去看說到底哪一個

390
00:13:00,000 --> 00:13:02,000
哪一塊哪一塊重要

391
00:13:02,000 --> 00:13:04,000
那最後如果我們得到我們最後的解釋是

392
00:13:04,000 --> 00:13:06,000
因為

393
00:13:06,000 --> 00:13:08,000
他判斷這張圖是

394
00:13:08,000 --> 00:13:10,000
青蛙的原因是因為

395
00:13:10,000 --> 00:13:12,000
他有這個很具代表性的

396
00:13:12,000 --> 00:13:14,000
這個頭那我們就知道

397
00:13:14,000 --> 00:13:16,000
這個模型其實是

398
00:13:16,000 --> 00:13:18,000
學往對的方向而不是

399
00:13:18,000 --> 00:13:20,000
在抓一些背景的漏洞

400
00:13:20,000 --> 00:13:22,000
或是一些shortcut

401
00:13:22,000 --> 00:13:24,000
就是一些捷徑

402
00:13:24,000 --> 00:13:26,000
捷徑的feature來讓我們的

403
00:13:26,000 --> 00:13:28,000
image classification的accuracy上升

404
00:13:28,000 --> 00:13:30,000
那或是像是在

405
00:13:30,000 --> 00:13:32,000
medical diagnosis就例如說

406
00:13:32,000 --> 00:13:34,000
我們就假設

407
00:13:34,000 --> 00:13:36,000
假設今天有一個檢測

408
00:13:36,000 --> 00:13:38,000
你是不是得covid的classifier

409
00:13:38,000 --> 00:13:40,000
那大家都知道

410
00:13:40,000 --> 00:13:42,000
covid就是很大

411
00:13:42,000 --> 00:13:44,000
很大的機率就會例如

412
00:13:44,000 --> 00:13:46,000
發燒喉嚨痛那今天假設

413
00:13:46,000 --> 00:13:48,000
你只是感冒

414
00:13:48,000 --> 00:13:50,000
那你只要輸入發燒跟

415
00:13:50,000 --> 00:13:52,000
喉嚨痛這兩個症狀

416
00:13:52,000 --> 00:13:54,000
進去他就說你的covid

417
00:13:54,000 --> 00:13:56,000
那你就是慌了就為什麼

418
00:13:56,000 --> 00:13:58,000
所以這時候如果我們要去

419
00:13:58,000 --> 00:14:00,000
判斷說今天這個

420
00:14:00,000 --> 00:14:02,000
的這個

421
00:14:02,000 --> 00:14:04,000
是不是真的學到我們要

422
00:14:04,000 --> 00:14:06,000
學的特徵就例如說我們

423
00:14:06,000 --> 00:14:08,000
也提供了一些肺部X光照片

424
00:14:08,000 --> 00:14:10,000
啊什麼的

425
00:14:10,000 --> 00:14:12,000
他就會去說因為他做出這個covid診斷

426
00:14:12,000 --> 00:14:14,000
並不單單只是

427
00:14:14,000 --> 00:14:16,000
透過你有

428
00:14:16,000 --> 00:14:18,000
喉嚨痛跟發燒這兩個特徵

429
00:14:18,000 --> 00:14:20,000
而得出你有的covid這個結論

430
00:14:20,000 --> 00:14:22,000
所以我們今天

431
00:14:22,000 --> 00:14:24,000
如果在

432
00:14:24,000 --> 00:14:26,000
提供這種prediction result給

433
00:14:26,000 --> 00:14:28,000
使用者的時候我們附帶上

434
00:14:28,000 --> 00:14:30,000
我們因為detect到

435
00:14:30,000 --> 00:14:32,000
你有什麼什麼特徵

436
00:14:32,000 --> 00:14:34,000
使用者在相信

437
00:14:34,000 --> 00:14:36,000
這一種prediction model

438
00:14:36,000 --> 00:14:38,000
就會更加的幸福

439
00:14:38,000 --> 00:14:40,000
好

440
00:14:40,000 --> 00:14:42,000
那我喝個水

441
00:14:44,000 --> 00:14:46,000
所以

442
00:14:46,000 --> 00:14:48,000
總結來說就是AI跟XAI

443
00:14:48,000 --> 00:14:50,000
他其實上他是一個相輔相成

444
00:14:50,000 --> 00:14:52,000
的一個循環的

445
00:14:52,000 --> 00:14:54,000
循環的一個過程

446
00:14:54,000 --> 00:14:56,000
如果今天沒有prediction model

447
00:14:56,000 --> 00:14:58,000
那我們今天如果沒有AI的預測

448
00:14:58,000 --> 00:15:00,000
那我們根本就不需要去解釋

449
00:15:00,000 --> 00:15:02,000
這個東西所以XAI就不會

450
00:15:02,000 --> 00:15:04,000
不會出現

451
00:15:04,000 --> 00:15:06,000
所以我們今天XAI其實

452
00:15:06,000 --> 00:15:08,000
主要是透過

453
00:15:08,000 --> 00:15:10,000
我們另外訓練一個

454
00:15:10,000 --> 00:15:12,000
模型或是模型這個prediction模型

455
00:15:12,000 --> 00:15:14,000
本身就具有可解釋的特性

456
00:15:14,000 --> 00:15:16,000
然後來達到這個

457
00:15:16,000 --> 00:15:18,000
提供解釋的這個動作

458
00:15:18,000 --> 00:15:20,000
所以你可以看

459
00:15:20,000 --> 00:15:22,000
這邊有一張柴犬

460
00:15:22,000 --> 00:15:24,000
然後這邊有一個prediction model

461
00:15:24,000 --> 00:15:26,000
他是一隻柴犬

462
00:15:26,000 --> 00:15:28,000
那為什麼

463
00:15:28,000 --> 00:15:30,000
有可能是這個柴犬趴在地上

464
00:15:30,000 --> 00:15:32,000
因為大部分的狗都趴在地上

465
00:15:32,000 --> 00:15:34,000
我學到這邊比較

466
00:15:34,000 --> 00:15:36,000
偏旁的這些特徵

467
00:15:36,000 --> 00:15:38,000
導致他判斷他是柴犬

468
00:15:38,000 --> 00:15:40,000
也有可能或是因為他

469
00:15:40,000 --> 00:15:42,000
只看到他是橘色的毛色

470
00:15:42,000 --> 00:15:44,000
就說他是柴犬

471
00:15:44,000 --> 00:15:46,000
類似這種我們不知道

472
00:15:46,000 --> 00:15:48,000
因為他是一個黑盒子的模型

473
00:15:48,000 --> 00:15:50,000
就是我們所謂的black box model

474
00:15:50,000 --> 00:15:52,000
所以我們需要另外一個

475
00:15:52,000 --> 00:15:54,000
XAI的這種model

476
00:15:54,000 --> 00:15:56,000
去把這個黑盒打開

477
00:15:56,000 --> 00:15:58,000
把這個black box給打開

478
00:15:58,000 --> 00:16:00,000
然後我們就看到說為什麼他給出

479
00:16:00,000 --> 00:16:02,000
這個圖片是一隻柴犬

480
00:16:02,000 --> 00:16:04,000
然後因為他看到柴犬細細的眼睛

481
00:16:04,000 --> 00:16:06,000
跟柴犬特有的耳朵

482
00:16:06,000 --> 00:16:08,000
那因為這個特徵的

483
00:16:08,000 --> 00:16:10,000
給予

484
00:16:10,000 --> 00:16:12,000
的學習所以我們

485
00:16:12,000 --> 00:16:14,000
讓這個圖片被判斷為柴犬

486
00:16:14,000 --> 00:16:16,000
那這時候這個prediction model

487
00:16:16,000 --> 00:16:18,000
就非常的可信了

488
00:16:18,000 --> 00:16:20,000
因為我們知道他學習到

489
00:16:20,000 --> 00:16:22,000
正確的方向

490
00:16:22,000 --> 00:16:24,000
而不是他去偷懶

491
00:16:24,000 --> 00:16:26,000
去偷懶

492
00:16:26,000 --> 00:16:28,000
學習別的特徵造成這個prediction的結果

493
00:16:28,000 --> 00:16:30,000
所以這個模型

494
00:16:30,000 --> 00:16:32,000
prediction model會是比較一個可信的

495
00:16:32,000 --> 00:16:34,000
一個程度

496
00:16:34,000 --> 00:16:36,000
ok

497
00:16:36,000 --> 00:16:38,000
那剛才那個就是

498
00:16:38,000 --> 00:16:40,000
一個XAI的

499
00:16:40,000 --> 00:16:42,000
大概念的一個解釋

500
00:16:42,000 --> 00:16:44,000
那我們現在來

501
00:16:44,000 --> 00:16:46,000
比較深入一點

502
00:16:46,000 --> 00:16:48,000
因為我不確定這邊是不是全部都是

503
00:16:48,000 --> 00:16:50,000
CS background的人

504
00:16:50,000 --> 00:16:52,000
的同學或是老師

505
00:16:52,000 --> 00:16:54,000
或是一些博士

506
00:16:54,000 --> 00:16:56,000
碩士生所以我今天就是

507
00:16:56,000 --> 00:16:58,000
會給一個比較high level

508
00:16:58,000 --> 00:17:00,000
的一個

509
00:17:00,000 --> 00:17:02,000
talk那我們現在就是

510
00:17:02,000 --> 00:17:04,000
深入了解就是

511
00:17:04,000 --> 00:17:06,000
這種XAI有什麼

512
00:17:06,000 --> 00:17:08,000
現行有什麼

513
00:17:08,000 --> 00:17:10,000
sota technique

514
00:17:10,000 --> 00:17:12,000
就是可以去執行這個

515
00:17:12,000 --> 00:17:14,000
explanation的動作

516
00:17:14,000 --> 00:17:16,000
ok

517
00:17:16,000 --> 00:17:18,000
那在講這個之前我們先

518
00:17:18,000 --> 00:17:20,000
可以大概看一下

519
00:17:20,000 --> 00:17:22,000
幾個不同的scope

520
00:17:22,000 --> 00:17:24,000
那這邊有分成global跟local

521
00:17:24,000 --> 00:17:26,000
我其實就大概講一下

522
00:17:26,000 --> 00:17:28,000
這個global其實就是

523
00:17:28,000 --> 00:17:30,000
我們在看模型

524
00:17:30,000 --> 00:17:32,000
假設今天這個image classifier

525
00:17:32,000 --> 00:17:34,000
這個classifier

526
00:17:34,000 --> 00:17:36,000
in total

527
00:17:36,000 --> 00:17:38,000
就是這個模型在乎什麼特徵

528
00:17:38,000 --> 00:17:40,000
也就是說我們今天如果都

529
00:17:40,000 --> 00:17:42,000
都例如在train一個

530
00:17:42,000 --> 00:17:44,000
假設狗的品種分類

531
00:17:44,000 --> 00:17:46,000
的這種圖片分類

532
00:17:46,000 --> 00:17:48,000
的model

533
00:17:48,000 --> 00:17:50,000
那我們可以就是

534
00:17:50,000 --> 00:17:52,000
想要知道這個模型到底在乎什麼

535
00:17:52,000 --> 00:17:54,000
例如說狗的很多不同品種

536
00:17:54,000 --> 00:17:56,000
耳朵都不一樣所以耳朵就是

537
00:17:56,000 --> 00:17:58,000
這個模型在乎的一個特徵

538
00:17:58,000 --> 00:18:00,000
這就是global的

539
00:18:00,000 --> 00:18:02,000
scope那什麼是local呢

540
00:18:02,000 --> 00:18:04,000
local比較偏向是

541
00:18:04,000 --> 00:18:06,000
我們去解釋每一張

542
00:18:06,000 --> 00:18:08,000
圖片他在乎什麼

543
00:18:08,000 --> 00:18:10,000
像是我舉個例子

544
00:18:10,000 --> 00:18:12,000
像剛剛那張柴犬

545
00:18:12,000 --> 00:18:14,000
我們要做global的話我們就是

546
00:18:14,000 --> 00:18:16,000
必須要去看上面的classification

547
00:18:16,000 --> 00:18:18,000
model他在乎的

548
00:18:18,000 --> 00:18:20,000
在所有的狗裡面他在乎的什麼特徵

549
00:18:20,000 --> 00:18:22,000
但是如果在local scope下面的話

550
00:18:22,000 --> 00:18:24,000
我們就可以我們就必須一張一張

551
00:18:24,000 --> 00:18:26,000
圖片去看說

552
00:18:26,000 --> 00:18:28,000
這張圖片他是因為

553
00:18:28,000 --> 00:18:30,000
柴犬的臉那下一張圖片

554
00:18:30,000 --> 00:18:32,000
可能因為什麼邊境牧羊犬

555
00:18:32,000 --> 00:18:34,000
的尾巴或是邊境牧羊犬的

556
00:18:34,000 --> 00:18:36,000
耳朵這種所以在

557
00:18:36,000 --> 00:18:38,000
local scope底下每一張圖片

558
00:18:38,000 --> 00:18:40,000
都會具有每一張圖片的解釋

559
00:18:40,000 --> 00:18:42,000
那這其實有各有各的好處就是

560
00:18:42,000 --> 00:18:44,000
我們當今天如果要去宏觀的看說

561
00:18:44,000 --> 00:18:46,000
這個模型可不可信那我們當然就

562
00:18:46,000 --> 00:18:48,000
使用global就可以了嘛

563
00:18:48,000 --> 00:18:50,000
我們就要去提供給使用者說

564
00:18:50,000 --> 00:18:52,000
in total來說我們這個

565
00:18:52,000 --> 00:18:54,000
autopilot for example就是

566
00:18:54,000 --> 00:18:56,000
in total來說我們這個假設autopilot

567
00:18:56,000 --> 00:18:58,000
這個模型因為他

568
00:18:58,000 --> 00:19:00,000
會去

569
00:19:00,000 --> 00:19:02,000
detect紅綠燈

570
00:19:02,000 --> 00:19:04,000
有沒有亮或是有沒有行人或是路上

571
00:19:04,000 --> 00:19:06,000
有沒有障礙物這種in total的

572
00:19:06,000 --> 00:19:08,000
方式我們去說服使用者那我們當然

573
00:19:08,000 --> 00:19:10,000
就使用global那local的話

574
00:19:10,000 --> 00:19:12,000
就是我們說在現在這個

575
00:19:12,000 --> 00:19:14,000
場景裡面就這一秒

576
00:19:14,000 --> 00:19:16,000
那現在這一秒我們這個

577
00:19:16,000 --> 00:19:18,000
sensor detect到的這個街景

578
00:19:18,000 --> 00:19:20,000
那因為他有什麼什麼

579
00:19:20,000 --> 00:19:22,000
下一秒又可以提供到什麼

580
00:19:22,000 --> 00:19:24,000
所以當我們今天要去

581
00:19:24,000 --> 00:19:26,000
去分析每一秒的

582
00:19:26,000 --> 00:19:28,000
這種街景圖的時候

583
00:19:28,000 --> 00:19:30,000
那我們就必須使用local

584
00:19:30,000 --> 00:19:32,000
的模型那local模型就會

585
00:19:32,000 --> 00:19:34,000
提供比較

586
00:19:34,000 --> 00:19:36,000
算是比較客製化的一個

587
00:19:36,000 --> 00:19:38,000
解釋的結果給使用者

588
00:19:38,000 --> 00:19:40,000
ok那這個是

589
00:19:40,000 --> 00:19:42,000
global跟local那再來旁邊兩個

590
00:19:42,000 --> 00:19:44,000
有不同的manners就是一個是intrinsic

591
00:19:44,000 --> 00:19:46,000
一個是prototype那intrinsic

592
00:19:46,000 --> 00:19:48,000
就是剛才有提到說模型本身

593
00:19:48,000 --> 00:19:50,000
就具有可解釋性那什麼

594
00:19:50,000 --> 00:19:52,000
要具有可解釋性本身就具有可解釋性

595
00:19:52,000 --> 00:19:54,000
像這個決策數

596
00:19:54,000 --> 00:19:56,000
decision tree就是模型最後說

597
00:19:56,000 --> 00:19:58,000
喔我今天要預測

598
00:19:58,000 --> 00:20:00,000
他的結果是c

599
00:20:00,000 --> 00:20:02,000
那因為我們就可以從這個c

600
00:20:02,000 --> 00:20:04,000
往後走是假設他因為

601
00:20:04,000 --> 00:20:06,000
這個走到這個走到這個例如

602
00:20:06,000 --> 00:20:08,000
這樣子所以我們就可以知道模型在做

603
00:20:08,000 --> 00:20:10,000
決策的時候他是因為經過了

604
00:20:10,000 --> 00:20:12,000
什麼條件然後來達到這個

605
00:20:12,000 --> 00:20:14,000
最後prediction的結果

606
00:20:14,000 --> 00:20:16,000
那這個模型本身

607
00:20:16,000 --> 00:20:18,000
就是具有可解釋性因為

608
00:20:18,000 --> 00:20:20,000
我們可以從模型的決策過程中

609
00:20:20,000 --> 00:20:22,000
知道他做了

610
00:20:22,000 --> 00:20:24,000
截取了什麼特徵或是做了什麼

611
00:20:24,000 --> 00:20:26,000
做了什麼condition的選擇

612
00:20:26,000 --> 00:20:28,000
ok這個就是intrinsic

613
00:20:28,000 --> 00:20:30,000
model或是像右邊這個就是

614
00:20:30,000 --> 00:20:32,000
如果大家有稍微聽

615
00:20:32,000 --> 00:20:34,000
過一些machine learning的講座

616
00:20:34,000 --> 00:20:36,000
或是課程的話應該就會知道

617
00:20:36,000 --> 00:20:38,000
BERT這個東西那BERT這個東西

618
00:20:38,000 --> 00:20:40,000
他裡面字跟字在模型訓練裡面

619
00:20:40,000 --> 00:20:42,000
字會有一個

620
00:20:42,000 --> 00:20:44,000
東西叫做tension score

621
00:20:44,000 --> 00:20:46,000
所謂的tension score就是例如說

622
00:20:46,000 --> 00:20:48,000
我今天把一個句子

623
00:20:48,000 --> 00:20:50,000
丟到這個BERT model裡面

624
00:20:50,000 --> 00:20:52,000
那我每一個字對於模型最後

625
00:20:52,000 --> 00:20:54,000
預測出假設我要做semantic

626
00:20:54,000 --> 00:20:56,000
prediction我預測這句話是

627
00:20:56,000 --> 00:20:58,000
正向或是負向

628
00:20:58,000 --> 00:21:00,000
的情緒那

629
00:21:00,000 --> 00:21:02,000
我每一個字對於這個正向或負向

630
00:21:02,000 --> 00:21:04,000
情緒的貢獻程度

631
00:21:04,000 --> 00:21:06,000
都有加有減就是例如說

632
00:21:06,000 --> 00:21:08,000
I love this morning那love對於

633
00:21:08,000 --> 00:21:10,000
他最後判斷出是正向

634
00:21:10,000 --> 00:21:12,000
絕對有很大的幫助因為他love這個字

635
00:21:12,000 --> 00:21:14,000
本身就是一個正向的

636
00:21:14,000 --> 00:21:16,000
動詞那

637
00:21:16,000 --> 00:21:18,000
這個

638
00:21:18,000 --> 00:21:20,000
很大貢獻這個分數

639
00:21:20,000 --> 00:21:22,000
我們可以理解為

640
00:21:22,000 --> 00:21:24,000
model的tension weight

641
00:21:24,000 --> 00:21:26,000
就是這邊比較high level

642
00:21:26,000 --> 00:21:28,000
所以我們可以透過這些字跟字之間

643
00:21:28,000 --> 00:21:30,000
不同的重要的這種對於

644
00:21:30,000 --> 00:21:32,000
model prediction不同的重要程度

645
00:21:32,000 --> 00:21:34,000
來去判斷說

646
00:21:34,000 --> 00:21:36,000
今天這句話

647
00:21:36,000 --> 00:21:38,000
到底為什麼

648
00:21:38,000 --> 00:21:40,000
會做出他是

649
00:21:40,000 --> 00:21:42,000
正向的這個prediction result

650
00:21:42,000 --> 00:21:44,000
透過

651
00:21:44,000 --> 00:21:46,000
去拿裡面的

652
00:21:46,000 --> 00:21:48,000
important score來最後

653
00:21:48,000 --> 00:21:50,000
做prediction的結果

654
00:21:50,000 --> 00:21:52,000
那這個我剛才講的這兩個模型

655
00:21:52,000 --> 00:21:54,000
都是intrinsic

656
00:21:54,000 --> 00:21:56,000
就是模型本身是具有prediction模型

657
00:21:56,000 --> 00:21:58,000
模型本身是具有可理解之心的

658
00:21:58,000 --> 00:22:00,000
這個範疇那再來就是post hoc

659
00:22:00,000 --> 00:22:02,000
那post hoc我覺得

660
00:22:02,000 --> 00:22:04,000
我等一下可以講一下為什麼我比較focus

661
00:22:04,000 --> 00:22:06,000
在這個點上

662
00:22:06,000 --> 00:22:08,000
不是前面不好是因為我覺得

663
00:22:08,000 --> 00:22:10,000
現在目前大部分就是

664
00:22:10,000 --> 00:22:12,000
machine learning model都是用一些比較黑盒子的

665
00:22:12,000 --> 00:22:14,000
模型像是我可能就隨便

666
00:22:14,000 --> 00:22:16,000
建一個深度學習的

667
00:22:16,000 --> 00:22:18,000
網路

668
00:22:18,000 --> 00:22:20,000
就開始疊一些積木啊

669
00:22:20,000 --> 00:22:22,000
疊一些什麼全連接層

670
00:22:22,000 --> 00:22:24,000
什麼的convolution什麼的疊疊疊

671
00:22:24,000 --> 00:22:26,000
那這些

672
00:22:26,000 --> 00:22:28,000
這些prediction model縱使他有很好的

673
00:22:28,000 --> 00:22:30,000
結果但是他本身

674
00:22:30,000 --> 00:22:32,000
因為我不知道他裡面幹了什麼事

675
00:22:32,000 --> 00:22:34,000
就是例如說我不知道他

676
00:22:34,000 --> 00:22:36,000
他去學了什麼feature什麼

677
00:22:36,000 --> 00:22:38,000
所以這種比較

678
00:22:38,000 --> 00:22:40,000
黑盒的學習就需要

679
00:22:40,000 --> 00:22:42,000
這種post hoc的解釋

680
00:22:42,000 --> 00:22:44,000
就是我需要在模型訓練

681
00:22:44,000 --> 00:22:46,000
預測模型訓練完後再提供

682
00:22:46,000 --> 00:22:48,000
一個解釋專門用來解釋的

683
00:22:48,000 --> 00:22:50,000
模型來去解釋

684
00:22:50,000 --> 00:22:52,000
前面那個預測的模型

685
00:22:52,000 --> 00:22:54,000
所以這種模型

686
00:22:54,000 --> 00:22:56,000
在日常生活的這種

687
00:22:56,000 --> 00:22:58,000
scenario下是

688
00:22:58,000 --> 00:23:00,000
比較常遇到的就舉個例子

689
00:23:00,000 --> 00:23:02,000
像是例如說我們做推薦系統

690
00:23:02,000 --> 00:23:04,000
我們做推薦系統可能會用一些

691
00:23:04,000 --> 00:23:06,000
神經網路的

692
00:23:06,000 --> 00:23:08,000
預測模型來做訓練

693
00:23:08,000 --> 00:23:10,000
那這時候

694
00:23:10,000 --> 00:23:12,000
他神經網路的這個推薦系統

695
00:23:12,000 --> 00:23:14,000
本身就不具有可解釋性

696
00:23:14,000 --> 00:23:16,000
對吧所以我們就需要一個

697
00:23:16,000 --> 00:23:18,000
事後的解釋性模型

698
00:23:18,000 --> 00:23:20,000
來去解釋那個推薦的

699
00:23:20,000 --> 00:23:22,000
預測模型

700
00:23:22,000 --> 00:23:24,000
那這邊一樣有提供

701
00:23:24,000 --> 00:23:26,000
這個事後解釋模型一樣有兩個

702
00:23:26,000 --> 00:23:28,000
scope一個就是global一個是local

703
00:23:28,000 --> 00:23:30,000
那global的話就一樣就是

704
00:23:30,000 --> 00:23:32,000
我去看說這個神經網路

705
00:23:32,000 --> 00:23:34,000
預測模型呢他到底

706
00:23:34,000 --> 00:23:36,000
這個模型本身注重了什麼

707
00:23:36,000 --> 00:23:38,000
大方向的feature

708
00:23:38,000 --> 00:23:40,000
那local的話我就去說

709
00:23:40,000 --> 00:23:42,000
這個神經網路對於每一個

710
00:23:42,000 --> 00:23:44,000
使用者來說因為

711
00:23:44,000 --> 00:23:46,000
我看到使用者A

712
00:23:46,000 --> 00:23:48,000
他的年齡過

713
00:23:48,000 --> 00:23:50,000
18歲然後例如說

714
00:23:50,000 --> 00:23:52,000
他是男性然後例如說

715
00:23:52,000 --> 00:23:54,000
他是例如說他居住在

716
00:23:54,000 --> 00:23:56,000
亞洲那居住在

717
00:23:56,000 --> 00:23:58,000
亞洲呢他會說中文

718
00:23:58,000 --> 00:24:00,000
他會說台語所以

719
00:24:00,000 --> 00:24:02,000
所以我推那個高五人的歌給他

720
00:24:02,000 --> 00:24:04,000
對就是每一個人都有不同的

721
00:24:04,000 --> 00:24:06,000
特徵所以我根據每一個人去提供

722
00:24:06,000 --> 00:24:08,000
不同的模型解釋這個就是在

723
00:24:08,000 --> 00:24:10,000
local scope在做的事情

724
00:24:10,000 --> 00:24:12,000
ok好那

725
00:24:12,000 --> 00:24:14,000
所以in conclusion就是

726
00:24:14,000 --> 00:24:16,000
今天推

727
00:24:16,000 --> 00:24:18,000
比較主流的分成這兩種

728
00:24:18,000 --> 00:24:20,000
intrinsic跟post hoc

729
00:24:20,000 --> 00:24:22,000
對然後

730
00:24:22,000 --> 00:24:24,000
我今天會比較著重在討論

731
00:24:24,000 --> 00:24:26,000
這個post hoc的explanation

732
00:24:26,000 --> 00:24:28,000
然後再更進一步

733
00:24:28,000 --> 00:24:30,000
就是我會比較著重在local的部分

734
00:24:30,000 --> 00:24:32,000
ok因為local比較是

735
00:24:32,000 --> 00:24:34,000
屬於更日常生活中

736
00:24:34,000 --> 00:24:36,000
會碰到的像我剛剛舉的

737
00:24:36,000 --> 00:24:38,000
推薦系統的場景

738
00:24:38,000 --> 00:24:40,000
ok

739
00:24:40,000 --> 00:24:42,000
好那

740
00:24:42,000 --> 00:24:44,000
稍微來講一下

741
00:24:44,000 --> 00:24:46,000
intrinsic local

742
00:24:46,000 --> 00:24:48,000
那就是這邊有一個

743
00:24:48,000 --> 00:24:50,000
這邊有一個圖片

744
00:24:50,000 --> 00:24:52,000
然後這是一篇文章

745
00:24:52,000 --> 00:24:54,000
那例如說

746
00:24:54,000 --> 00:24:56,000
我今天說欸這篇文章很重要

747
00:24:56,000 --> 00:24:58,000
為什麼例如說

748
00:24:58,000 --> 00:25:00,000
因為他detect到這個什麼ent23

749
00:25:00,000 --> 00:25:02,000
或是他detect到

750
00:25:02,000 --> 00:25:04,000
什麼natural

751
00:25:04,000 --> 00:25:06,000
tenacity

752
00:25:06,000 --> 00:25:08,000
這種字眼所以

753
00:25:08,000 --> 00:25:10,000
透過這種

754
00:25:10,000 --> 00:25:12,000
我說哪一個字哪一個字比較重要的

755
00:25:12,000 --> 00:25:14,000
這個過程

756
00:25:14,000 --> 00:25:16,000
我提供給這個使用者

757
00:25:16,000 --> 00:25:18,000
使用者說欸我今天為什麼

758
00:25:18,000 --> 00:25:20,000
拿這篇文章做出以下的預測

759
00:25:20,000 --> 00:25:22,000
是因為我在

760
00:25:22,000 --> 00:25:24,000
我的模型吃了這個ent23

761
00:25:24,000 --> 00:25:26,000
今天我模型吃了這種

762
00:25:26,000 --> 00:25:28,000
比較具有情緒的字眼

763
00:25:28,000 --> 00:25:30,000
這種的過程

764
00:25:30,000 --> 00:25:32,000
然後讓使用者更加信服

765
00:25:32,000 --> 00:25:34,000
說我的這種文字

766
00:25:34,000 --> 00:25:36,000
預測模型預測出來的

767
00:25:36,000 --> 00:25:38,000
結果是可以信服的

768
00:25:38,000 --> 00:25:40,000
ok這就是intrinsic

769
00:25:40,000 --> 00:25:42,000
本身的

770
00:25:42,000 --> 00:25:44,000
intrinsic本身要提供的

771
00:25:44,000 --> 00:25:46,000
的東西

772
00:25:46,000 --> 00:25:48,000
那再來就是

773
00:25:48,000 --> 00:25:50,000
intrinsic global

774
00:25:50,000 --> 00:25:52,000
我剛說global主要是

775
00:25:52,000 --> 00:25:54,000
在模型本身注重什麼

776
00:25:54,000 --> 00:25:56,000
所以例如說我們今天設計一個

777
00:25:56,000 --> 00:25:58,000
可解釋的

778
00:25:58,000 --> 00:26:00,000
CNN就是

779
00:26:00,000 --> 00:26:02,000
是屬於image classification

780
00:26:02,000 --> 00:26:04,000
的其中一個比較具有代表性的

781
00:26:04,000 --> 00:26:06,000
的模型

782
00:26:06,000 --> 00:26:08,000
那我今天就是要去說

783
00:26:08,000 --> 00:26:10,000
為什麼這個CNN會成功預測出

784
00:26:10,000 --> 00:26:12,000
這個貓是

785
00:26:12,000 --> 00:26:14,000
這個貓的圖片是一隻貓

786
00:26:14,000 --> 00:26:16,000
那是因為它detect到

787
00:26:16,000 --> 00:26:18,000
這個貓的頭

788
00:26:18,000 --> 00:26:20,000
那如果我們從CNN裡面

789
00:26:20,000 --> 00:26:22,000
把裡面抽取出一層

790
00:26:22,000 --> 00:26:24,000
例如說其中一層model weight

791
00:26:24,000 --> 00:26:26,000
那這個model weight我把它蓋在圖片上

792
00:26:26,000 --> 00:26:28,000
我們是不是可以去看說

793
00:26:28,000 --> 00:26:30,000
因為這個模型去

794
00:26:30,000 --> 00:26:32,000
對其中某些feature做convolution

795
00:26:32,000 --> 00:26:34,000
得到了某些

796
00:26:34,000 --> 00:26:36,000
特定的feature

797
00:26:36,000 --> 00:26:38,000
是不是這個CNN的模型去做出

798
00:26:38,000 --> 00:26:40,000
它是貓的prediction的這個結果

799
00:26:40,000 --> 00:26:42,000
那從模型中

800
00:26:42,000 --> 00:26:44,000
抽出這個mask

801
00:26:44,000 --> 00:26:46,000
或是抽出這個feature map

802
00:26:46,000 --> 00:26:48,000
然後來讓這個

803
00:26:48,000 --> 00:26:50,000
最後的結果是

804
00:26:50,000 --> 00:26:52,000
可以讓使用者來看說

805
00:26:52,000 --> 00:26:54,000
其實這個

806
00:26:54,000 --> 00:26:56,000
最後的預測結果

807
00:26:56,000 --> 00:26:58,000
是可以信服的

808
00:26:58,000 --> 00:27:00,000
這個過程它其實就是

809
00:27:00,000 --> 00:27:02,000
我們所謂的intrinsic的過程

810
00:27:02,000 --> 00:27:04,000
那所謂intrinsic就是

811
00:27:04,000 --> 00:27:06,000
模型本身就具有

812
00:27:06,000 --> 00:27:08,000
可以製造解釋的這個功能

813
00:27:08,000 --> 00:27:10,000
或是模型本身就具有

814
00:27:10,000 --> 00:27:12,000
可以提煉出某些component

815
00:27:12,000 --> 00:27:14,000
然後進而提供使用者解釋的

816
00:27:14,000 --> 00:27:16,000
這個

817
00:27:16,000 --> 00:27:18,000
過程我們就叫做

818
00:27:18,000 --> 00:27:20,000
intrinsic的過程

819
00:27:20,000 --> 00:27:22,000
ok

820
00:27:22,000 --> 00:27:24,000
那另外一個就是

821
00:27:24,000 --> 00:27:26,000
我們今天會比較著重的post hoc

822
00:27:26,000 --> 00:27:28,000
post hoc的explanation

823
00:27:28,000 --> 00:27:30,000
那post hoc explanation

824
00:27:30,000 --> 00:27:32,000
它主要是分成兩個步驟

825
00:27:32,000 --> 00:27:34,000
前面就會是我們的

826
00:27:34,000 --> 00:27:36,000
black box model

827
00:27:36,000 --> 00:27:38,000
所謂的black box model就是我們的prediction model

828
00:27:38,000 --> 00:27:40,000
我們會有data

829
00:27:40,000 --> 00:27:42,000
我們會有model去訓練

830
00:27:42,000 --> 00:27:44,000
那接下來我們會有一個explainer

831
00:27:44,000 --> 00:27:46,000
就是我們的所謂的拿來解釋

832
00:27:46,000 --> 00:27:48,000
這個prediction model

833
00:27:48,000 --> 00:27:50,000
的machine learning model

834
00:27:50,000 --> 00:27:52,000
ok

835
00:27:52,000 --> 00:27:54,000
那再來我們會需要一些metric

836
00:27:54,000 --> 00:27:56,000
就是需要一些評估準則

837
00:27:56,000 --> 00:27:58,000
來去看說

838
00:27:58,000 --> 00:28:00,000
這個explainer到底學得好不好

839
00:28:00,000 --> 00:28:02,000
並不是說我今天給你一個

840
00:28:02,000 --> 00:28:04,000
explainer你就要五條天去相信它

841
00:28:04,000 --> 00:28:06,000
所以我們當然可以透過

842
00:28:06,000 --> 00:28:08,000
很多很多不同種的

843
00:28:08,000 --> 00:28:10,000
metric來去判斷它好不好

844
00:28:10,000 --> 00:28:12,000
那其中最有名的就是

845
00:28:12,000 --> 00:28:14,000
屬於這個sharp e-value

846
00:28:14,000 --> 00:28:16,000
如果這邊有經濟學背景的

847
00:28:16,000 --> 00:28:18,000
或是曾經有學過經濟學的

848
00:28:18,000 --> 00:28:20,000
人呢

849
00:28:20,000 --> 00:28:22,000
可能會對這個字滿熟悉

850
00:28:22,000 --> 00:28:24,000
它就是同一個東西

851
00:28:24,000 --> 00:28:26,000
其實就只是要去算說

852
00:28:26,000 --> 00:28:28,000
每一個feature

853
00:28:28,000 --> 00:28:30,000
對於這個prediction model

854
00:28:30,000 --> 00:28:32,000
的貢獻程度是多少

855
00:28:32,000 --> 00:28:34,000
我們藉由這個

856
00:28:34,000 --> 00:28:36,000
game theory這個理論裡面的

857
00:28:36,000 --> 00:28:38,000
sharp e-value

858
00:28:38,000 --> 00:28:40,000
來製造我們的

859
00:28:40,000 --> 00:28:42,000
所謂的正確答案然後去做evaluation

860
00:28:42,000 --> 00:28:44,000
對

861
00:28:44,000 --> 00:28:46,000
那這個explainer有很多

862
00:28:46,000 --> 00:28:48,000
很多方法

863
00:28:48,000 --> 00:28:50,000
像是sharp啊像是line啊

864
00:28:50,000 --> 00:28:52,000
這種

865
00:28:52,000 --> 00:28:54,000
那這邊

866
00:28:54,000 --> 00:28:56,000
列出來這些方法其實

867
00:28:56,000 --> 00:28:58,000
有一個很大的缺點就是

868
00:28:58,000 --> 00:29:00,000
如果我們要做剛剛我們所說的

869
00:29:00,000 --> 00:29:02,000
local explanation的話

870
00:29:02,000 --> 00:29:04,000
那我們每張圖都必須要提供一個解釋

871
00:29:04,000 --> 00:29:06,000
那以現在目前的

872
00:29:06,000 --> 00:29:08,000
比較

873
00:29:08,000 --> 00:29:10,000
常見的方法

874
00:29:10,000 --> 00:29:12,000
我不能說全部因為現在有

875
00:29:12,000 --> 00:29:14,000
另外一種方法就是

876
00:29:14,000 --> 00:29:16,000
現在比較常見的方法呢

877
00:29:16,000 --> 00:29:18,000
就是我們一張圖

878
00:29:18,000 --> 00:29:20,000
例如說我們要給一張圖片解釋

879
00:29:20,000 --> 00:29:22,000
我們就必須要有一個explainer

880
00:29:22,000 --> 00:29:24,000
也就是說我們今天有十萬張圖片

881
00:29:24,000 --> 00:29:26,000
因為我們要給每一張圖片一個

882
00:29:26,000 --> 00:29:28,000
客製化的解釋結果

883
00:29:28,000 --> 00:29:30,000
所以我們就必須要有十萬

884
00:29:30,000 --> 00:29:32,000
那會導致什麼導致這個過程非常非常

885
00:29:32,000 --> 00:29:34,000
慢所以

886
00:29:34,000 --> 00:29:36,000
這些

887
00:29:36,000 --> 00:29:38,000
方法就有一些缺點

888
00:29:38,000 --> 00:29:40,000
當然就有些人說你今天有

889
00:29:40,000 --> 00:29:42,000
sharp e就是經濟學

890
00:29:42,000 --> 00:29:44,000
game theory這麼好的一個

891
00:29:44,000 --> 00:29:46,000
一個

892
00:29:46,000 --> 00:29:48,000
準則你為什麼不拿來用

893
00:29:48,000 --> 00:29:50,000
那我等一下會解釋一下為什麼我們

894
00:29:50,000 --> 00:29:52,000
不能直接拿sharp e來做

895
00:29:52,000 --> 00:29:54,000
最後模型解釋的一個結論

896
00:29:54,000 --> 00:29:56,000
ok

897
00:29:56,000 --> 00:29:58,000
好那我們就來講一下

898
00:29:58,000 --> 00:30:00,000
比較在網

899
00:30:00,000 --> 00:30:02,000
裡面挖一點那什麼是

900
00:30:02,000 --> 00:30:04,000
sharp e value呢其實sharp e value其實

901
00:30:04,000 --> 00:30:06,000
就是我們把game theory的一個

902
00:30:06,000 --> 00:30:08,000
東西借過來然後來

903
00:30:08,000 --> 00:30:10,000
來就是給模型

904
00:30:10,000 --> 00:30:12,000
的prediction做解釋

905
00:30:12,000 --> 00:30:14,000
好那我們

906
00:30:14,000 --> 00:30:16,000
要製造sharp e value必須要做一件事

907
00:30:16,000 --> 00:30:18,000
就是我們需要

908
00:30:18,000 --> 00:30:20,000
知道每一個feature我們的目的就是

909
00:30:20,000 --> 00:30:22,000
知道每一個feature的

910
00:30:22,000 --> 00:30:24,000
important score就是我們需要知道每一個feature

911
00:30:24,000 --> 00:30:26,000
的重要程度的分數

912
00:30:26,000 --> 00:30:28,000
那我們要知道每一個feature

913
00:30:28,000 --> 00:30:30,000
的重要分數

914
00:30:30,000 --> 00:30:32,000
必須要做一些什麼事

915
00:30:32,000 --> 00:30:34,000
其實很簡單就是我們要把

916
00:30:34,000 --> 00:30:36,000
每一個假設我們這邊有

917
00:30:36,000 --> 00:30:38,000
user0有四個feature

918
00:30:38,000 --> 00:30:40,000
5個12345

919
00:30:40,000 --> 00:30:42,000
我們要判斷這個user0

920
00:30:42,000 --> 00:30:44,000
是不是他可以

921
00:30:44,000 --> 00:30:46,000
還清這個房貸

922
00:30:46,000 --> 00:30:48,000
ok那我們就必須要知道說

923
00:30:48,000 --> 00:30:50,000
每一個feature對於

924
00:30:50,000 --> 00:30:52,000
能不能還清房貸的重要程度

925
00:30:52,000 --> 00:30:54,000
我們要做一件事就是例如說

926
00:30:54,000 --> 00:30:56,000
我們必須要

927
00:30:56,000 --> 00:30:58,000
這個job加這個

928
00:30:58,000 --> 00:31:00,000
marital status

929
00:31:00,000 --> 00:31:02,000
婚姻狀況的兩個feature

930
00:31:02,000 --> 00:31:04,000
的共同貢獻

931
00:31:04,000 --> 00:31:06,000
對於這個房貸

932
00:31:06,000 --> 00:31:08,000
能不能還清房貸這個prediction

933
00:31:08,000 --> 00:31:10,000
的重要程度

934
00:31:10,000 --> 00:31:12,000
所以我們必須要去

935
00:31:12,000 --> 00:31:14,000
go through

936
00:31:14,000 --> 00:31:16,000
all the combination

937
00:31:16,000 --> 00:31:18,000
feature的combination

938
00:31:18,000 --> 00:31:20,000
也就是說我們必須要說

939
00:31:20,000 --> 00:31:22,000
我們必須要去走例如age加job

940
00:31:22,000 --> 00:31:24,000
加marital加education

941
00:31:24,000 --> 00:31:26,000
或是age加job加marital

942
00:31:26,000 --> 00:31:28,000
或是age加job

943
00:31:28,000 --> 00:31:30,000
這種所有的feature的組合我們才可以知道

944
00:31:30,000 --> 00:31:32,000
在shopping eval裡面我們才可以知道

945
00:31:32,000 --> 00:31:34,000
每一個

946
00:31:34,000 --> 00:31:36,000
每一個單一feature對於最後prediction

947
00:31:36,000 --> 00:31:38,000
結果的重要程度

948
00:31:38,000 --> 00:31:40,000
所以這會導致說什麼

949
00:31:40,000 --> 00:31:42,000
這會導致說如果我這邊只有

950
00:31:42,000 --> 00:31:44,000
5個feature那倒還好

951
00:31:44,000 --> 00:31:46,000
因為這個組合量就是2的5次方

952
00:31:46,000 --> 00:31:48,000
要不要要不要

953
00:31:48,000 --> 00:31:50,000
所以是2的5次方

954
00:31:50,000 --> 00:31:52,000
那今天如果我在

955
00:31:52,000 --> 00:31:54,000
大公司裡面做推薦系統

956
00:31:54,000 --> 00:31:56,000
我有2000個feature

957
00:31:56,000 --> 00:31:58,000
那就會是2的2000次方

958
00:31:58,000 --> 00:32:00,000
這個一個user就需要

959
00:32:00,000 --> 00:32:02,000
2的2000次方的計算的

960
00:32:02,000 --> 00:32:04,000
次數

961
00:32:04,000 --> 00:32:06,000
那還得了我今天有11個user

962
00:32:06,000 --> 00:32:08,000
那撐下去

963
00:32:08,000 --> 00:32:10,000
那就是算不完了

964
00:32:10,000 --> 00:32:12,000
整個運算過程算不完了

965
00:32:12,000 --> 00:32:14,000
所以今天這個shopping eval

966
00:32:14,000 --> 00:32:16,000
為什麼不能用

967
00:32:16,000 --> 00:32:18,000
它其實本身是一個NP-hard problem

968
00:32:18,000 --> 00:32:20,000
就是它的複雜度太高了

969
00:32:20,000 --> 00:32:22,000
而且我們不能用

970
00:32:22,000 --> 00:32:24,000
低複雜度的方法去

971
00:32:24,000 --> 00:32:26,000
去驗證它

972
00:32:26,000 --> 00:32:28,000
我們算出來的東西是不是對

973
00:32:28,000 --> 00:32:30,000
這個東西就NP-hard

974
00:32:30,000 --> 00:32:32,000
所以我們在

975
00:32:32,000 --> 00:32:34,000
我們在直接拿shopping eval

976
00:32:34,000 --> 00:32:36,000
這個詞來當作

977
00:32:36,000 --> 00:32:38,000
最後解釋的important score的話

978
00:32:38,000 --> 00:32:40,000
其實可以但是

979
00:32:40,000 --> 00:32:42,000
是不現實的

980
00:32:42,000 --> 00:32:44,000
因為它太

981
00:32:44,000 --> 00:32:46,000
太吃時間

982
00:32:46,000 --> 00:32:48,000
它需要太大的計算的複雜度

983
00:32:48,000 --> 00:32:50,000
所以導致我們

984
00:32:50,000 --> 00:32:52,000
沒辦法使用這個狀況

985
00:32:52,000 --> 00:32:54,000
ok

986
00:32:54,000 --> 00:32:56,000
剛才漏講一下後面這個

987
00:32:56,000 --> 00:32:58,000
其實後面這個東西它就是在算說

988
00:32:58,000 --> 00:33:00,000
如果我今天把

989
00:33:00,000 --> 00:33:02,000
例如說我今天只在乎job跟merito

990
00:33:02,000 --> 00:33:04,000
我今天把另外三個拿掉後

991
00:33:04,000 --> 00:33:06,000
那我的model會

992
00:33:06,000 --> 00:33:08,000
的prediction會做出什麼結果

993
00:33:08,000 --> 00:33:10,000
我model prediction

994
00:33:10,000 --> 00:33:12,000
會發生什麼變化

995
00:33:12,000 --> 00:33:14,000
如果我今天把這個balance

996
00:33:14,000 --> 00:33:16,000
把job把merito拿掉

997
00:33:16,000 --> 00:33:18,000
我只把age跟education

998
00:33:18,000 --> 00:33:20,000
考進去我的prediction model

999
00:33:20,000 --> 00:33:22,000
然後我今天它原本是

1000
00:33:22,000 --> 00:33:24,000
不能還房貸的預測結果

1001
00:33:24,000 --> 00:33:26,000
突然變成說你可以還得起房貸

1002
00:33:26,000 --> 00:33:28,000
那這說明什麼

1003
00:33:28,000 --> 00:33:30,000
這三個feature很重要

1004
00:33:30,000 --> 00:33:32,000
這三個feature是導致它預測正確的

1005
00:33:32,000 --> 00:33:34,000
一個key feature

1006
00:33:34,000 --> 00:33:36,000
ok

1007
00:33:36,000 --> 00:33:38,000
所以透過這種不斷的

1008
00:33:38,000 --> 00:33:40,000
這種iterate的過程

1009
00:33:40,000 --> 00:33:42,000
去找到說每一個feature的

1010
00:33:42,000 --> 00:33:44,000
重要的分數

1011
00:33:44,000 --> 00:33:46,000
這個就是shopping value

1012
00:33:46,000 --> 00:33:48,000
ok

1013
00:33:48,000 --> 00:33:50,000
懂經濟學的人應該

1014
00:33:50,000 --> 00:33:52,000
看到這個東西會覺得蠻

1015
00:33:52,000 --> 00:33:54,000
蠻親切的

1016
00:33:54,000 --> 00:33:56,000
ok

1017
00:33:56,000 --> 00:33:58,000
好那

1018
00:33:58,000 --> 00:34:00,000
我shopping value不能用的話

1019
00:34:00,000 --> 00:34:02,000
那怎麼辦

1020
00:34:02,000 --> 00:34:04,000
這就是我在做研究

1021
00:34:04,000 --> 00:34:06,000
就是我想要把這個

1022
00:34:06,000 --> 00:34:08,000
explanation的這個過程給加速

1023
00:34:08,000 --> 00:34:10,000
我想要讓

1024
00:34:10,000 --> 00:34:12,000
因為每一個feature

1025
00:34:12,000 --> 00:34:14,000
每一個

1026
00:34:14,000 --> 00:34:16,000
我們在做local explanation

1027
00:34:16,000 --> 00:34:18,000
每一個使用者都必須要

1028
00:34:18,000 --> 00:34:20,000
給一個客製化的

1029
00:34:20,000 --> 00:34:22,000
explanation的結果

1030
00:34:22,000 --> 00:34:24,000
那我剛才提到每一個客製化的explanation的結果

1031
00:34:24,000 --> 00:34:26,000
都必須要有一個獨立的

1032
00:34:26,000 --> 00:34:28,000
explanator

1033
00:34:28,000 --> 00:34:30,000
就是一個解釋prediction model的模型

1034
00:34:30,000 --> 00:34:32,000
那這個過程本身

1035
00:34:32,000 --> 00:34:34,000
就是一個非常耗

1036
00:34:34,000 --> 00:34:36,000
耗時間的一個過程

1037
00:34:36,000 --> 00:34:38,000
像是你如果

1038
00:34:38,000 --> 00:34:40,000
給一個推薦結果然後你叫使用者

1039
00:34:40,000 --> 00:34:42,000
說不好意思等我10秒

1040
00:34:42,000 --> 00:34:44,000
我給你一個推薦我給你一個解釋

1041
00:34:44,000 --> 00:34:46,000
使用者一定就不能接受

1042
00:34:46,000 --> 00:34:48,000
如果你一個網頁叫你等10秒

1043
00:34:48,000 --> 00:34:50,000
你一定就左上角插他就按掉了

1044
00:34:50,000 --> 00:34:52,000
類似這樣

1045
00:34:52,000 --> 00:34:54,000
所以這個加速結果是很重要

1046
00:34:54,000 --> 00:34:56,000
那在這邊這個work

1047
00:34:56,000 --> 00:34:58,000
這是我的去年投稿上的一個work

1048
00:34:58,000 --> 00:35:00,000
這個work

1049
00:35:00,000 --> 00:35:02,000
這個work就是

1050
00:35:02,000 --> 00:35:04,000
我們目的是在加速這個

1051
00:35:04,000 --> 00:35:06,000
shopping value的

1052
00:35:06,000 --> 00:35:08,000
這個運算過程

1053
00:35:08,000 --> 00:35:10,000
然後把這個過程的結果

1054
00:35:10,000 --> 00:35:12,000
提供給使用者當作

1055
00:35:12,000 --> 00:35:14,000
解釋的結果

1056
00:35:14,000 --> 00:35:16,000
ok那我們做了什麼像我剛才在講說

1057
00:35:16,000 --> 00:35:18,000
shopping value他其實

1058
00:35:18,000 --> 00:35:20,000
因為我要go through all the combination

1059
00:35:20,000 --> 00:35:22,000
of the feature set

1060
00:35:22,000 --> 00:35:24,000
所以我們今天假設有五個feature

1061
00:35:24,000 --> 00:35:26,000
那就是2的五次方

1062
00:35:26,000 --> 00:35:28,000
那是不是每一個feature的組合

1063
00:35:28,000 --> 00:35:30,000
對模型來說很重要呢

1064
00:35:30,000 --> 00:35:32,000
不見得為什麼就是有些feature

1065
00:35:32,000 --> 00:35:34,000
他的交互作用其實對模型來說

1066
00:35:34,000 --> 00:35:36,000
是不重要的

1067
00:35:36,000 --> 00:35:38,000
那這個資訊可不可以在模型訓練完

1068
00:35:38,000 --> 00:35:40,000
之後就得到呢

1069
00:35:40,000 --> 00:35:42,000
其實是可以的就是我們其實可以把

1070
00:35:42,000 --> 00:35:44,000
模型的訓練的權重

1071
00:35:44,000 --> 00:35:46,000
給拿出來去看到說

1072
00:35:46,000 --> 00:35:48,000
feature1跟feature2

1073
00:35:48,000 --> 00:35:50,000
黑色代表很重要那feature

1074
00:35:50,000 --> 00:35:52,000
x1跟x2他很重要

1075
00:35:52,000 --> 00:35:54,000
x1跟x3

1076
00:35:54,000 --> 00:35:56,000
突然之間沒有跟x2那麼重要

1077
00:35:56,000 --> 00:35:58,000
x1跟x5來說

1078
00:35:58,000 --> 00:36:00,000
其實完全不重要

1079
00:36:00,000 --> 00:36:02,000
所以這個時候我們就可以把x1x5

1080
00:36:02,000 --> 00:36:04,000
這個組合從算shopping value

1081
00:36:04,000 --> 00:36:06,000
的這個組合給拿掉

1082
00:36:06,000 --> 00:36:08,000
那拿掉之後

1083
00:36:08,000 --> 00:36:10,000
例如說我們原本要2的五次方可能要32次

1084
00:36:10,000 --> 00:36:12,000
可能透過

1085
00:36:12,000 --> 00:36:14,000
這種拿掉的過程例如說

1086
00:36:14,000 --> 00:36:16,000
我們把這個灰色以下的

1087
00:36:16,000 --> 00:36:18,000
色階的色塊的

1088
00:36:18,000 --> 00:36:20,000
組合全部拿掉那我們

1089
00:36:20,000 --> 00:36:22,000
裡面所需要算的次數就變成是

1090
00:36:22,000 --> 00:36:24,000
可能2 2 4 6 8

1091
00:36:24,000 --> 00:36:26,000
還有14次

1092
00:36:26,000 --> 00:36:28,000
所以其實是減了一半的過程

1093
00:36:28,000 --> 00:36:30,000
對吧這個過程其實是

1094
00:36:30,000 --> 00:36:32,000
可以加速這個

1095
00:36:32,000 --> 00:36:34,000
shopping value的計算

1096
00:36:34,000 --> 00:36:36,000
然後把這個東西變成一個

1097
00:36:36,000 --> 00:36:38,000
使用者可以接受的

1098
00:36:38,000 --> 00:36:40,000
一個等待時間

1099
00:36:40,000 --> 00:36:42,000
那最後提供給使用者

1100
00:36:42,000 --> 00:36:44,000
比較快速的這個解釋的

1101
00:36:44,000 --> 00:36:46,000
解釋的

1102
00:36:46,000 --> 00:36:48,000
這個結果

1103
00:36:48,000 --> 00:36:50,000
所以這個數學其實就是在表達說

1104
00:36:50,000 --> 00:36:52,000
我們今天在shopping value

1105
00:36:52,000 --> 00:36:54,000
裡面我們需要

1106
00:36:54,000 --> 00:36:56,000
去經歷所有的

1107
00:36:56,000 --> 00:36:58,000
所有的feature的組合

1108
00:36:58,000 --> 00:37:00,000
那我們今天把它變成是

1109
00:37:00,000 --> 00:37:02,000
我們透過模型的權重

1110
00:37:02,000 --> 00:37:04,000
去看到feature跟feature之間的

1111
00:37:04,000 --> 00:37:06,000
interaction的重要性

1112
00:37:06,000 --> 00:37:08,000
然後把不重要拿掉

1113
00:37:08,000 --> 00:37:10,000
最後我們去算

1114
00:37:10,000 --> 00:37:12,000
approximate的shopping value

1115
00:37:12,000 --> 00:37:14,000
把這個shopping value當作

1116
00:37:14,000 --> 00:37:16,000
當作是

1117
00:37:16,000 --> 00:37:18,000
explanation的important score

1118
00:37:18,000 --> 00:37:20,000
提供給使用者

1119
00:37:20,000 --> 00:37:22,000
就是這個work的精神

1120
00:37:22,000 --> 00:37:24,000
ok

1121
00:37:24,000 --> 00:37:26,000
所以你可以看到說

1122
00:37:26,000 --> 00:37:28,000
我們這個work其實有一個

1123
00:37:28,000 --> 00:37:30,000
application的scenario

1124
00:37:30,000 --> 00:37:32,000
就是我們今天在train的一個

1125
00:37:32,000 --> 00:37:34,000
prediction model

1126
00:37:34,000 --> 00:37:36,000
我們去預測說

1127
00:37:36,000 --> 00:37:38,000
他的income是高還是低

1128
00:37:38,000 --> 00:37:40,000
這個東西,我們其實可以用我們的模型

1129
00:37:40,000 --> 00:37:42,000
去解釋這個訓練好的

1130
00:37:42,000 --> 00:37:44,000
這個prediction model

1131
00:37:44,000 --> 00:37:46,000
然後進而去提供說

1132
00:37:46,000 --> 00:37:48,000
為什麼他可能是因為你的

1133
00:37:48,000 --> 00:37:50,000
高學歷,例如說你是

1134
00:37:50,000 --> 00:37:52,000
稻乾工作人,類似那種

1135
00:37:52,000 --> 00:37:54,000
然後是造成說

1136
00:37:54,000 --> 00:37:56,000
我判斷你是高工資

1137
00:37:56,000 --> 00:37:58,000
的這種結果

1138
00:37:58,000 --> 00:38:00,000
所以我們這個模型其實是

1139
00:38:00,000 --> 00:38:02,000
可以用一個比較快速的

1140
00:38:02,000 --> 00:38:04,000
快速的這個explanation的方式

1141
00:38:04,000 --> 00:38:06,000
然後在

1142
00:38:06,000 --> 00:38:08,000
提供給使用者的這個情境

1143
00:38:08,000 --> 00:38:10,000
上面做使用

1144
00:38:10,000 --> 00:38:12,000
那右下角這個圖其實可以看到

1145
00:38:12,000 --> 00:38:14,000
左邊這個藍色的這個bar

1146
00:38:14,000 --> 00:38:16,000
其實是

1147
00:38:16,000 --> 00:38:18,000
ground truth

1148
00:38:18,000 --> 00:38:20,000
也就是說我們用經濟學

1149
00:38:20,000 --> 00:38:22,000
跟theory的那個公式去算出來

1150
00:38:22,000 --> 00:38:24,000
說屬於這個

1151
00:38:24,000 --> 00:38:26,000
屬於這個feature來說

1152
00:38:26,000 --> 00:38:28,000
真正他應該要有

1153
00:38:28,000 --> 00:38:30,000
那可以看到其實

1154
00:38:30,000 --> 00:38:32,000
我們就算把那些不重要的

1155
00:38:32,000 --> 00:38:34,000
feature跟interaction給拿掉

1156
00:38:34,000 --> 00:38:36,000
我們的shopping value在

1157
00:38:36,000 --> 00:38:38,000
我們的這個model在預測出來

1158
00:38:38,000 --> 00:38:40,000
這個

1159
00:38:40,000 --> 00:38:42,000
importance的這個score

1160
00:38:42,000 --> 00:38:44,000
他其實跟shopping value是非常靠近

1161
00:38:44,000 --> 00:38:46,000
完全一模一樣

1162
00:38:46,000 --> 00:38:48,000
畢竟我們把一些combination拿掉了

1163
00:38:48,000 --> 00:38:50,000
所以這個東西其實是

1164
00:38:50,000 --> 00:38:52,000
更快速但是我們同樣不失去

1165
00:38:52,000 --> 00:38:54,000
那個shopping value的那個

1166
00:38:54,000 --> 00:38:56,000
準度所以我們在提供給

1167
00:38:56,000 --> 00:38:58,000
每個feature的重要性

1168
00:38:58,000 --> 00:39:00,000
給user的時候我們可以說

1169
00:39:00,000 --> 00:39:02,000
學歷這一塊的feature

1170
00:39:02,000 --> 00:39:04,000
對於我們的

1171
00:39:04,000 --> 00:39:06,000
模型來說預測你是

1172
00:39:06,000 --> 00:39:08,000
高薪水低薪水的

1173
00:39:08,000 --> 00:39:10,000
這個

1174
00:39:10,000 --> 00:39:12,000
模型來說是很重要的

1175
00:39:12,000 --> 00:39:14,000
所以我們會把這個例如分數

1176
00:39:14,000 --> 00:39:16,000
或是把這個重要程度的

1177
00:39:16,000 --> 00:39:18,000
ranking的結果提供給

1178
00:39:18,000 --> 00:39:20,000
使用者作為他

1179
00:39:20,000 --> 00:39:22,000
想不想相信這個

1180
00:39:22,000 --> 00:39:24,000
這個預測模型的一個參考

1181
00:39:24,000 --> 00:39:26,000
ok

1182
00:39:26,000 --> 00:39:28,000
好

1183
00:39:28,000 --> 00:39:30,000
那下一個工作

1184
00:39:30,000 --> 00:39:32,000
那我加速一下

1185
00:39:32,000 --> 00:39:34,000
下一個工作的話是

1186
00:39:34,000 --> 00:39:36,000
因為我們前面是

1187
00:39:36,000 --> 00:39:38,000
加速那個shopping value

1188
00:39:38,000 --> 00:39:40,000
的計算過程

1189
00:39:40,000 --> 00:39:42,000
對吧

1190
00:39:42,000 --> 00:39:44,000
這個工作是我們

1191
00:39:44,000 --> 00:39:46,000
與其要去加速那個過程

1192
00:39:46,000 --> 00:39:48,000
那倒不如說我們去訓練一個模型

1193
00:39:48,000 --> 00:39:50,000
去把shopping value

1194
00:39:50,000 --> 00:39:52,000
計算的那個distribution

1195
00:39:52,000 --> 00:39:54,000
計算那個distribution給學起來

1196
00:39:54,000 --> 00:39:56,000
那這個東西其實

1197
00:39:56,000 --> 00:39:58,000
可以更快地去

1198
00:39:58,000 --> 00:40:00,000
給預測結果

1199
00:40:00,000 --> 00:40:02,000
為什麼呢是因為

1200
00:40:02,000 --> 00:40:04,000
我們這個傳統的

1201
00:40:04,000 --> 00:40:06,000
一般的這種DNA模型

1202
00:40:06,000 --> 00:40:08,000
我們剛才是每一個

1203
00:40:08,000 --> 00:40:10,000
每一個

1204
00:40:10,000 --> 00:40:12,000
user我們要給他一個

1205
00:40:12,000 --> 00:40:14,000
客製化的結果我們就必須要有一個

1206
00:40:14,000 --> 00:40:16,000
explanation model

1207
00:40:16,000 --> 00:40:18,000
所以我們今天要預測十萬個user

1208
00:40:18,000 --> 00:40:20,000
我們就要給十萬個model

1209
00:40:20,000 --> 00:40:22,000
那在這邊我們只要給一個user

1210
00:40:22,000 --> 00:40:24,000
我們只要給一個model去

1211
00:40:24,000 --> 00:40:26,000
預測所有user的

1212
00:40:26,000 --> 00:40:28,000
explanation結果就可以了

1213
00:40:28,000 --> 00:40:30,000
那這個過程其實上也是加速

1214
00:40:30,000 --> 00:40:32,000
加速我們給

1215
00:40:32,000 --> 00:40:34,000
explanation過程的這個進程

1216
00:40:34,000 --> 00:40:36,000
ok那為什麼是因為

1217
00:40:36,000 --> 00:40:38,000
一般的這種

1218
00:40:38,000 --> 00:40:40,000
深度學習這種網路

1219
00:40:40,000 --> 00:40:42,000
我們只要給例如說我們可以

1220
00:40:42,000 --> 00:40:44,000
一次把十萬個user當作

1221
00:40:44,000 --> 00:40:46,000
data送進去那個

1222
00:40:46,000 --> 00:40:48,000
預測網路然後這個預測網路

1223
00:40:48,000 --> 00:40:50,000
他就可以突出屬於這十萬個

1224
00:40:50,000 --> 00:40:52,000
不同的結果

1225
00:40:52,000 --> 00:40:54,000
ok所以我們再也不需要

1226
00:40:54,000 --> 00:40:56,000
我們再也不需要一個使用者

1227
00:40:56,000 --> 00:40:58,000
對應一個獨立的

1228
00:40:58,000 --> 00:41:00,000
explanator

1229
00:41:00,000 --> 00:41:02,000
我們現在只需要一個explanator

1230
00:41:02,000 --> 00:41:04,000
去對應所有user

1231
00:41:04,000 --> 00:41:06,000
這個訓練過程

1232
00:41:06,000 --> 00:41:08,000
其實是我另外一個work

1233
00:41:08,000 --> 00:41:10,000
那這篇也在投稿當中

1234
00:41:10,000 --> 00:41:12,000
那他主要就是說

1235
00:41:12,000 --> 00:41:14,000
我們是不是可以透過一些

1236
00:41:14,000 --> 00:41:16,000
sorry

1237
00:41:16,000 --> 00:41:18,000
透過一些正樣本跟負樣本的這種

1238
00:41:18,000 --> 00:41:20,000
學習什麼是正樣本

1239
00:41:20,000 --> 00:41:22,000
例如說

1240
00:41:22,000 --> 00:41:24,000
我們今天把某些一張圖片

1241
00:41:24,000 --> 00:41:26,000
把某些重要的

1242
00:41:26,000 --> 00:41:28,000
特徵給遮掉

1243
00:41:28,000 --> 00:41:30,000
如果我們遮掉這個特徵呢

1244
00:41:30,000 --> 00:41:32,000
是屬於不重要的特徵

1245
00:41:32,000 --> 00:41:34,000
比如說我們遮掉狗的眼睛

1246
00:41:34,000 --> 00:41:36,000
那因為他有另外一隻眼睛

1247
00:41:36,000 --> 00:41:38,000
所以可能一隻眼睛相對來說不重要

1248
00:41:38,000 --> 00:41:40,000
那模型在判斷

1249
00:41:40,000 --> 00:41:42,000
這張圖是不是一隻狗的時候

1250
00:41:42,000 --> 00:41:44,000
他還是做出一樣的判斷

1251
00:41:44,000 --> 00:41:46,000
這個就是所謂的正樣本

1252
00:41:46,000 --> 00:41:48,000
那這個正樣本其實可以幫助

1253
00:41:48,000 --> 00:41:50,000
幫助我們去解釋

1254
00:41:50,000 --> 00:41:52,000
例如說我們說

1255
00:41:52,000 --> 00:41:54,000
我們希望一個人判斷說

1256
00:41:54,000 --> 00:41:56,000
這張圖片

1257
00:41:56,000 --> 00:41:58,000
希望一個模型判斷說他是不是一隻狗

1258
00:41:58,000 --> 00:42:00,000
那我們給出的解釋

1259
00:42:00,000 --> 00:42:02,000
因為狗

1260
00:42:02,000 --> 00:42:04,000
狗在乎這些特徵

1261
00:42:04,000 --> 00:42:06,000
所以我模型做出

1262
00:42:06,000 --> 00:42:08,000
這個prediction的結果

1263
00:42:08,000 --> 00:42:10,000
那這些東西是正向

1264
00:42:10,000 --> 00:42:12,000
那我們可以給一些負向

1265
00:42:12,000 --> 00:42:14,000
例如說我們這邊給一個場景錄

1266
00:42:14,000 --> 00:42:16,000
場景錄就不是狗

1267
00:42:16,000 --> 00:42:18,000
所以模型就會知道說

1268
00:42:18,000 --> 00:42:20,000
今天遇到這個場景錄的時候

1269
00:42:20,000 --> 00:42:22,000
他就是屬於這個狗的

1270
00:42:22,000 --> 00:42:24,000
negative sample

1271
00:42:24,000 --> 00:42:26,000
就是所謂的負面樣

1272
00:42:26,000 --> 00:42:28,000
負面教材

1273
00:42:28,000 --> 00:42:30,000
負面教材跟負面教材的時候

1274
00:42:30,000 --> 00:42:32,000
我就可以去學

1275
00:42:32,000 --> 00:42:34,000
就是我希望我的模型

1276
00:42:34,000 --> 00:42:36,000
給出的解釋

1277
00:42:36,000 --> 00:42:38,000
要越靠近正面教材

1278
00:42:38,000 --> 00:42:40,000
然後離負面教材越來越遠

1279
00:42:40,000 --> 00:42:42,000
這就是我要做的事情

1280
00:42:42,000 --> 00:42:44,000
所以我透過我的這個

1281
00:42:44,000 --> 00:42:46,000
設計的這個模型

1282
00:42:46,000 --> 00:42:48,000
那這個過程

1283
00:42:48,000 --> 00:42:50,000
其實有一個名詞叫contrastive learning

1284
00:42:50,000 --> 00:42:52,000
就是中文叫

1285
00:42:52,000 --> 00:42:54,000
對比學習吧

1286
00:42:54,000 --> 00:42:56,000
應該是這個對比學習的過程

1287
00:42:56,000 --> 00:42:58,000
然後讓模型知道什麼是對

1288
00:42:58,000 --> 00:43:00,000
什麼是錯

1289
00:43:00,000 --> 00:43:02,000
然後我希望我對的跟錯的

1290
00:43:02,000 --> 00:43:04,000
之間的距離越來越大

1291
00:43:04,000 --> 00:43:06,000
然後讓模型往正確方向去訓練

1292
00:43:06,000 --> 00:43:08,000
那為什麼後面還有一個

1293
00:43:08,000 --> 00:43:10,000
fine tuning的過程

1294
00:43:10,000 --> 00:43:12,000
這邊的fine tuning的過程是

1295
00:43:12,000 --> 00:43:14,000
為什麼我剛剛提到shoppy value

1296
00:43:14,000 --> 00:43:16,000
是因為shoppy value有很強大的

1297
00:43:16,000 --> 00:43:18,000
經濟學game theory的一些

1298
00:43:18,000 --> 00:43:20,000
理論上的support

1299
00:43:20,000 --> 00:43:22,000
所以如果我們能

1300
00:43:22,000 --> 00:43:24,000
如果我們能製造出

1301
00:43:24,000 --> 00:43:26,000
這些

1302
00:43:26,000 --> 00:43:28,000
這些important score

1303
00:43:28,000 --> 00:43:30,000
他也具有shoppy value

1304
00:43:30,000 --> 00:43:32,000
這些特性的話

1305
00:43:32,000 --> 00:43:34,000
那

1306
00:43:34,000 --> 00:43:36,000
在提供給

1307
00:43:36,000 --> 00:43:38,000
我不敢說提供給使用者用

1308
00:43:38,000 --> 00:43:40,000
但至少在提供給一些

1309
00:43:40,000 --> 00:43:42,000
例如machine learning engineer

1310
00:43:42,000 --> 00:43:44,000
或是一些高層

1311
00:43:44,000 --> 00:43:46,000
他們要去看說去evaluate說

1312
00:43:46,000 --> 00:43:48,000
這些evaluation的

1313
00:43:48,000 --> 00:43:50,000
這些explanation的結果是不是可信

1314
00:43:50,000 --> 00:43:52,000
那這個過程其實上

1315
00:43:52,000 --> 00:43:54,000
一是去讓人家更幸福這個過程

1316
00:43:54,000 --> 00:43:56,000
二是我透過這個fine tuning的過程

1317
00:43:56,000 --> 00:43:58,000
我希望我的

1318
00:43:58,000 --> 00:44:00,000
我的這些東西不要離shoppy value

1319
00:44:00,000 --> 00:44:02,000
太遠

1320
00:44:02,000 --> 00:44:04,000
那這個不要離shoppy value太遠的

1321
00:44:04,000 --> 00:44:06,000
這個特性他somehow可以去

1322
00:44:06,000 --> 00:44:08,000
因為這邊我完全沒有使用任何的

1323
00:44:08,000 --> 00:44:10,000
一些shoppy value

1324
00:44:10,000 --> 00:44:12,000
作為label去訓練

1325
00:44:12,000 --> 00:44:14,000
那後面我給少量的label

1326
00:44:14,000 --> 00:44:16,000
我是可以把他拉回shoppy value的正軌

1327
00:44:16,000 --> 00:44:18,000
讓整個

1328
00:44:18,000 --> 00:44:20,000
整個大模型在訓練的時候

1329
00:44:20,000 --> 00:44:22,000
不要離我們剛才所謂的shoppy value

1330
00:44:22,000 --> 00:44:24,000
給explanation這個framework太遠

1331
00:44:24,000 --> 00:44:26,000
讓我們可以

1332
00:44:26,000 --> 00:44:28,000
拿這個結果去

1333
00:44:28,000 --> 00:44:30,000
讓別人相信說

1334
00:44:30,000 --> 00:44:32,000
我們不是隨便去製造一個

1335
00:44:32,000 --> 00:44:34,000
important score的預測

1336
00:44:34,000 --> 00:44:36,000
我們是基於shoppy value的

1337
00:44:36,000 --> 00:44:38,000
這個大框架去做

1338
00:44:38,000 --> 00:44:40,000
prediction

1339
00:44:40,000 --> 00:44:42,000
所以這個模型其實有

1340
00:44:42,000 --> 00:44:44,000
幾個優點

1341
00:44:44,000 --> 00:44:46,000
第一個是他可以很快

1342
00:44:46,000 --> 00:44:48,000
因為他只要一個模型就可以應付所有的user

1343
00:44:48,000 --> 00:44:50,000
不像是以前一個模型

1344
00:44:50,000 --> 00:44:52,000
只能應付一個user

1345
00:44:52,000 --> 00:44:54,000
然後再來就是他提供了正樣本跟負樣本的選取

1346
00:44:54,000 --> 00:44:56,000
然後讓整個訓練的

1347
00:44:56,000 --> 00:44:58,000
過程中我們不需要

1348
00:44:58,000 --> 00:45:00,000
太大量的樣本

1349
00:45:00,000 --> 00:45:02,000
不需要太大量的label

1350
00:45:02,000 --> 00:45:04,000
然後也可以去訓練出對於所有user的

1351
00:45:04,000 --> 00:45:06,000
這個訓練結果

1352
00:45:06,000 --> 00:45:08,000
好那這個我就

1353
00:45:08,000 --> 00:45:10,000
就不講了我就跳過

1354
00:45:10,000 --> 00:45:12,000
可以看到右邊這個

1355
00:45:12,000 --> 00:45:14,000
右邊這個兩張圖就是

1356
00:45:14,000 --> 00:45:16,000
我們訓練的結果

1357
00:45:16,000 --> 00:45:18,000
這個訓練的結果就是可以看到說

1358
00:45:18,000 --> 00:45:20,000
這是一隻鳥嘛

1359
00:45:20,000 --> 00:45:22,000
那這個鳥的中間被框住

1360
00:45:22,000 --> 00:45:24,000
紅色就代表重要,藍色就代表不重要

1361
00:45:24,000 --> 00:45:26,000
所以我們就知道

1362
00:45:26,000 --> 00:45:28,000
這個image classification model

1363
00:45:28,000 --> 00:45:30,000
他其實上是在

1364
00:45:30,000 --> 00:45:32,000
為什麼會預測他是鳥

1365
00:45:32,000 --> 00:45:34,000
那就是因為他抓到了這個鳥的特徵

1366
00:45:34,000 --> 00:45:36,000
所以我們就可以去相信

1367
00:45:36,000 --> 00:45:38,000
這個image classification model是做對的

1368
00:45:38,000 --> 00:45:40,000
然後也可以去看說

1369
00:45:40,000 --> 00:45:42,000
我們這個explainer是trend好的

1370
00:45:42,000 --> 00:45:44,000
是trend對的

1371
00:45:44,000 --> 00:45:46,000
下面這個狗

1372
00:45:46,000 --> 00:45:48,000
最重要的這個特徵是臉

1373
00:45:48,000 --> 00:45:50,000
狗的這個臉

1374
00:45:50,000 --> 00:45:52,000
那我們就把我們的這個

1375
00:45:52,000 --> 00:45:54,000
explainer訓練結果

1376
00:45:54,000 --> 00:45:56,000
他其實就是說這個臉很重要

1377
00:45:56,000 --> 00:45:58,000
那我們把這個臉highlight起來

1378
00:45:58,000 --> 00:46:00,000
那就是最後的explanation

1379
00:46:00,000 --> 00:46:02,000
結果

1380
00:46:04,000 --> 00:46:06,000
好那有幾個

1381
00:46:06,000 --> 00:46:08,000
有幾個application

1382
00:46:08,000 --> 00:46:10,000
就是例如說

1383
00:46:10,000 --> 00:46:12,000
其實我前面大致上都提過

1384
00:46:12,000 --> 00:46:14,000
XAI在recommended system上面

1385
00:46:14,000 --> 00:46:16,000
的重要性

1386
00:46:16,000 --> 00:46:18,000
是因為可以針對幾個不同的

1387
00:46:18,000 --> 00:46:20,000
人

1388
00:46:20,000 --> 00:46:22,000
幾個不同的使用情境來說

1389
00:46:22,000 --> 00:46:24,000
例如說我對於客人來說

1390
00:46:24,000 --> 00:46:26,000
我可以讓他知道我拿什麼

1391
00:46:26,000 --> 00:46:28,000
怎麼逼選給你訓練

1392
00:46:28,000 --> 00:46:30,000
那為什麼你會做出這個結果

1393
00:46:30,000 --> 00:46:32,000
讓大家覺得

1394
00:46:32,000 --> 00:46:34,000
這個decision是對

1395
00:46:34,000 --> 00:46:36,000
然後更安心

1396
00:46:36,000 --> 00:46:38,000
對於這個recommended system更安心

1397
00:46:38,000 --> 00:46:40,000
那對於商人來說

1398
00:46:40,000 --> 00:46:42,000
那他可以透過這個

1399
00:46:42,000 --> 00:46:44,000
例如說我投放廣告

1400
00:46:44,000 --> 00:46:46,000
那你總要跟廣告商說

1401
00:46:46,000 --> 00:46:48,000
因為我

1402
00:46:48,000 --> 00:46:50,000
截取了使用者

1403
00:46:50,000 --> 00:46:52,000
使用者的A feature B feature

1404
00:46:52,000 --> 00:46:54,000
C feature D feature

1405
00:46:54,000 --> 00:46:56,000
然後導致

1406
00:46:56,000 --> 00:46:58,000
我推薦這個使用者廣告

1407
00:46:58,000 --> 00:47:00,000
所以商人可以透過這種

1408
00:47:00,000 --> 00:47:02,000
顯示的分析去做出

1409
00:47:02,000 --> 00:47:04,000
更好的例如說

1410
00:47:04,000 --> 00:47:06,000
因為我發現可能這個市場

1411
00:47:06,000 --> 00:47:08,000
某些使用者會在乎什麼

1412
00:47:08,000 --> 00:47:10,000
商品的特徵

1413
00:47:10,000 --> 00:47:12,000
我可以去對這些商品的特徵做調整

1414
00:47:12,000 --> 00:47:14,000
然後他也可以更信服

1415
00:47:14,000 --> 00:47:16,000
這個廣告的投放

1416
00:47:16,000 --> 00:47:18,000
那對於我們

1417
00:47:18,000 --> 00:47:20,000
這種工程師來說

1418
00:47:20,000 --> 00:47:22,000
提供這種

1419
00:47:22,000 --> 00:47:24,000
explanation的結果

1420
00:47:24,000 --> 00:47:26,000
他其實可以幫我們去

1421
00:47:26,000 --> 00:47:28,000
debug這個system

1422
00:47:28,000 --> 00:47:30,000
也可以讓我們去改善這個system

1423
00:47:30,000 --> 00:47:32,000
例如說我們如果抓錯了feature的話

1424
00:47:32,000 --> 00:47:34,000
我們要怎麼去調整

1425
00:47:34,000 --> 00:47:36,000
那再來就是health care

1426
00:47:36,000 --> 00:47:38,000
那就是例如說

1427
00:47:38,000 --> 00:47:40,000
我們對於病人來說

1428
00:47:40,000 --> 00:47:42,000
我們可以去說服病人說

1429
00:47:42,000 --> 00:47:44,000
相信這個診斷結果是沒錯

1430
00:47:44,000 --> 00:47:46,000
那對於醫生來說

1431
00:47:46,000 --> 00:47:48,000
可以去協助他做正確的結論

1432
00:47:48,000 --> 00:47:50,000
就是醫生憑什麼相信

1433
00:47:50,000 --> 00:47:52,000
這個prediction model

1434
00:47:52,000 --> 00:47:54,000
但你總要說服他說

1435
00:47:54,000 --> 00:47:56,000
因為我detect到什麼症狀

1436
00:47:56,000 --> 00:47:58,000
這個東西其實是

1437
00:47:58,000 --> 00:48:00,000
可以協助醫生

1438
00:48:00,000 --> 00:48:02,000
但我必須要說

1439
00:48:02,000 --> 00:48:04,000
他不能取代醫生的重要程度

1440
00:48:04,000 --> 00:48:06,000
所有的AI model

1441
00:48:06,000 --> 00:48:08,000
他都是在協助為本質

1442
00:48:08,000 --> 00:48:10,000
這個outlier

1443
00:48:10,000 --> 00:48:12,000
我覺得就先跳過

1444
00:48:12,000 --> 00:48:14,000
OK

1445
00:48:14,000 --> 00:48:16,000
好那最後的話

1446
00:48:16,000 --> 00:48:18,000
我來講幾個常見的

1447
00:48:18,000 --> 00:48:20,000
這個open source package

1448
00:48:20,000 --> 00:48:22,000
這些都是免費完全免費

1449
00:48:22,000 --> 00:48:24,000
不用付任何錢

1450
00:48:24,000 --> 00:48:26,000
第一個就是Captain

1451
00:48:26,000 --> 00:48:28,000
Captain其實是Facebook開發的一個

1452
00:48:28,000 --> 00:48:30,000
可解釋性的

1453
00:48:30,000 --> 00:48:32,000
開源的套件

1454
00:48:32,000 --> 00:48:34,000
那這個套件

1455
00:48:34,000 --> 00:48:36,000
使用的方式很簡單

1456
00:48:36,000 --> 00:48:38,000
就我們要使用這種

1457
00:48:38,000 --> 00:48:40,000
套件的時候

1458
00:48:40,000 --> 00:48:42,000
首先我們必須要有一個

1459
00:48:42,000 --> 00:48:44,000
我們要解釋的模型

1460
00:48:44,000 --> 00:48:46,000
如果沒有解釋模型

1461
00:48:46,000 --> 00:48:48,000
那這個XI就沒用了

1462
00:48:48,000 --> 00:48:50,000
所以我們

1463
00:48:50,000 --> 00:48:52,000
這個code的話就是

1464
00:48:52,000 --> 00:48:54,000
首先我們要有一個

1465
00:48:54,000 --> 00:48:56,000
我們要去解釋的目標模型

1466
00:48:56,000 --> 00:48:58,000
那這個integrated gradient

1467
00:48:58,000 --> 00:49:00,000
這個東西

1468
00:49:00,000 --> 00:49:02,000
其實就是

1469
00:49:02,000 --> 00:49:04,000
其中一個我們剛才說

1470
00:49:04,000 --> 00:49:06,000
一直在說的explainer

1471
00:49:06,000 --> 00:49:08,000
就是解釋模型的

1472
00:49:08,000 --> 00:49:10,000
機器學系模型

1473
00:49:10,000 --> 00:49:12,000
有點local

1474
00:49:12,000 --> 00:49:14,000
所以我們把這個

1475
00:49:14,000 --> 00:49:16,000
image classifier丟進這個

1476
00:49:16,000 --> 00:49:18,000
的explainer裡面

1477
00:49:18,000 --> 00:49:20,000
那他的

1478
00:49:20,000 --> 00:49:22,000
這個explainer的

1479
00:49:22,000 --> 00:49:24,000
output結果就會是

1480
00:49:24,000 --> 00:49:26,000
我去highlight一張圖片哪裡重要

1481
00:49:26,000 --> 00:49:28,000
所以右邊這個結果就是

1482
00:49:28,000 --> 00:49:30,000
這個東西 output出來的結果

1483
00:49:30,000 --> 00:49:32,000
這是一隻天鵝

1484
00:49:32,000 --> 00:49:34,000
那他predict是不是一隻天鵝

1485
00:49:34,000 --> 00:49:36,000
是因為他

1486
00:49:36,000 --> 00:49:38,000
看了

1487
00:49:38,000 --> 00:49:40,000
這些重要的feature

1488
00:49:40,000 --> 00:49:42,000
所以我們就可以透過這個輪廓

1489
00:49:42,000 --> 00:49:44,000
他真的是detect到這個天鵝

1490
00:49:44,000 --> 00:49:46,000
而不是detect到旁邊這些水

1491
00:49:46,000 --> 00:49:48,000
這就是過程

1492
00:49:48,000 --> 00:49:50,000
那不然就是

1493
00:49:50,000 --> 00:49:52,000
例如說我們有一些文字的模型

1494
00:49:52,000 --> 00:49:54,000
就是文字的classifier的結果

1495
00:49:54,000 --> 00:49:56,000
那是因為為什麼他會說

1496
00:49:56,000 --> 00:49:58,000
這句話是一個

1497
00:49:58,000 --> 00:50:00,000
positive的attitude

1498
00:50:00,000 --> 00:50:02,000
那是因為沒有

1499
00:50:02,000 --> 00:50:04,000
例如fantastic的字

1500
00:50:04,000 --> 00:50:06,000
那為什麼他是positive

1501
00:50:06,000 --> 00:50:08,000
因為他有best

1502
00:50:08,000 --> 00:50:10,000
那為什麼他不好

1503
00:50:10,000 --> 00:50:12,000
例如說negative

1504
00:50:12,000 --> 00:50:14,000
類似這種showcase

1505
00:50:14,000 --> 00:50:16,000
所以這整個package的

1506
00:50:16,000 --> 00:50:18,000
使用方式非常簡單

1507
00:50:18,000 --> 00:50:20,000
所以只要幾行

1508
00:50:20,000 --> 00:50:22,000
一行兩行三行

1509
00:50:22,000 --> 00:50:24,000
只要三行就可以搞定

1510
00:50:24,000 --> 00:50:26,000
explanation的process

1511
00:50:26,000 --> 00:50:28,000
那當然就是這裡面還有一些

1512
00:50:28,000 --> 00:50:30,000
模型調教的一些

1513
00:50:30,000 --> 00:50:32,000
trick或是一些經驗談

1514
00:50:32,000 --> 00:50:34,000
那這個就是要靠

1515
00:50:34,000 --> 00:50:36,000
大家平常常去用的一些

1516
00:50:36,000 --> 00:50:38,000
technique才會知道的一些

1517
00:50:38,000 --> 00:50:40,000
makeup

1518
00:50:40,000 --> 00:50:42,000
那另外一個package叫shop

1519
00:50:42,000 --> 00:50:44,000
那他shop他也是

1520
00:50:44,000 --> 00:50:46,000
用同樣的concept在

1521
00:50:46,000 --> 00:50:48,000
設計這個package

1522
00:50:48,000 --> 00:50:50,000
一樣他就是例如說

1523
00:50:50,000 --> 00:50:52,000
我需要有一個prediction model在這裡

1524
00:50:52,000 --> 00:50:54,000
然後把他寫成一個function

1525
00:50:54,000 --> 00:50:56,000
那我已經有一個prediction model在這裡

1526
00:50:56,000 --> 00:50:58,000
我已經有一個explanator在這裡

1527
00:50:58,000 --> 00:51:00,000
那這個explanator的目的

1528
00:51:00,000 --> 00:51:02,000
就是要去製造說

1529
00:51:02,000 --> 00:51:04,000
每一個圖片

1530
00:51:04,000 --> 00:51:06,000
或是每一個

1531
00:51:06,000 --> 00:51:08,000
每一句話或是每一個user

1532
00:51:08,000 --> 00:51:10,000
他重要的feature或重要的字

1533
00:51:10,000 --> 00:51:12,000
或是重要的pixel是什麼

1534
00:51:12,000 --> 00:51:14,000
那就是透過這個

1535
00:51:14,000 --> 00:51:16,000
這個explanator

1536
00:51:16,000 --> 00:51:18,000
來最後做一個製造

1537
00:51:18,000 --> 00:51:20,000
所以他output出來的shop event

1538
00:51:20,000 --> 00:51:22,000
就是屬於每一個pixel

1539
00:51:22,000 --> 00:51:24,000
重要的important score

1540
00:51:24,000 --> 00:51:26,000
ok所以整個過程就會比較像是這樣

1541
00:51:26,000 --> 00:51:28,000
我已經有一個黑盒模型

1542
00:51:28,000 --> 00:51:30,000
然後最後把他打開

1543
00:51:30,000 --> 00:51:32,000
然後知道每一個feature的重要程度是什麼

1544
00:51:32,000 --> 00:51:34,000
ok

1545
00:51:34,000 --> 00:51:36,000
所以整個feature會比較像是這樣

1546
00:51:36,000 --> 00:51:38,000
就例如說這是一艘船

1547
00:51:38,000 --> 00:51:40,000
所以他就會說

1548
00:51:40,000 --> 00:51:42,000
highlight船的這個

1549
00:51:42,000 --> 00:51:44,000
部件在這裡

1550
00:51:44,000 --> 00:51:46,000
那就讓人家知道說

1551
00:51:46,000 --> 00:51:48,000
這個船很重要

1552
00:51:48,000 --> 00:51:50,000
就可以了解到這個船的特徵

1553
00:51:50,000 --> 00:51:52,000
ok

1554
00:51:52,000 --> 00:51:54,000
那後面這些圖是

1555
00:51:54,000 --> 00:51:56,000
說今天錯誤的樣本

1556
00:51:56,000 --> 00:51:58,000
會發生什麼事

1557
00:51:58,000 --> 00:52:00,000
其實後面就不用管

1558
00:52:00,000 --> 00:52:02,000
因為我們只在

1559
00:52:02,000 --> 00:52:04,000
XAI這個模型

1560
00:52:04,000 --> 00:52:06,000
其實我們不能去導正

1561
00:52:06,000 --> 00:52:08,000
直接去導正

1562
00:52:08,000 --> 00:52:10,000
prediction model不好的結果

1563
00:52:10,000 --> 00:52:12,000
我們就是基於prediction model

1564
00:52:12,000 --> 00:52:14,000
給出來的結果做最忠實

1565
00:52:14,000 --> 00:52:16,000
最真誠的

1566
00:52:16,000 --> 00:52:18,000
這個解釋的結果

1567
00:52:18,000 --> 00:52:20,000
所以今天不能說

1568
00:52:20,000 --> 00:52:22,000
為什麼這個

1569
00:52:22,000 --> 00:52:24,000
他在fountain這個level下

1570
00:52:24,000 --> 00:52:26,000
他的explanation的結果好像很爛

1571
00:52:26,000 --> 00:52:28,000
那廢話因為他prediction

1572
00:52:28,000 --> 00:52:30,000
本來就是錯

1573
00:52:30,000 --> 00:52:32,000
因為你本來決策就錯了

1574
00:52:32,000 --> 00:52:34,000
所以我基於你做錯的決策

1575
00:52:34,000 --> 00:52:36,000
去做錯誤的explanation

1576
00:52:36,000 --> 00:52:38,000
其實是

1577
00:52:38,000 --> 00:52:40,000
XAI是不能管

1578
00:52:40,000 --> 00:52:42,000
我們只是基於你給我的

1579
00:52:42,000 --> 00:52:44,000
prediction model最忠實的決定

1580
00:52:44,000 --> 00:52:46,000
所以在看這個speed

1581
00:52:46,000 --> 00:52:48,000
這個boat

1582
00:52:48,000 --> 00:52:50,000
這個level才是比較

1583
00:52:50,000 --> 00:52:52,000
合理的

1584
00:52:52,000 --> 00:52:54,000
好

1585
00:52:54,000 --> 00:52:56,000
可能多拖了五分鐘

1586
00:52:56,000 --> 00:52:58,000
那今天演講就

1587
00:52:58,000 --> 00:53:00,000
大概到這裡

1588
00:53:00,000 --> 00:53:02,000
謝謝大家

1589
00:53:06,000 --> 00:53:08,000
有問題都可以提問

1590
00:53:10,000 --> 00:53:12,000
我想確認一下

1591
00:53:12,000 --> 00:53:14,000
因為現在沒有什麼設定上的問題

1592
00:53:14,000 --> 00:53:16,000
所以說

1593
00:53:16,000 --> 00:53:18,000
有問題的人

1594
00:53:18,000 --> 00:53:20,000
可以直接問一下

1595
00:53:36,000 --> 00:53:38,000
你好

1596
00:53:38,000 --> 00:53:40,000
我在聊天室有一個問題

1597
00:53:40,000 --> 00:53:42,000
好想要問

1598
00:53:42,000 --> 00:53:44,000
因為我主要是做tree-based model

1599
00:53:44,000 --> 00:53:46,000
就是提升資源區那種

1600
00:53:46,000 --> 00:53:48,000
然後因為

1601
00:53:48,000 --> 00:53:50,000
就是在很多那種數據競賽

1602
00:53:50,000 --> 00:53:52,000
或是實用目的可能比較少

1603
00:53:52,000 --> 00:53:54,000
那數據競賽

1604
00:53:54,000 --> 00:53:56,000
最後都會結合很多

1605
00:53:56,000 --> 00:53:58,000
模型然後塞在一起

1606
00:53:58,000 --> 00:54:00,000
那這種也可以用XAI這種方式嗎

1607
00:54:02,000 --> 00:54:04,000
如果是post hoc的話

1608
00:54:04,000 --> 00:54:06,000
你是用什麼

1609
00:54:06,000 --> 00:54:08,000
XGBoost或是LightGBM

1610
00:54:08,000 --> 00:54:10,000
例如說我最近就有研究

1611
00:54:10,000 --> 00:54:12,000
就是XGBoost加LightGBM

1612
00:54:12,000 --> 00:54:14,000
然後結果再把它拼進去

1613
00:54:14,000 --> 00:54:16,000
OK

1614
00:54:16,000 --> 00:54:18,000
我必須要說XGBoost那些

1615
00:54:18,000 --> 00:54:20,000
縱使它是樹模型

1616
00:54:20,000 --> 00:54:22,000
但是它中間有很多不同的layer

1617
00:54:22,000 --> 00:54:24,000
它其實是不能解釋的

1618
00:54:24,000 --> 00:54:26,000
所以一個可解

1619
00:54:26,000 --> 00:54:28,000
如果我們要說一個模型本身具有可解釋性

1620
00:54:28,000 --> 00:54:30,000
那它每一個component都要是清楚的

1621
00:54:30,000 --> 00:54:32,000
就縱使中間有一個

1622
00:54:32,000 --> 00:54:34,000
是不清楚的

1623
00:54:34,000 --> 00:54:36,000
那它整個就是不清楚的

1624
00:54:36,000 --> 00:54:38,000
XGBoost或是LightGBM

1625
00:54:38,000 --> 00:54:40,000
都必須要用post hoc的方式

1626
00:54:40,000 --> 00:54:42,000
所以用那些package

1627
00:54:42,000 --> 00:54:44,000
應該是可以去幫你做

1628
00:54:44,000 --> 00:54:46,000
解釋上面的動作

1629
00:54:48,000 --> 00:54:50,000
那如果我今天的模型的預測

1630
00:54:50,000 --> 00:54:52,000
是基於這四種模型的

1631
00:54:52,000 --> 00:54:54,000
預測結果去做平均的話

1632
00:54:54,000 --> 00:54:56,000
那我有辦法

1633
00:54:56,000 --> 00:54:58,000
一樣用你剛說的工具去回推

1634
00:54:58,000 --> 00:55:00,000
就是它綜合的

1635
00:55:00,000 --> 00:55:02,000
這樣子的性能

1636
00:55:02,000 --> 00:55:04,000
然後它的feature對哪一些

1637
00:55:04,000 --> 00:55:06,000
feature是哪一些重要的嗎

1638
00:55:06,000 --> 00:55:08,000
你四個模型

1639
00:55:08,000 --> 00:55:10,000
都是不同的模型嗎

1640
00:55:10,000 --> 00:55:12,000
就是其實我是用

1641
00:55:12,000 --> 00:55:14,000
不同的模型

1642
00:55:14,000 --> 00:55:16,000
然後去訓練

1643
00:55:16,000 --> 00:55:18,000
然後去預測出結果

1644
00:55:18,000 --> 00:55:20,000
只是說我最終的預測是這四個模型的輸出

1645
00:55:20,000 --> 00:55:22,000
再去做平均

1646
00:55:22,000 --> 00:55:24,000
ok 就單純的insampling這樣

1647
00:55:24,000 --> 00:55:26,000
ok

1648
00:55:26,000 --> 00:55:28,000
那我覺得是不太

1649
00:55:28,000 --> 00:55:30,000
不太能對四個模型的綜合

1650
00:55:30,000 --> 00:55:32,000
做評估

1651
00:55:32,000 --> 00:55:34,000
四個模型各做一個評估

1652
00:55:34,000 --> 00:55:36,000
對對

1653
00:55:36,000 --> 00:55:38,000
例如說我explanation score

1654
00:55:38,000 --> 00:55:40,000
把它加起來平均

1655
00:55:40,000 --> 00:55:42,000
對對對

1656
00:55:42,000 --> 00:55:44,000
ok 謝謝

1657
00:55:44,000 --> 00:55:46,000
ok 謝謝

1658
00:55:46,000 --> 00:55:48,000
謝謝你的問題

1659
00:55:48,000 --> 00:55:50,000
然後推薦系統中

1660
00:55:50,000 --> 00:55:52,000
遇到全新的商品

1661
00:55:52,000 --> 00:55:54,000
可能啊可能

1662
00:55:54,000 --> 00:55:56,000
例如說我就舉個最簡單的例子

1663
00:55:56,000 --> 00:55:58,000
就為什麼一些

1664
00:55:58,000 --> 00:56:00,000
假設Netflix它一進去

1665
00:56:00,000 --> 00:56:02,000
它叫你按說你喜歡什麼歌

1666
00:56:02,000 --> 00:56:04,000
你喜歡什麼藝人

1667
00:56:04,000 --> 00:56:06,000
你看過什麼影片

1668
00:56:06,000 --> 00:56:08,000
這些東西就是在建立你的個人的profile

1669
00:56:08,000 --> 00:56:10,000
那透過這些相同的profile

1670
00:56:10,000 --> 00:56:12,000
我可以去找到跟你

1671
00:56:12,000 --> 00:56:14,000
習性比較像的使用者

1672
00:56:14,000 --> 00:56:16,000
那我就把這些使用者的先前的習慣

1673
00:56:16,000 --> 00:56:18,000
當作你最一開始的推薦結果

1674
00:56:18,000 --> 00:56:20,000
那你當然之後

1675
00:56:20,000 --> 00:56:22,000
拿到這些推薦結果你會繼續再做你自己的使用嘛

1676
00:56:22,000 --> 00:56:24,000
那再把你自己的使用的

1677
00:56:24,000 --> 00:56:26,000
這些東西加上別人的

1678
00:56:26,000 --> 00:56:28,000
一些以前的習慣

1679
00:56:28,000 --> 00:56:30,000
如何來弄起來

1680
00:56:30,000 --> 00:56:32,000
然後做最後的

1681
00:56:32,000 --> 00:56:34,000
例如說你使用半年之後

1682
00:56:34,000 --> 00:56:36,000
你會發現結果越來越準

1683
00:56:36,000 --> 00:56:38,000
就是因為它推薦系統模型

1684
00:56:38,000 --> 00:56:40,000
你在經歷的過程

1685
00:56:40,000 --> 00:56:42,000
ok 希望有回答到你的問題

1686
00:56:44,000 --> 00:56:46,000
推薦的入門

1687
00:56:46,000 --> 00:56:48,000
ok 有

1688
00:56:48,000 --> 00:56:50,000
就是你可以上網搜

1689
00:56:50,000 --> 00:56:52,000
XAI什麼block

1690
00:56:52,000 --> 00:56:54,000
有一個寫的蠻好的

1691
00:56:54,000 --> 00:56:56,000
算是一本書吧

1692
00:56:56,000 --> 00:56:58,000
五個章節還是十個章節

1693
00:56:58,000 --> 00:57:00,000
然後我覺得他寫的蠻好的

1694
00:57:00,000 --> 00:57:02,000
然後包括現在這個XAI很多人在做

1695
00:57:02,000 --> 00:57:04,000
所以你去youtube上面

1696
00:57:04,000 --> 00:57:06,000
打例如introduction to

1697
00:57:06,000 --> 00:57:08,000
XAI可能也會跳出一些

1698
00:57:08,000 --> 00:57:10,000
不錯的影片

1699
00:57:10,000 --> 00:57:12,000
但我蠻推薦我剛才說的那個block

1700
00:57:12,000 --> 00:57:14,000
ok

1701
00:57:14,000 --> 00:57:16,000
特徵

1702
00:57:16,000 --> 00:57:18,000
ok 在這邊

1703
00:57:18,000 --> 00:57:20,000
其實都

1704
00:57:20,000 --> 00:57:22,000
ok

1705
00:57:22,000 --> 00:57:24,000
在我剛才講的

1706
00:57:24,000 --> 00:57:26,000
這個假設

1707
00:57:26,000 --> 00:57:28,000
它其實都假設每個特徵

1708
00:57:28,000 --> 00:57:30,000
是獨立的

1709
00:57:30,000 --> 00:57:32,000
那也有人在

1710
00:57:32,000 --> 00:57:34,000
研究說

1711
00:57:34,000 --> 00:57:36,000
那今天特徵相異的時候

1712
00:57:36,000 --> 00:57:38,000
我應該要怎麼去

1713
00:57:38,000 --> 00:57:40,000
去分析

1714
00:57:40,000 --> 00:57:42,000
那這些人就是比較著重在研究

1715
00:57:42,000 --> 00:57:44,000
feature interaction的這種XAI的方式

1716
00:57:44,000 --> 00:57:46,000
有有有

1717
00:57:46,000 --> 00:57:48,000
有些人在做這些方式

1718
00:57:48,000 --> 00:57:50,000
我記得上海

1719
00:57:50,000 --> 00:57:52,000
上海交通大學的

1720
00:57:52,000 --> 00:57:54,000
張全時老師的實驗室

1721
00:57:54,000 --> 00:57:56,000
有一些papers在研究

1722
00:57:56,000 --> 00:57:58,000
這方面的東西

1723
00:57:58,000 --> 00:58:00,000
如果你有興趣可以去看一下

1724
00:58:00,000 --> 00:58:02,000
我相信問出這麼specific的問題的人應該

1725
00:58:02,000 --> 00:58:04,000
對這方面應該是稍微有研究

1726
00:58:04,000 --> 00:58:06,000
或是其實是個expert

1727
00:58:06,000 --> 00:58:08,000
所以這樣講應該

1728
00:58:08,000 --> 00:58:10,000
希望能回答到你的問題

1729
00:58:10,000 --> 00:58:12,000
ok

1730
00:58:12,000 --> 00:58:14,000
ok

1731
00:58:14,000 --> 00:58:16,000
這種

1732
00:58:16,000 --> 00:58:18,000
這種全新商品的推薦模型

1733
00:58:18,000 --> 00:58:20,000
叫做

1734
00:58:20,000 --> 00:58:22,000
co-start

1735
00:58:22,000 --> 00:58:24,000
recommendation

1736
00:58:24,000 --> 00:58:26,000
ok

1737
00:58:26,000 --> 00:58:28,000
很多很多

1738
00:58:28,000 --> 00:58:30,000
很多很多方式

1739
00:58:30,000 --> 00:58:32,000
我宣傳一下

1740
00:58:32,000 --> 00:58:34,000
我之前發了一篇paper

1741
00:58:34,000 --> 00:58:36,000
叫做TPR

1742
00:58:36,000 --> 00:58:38,000
textual Preference

1743
00:58:38,000 --> 00:58:40,000
Ranking

1744
00:58:40,000 --> 00:58:42,000
這個東西它可以透過

1745
00:58:42,000 --> 00:58:44,000
不同的使用者特徵

1746
00:58:44,000 --> 00:58:46,000
然後來達到這種

1747
00:58:46,000 --> 00:58:48,000
你剛才所謂的這種

1748
00:58:48,000 --> 00:58:50,000
co-start recommendation

1749
00:58:50,000 --> 00:58:52,000
的推薦效果

1750
00:58:52,000 --> 00:58:54,000
對

1751
00:58:54,000 --> 00:58:56,000
這是我之前自己發的

1752
00:58:56,000 --> 00:58:58,000
跟我們商量一下

1753
00:58:58,000 --> 00:59:00,000
或者是你可以去找

1754
00:59:00,000 --> 00:59:02,000
找有一個

1755
00:59:02,000 --> 00:59:04,000
UCSD有一個老師叫Julia McCauley

1756
00:59:04,000 --> 00:59:06,000
他們實驗室也有很多人在做

1757
00:59:06,000 --> 00:59:08,000
這種co-start recommendation

1758
00:59:08,000 --> 00:59:10,000
然後你打這個關鍵字

1759
00:59:10,000 --> 00:59:12,000
應該可以跳出很多

1760
00:59:12,000 --> 00:59:14,000
ok

1761
00:59:14,000 --> 00:59:16,000
希望回答到你的問題

1762
00:59:20,000 --> 00:59:22,000
喂

1763
00:59:22,000 --> 00:59:24,000
不好意思我想要問一個問題

1764
00:59:24,000 --> 00:59:26,000
就是你剛剛在訓練

1765
00:59:26,000 --> 00:59:28,000
那個狗狗的圖

1766
00:59:28,000 --> 00:59:30,000
就是positive跟negative

1767
00:59:30,000 --> 00:59:32,000
的那個狗狗的圖

1768
00:59:32,000 --> 00:59:34,000
跟對比下面

1769
00:59:34,000 --> 00:59:36,000
下面一張

1770
00:59:36,000 --> 00:59:38,000
那個錯誤的圖

1771
00:59:38,000 --> 00:59:40,000
然後你把狗狗的那個眼睛拔掉了

1772
00:59:40,000 --> 00:59:42,000
那我在想說

1773
00:59:42,000 --> 00:59:44,000
你在那個錯誤的答案

1774
00:59:44,000 --> 00:59:46,000
是否就是

1775
00:59:46,000 --> 00:59:48,000
也許把那隻狗狗的眼睛貼上去

1776
00:59:48,000 --> 00:59:50,000
會不會是

1777
00:59:50,000 --> 00:59:52,000
會不會讓訓練的效果比較好

1778
00:59:52,000 --> 00:59:54,000
喔

1779
00:59:54,000 --> 00:59:56,000
我這邊只是給一個

1780
00:59:56,000 --> 00:59:58,000
例子

1781
00:59:58,000 --> 01:00:00,000
但其實像我真的在訓練的時候

1782
01:00:00,000 --> 01:00:02,000
例如說我是

1783
01:00:02,000 --> 01:00:04,000
假設他是一個32x32的圖片

1784
01:00:04,000 --> 01:00:06,000
那我就是給一個random mask

1785
01:00:06,000 --> 01:00:08,000
那這個random mask套上去的時候

1786
01:00:08,000 --> 01:00:10,000
他其實並不會

1787
01:00:10,000 --> 01:00:12,000
例如說並不會單純聚在這

1788
01:00:12,000 --> 01:00:14,000
他可能是散佈在一張圖片的不同地方

1789
01:00:14,000 --> 01:00:16,000
那例如說散佈在不同圖片的地方

1790
01:00:16,000 --> 01:00:18,000
我怎麼確認這個

1791
01:00:18,000 --> 01:00:20,000
被遮住過後的

1792
01:00:20,000 --> 01:00:22,000
這種

1793
01:00:22,000 --> 01:00:24,000
example是positive

1794
01:00:24,000 --> 01:00:26,000
我就把他丟到原本的prediction model去看說

1795
01:00:26,000 --> 01:00:28,000
他prediction的

1796
01:00:28,000 --> 01:00:30,000
例如說predict出來他是狗的分數

1797
01:00:30,000 --> 01:00:32,000
是不是掉很多

1798
01:00:32,000 --> 01:00:34,000
如果他幾乎沒掉

1799
01:00:34,000 --> 01:00:36,000
那我就可以肯定說我遮住的這些feature

1800
01:00:36,000 --> 01:00:38,000
所以我覺得你剛才說的是對的

1801
01:00:38,000 --> 01:00:40,000
例如說我今天把這個東西

1802
01:00:40,000 --> 01:00:42,000
遮到其他地方是有可能

1803
01:00:42,000 --> 01:00:44,000
幫助模型訓練是有可能

1804
01:00:44,000 --> 01:00:46,000
所以我在

1805
01:00:46,000 --> 01:00:48,000
這個是比較technical detail

1806
01:00:48,000 --> 01:00:50,000
我在訓練的時候其實是真的有做這件事情

1807
01:00:50,000 --> 01:00:52,000
所以像

1808
01:00:52,000 --> 01:00:54,000
像這種方式直接遮的話

1809
01:00:54,000 --> 01:00:56,000
那他有可能遮出來的東西

1810
01:00:56,000 --> 01:00:58,000
是例如說

1811
01:00:58,000 --> 01:01:00,000
我就直接遮掉很重要的東西是有可能

1812
01:01:00,000 --> 01:01:02,000
我覺得你的問題

1813
01:01:02,000 --> 01:01:04,000
是一個很好的問題

1814
01:01:04,000 --> 01:01:06,000
ok謝謝

1815
01:01:06,000 --> 01:01:08,000
好謝謝

1816
01:01:08,000 --> 01:01:10,000
喂你好

1817
01:01:10,000 --> 01:01:12,000
哈囉

1818
01:01:12,000 --> 01:01:14,000
欸sorry我的那個

1819
01:01:14,000 --> 01:01:16,000
鏡頭壞掉我把你打開

1820
01:01:16,000 --> 01:01:18,000
沒關係沒關係我們很free

1821
01:01:18,000 --> 01:01:20,000
對

1822
01:01:20,000 --> 01:01:22,000
那Alan跟我想問一下那個

1823
01:01:22,000 --> 01:01:24,000
第12頁那個sharp t value那邊

1824
01:01:24,000 --> 01:01:26,000
ok

1825
01:01:26,000 --> 01:01:28,000
就是我想確認我的那個觀念沒有錯

1826
01:01:28,000 --> 01:01:30,000
ok

1827
01:01:30,000 --> 01:01:32,000
我可以理解他是

1828
01:01:32,000 --> 01:01:34,000
我可以理解那difference那邊

1829
01:01:34,000 --> 01:01:36,000
是我把某些feature拿掉以後

1830
01:01:36,000 --> 01:01:38,000
然後他的difference如果很大的話

1831
01:01:38,000 --> 01:01:40,000
就代表那個feature是重要的

1832
01:01:40,000 --> 01:01:42,000
是這樣理解嗎

1833
01:01:42,000 --> 01:01:44,000
對沒錯

1834
01:01:44,000 --> 01:01:46,000
因為他改變了原本的prediction的pattern

1835
01:01:46,000 --> 01:01:48,000
那下一頁

1836
01:01:48,000 --> 01:01:50,000
那個第13頁就是

1837
01:01:50,000 --> 01:01:52,000
在您的paper中

1838
01:01:52,000 --> 01:01:54,000
就是有建立各個feature之間的

1839
01:01:54,000 --> 01:01:56,000
的關係

1840
01:01:56,000 --> 01:01:58,000
那個矩陣

1841
01:01:58,000 --> 01:02:00,000
我可以把它理解成是那種

1842
01:02:00,000 --> 01:02:02,000
的這種關係嗎

1843
01:02:02,000 --> 01:02:04,000
可以

1844
01:02:04,000 --> 01:02:06,000
那為什麼

1845
01:02:06,000 --> 01:02:08,000
為什麼他們相關係數

1846
01:02:08,000 --> 01:02:10,000
的高或低會跟

1847
01:02:10,000 --> 01:02:12,000
就是我預測出來他這個feature

1848
01:02:12,000 --> 01:02:14,000
對結果的重要性是有關的

1849
01:02:14,000 --> 01:02:16,000
之間的分別

1850
01:02:16,000 --> 01:02:18,000
跟

1851
01:02:18,000 --> 01:02:20,000
你還有抱歉打斷你

1852
01:02:20,000 --> 01:02:22,000
我太興奮了

1853
01:02:22,000 --> 01:02:24,000
ok好

1854
01:02:24,000 --> 01:02:26,000
那這個東西為什麼跟那個prediction有關

1855
01:02:26,000 --> 01:02:28,000
是因為我這個矩陣

1856
01:02:28,000 --> 01:02:30,000
你可以把它理解成一種相關係數

1857
01:02:30,000 --> 01:02:32,000
但他不是完全是correlation

1858
01:02:32,000 --> 01:02:34,000
他是基於我們model

1859
01:02:34,000 --> 01:02:36,000
predict出來的中間那些prediction

1860
01:02:36,000 --> 01:02:38,000
predict出來的那個model weight

1861
01:02:38,000 --> 01:02:40,000
我們把那個model weight抽出來

1862
01:02:40,000 --> 01:02:42,000
去建立這個

1863
01:02:42,000 --> 01:02:44,000
feature跟feature之間關係的

1864
01:02:44,000 --> 01:02:46,000
這種權重的

1865
01:02:46,000 --> 01:02:48,000
的矩陣

1866
01:02:48,000 --> 01:02:50,000
的這種權重圖

1867
01:02:50,000 --> 01:02:52,000
所以他這裡面每一個圖片的

1868
01:02:52,000 --> 01:02:54,000
每一個色塊的這種interaction

1869
01:02:54,000 --> 01:02:56,000
的高或低都是

1870
01:02:56,000 --> 01:02:58,000
based on

1871
01:02:58,000 --> 01:03:00,000
model prediction的結果

1872
01:03:00,000 --> 01:03:02,000
所以我們才可以拿這個東西

1873
01:03:02,000 --> 01:03:04,000
當作去減少這種

1874
01:03:04,000 --> 01:03:06,000
計算combination

1875
01:03:06,000 --> 01:03:08,000
的依據

1876
01:03:08,000 --> 01:03:10,000
他不單單只是

1877
01:03:10,000 --> 01:03:12,000
對

1878
01:03:12,000 --> 01:03:14,000
就是例如說我可能

1879
01:03:14,000 --> 01:03:16,000
換了另外一個input

1880
01:03:16,000 --> 01:03:18,000
然後可能兩個feature同時的可能增加

1881
01:03:18,000 --> 01:03:20,000
或減少或是之間的關聯

1882
01:03:20,000 --> 01:03:22,000
然後是based在這個weight的變化

1883
01:03:22,000 --> 01:03:24,000
去建那個matrix

1884
01:03:24,000 --> 01:03:26,000
例如說你可以

1885
01:03:26,000 --> 01:03:28,000
把

1886
01:03:28,000 --> 01:03:30,000
今天這個model裡面某一個

1887
01:03:30,000 --> 01:03:32,000
乘的weight拿出來

1888
01:03:32,000 --> 01:03:34,000
那我們就可以去透過這個weight

1889
01:03:34,000 --> 01:03:36,000
可以去看說今天這個x1跟這個x2

1890
01:03:36,000 --> 01:03:38,000
他是不是

1891
01:03:38,000 --> 01:03:40,000
例如說他interaction是不是比較大

1892
01:03:40,000 --> 01:03:42,000
或是今天x1跟x3是不是比較大

1893
01:03:42,000 --> 01:03:44,000
類似這樣

1894
01:03:46,000 --> 01:03:48,000
可以想像是變化的

1895
01:03:48,000 --> 01:03:50,000
一起變化的那種感覺嗎

1896
01:03:50,000 --> 01:03:52,000
就一起變

1897
01:03:52,000 --> 01:03:54,000
就例如說

1898
01:03:54,000 --> 01:03:56,000
今天這個x1加x3

1899
01:03:56,000 --> 01:03:58,000
變化嗎

1900
01:03:58,000 --> 01:04:00,000
應該說今天這個x1x3對於

1901
01:04:00,000 --> 01:04:02,000
模型的訓練

1902
01:04:02,000 --> 01:04:04,000
這邊先不牽扯到變化

1903
01:04:04,000 --> 01:04:06,000
我們單純看說

1904
01:04:06,000 --> 01:04:08,000
就單純把這個模型扒開

1905
01:04:08,000 --> 01:04:10,000
然後強制拿裡面的某一個

1906
01:04:10,000 --> 01:04:12,000
訓練的權重出來

1907
01:04:12,000 --> 01:04:14,000
拿出這個訓練的權重出來

1908
01:04:14,000 --> 01:04:16,000
我們可以去提取

1909
01:04:16,000 --> 01:04:18,000
就是說這個x1跟x3

1910
01:04:18,000 --> 01:04:20,000
加在一起的時候

1911
01:04:20,000 --> 01:04:22,000
對於這個prediction來說到底多重要

1912
01:04:22,000 --> 01:04:24,000
類似這樣

1913
01:04:24,000 --> 01:04:26,000
例如說他的x1加x3

1914
01:04:26,000 --> 01:04:28,000
那條weight很粗

1915
01:04:28,000 --> 01:04:30,000
例如說可能是0.8

1916
01:04:30,000 --> 01:04:32,000
那我們就把這個0.8

1917
01:04:32,000 --> 01:04:34,000
貼在這,類似這樣

1918
01:04:34,000 --> 01:04:36,000
先沒有牽扯到後面

1919
01:04:38,000 --> 01:04:40,000
那還有一個小問題想問

1920
01:04:40,000 --> 01:04:42,000
沒事沒事

1921
01:04:42,000 --> 01:04:44,000
因為我們現在可能討論說

1922
01:04:44,000 --> 01:04:46,000
單一某一個feature對結果的重要程度

1923
01:04:46,000 --> 01:04:48,000
到底是高還低

1924
01:04:48,000 --> 01:04:50,000
那會不會說有一種狀況是說

1925
01:04:50,000 --> 01:04:52,000
獨立看A他其實影響不大

1926
01:04:52,000 --> 01:04:54,000
獨立看B他影響也不大

1927
01:04:54,000 --> 01:04:56,000
但是然而只有A跟B

1928
01:04:56,000 --> 01:04:58,000
同時存在的時候

1929
01:04:58,000 --> 01:05:00,000
他對結果是影響很大的

1930
01:05:00,000 --> 01:05:02,000
那這種情況我要怎麼去解釋他

1931
01:05:02,000 --> 01:05:04,000
ok

1932
01:05:04,000 --> 01:05:06,000
我覺得這個問題很好

1933
01:05:06,000 --> 01:05:08,000
我覺得這個問題跟前面

1934
01:05:08,000 --> 01:05:10,000
就是

1935
01:05:10,000 --> 01:05:12,000
有一個人提到

1936
01:05:12,000 --> 01:05:14,000
就是今天這個feature

1937
01:05:14,000 --> 01:05:16,000
不是相依的這種情況

1938
01:05:16,000 --> 01:05:18,000
產生你剛才那個問題

1939
01:05:18,000 --> 01:05:20,000
就是今天就是A B不是獨立的

1940
01:05:20,000 --> 01:05:22,000
那A B加在一起

1941
01:05:22,000 --> 01:05:24,000
如果A B不是獨立

1942
01:05:24,000 --> 01:05:26,000
那A不重要B不重要

1943
01:05:26,000 --> 01:05:28,000
那A加B有可能重要

1944
01:05:28,000 --> 01:05:30,000
有可能產生這種情形

1945
01:05:30,000 --> 01:05:32,000
那這種方式要怎麼去判斷

1946
01:05:32,000 --> 01:05:34,000
例如說我們去設計這個

1947
01:05:34,000 --> 01:05:36,000
explanation model的時候

1948
01:05:36,000 --> 01:05:38,000
我們本來就要去考慮

1949
01:05:38,000 --> 01:05:40,000
就不能把這種feature獨立的這種

1950
01:05:40,000 --> 01:05:42,000
假設加在我們explanation model的設計

1951
01:05:42,000 --> 01:05:44,000
所以像是我今天這兩個word

1952
01:05:44,000 --> 01:05:46,000
就是不管是剛才那個

1953
01:05:46,000 --> 01:05:48,000
九宮格或是這個word

1954
01:05:48,000 --> 01:05:50,000
我們都假設每一個feature是獨立的

1955
01:05:50,000 --> 01:05:52,000
所以我們在算的時候我們都把每一個feature當作

1956
01:05:52,000 --> 01:05:54,000
算是一個

1957
01:05:54,000 --> 01:05:56,000
特徵來算

1958
01:05:56,000 --> 01:05:58,000
但如果你今天要考慮那種feature不同組合的話

1959
01:05:58,000 --> 01:06:00,000
那你考慮的層面可能

1960
01:06:00,000 --> 01:06:02,000
例如說你並不單只是

1961
01:06:02,000 --> 01:06:04,000
考慮A B C D

1962
01:06:04,000 --> 01:06:06,000
你可能還要考慮A B C D

1963
01:06:06,000 --> 01:06:08,000
A加B A加C A加D

1964
01:06:08,000 --> 01:06:10,000
當作A加D等於

1965
01:06:10,000 --> 01:06:12,000
假設等於F類似這種

1966
01:06:12,000 --> 01:06:14,000
就是你把A加B

1967
01:06:14,000 --> 01:06:16,000
當作一個新的feature來分析

1968
01:06:16,000 --> 01:06:18,000
這是我目前想要比較naive的

1969
01:06:18,000 --> 01:06:20,000
解法

1970
01:06:20,000 --> 01:06:22,000
我記得就是我剛才講的交通大學

1971
01:06:22,000 --> 01:06:24,000
上海交通大學的那個張宣世老師

1972
01:06:24,000 --> 01:06:26,000
他們的實驗室

1973
01:06:26,000 --> 01:06:28,000
有人在研究這種

1974
01:06:28,000 --> 01:06:30,000
這種feature interaction

1975
01:06:30,000 --> 01:06:32,000
組合的

1976
01:06:32,000 --> 01:06:34,000
貢獻度

1977
01:06:34,000 --> 01:06:36,000
對於最後prediction

1978
01:06:36,000 --> 01:06:38,000
就是explanation的performance的影響

1979
01:06:38,000 --> 01:06:40,000
是有人在做這個

1980
01:06:40,000 --> 01:06:42,000
但我的研究就比較

1981
01:06:42,000 --> 01:06:44,000
focus在基於

1982
01:06:44,000 --> 01:06:46,000
這種獨立feature的

1983
01:06:46,000 --> 01:06:48,000
對對對

1984
01:06:48,000 --> 01:06:50,000
了解

1985
01:06:50,000 --> 01:06:52,000
謝謝Alan

1986
01:06:52,000 --> 01:06:54,000
感謝你的問題

1987
01:07:04,000 --> 01:07:06,000
討論區裡面有一個人有問說

1988
01:07:06,000 --> 01:07:08,000
random mask影像的時候

1989
01:07:08,000 --> 01:07:10,000
mask size要怎麼選擇

1990
01:07:10,000 --> 01:07:12,000
mask size

1991
01:07:12,000 --> 01:07:14,000
你是說整張mask的

1992
01:07:14,000 --> 01:07:16,000
大小嗎

1993
01:07:16,000 --> 01:07:18,000
還是

1994
01:07:18,000 --> 01:07:20,000
比如說像狗的眼睛

1995
01:07:20,000 --> 01:07:22,000
那一個

1996
01:07:22,000 --> 01:07:24,000
比如說你今天

1997
01:07:24,000 --> 01:07:26,000
你今天mask如果是

1998
01:07:26,000 --> 01:07:28,000
比眼睛還要小的話

1999
01:07:28,000 --> 01:07:30,000
這個mask是有效的

2000
01:07:30,000 --> 01:07:32,000
ok

2001
01:07:32,000 --> 01:07:34,000
我們在做這種東西的時候

2002
01:07:34,000 --> 01:07:36,000
我們最小單位是一個pixel

2003
01:07:36,000 --> 01:07:38,000
對所以

2004
01:07:38,000 --> 01:07:40,000
我們應該不可能比pixel還要小

2005
01:07:40,000 --> 01:07:42,000
對所以例如說

2006
01:07:42,000 --> 01:07:44,000
如果mask size你再問說

2007
01:07:44,000 --> 01:07:46,000
要mask幾個的話

2008
01:07:46,000 --> 01:07:48,000
這種東西就是

2009
01:07:48,000 --> 01:07:50,000
例如說我們在random的時候完全不去

2010
01:07:50,000 --> 01:07:52,000
我在這個works裡面完全沒有去限制

2011
01:07:52,000 --> 01:07:54,000
但我知道有人是會去限制說

2012
01:07:54,000 --> 01:07:56,000
我不希望我遮掉的東西太多

2013
01:07:56,000 --> 01:07:58,000
就是為什麼不希望

2014
01:07:58,000 --> 01:08:00,000
遮掉的東西太多是因為

2015
01:08:00,000 --> 01:08:02,000
如果遮太多的話其實會反而導致

2016
01:08:02,000 --> 01:08:04,000
他那個random出來的結果不這麼positive

2017
01:08:04,000 --> 01:08:06,000
類似這樣

2018
01:08:06,000 --> 01:08:08,000
或是根據他的目的

2019
01:08:08,000 --> 01:08:10,000
而有不同的那個

2020
01:08:10,000 --> 01:08:12,000
選擇類似這樣

2021
01:08:12,000 --> 01:08:14,000
或是他可能只要挑幾個很重要的

2022
01:08:14,000 --> 01:08:16,000
feature出來

2023
01:08:16,000 --> 01:08:18,000
那我今天如果mask掉了

2024
01:08:18,000 --> 01:08:20,000
例如說很少部分

2025
01:08:20,000 --> 01:08:22,000
那其實就不是我們樂見的結果

2026
01:08:22,000 --> 01:08:24,000
類似這樣

2027
01:08:24,000 --> 01:08:26,000
但如果你是說mask的那個

2028
01:08:26,000 --> 01:08:28,000
那個dimension的話

2029
01:08:28,000 --> 01:08:30,000
那他必須要跟原本的image的dimension是一樣

2030
01:08:30,000 --> 01:08:32,000
不然我蓋不上去

2031
01:08:32,000 --> 01:08:34,000
對

2032
01:08:34,000 --> 01:08:36,000
OK

2033
01:08:36,000 --> 01:08:38,000
希望有回答到你的問題

2034
01:08:40,000 --> 01:08:42,000
這是安德嗎

2035
01:08:44,000 --> 01:08:46,000
OK

2036
01:08:46,000 --> 01:08:48,000
好 謝謝

2037
01:08:48,000 --> 01:08:50,000
感覺這個有點人為決定

2038
01:08:50,000 --> 01:08:52,000
因為我會覺得說像比如說你今天mask size

2039
01:08:52,000 --> 01:08:54,000
如果今天你的mask size

2040
01:08:54,000 --> 01:08:56,000
是

2041
01:08:56,000 --> 01:08:58,000
感覺上是有一種所謂的feature

2042
01:08:58,000 --> 01:09:00,000
的最小單位的這種概念

2043
01:09:00,000 --> 01:09:02,000
就是說因為你今天眼睛

2044
01:09:02,000 --> 01:09:04,000
feature的最小單位

2045
01:09:04,000 --> 01:09:06,000
你一定會超過一個pixel

2046
01:09:06,000 --> 01:09:08,000
因為你的

2047
01:09:08,000 --> 01:09:10,000
情況下面

2048
01:09:10,000 --> 01:09:12,000
我不知道 我只是覺得說

2049
01:09:12,000 --> 01:09:14,000
這個問題我也不知道怎麼回答

2050
01:09:14,000 --> 01:09:16,000
或者是說這個問題

2051
01:09:16,000 --> 01:09:18,000
有時候感覺上你這個size的選擇

2052
01:09:18,000 --> 01:09:20,000
是不是其實蠻主觀的

2053
01:09:20,000 --> 01:09:22,000
這個選擇

2054
01:09:22,000 --> 01:09:24,000
其實有人在做

2055
01:09:24,000 --> 01:09:26,000
就是例如說

2056
01:09:26,000 --> 01:09:28,000
也不是有人在做

2057
01:09:28,000 --> 01:09:30,000
其中一個方法就是例如說

2058
01:09:30,000 --> 01:09:32,000
他知道他指這些component

2059
01:09:32,000 --> 01:09:34,000
這些object都是比較大

2060
01:09:34,000 --> 01:09:36,000
例如眼睛是比較大

2061
01:09:36,000 --> 01:09:38,000
那他就例如說他的mask他就不是random

2062
01:09:38,000 --> 01:09:40,000
每一個pixel 他是random

2063
01:09:40,000 --> 01:09:42,000
每4x4 pixel

2064
01:09:42,000 --> 01:09:44,000
random每6x6 pixel

2065
01:09:44,000 --> 01:09:46,000
那透過這個方式去遮

2066
01:09:46,000 --> 01:09:48,000
也有人是這樣做

2067
01:09:48,000 --> 01:09:50,000
但我覺得這個東西就是

2068
01:09:50,000 --> 01:09:52,000
因為我們都已經不知道模型

2069
01:09:52,000 --> 01:09:54,000
他在乎的pixel可能是眼睛的某

2070
01:09:54,000 --> 01:09:56,000
右上加左下

2071
01:09:56,000 --> 01:09:58,000
類似這種

2072
01:09:58,000 --> 01:10:00,000
如果給這麼強的假設

2073
01:10:00,000 --> 01:10:02,000
我覺得模型訓練會比較不好

2074
01:10:02,000 --> 01:10:04,000
就是這種

2075
01:10:04,000 --> 01:10:06,000
explanation model會比較不好

2076
01:10:06,000 --> 01:10:08,000
當然你說的是

2077
01:10:08,000 --> 01:10:10,000
exactly right

2078
01:10:10,000 --> 01:10:12,000
真的是這樣子

2079
01:10:12,000 --> 01:10:14,000
其實有人詬病說

2080
01:10:14,000 --> 01:10:16,000
這種做出來的解釋

2081
01:10:16,000 --> 01:10:18,000
他其實就是大概

2082
01:10:18,000 --> 01:10:20,000
遮一下遮一下

2083
01:10:20,000 --> 01:10:22,000
例如說大概秀出

2084
01:10:22,000 --> 01:10:24,000
其實這邊眼睛也沒遮到

2085
01:10:24,000 --> 01:10:26,000
其實有可能就是

2086
01:10:26,000 --> 01:10:28,000
因為這種mask

2087
01:10:28,000 --> 01:10:30,000
一開始還沒有做好的原因

2088
01:10:30,000 --> 01:10:32,000
導致我最後給出來的東西

2089
01:10:32,000 --> 01:10:34,000
不這麼comprehensive

2090
01:10:36,000 --> 01:10:38,000
這是有可能

2091
01:10:38,000 --> 01:10:40,000
我覺得這個問題超好的

2092
01:10:40,000 --> 01:10:42,000
好

2093
01:10:52,000 --> 01:10:54,000
感覺上

2094
01:10:54,000 --> 01:10:56,000
聊天室裡面沒有新的問題

2095
01:10:58,000 --> 01:11:00,000
那我們再謝謝一次

2096
01:11:00,000 --> 01:11:02,000
裕能今天的演講

2097
01:11:04,000 --> 01:11:06,000
謝謝大家

2098
01:11:10,000 --> 01:11:12,000
謝謝

2099
01:11:12,000 --> 01:11:14,000
感謝大家的捧場

2100
01:11:14,000 --> 01:11:16,000
今天有幾個人

2101
01:11:16,000 --> 01:11:18,000
我比較好奇

2102
01:11:18,000 --> 01:11:20,000
因為我看不到

2103
01:11:20,000 --> 01:11:22,000
今天我這邊看到是有

2104
01:11:22,000 --> 01:11:24,000
最高有到32

2105
01:11:24,000 --> 01:11:26,000
才這麼多

2106
01:11:26,000 --> 01:11:28,000
我發現好多人

2107
01:11:28,000 --> 01:11:30,000
是怎樣間領域的關係

2108
01:11:32,000 --> 01:11:34,000
可是沒有人幫我的facebook按讚

2109
01:11:34,000 --> 01:11:36,000
開玩笑

2110
01:11:36,000 --> 01:11:38,000
必須說我之前

2111
01:11:38,000 --> 01:11:40,000
給過一次我本身是物理專業的

2112
01:11:40,000 --> 01:11:42,000
total五個人

2113
01:11:44,000 --> 01:11:46,000
可能這個東西

2114
01:11:46,000 --> 01:11:48,000
大家比較好奇

2115
01:11:48,000 --> 01:11:50,000
然後不知道怎麼入門吧

2116
01:11:50,000 --> 01:11:52,000
我也不知道

2117
01:11:52,000 --> 01:11:54,000
不過蠻開心有這個機會

2118
01:11:54,000 --> 01:11:56,000
分享一下所學

2119
01:11:56,000 --> 01:11:58,000
不然都在吃社會資源

2120
01:11:58,000 --> 01:12:00,000
總要貢獻一下

2121
01:12:00,000 --> 01:12:02,000
吃社會資源

2122
01:12:02,000 --> 01:12:04,000
對

2123
01:12:04,000 --> 01:12:06,000
你是高虹安嗎

2124
01:12:06,000 --> 01:12:08,000
沒有

2125
01:12:08,000 --> 01:12:10,000
我不是台大的

2126
01:12:10,000 --> 01:12:12,000
沒事

2127
01:12:12,000 --> 01:12:14,000
我全身而退

2128
01:12:14,000 --> 01:12:16,000
OK

2129
01:12:16,000 --> 01:12:18,000
感謝

2130
01:12:18,000 --> 01:12:20,000
突然在外查

2131
01:12:20,000 --> 01:12:22,000
補問一個問題

2132
01:12:22,000 --> 01:12:24,000
比如說你前一張投影片裡面

2133
01:12:26,000 --> 01:12:28,000
這個嗎

2134
01:12:28,000 --> 01:12:30,000
那個舉證的

2135
01:12:30,000 --> 01:12:32,000
這個嗎

2136
01:12:32,000 --> 01:12:34,000
對對對

2137
01:12:34,000 --> 01:12:36,000
舉證對角

2138
01:12:36,000 --> 01:12:38,000
所有這種x1 x1 x2 x2

2139
01:12:38,000 --> 01:12:40,000
你自動忽略是這個意思嗎

2140
01:12:40,000 --> 01:12:42,000
因為他們在這個

2141
01:12:42,000 --> 01:12:44,000
自己跟自己的關係

2142
01:12:44,000 --> 01:12:46,000
就是不討論

2143
01:12:46,000 --> 01:12:48,000
我們就不討論

2144
01:12:48,000 --> 01:12:50,000
因為可能在這個問題定義

2145
01:12:50,000 --> 01:12:52,000
定義裡面就沒有意義的

2146
01:12:52,000 --> 01:12:54,000
感覺

2147
01:12:54,000 --> 01:12:56,000
因為shopping value

2148
01:12:56,000 --> 01:12:58,000
自己跟自己還是自己

2149
01:12:58,000 --> 01:13:00,000
自己跟自己的組合還是自己

2150
01:13:00,000 --> 01:13:02,000
所以我們就不討論

2151
01:13:02,000 --> 01:13:04,000
那搶單兒自己跟自己

2152
01:13:04,000 --> 01:13:06,000
前提是高度相關

2153
01:13:06,000 --> 01:13:08,000
對

2154
01:13:10,000 --> 01:13:12,000
其實我不知道怎麼接觸分享

2155
01:13:12,000 --> 01:13:14,000
呵呵

2156
01:13:16,000 --> 01:13:18,000
那大概我想一下

2157
01:13:18,000 --> 01:13:20,000
那我可能先stop recording

2158
01:13:20,000 --> 01:13:22,000
OK

