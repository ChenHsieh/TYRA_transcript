WEBVTT

00:00.000 --> 00:03.320
謝謝大家今天參與今天Project Teal的演講

00:03.320 --> 00:07.940
我是今天的主持人,我是在魯汶大學念PhD的高賢

00:07.940 --> 00:10.500
今天的講者是靜江

00:10.500 --> 00:16.900
靜江是MIT現在的博士候選人

00:16.900 --> 00:23.560
他在進入MIT之前,他在台大拿到了電機系的一個士學位

00:23.560 --> 00:29.560
那他現在的研究主要是專長在人類的決策

00:29.560 --> 00:35.560
還有人跟我們的社會社群媒體如何的互動

00:35.560 --> 00:40.060
尤其當我們的社群媒體充斥著很多真實的訊息

00:40.060 --> 00:42.060
還有假訊息的情況下

00:42.060 --> 00:47.560
人跟我們的社會媒體社會網絡是怎麼互動的

00:47.560 --> 00:51.560
尤其是我們的人類的行為如何隨著時間

00:51.560 --> 00:55.560
漸漸的演化成一個大型規模的社會現象

00:55.560 --> 00:57.560
這是他所關心的議題

00:57.560 --> 01:01.560
那他也會特別用不同的理論角度

01:01.560 --> 01:05.560
不同的研究方法去關心他剛剛所講的這個研究的興趣

01:05.560 --> 01:08.560
那今天我們邀請他來演講這個題目呢

01:08.560 --> 01:12.560
就是跟Persuasion,跟策略性的新聞的分享

01:12.560 --> 01:16.560
跟社會網絡之間的關心的一個題目

01:16.560 --> 01:18.560
那我就先,我就不多說了

01:18.560 --> 01:21.560
馬上就請我們靜嘉來進行今天的報告

01:21.560 --> 01:24.560
對,那靜嘉,the floor is yours

01:24.560 --> 01:25.560
OK, thank you

01:25.560 --> 01:26.560
謝謝高雄的介紹

01:26.560 --> 01:29.560
大家好,我現在在MIT念書

01:29.560 --> 01:32.560
然後這是我,應該是最後一年了

01:32.560 --> 01:34.560
今天我要介紹的一個是我的project叫

01:34.560 --> 01:39.560
Persuasion, New Sharing and Cascade on Social Networks

01:39.560 --> 01:43.560
然後這是一個join work with my post-doc

01:44.560 --> 01:46.560
還有我的advisor

01:46.560 --> 01:49.560
然後我現在其實在engineering school底下

01:49.560 --> 01:50.560
然後這個問題

01:50.560 --> 01:53.560
但是我其實做的東西是比較偏economics theory

01:53.560 --> 01:56.560
好,那我們開始吧

01:56.560 --> 01:59.560
首先就是現在呢

01:59.560 --> 02:02.560
自從這個社交媒體發明了之後

02:02.560 --> 02:06.560
就其實大家改變了這種消費新聞的行為

02:06.560 --> 02:09.560
像美國人大概五分之一的人就會說

02:09.560 --> 02:12.560
他們其實通常都是從社交媒體上面得到新聞

02:12.560 --> 02:14.560
但是這種社交媒體呢

02:14.560 --> 02:15.560
然後社交媒體呢

02:15.560 --> 02:18.560
它也會增進大家的這種peer-to-peer interaction

02:18.560 --> 02:19.560
就是人際之間的互動

02:19.560 --> 02:23.560
然後其實它也會加速這樣子訊息的流通

02:23.560 --> 02:25.560
但另外我們也發現說

02:25.560 --> 02:26.560
其實在social media上面

02:26.560 --> 02:29.560
其實你是有點像是被動的接收訊息

02:29.560 --> 02:32.560
因為通常都是你的同事

02:32.560 --> 02:35.560
你的朋友決定分享給你新聞

02:35.560 --> 02:38.560
或者是這些演算法去推送給你新聞

02:38.560 --> 02:40.560
其實是他們subjectively

02:40.560 --> 02:44.560
選擇這些新聞在你被動的去接收這樣的新聞

02:44.560 --> 02:45.560
另外還有social media

02:45.560 --> 02:48.560
他們主要還是想要賺錢嘛

02:48.560 --> 02:51.560
那其實他們在

02:51.560 --> 02:54.560
在分配這些廣告或什麼之類的時候

02:54.560 --> 02:56.560
其實無形中他們也可能是

02:56.560 --> 02:58.560
加速了misinformation的

02:58.560 --> 03:02.560
就amplify misinformation on the platform

03:02.560 --> 03:06.560
然後今天我要study的問題就是說

03:06.560 --> 03:08.560
就是大家分享新聞的動機是什麼

03:08.560 --> 03:10.560
就是說這個其實是大家

03:10.560 --> 03:12.560
現在學界還蠻關心的問題

03:12.560 --> 03:14.560
就是說到底大家分享新聞

03:14.560 --> 03:17.560
是為了要去告訴別人一些事情呢

03:17.560 --> 03:18.560
還是表達自己的觀點

03:18.560 --> 03:22.560
或者是說他其實是想要找同溫層

03:22.560 --> 03:23.560
或者是想要去

03:23.560 --> 03:26.560
就persuade別人

03:26.560 --> 03:27.560
那另外就是說

03:27.560 --> 03:29.560
在這樣的動機之下

03:29.560 --> 03:30.560
那什麼樣的新聞

03:30.560 --> 03:34.560
其實會在社交媒體上面傳得比較遠

03:34.560 --> 03:38.560
就包含說像可信度的這個影響呢

03:38.560 --> 03:41.560
還有以及他怎麼樣去

03:41.560 --> 03:43.560
以及這樣子

03:43.560 --> 03:45.560
應該說他

03:45.560 --> 03:48.560
跟社會的一些

03:48.560 --> 03:49.560
characteristic

03:49.560 --> 03:51.560
就是他的一些特性有沒有什麼關係

03:51.560 --> 03:54.560
然後像這個領域他現在就像

03:54.560 --> 03:57.560
我切入的角度會是economics的角度

03:57.560 --> 03:58.560
然後有一些psychologist

03:58.560 --> 04:00.560
他可能就會去study就是說

04:00.560 --> 04:02.560
他們有沒有一些behavioral bias

04:02.560 --> 04:04.560
那political science他們就比較focus

04:04.560 --> 04:05.560
在misinformation

04:05.560 --> 04:08.560
在政治上面的影響

04:08.560 --> 04:11.560
以及他們兩黨不同的新聞

04:11.560 --> 04:13.560
他們可能會比較願意去傳

04:13.560 --> 04:16.560
是不是自己跟自己黨相關的新聞呢

04:16.560 --> 04:17.560
或者是

04:17.560 --> 04:19.560
然後他們會怎麼樣去看待

04:19.560 --> 04:21.560
跟自己是同黨的新聞

04:21.560 --> 04:22.560
他是可信度比較高呢

04:22.560 --> 04:23.560
或可能比較少

04:23.560 --> 04:24.560
然後其實像這樣子的領域

04:24.560 --> 04:27.560
他們都還是還蠻仰賴CS的幫忙

04:27.560 --> 04:30.560
就是他們還是會做一些computational的事情

04:30.560 --> 04:33.560
那今天我的這個問題呢

04:33.560 --> 04:35.560
就是接下來的model

04:35.560 --> 04:36.560
都會based on一個question

04:36.560 --> 04:39.560
就是說如果大家在分享的新聞

04:39.560 --> 04:40.560
上面的動機

04:40.560 --> 04:43.560
其實是想要去讓你的follower

04:43.560 --> 04:44.560
跟你想的比較接近

04:44.560 --> 04:46.560
那麼會發生什麼事

04:46.560 --> 04:47.560
所以其實這個model

04:47.560 --> 04:49.560
算是一個what if的question

04:49.560 --> 04:51.560
就是說如果這是大家的動機

04:51.560 --> 04:52.560
大家想要去讓別人

04:52.560 --> 04:54.560
跟你想的比較類似的話

04:54.560 --> 04:56.560
那麼

04:56.560 --> 04:58.560
什麼樣的新聞你會去傳

04:58.560 --> 05:00.560
然後以及什麼樣的新聞

05:00.560 --> 05:02.560
可能在什麼樣的社會

05:02.560 --> 05:05.560
會傳得比較遠

05:05.560 --> 05:08.560
OK

05:08.560 --> 05:09.560
好

05:09.560 --> 05:11.560
那就我剛才講的

05:11.560 --> 05:13.560
就是我是用economics的角度

05:13.560 --> 05:14.560
切入這個問題

05:14.560 --> 05:16.560
所以接下來我會用

05:16.560 --> 05:20.560
就是所謂的賽局理論來講這個model

05:20.560 --> 05:21.560
然後另外就是我們這篇work

05:21.560 --> 05:23.560
已經submit到

05:23.560 --> 05:25.560
就是Journal of Economics Theory

05:25.560 --> 05:28.560
然後這邊有一個SSR的link

05:28.560 --> 05:30.560
如果大家感興趣那個Journal version

05:30.560 --> 05:34.560
想要看的話就歡迎掃碼一下

05:34.560 --> 05:36.560
首先我跟大家講一下這個model

05:36.560 --> 05:39.560
一些比較大的assumption

05:39.560 --> 05:40.560
當然我們會考慮一個society

05:40.560 --> 05:44.560
就是每一個人的這種觀念不一樣

05:44.560 --> 05:46.560
就大家不是同心協力

05:46.560 --> 05:49.560
都覺得就是偏左或偏右

05:49.560 --> 05:52.560
大家就是可以是有不同的觀點

05:52.560 --> 05:54.560
然後

05:54.560 --> 05:56.560
一個人他會希望說我的

05:56.560 --> 05:59.560
同儕跟我的這個想法比較類似

05:59.560 --> 06:02.560
然後另外是

06:02.560 --> 06:04.560
我們在這裡會用的persuasion這個詞

06:04.560 --> 06:06.560
代表的是說

06:06.560 --> 06:10.560
你給別人一個objective的information

06:10.560 --> 06:11.560
就是一個新的information

06:11.560 --> 06:14.560
去影響他的belief

06:14.560 --> 06:16.560
所以當我在講persuasion的話

06:16.560 --> 06:18.560
我的意思是這個意思

06:18.560 --> 06:21.560
另外在分享的時候

06:21.560 --> 06:23.560
會有一些成本出現

06:23.560 --> 06:26.560
就是說你可以把它想成是

06:26.560 --> 06:27.560
我平常一直在滑手機

06:27.560 --> 06:28.560
滑到一半的時候

06:28.560 --> 06:30.560
我突然覺得我得

06:30.560 --> 06:31.560
突然想要傳這個新聞

06:31.560 --> 06:33.560
你可以思考了一下

06:33.560 --> 06:34.560
你原本是一直在滑手機

06:34.560 --> 06:35.560
然後你突然得停下來

06:35.560 --> 06:38.560
就model它是有一個小小的成本在裡頭

06:38.560 --> 06:40.560
因為有這個小小的成本在

06:40.560 --> 06:41.560
所以其實是有一個

06:41.560 --> 06:44.560
在經濟上我們叫它

06:44.560 --> 06:46.560
策略性替代的行為

06:46.560 --> 06:47.560
strategic substitute

06:47.560 --> 06:48.560
就是說

06:48.560 --> 06:50.560
當別人會做這件事情的時候

06:50.560 --> 06:51.560
你就不想去做這件事情

06:51.560 --> 06:52.560
因為你覺得別人會幫你做

06:52.560 --> 06:54.560
所以這邊你為了要省那個成本

06:54.560 --> 06:55.560
你可能會覺得

06:55.560 --> 06:57.560
如果別人已經都傳了這個新聞的話

06:57.560 --> 06:59.560
那我就沒有傳的必要

06:59.560 --> 07:02.560
另外是最後會apply這個model

07:02.560 --> 07:03.560
到一個society

07:03.560 --> 07:05.560
就是有分化的情形

07:05.560 --> 07:06.560
兩黨分化的情形

07:06.560 --> 07:07.560
然後去看說

07:07.560 --> 07:10.560
在兩黨分化的這個社會底下

07:10.560 --> 07:13.560
什麼狀況會導致

07:13.560 --> 07:15.560
比較不準確的新聞

07:15.560 --> 07:21.560
會傳的比準確的新聞還要遠

07:21.560 --> 07:23.560
不好意思我可以問個問題嗎

07:23.560 --> 07:24.560
我可以打斷嗎

07:24.560 --> 07:25.560
沒事沒事

07:25.560 --> 07:27.560
我們應該還蠻確定的

07:27.560 --> 07:29.560
我想要問一下就是

07:29.560 --> 07:31.560
二跟三之間的

07:31.560 --> 07:32.560
算是關係吧

07:32.560 --> 07:34.560
因為如果說

07:34.560 --> 07:36.560
我在social media上面分享東西

07:36.560 --> 07:37.560
我希望

07:37.560 --> 07:39.560
就是我希望我在我的同溫層裡面

07:39.560 --> 07:42.560
那

07:42.560 --> 07:43.560
這時候我們講的persuasion

07:43.560 --> 07:45.560
好像跟平常是我們想像的persuasion

07:45.560 --> 07:46.560
很不一樣

07:46.560 --> 07:47.560
譬如說如果

07:47.560 --> 07:48.560
上面都是我的同溫層

07:48.560 --> 07:50.560
那我PO一個東西

07:50.560 --> 07:51.560
我的理解會是

07:51.560 --> 07:53.560
或者是我會希望他們就接受了

07:53.560 --> 07:56.560
就是沒有很多的persuasion

07:56.560 --> 07:58.560
那通常我們想像的persuasion是

07:58.560 --> 08:00.560
那些人可能原本是中立的

08:00.560 --> 08:02.560
或甚至跟我是不一樣的

08:02.560 --> 08:03.560
就是觀點

08:03.560 --> 08:04.560
不一樣的立場這樣

08:04.560 --> 08:06.560
然後我經過

08:06.560 --> 08:07.560
分享一些新的資訊

08:07.560 --> 08:08.560
來說服他們

08:08.560 --> 08:10.560
譬如說加入我的陣營這樣

08:10.560 --> 08:11.560
對那所以

08:11.560 --> 08:13.560
如果說

08:13.560 --> 08:15.560
你的model原本就是預設說

08:15.560 --> 08:16.560
大家都會希望

08:16.560 --> 08:17.560
待在自己的同溫層裡面

08:17.560 --> 08:19.560
那他persuasion的力道

08:19.560 --> 08:20.560
是不是就會比較

08:20.560 --> 08:22.560
相對會比較弱一點

08:22.560 --> 08:23.560
喔不好意思

08:23.560 --> 08:24.560
我可能剛才沒有解釋好

08:24.560 --> 08:25.560
這個第二點

08:25.560 --> 08:26.560
第二點他不是只是說

08:26.560 --> 08:27.560
你想在同溫層裡面

08:27.560 --> 08:28.560
是說

08:28.560 --> 08:30.560
我的動機是希望別人

08:30.560 --> 08:32.560
跟我的想法類似

08:32.560 --> 08:33.560
那個preference

08:33.560 --> 08:34.560
這個意思

08:34.560 --> 08:35.560
就是說你希望別人的想法

08:35.560 --> 08:36.560
跟你的

08:36.560 --> 08:37.560
別人做的事情

08:37.560 --> 08:39.560
跟你的想法是類似的

08:39.560 --> 08:41.560
他有那個persuasion的動機

08:41.560 --> 08:43.560
所以其實我是在解釋

08:43.560 --> 08:44.560
對

08:44.560 --> 08:45.560
OK

08:45.560 --> 08:46.560
謝謝

08:46.560 --> 08:47.560
可能是我剛剛沒聽清楚

08:47.560 --> 08:48.560
不好意思

08:48.560 --> 08:49.560
好

08:49.560 --> 08:50.560
這個這裡的

08:50.560 --> 08:52.560
persuasion的communication mechanism

08:52.560 --> 08:53.560
有在乎是一對一

08:53.560 --> 08:55.560
或是一對多的嗎

08:55.560 --> 08:56.560
喔那是個good question

08:56.560 --> 08:57.560
就是說

08:57.560 --> 08:59.560
這邊的persuasion是

08:59.560 --> 09:01.560
因為我們這個model

09:01.560 --> 09:02.560
比較像是在考慮

09:02.560 --> 09:03.560
twitter這種東西

09:03.560 --> 09:04.560
所以你就想說

09:04.560 --> 09:05.560
我一

09:05.560 --> 09:06.560
分享這個新聞之後

09:06.560 --> 09:07.560
就是等於是

09:07.560 --> 09:09.560
你所有的朋友都會看到

09:09.560 --> 09:11.560
對就是一個比較

09:11.560 --> 09:12.560
簡單的something

09:12.560 --> 09:13.560
就是說就是broadcast

09:13.560 --> 09:15.560
就是我一分享了

09:15.560 --> 09:16.560
那我就可以

09:16.560 --> 09:17.560
而且我知道

09:17.560 --> 09:19.560
我知道我所有的朋友都會看到

09:19.560 --> 09:20.560
就是比較

09:20.560 --> 09:22.560
所以才會有strategic substitute

09:22.560 --> 09:24.560
因為別人可以broadcast

09:24.560 --> 09:26.560
對對對

09:26.560 --> 09:27.560
了解

09:27.560 --> 09:28.560
是的是的

09:28.560 --> 09:29.560
yeah

09:29.560 --> 09:30.560
that's a good question

09:30.560 --> 09:31.560
對

09:31.560 --> 09:33.560
就是你沒有說你特別去選

09:33.560 --> 09:34.560
我要傳給誰

09:34.560 --> 09:35.560
就是我一

09:35.560 --> 09:36.560
我傳就只有決定說

09:36.560 --> 09:37.560
我要傳

09:37.560 --> 09:38.560
然後我知道我所有的follow

09:38.560 --> 09:39.560
我都會看到

09:39.560 --> 09:40.560
這樣

09:40.560 --> 09:42.560
OK

09:42.560 --> 09:43.560
嗯

09:43.560 --> 09:45.560
然後這邊是給大家一個

09:45.560 --> 09:46.560
就是broad picture

09:46.560 --> 09:47.560
about

09:47.560 --> 09:48.560
我們的這個主要的結果

09:48.560 --> 09:49.560
第一個就是說

09:49.560 --> 09:50.560
我們當然是刻劃這個

09:50.560 --> 09:51.560
equilibrium

09:51.560 --> 09:52.560
到底長什麼樣子

09:52.560 --> 09:53.560
嗯

09:53.560 --> 09:55.560
然後包含像我們identify

09:55.560 --> 09:56.560
呃

09:56.560 --> 09:58.560
大家在分享新聞的這些

09:58.560 --> 09:59.560
就是說你是based on

09:59.560 --> 10:00.560
這個persuasion的模式

10:00.560 --> 10:01.560
但其實

10:01.560 --> 10:03.560
在進一步把它decompose

10:03.560 --> 10:04.560
就是把它分析出來

10:04.560 --> 10:05.560
終於會發現說

10:05.560 --> 10:06.560
其實更極端的人

10:06.560 --> 10:07.560
他當然會想要

10:07.560 --> 10:09.560
更有那一種

10:09.560 --> 10:10.560
呃

10:10.560 --> 10:11.560
動力去分享

10:11.560 --> 10:13.560
而且當然是分享那些

10:13.560 --> 10:14.560
呃

10:14.560 --> 10:16.560
跟我想法是align

10:16.560 --> 10:17.560
就是說哦

10:17.560 --> 10:18.560
如果是偏右的極端的人

10:18.560 --> 10:19.560
那當然我會去

10:19.560 --> 10:21.560
想要去分享偏右的

10:21.560 --> 10:22.560
我不會去

10:22.560 --> 10:23.560
分享偏左的

10:23.560 --> 10:24.560
另外是

10:24.560 --> 10:25.560
呃

10:25.560 --> 10:26.560
persuasiveness of news

10:26.560 --> 10:28.560
就是說這個新聞

10:28.560 --> 10:29.560
我一旦傳了出去之後

10:29.560 --> 10:30.560
我可以改變

10:30.560 --> 10:32.560
多少人的

10:32.560 --> 10:33.560
belief

10:33.560 --> 10:34.560
就是說

10:34.560 --> 10:35.560
到底他成效如何

10:35.560 --> 10:36.560
假如我一直傳出去

10:36.560 --> 10:37.560
哎

10:37.560 --> 10:38.560
其實也沒有人會相信

10:38.560 --> 10:39.560
這個東西

10:39.560 --> 10:40.560
沒有人在改變他的想法的話

10:40.560 --> 10:41.560
那我幹嘛傳

10:41.560 --> 10:42.560
呃

10:42.560 --> 10:43.560
最後一個東西

10:43.560 --> 10:44.560
我幫你講

10:44.560 --> 10:45.560
就是說

10:45.560 --> 10:46.560
你在傳的時候

10:46.560 --> 10:48.560
你會去評估說

10:48.560 --> 10:49.560
哎

10:49.560 --> 10:50.560
到底

10:50.560 --> 10:51.560
嗯

10:51.560 --> 10:52.560
在均衡狀況底下

10:52.560 --> 10:53.560
到底有多少人在傳這個東西

10:53.560 --> 10:54.560
然後你會覺得說

10:54.560 --> 10:55.560
哦

10:55.560 --> 10:56.560
其實我的follower

10:56.560 --> 10:58.560
說不定很大的機率

10:58.560 --> 10:59.560
已經會聽到這個新聞

10:59.560 --> 11:00.560
我就不需要傳了

11:00.560 --> 11:01.560
對

11:01.560 --> 11:02.560
所以這是

11:02.560 --> 11:04.560
這主要的三個component

11:04.560 --> 11:05.560
呃

11:05.560 --> 11:06.560
可以再clarify

11:06.560 --> 11:07.560
均衡的概念嗎

11:07.560 --> 11:08.560
哦

11:08.560 --> 11:09.560
均衡就是說

11:09.560 --> 11:10.560
均衡

11:10.560 --> 11:11.560
哦

11:11.560 --> 11:12.560
對

11:12.560 --> 11:13.560
均衡這個概念就是說

11:13.560 --> 11:14.560
呃

11:14.560 --> 11:16.560
在這個model底下

11:16.560 --> 11:17.560
大家

11:17.560 --> 11:20.560
你去預測別人的行為在做什麼

11:20.560 --> 11:21.560
然後

11:21.560 --> 11:23.560
你預測那個行為之下

11:23.560 --> 11:24.560
你

11:24.560 --> 11:27.560
你會做一個選擇去

11:27.560 --> 11:28.560
在那個

11:28.560 --> 11:30.560
當你在預測別人的行為之下

11:30.560 --> 11:31.560
你會

11:31.560 --> 11:33.560
然後optimize你自己的行為嗎

11:33.560 --> 11:34.560
就是說

11:34.560 --> 11:36.560
我如果預期到大家都去超市

11:36.560 --> 11:37.560
把東西買光的話

11:37.560 --> 11:39.560
那我也會去超市

11:39.560 --> 11:40.560
買光這樣

11:40.560 --> 11:41.560
但是

11:41.560 --> 11:42.560
呃

11:42.560 --> 11:43.560
也跟著去超市買東西之類的

11:43.560 --> 11:44.560
所以

11:44.560 --> 11:45.560
均衡的話就是說

11:45.560 --> 11:47.560
在你預測別人的行為之下

11:47.560 --> 11:50.560
你就會做這樣子對你最好的行為

11:50.560 --> 11:51.560
但是你也同時知道說

11:51.560 --> 11:52.560
哦

11:52.560 --> 11:53.560
你做了這個最好的行為之後

11:53.560 --> 11:55.560
別人也在同時

11:55.560 --> 11:57.560
在設想你會做什麼樣的行為

11:57.560 --> 11:59.560
於是在這種交互的行為之下

11:59.560 --> 12:00.560
他達到一個均衡

12:00.560 --> 12:01.560
就是說

12:01.560 --> 12:02.560
呃

12:02.560 --> 12:03.560
這個情況下

12:03.560 --> 12:05.560
沒有人會改變他的行為

12:05.560 --> 12:06.560
所以

12:06.560 --> 12:07.560
你知道漸漸的就是

12:07.560 --> 12:09.560
達到一個平衡

12:09.560 --> 12:10.560
也不是說漸漸的達到平衡

12:10.560 --> 12:11.560
就是他在平衡狀態下

12:11.560 --> 12:12.560
就是

12:12.560 --> 12:13.560
你做這個行為

12:13.560 --> 12:14.560
我現在做這個行為

12:14.560 --> 12:15.560
就是對你最好的

12:15.560 --> 12:16.560
呃

12:16.560 --> 12:17.560
response

12:17.560 --> 12:18.560
然後同時是

12:18.560 --> 12:19.560
所以我不會去改變我的行為

12:19.560 --> 12:21.560
然後你也不會再去改變你的行為

12:21.560 --> 12:23.560
所以就達到一個均衡

12:23.560 --> 12:27.560
所以這個game theory下面的一個assumption

12:27.560 --> 12:28.560
不是assumption就是說

12:28.560 --> 12:29.560
呃

12:29.560 --> 12:30.560
不能講assumption

12:30.560 --> 12:31.560
就是說equilibrium

12:31.560 --> 12:32.560
就是說game

12:32.560 --> 12:33.560
就是說

12:33.560 --> 12:34.560
game就

12:34.560 --> 12:35.560
對在economy裡頭

12:35.560 --> 12:36.560
game

12:36.560 --> 12:38.560
其實就像你在玩

12:38.560 --> 12:40.560
撲克牌遊戲一樣

12:40.560 --> 12:41.560
我會覺得

12:41.560 --> 12:43.560
喔別人在玩什麼招數

12:43.560 --> 12:45.560
然後我要想辦法去抵抗他

12:45.560 --> 12:46.560
我會做

12:46.560 --> 12:47.560
假設他做了這件事情

12:47.560 --> 12:48.560
那我就是

12:48.560 --> 12:50.560
挑我最好的那個

12:50.560 --> 12:51.560
呃

12:51.560 --> 12:52.560
牌組之類的

12:52.560 --> 12:53.560
但是你也同時在想說

12:53.560 --> 12:55.560
喔別人也知道

12:55.560 --> 12:57.560
別人也在猜你的行為是什麼

12:57.560 --> 12:58.560
然後變成是說均衡底下

12:58.560 --> 12:59.560
你可能會覺得

12:59.560 --> 13:00.560
喔我應該怎麼樣出手

13:00.560 --> 13:01.560
然後大家都不會

13:01.560 --> 13:02.560
呃

13:02.560 --> 13:04.560
有任何動機去改變他的行為

13:04.560 --> 13:05.560
就他達到了一個

13:05.560 --> 13:07.560
互相抵抗的一個

13:07.560 --> 13:08.560
呃

13:08.560 --> 13:09.560
呃

13:09.560 --> 13:10.560
平衡

13:10.560 --> 13:11.560
所以那個時候

13:11.560 --> 13:13.560
那個狀態我們就都要加均衡

13:13.560 --> 13:14.560
了解

13:14.560 --> 13:15.560
那我想問一下

13:15.560 --> 13:16.560
就是說

13:16.560 --> 13:17.560
比如說prison dilemma

13:17.560 --> 13:19.560
這樣算是會有均衡的state嗎

13:19.560 --> 13:20.560
那個就是均衡

13:20.560 --> 13:21.560
prison dilemma就是均衡

13:21.560 --> 13:22.560
那個就是均衡

13:22.560 --> 13:23.560
那個就是因為

13:23.560 --> 13:25.560
我知道說如果我不講了

13:25.560 --> 13:26.560
我不講

13:26.560 --> 13:27.560
但是對方可能

13:27.560 --> 13:28.560
就是說

13:28.560 --> 13:30.560
我知道對方講或不講

13:30.560 --> 13:31.560
我

13:31.560 --> 13:33.560
講了都對我比較好

13:33.560 --> 13:34.560
所以我就會選擇去講

13:34.560 --> 13:36.560
然後對方也知道說啊那個

13:36.560 --> 13:37.560
不管講或不講

13:37.560 --> 13:38.560
他還是講比較

13:38.560 --> 13:39.560
就就變兩個人都講

13:39.560 --> 13:41.560
然後兩個人都被懲罰

13:41.560 --> 13:42.560
這個意思

13:42.560 --> 13:43.560
了解謝謝

13:43.560 --> 13:44.560
好

13:44.560 --> 13:45.560
呃

13:45.560 --> 13:46.560
不好意思我想要

13:46.560 --> 13:48.560
就是再問一下均衡的這個問題

13:48.560 --> 13:49.560
嗯那

13:49.560 --> 13:50.560
呃

13:50.560 --> 13:52.560
就是考慮均衡的時候

13:52.560 --> 13:54.560
會討論個體差異嗎

13:54.560 --> 13:56.560
因為每一個人

13:56.560 --> 13:57.560
呃

13:57.560 --> 13:58.560
之前會長得不太一樣

13:58.560 --> 13:59.560
呃

13:59.560 --> 14:01.560
他們有很呃

14:01.560 --> 14:02.560
一看裡面

14:02.560 --> 14:04.560
他們會把這個叫做type

14:04.560 --> 14:05.560
就是你是什麼樣的類型

14:05.560 --> 14:06.560
然後另外是說

14:06.560 --> 14:08.560
他一定可以考慮個體差異的

14:08.560 --> 14:09.560
只是說

14:09.560 --> 14:10.560
一看裡面

14:10.560 --> 14:12.560
常常會問的一個問題是說

14:12.560 --> 14:14.560
你到底知不知道這個個體差異

14:14.560 --> 14:15.560
就是說

14:15.560 --> 14:17.560
假設我今天到底知不知道你

14:17.560 --> 14:18.560
我如果已經知道

14:18.560 --> 14:19.560
這樣我們就知道

14:19.560 --> 14:20.560
川普他就是支持

14:20.560 --> 14:21.560
共和黨

14:21.560 --> 14:22.560
但是你現在走在路上

14:22.560 --> 14:23.560
你看到某一個人

14:23.560 --> 14:25.560
你也不知道他到底是支持共和黨

14:25.560 --> 14:26.560
或者是

14:26.560 --> 14:27.560
民主黨對吧

14:27.560 --> 14:28.560
就等於是說

14:28.560 --> 14:30.560
他們會用這種方式

14:30.560 --> 14:32.560
呃

14:32.560 --> 14:33.560
嗯

14:33.560 --> 14:34.560
他們是會考慮個體差異

14:34.560 --> 14:36.560
然後他們會去看哦

14:36.560 --> 14:37.560
我不知道你是

14:37.560 --> 14:38.560
主要是我不知道

14:38.560 --> 14:40.560
你到底是什麼樣子類型的人

14:40.560 --> 14:42.560
或者是我知道你是什麼樣類型的人

14:42.560 --> 14:44.560
會導致有不一樣的strategy

14:44.560 --> 14:45.560
對他的

14:45.560 --> 14:46.560
他會對對

14:46.560 --> 14:48.560
然後像我們這個model裡面

14:48.560 --> 14:49.560
我們會假設

14:49.560 --> 14:51.560
大家都不知道別人在想什麼

14:51.560 --> 14:52.560
但是

14:52.560 --> 14:54.560
我知道

14:54.560 --> 14:55.560
我們會make assumption就是說

14:55.560 --> 14:56.560
哦我知道

14:56.560 --> 14:58.560
整體社會大致上在想什麼

14:58.560 --> 14:59.560
但是我不知道

14:59.560 --> 15:01.560
specifically like

15:01.560 --> 15:02.560
高賢他在想什麼

15:02.560 --> 15:03.560
我不知道

15:03.560 --> 15:04.560
但是我知道

15:04.560 --> 15:05.560
哦我們可能這一群人

15:05.560 --> 15:07.560
普遍都是支持

15:07.560 --> 15:08.560
呀

15:08.560 --> 15:09.560
臺灣怎麼樣

15:09.560 --> 15:10.560
或者是ok

15:10.560 --> 15:11.560
你懂我意思

15:11.560 --> 15:12.560
對

15:12.560 --> 15:13.560
可是這個這個assumption

15:13.560 --> 15:15.560
好像跟我們平常是在

15:15.560 --> 15:18.560
社交網站上面的

15:18.560 --> 15:21.560
互動有一點點不太一樣

15:21.560 --> 15:23.560
就是我我通常就是譬如說

15:23.560 --> 15:25.560
不管在推特上或者在

15:25.560 --> 15:26.560
呃facebook上

15:26.560 --> 15:28.560
我通常會大概知道我的follower

15:28.560 --> 15:29.560
大概知道了

15:29.560 --> 15:31.560
但不是百分百知道

15:31.560 --> 15:33.560
但我大概可以猜測出來他們在

15:33.560 --> 15:34.560
想什麼

15:34.560 --> 15:35.560
那對

15:35.560 --> 15:36.560
哦

15:36.560 --> 15:37.560
不好意思你先說

15:37.560 --> 15:38.560
不好意思

15:38.560 --> 15:38.560


15:38.560 --> 15:40.560
所以我們在這邊其實沒有

15:40.560 --> 15:41.560
呃到時候你看到那個商品

15:41.560 --> 15:43.560
就是說我大概只是知道說

15:43.560 --> 15:44.560
我的那個distribution是什麼

15:44.560 --> 15:46.560
但我不知道確切

15:46.560 --> 15:47.560
這樣

15:47.560 --> 15:48.560
ok

15:48.560 --> 15:49.560
對ok

15:49.560 --> 15:51.560
我會問這個那個

15:51.560 --> 15:53.560
不好意思你先說

15:53.560 --> 15:54.560
沒有你講講講

15:54.560 --> 15:55.560
我有聽過

15:55.560 --> 15:58.560
我會問這個那個equilibrium的問題

15:58.560 --> 15:59.560
其實是因為

15:59.560 --> 16:01.560
第一個是就算是假設

16:01.560 --> 16:02.560
所有人都是rational的

16:02.560 --> 16:04.560
他們的optimization可能會不太一樣

16:04.560 --> 16:05.560
就是每個人要的東西

16:05.560 --> 16:06.560
感覺會有點不太一樣

16:06.560 --> 16:08.560
那這個感覺你剛剛的

16:08.560 --> 16:10.560
呃回答有

16:10.560 --> 16:12.560
就是有cover到這一部分

16:12.560 --> 16:14.560
那可是因為你還有另一個

16:14.560 --> 16:15.560
假設是

16:15.560 --> 16:17.560
就是在你這個study裡面

16:17.560 --> 16:18.560
是人是rational的嗎

16:18.560 --> 16:20.560
那如果你把人不是rational的

16:20.560 --> 16:21.560
考慮進來

16:21.560 --> 16:22.560
等於就又多了一個dimension

16:22.560 --> 16:24.560
所以有些人他如果不是

16:24.560 --> 16:25.560
呃不是rational的

16:25.560 --> 16:27.560
那他的equilibrium又會長得

16:27.560 --> 16:29.560
跟rational那些人不太一樣

16:29.560 --> 16:31.560
所以好像就會變得非常複雜

16:31.560 --> 16:32.560
呃對

16:32.560 --> 16:35.560
但是目前就是先考

16:35.560 --> 16:37.560
因為我們try to就

16:37.560 --> 16:38.560
其實有點mess

16:38.560 --> 16:39.560
我們的主要的message

16:39.560 --> 16:40.560
就跟大家講是說

16:40.560 --> 16:41.560
哦

16:41.560 --> 16:42.560
因為其實你說那rational的話

16:42.560 --> 16:44.560
那其實很多事情都很好解釋

16:44.560 --> 16:45.560
因為那rational就直接

16:45.560 --> 16:46.560
那rational就說

16:46.560 --> 16:48.560
啊他就想這樣做

16:48.560 --> 16:49.560
但是然後等於是說

16:49.560 --> 16:50.560
我們的model會變成是說

16:50.560 --> 16:51.560
哦

16:51.560 --> 16:52.560
even

16:52.560 --> 16:53.560
你覺得大家都是rational的

16:53.560 --> 16:55.560
狀況底下

16:55.560 --> 16:56.560
這種比較不準確的新聞

16:56.560 --> 16:57.560
他還是願意傳

16:57.560 --> 16:58.560
然後會發生什麼事情

16:58.560 --> 16:59.560
所以就變了

16:59.560 --> 17:01.560
這是主要這種rational model

17:01.560 --> 17:02.560
在try to

17:02.560 --> 17:03.560
不然因為

17:03.560 --> 17:04.560
如果你說

17:04.560 --> 17:05.560
大家都是irrational的話

17:05.560 --> 17:06.560
就會變成說

17:06.560 --> 17:08.560
哦其實

17:08.560 --> 17:10.560
那就直接把它歸類為irrational

17:10.560 --> 17:11.560
然後但是

17:11.560 --> 17:12.560
其實ecom他們有時候

17:12.560 --> 17:13.560
也會考慮bounded rational

17:13.560 --> 17:14.560
就是說他有

17:14.560 --> 17:15.560
有一些部分他是rational

17:15.560 --> 17:16.560
有一些部分irrational

17:16.560 --> 17:18.560
或者是像這種

17:18.560 --> 17:19.560
另外還有一種model

17:19.560 --> 17:20.560
就是像你剛才講

17:20.560 --> 17:21.560
就一部

17:21.560 --> 17:22.560
有可能大部分的人是rational

17:22.560 --> 17:23.560
但有少部分人irrational

17:23.560 --> 17:24.560
那又會發生什麼事

17:24.560 --> 17:25.560
但我們這個model

17:25.560 --> 17:26.560
就是考慮

17:26.560 --> 17:27.560
就是

17:27.560 --> 17:28.560
大家都是rational

17:28.560 --> 17:29.560
比較簡單一點

17:29.560 --> 17:30.560
了解了解

17:30.560 --> 17:31.560
我先講一下

17:31.560 --> 17:32.560
反正我們這邊人也不多

17:32.560 --> 17:33.560
我們大概

17:33.560 --> 17:34.560
等一下可能就會是這個

17:34.560 --> 17:35.560
非常互動的討論形式

17:35.560 --> 17:36.560
因為我自己是psychologist

17:36.560 --> 17:38.560
所以我是做experimental

17:38.560 --> 17:39.560
我是experimental psychologist

17:39.560 --> 17:40.560
所以

17:40.560 --> 17:42.560
experimental psychologist的

17:42.560 --> 17:43.560
那個

17:43.560 --> 17:44.560
出發點

17:44.560 --> 17:45.560
就會比較像是

17:45.560 --> 17:46.560
人by default

17:46.560 --> 17:47.560
就是irrational

17:47.560 --> 17:48.560
但我們當然不會說

17:48.560 --> 17:49.560
啊他就irrational

17:49.560 --> 17:50.560
所以我們就不用研究他的行為

17:50.560 --> 17:51.560
反正他就irrational

17:51.560 --> 17:52.560
但我們會去嘗試解釋

17:52.560 --> 17:54.560
他irrational背後的原因是什麼

17:54.560 --> 17:55.560
譬如說他可能會受到

17:55.560 --> 17:56.560
什麼東西

17:56.560 --> 17:57.560
呃

17:57.560 --> 17:58.560
影響啊

17:58.560 --> 17:59.560
或者他會

17:59.560 --> 18:00.560
在什麼情況

18:00.560 --> 18:01.560
他會用heuristics

18:01.560 --> 18:02.560
什麼情況他會

18:02.560 --> 18:03.560
就是reason

18:03.560 --> 18:04.560
你去做一個決定

18:04.560 --> 18:05.560
等等這樣

18:05.560 --> 18:06.560
對但是就是

18:06.560 --> 18:07.560
我先把我的那個

18:07.560 --> 18:08.560
stance講出來

18:08.560 --> 18:09.560
OKOKOK

18:09.560 --> 18:11.560
為什麼我會問這個問題

18:11.560 --> 18:12.560
好好好

18:12.560 --> 18:13.560
我知道我知道你的意思

18:13.560 --> 18:14.560
好

18:14.560 --> 18:15.560
等於是說

18:15.560 --> 18:16.560
主要是在這裡

18:16.560 --> 18:17.560
就沒有什麼behavioral bias

18:17.560 --> 18:19.560
就純粹大家就是

18:19.560 --> 18:20.560
你可以把大家

18:20.560 --> 18:21.560
就想像他就是

18:21.560 --> 18:22.560
很精密的儀器

18:22.560 --> 18:23.560
他可以去算很多東西

18:23.560 --> 18:24.560
然後

18:24.560 --> 18:25.560
even在這樣的情況下

18:25.560 --> 18:27.560
大家可能還是想要穿

18:27.560 --> 18:28.560
不準確的行為

18:28.560 --> 18:29.560
這樣

18:29.560 --> 18:30.560
OKOK

18:30.560 --> 18:31.560
OK

18:31.560 --> 18:32.560
好

18:32.560 --> 18:33.560
嗯

18:33.560 --> 18:34.560
好另外還有一個

18:34.560 --> 18:35.560
就是主要

18:35.560 --> 18:36.560
其實這是更主要的結果

18:36.560 --> 18:37.560
就是說

18:37.560 --> 18:38.560
在這種底下

18:38.560 --> 18:39.560
呃

18:39.560 --> 18:40.560
我們去探討說這種

18:40.560 --> 18:42.560
傳播的這個尺度

18:42.560 --> 18:43.560
以及新聞可信度

18:43.560 --> 18:44.560
以及

18:44.560 --> 18:45.560
就是這種

18:45.560 --> 18:46.560
呃

18:46.560 --> 18:48.560
這個社會的一些特性的關聯

18:48.560 --> 18:50.560
然後我們就會發現說

18:50.560 --> 18:51.560
哦其實

18:51.560 --> 18:52.560
就是比較

18:52.560 --> 18:53.560
呃

18:53.560 --> 18:54.560
沒有那麼可信的新聞

18:54.560 --> 18:55.560
其實就有點不準確的新聞呢

18:55.560 --> 18:56.560
他反而可以

18:56.560 --> 18:57.560
傳的更遠

18:57.560 --> 18:58.560
如果說

18:58.560 --> 18:59.560
這一個

18:59.560 --> 19:01.560
network的

19:01.560 --> 19:03.560
連結是非常緊密

19:03.560 --> 19:04.560
就是說

19:04.560 --> 19:05.560
每個人都好多個follow的話

19:05.560 --> 19:06.560
那其實這可能會

19:06.560 --> 19:07.560
促進那一些

19:07.560 --> 19:09.560
比較不準確的新聞

19:09.560 --> 19:10.560
去傳播的更遠

19:10.560 --> 19:11.560
而另外還有說

19:11.560 --> 19:14.560
就是如果這個社會的分化

19:14.560 --> 19:15.560
更嚴重的話

19:15.560 --> 19:18.560
那麼他可能把這個threshold

19:18.560 --> 19:19.560
在這個

19:19.560 --> 19:20.560
呃

19:20.560 --> 19:22.560
網路緊密度的這個threshold降低

19:22.560 --> 19:23.560
就是說

19:23.560 --> 19:25.560
我剛才是講說

19:25.560 --> 19:26.560
如果這個社會

19:26.560 --> 19:27.560
如果越緊密的話呢

19:27.560 --> 19:28.560
呃

19:28.560 --> 19:29.560
這種比較不準確的新聞

19:29.560 --> 19:30.560
就可以傳的越遠

19:30.560 --> 19:32.560
那如果你又讓這個

19:32.560 --> 19:34.560
極化的程度更高的話

19:34.560 --> 19:35.560
反而那些

19:35.560 --> 19:36.560
就是甚至連那些

19:36.560 --> 19:38.560
可能不是很緊密連接的網路呢

19:38.560 --> 19:39.560
也能使得

19:39.560 --> 19:40.560
呃

19:40.560 --> 19:41.560
不準確的新聞

19:41.560 --> 19:42.560
去傳播的更遠

19:42.560 --> 19:43.560
然後另外

19:43.560 --> 19:44.560
大家可能會想說

19:44.560 --> 19:45.560
哎那萬一我去增加

19:45.560 --> 19:47.560
兩檔之內

19:47.560 --> 19:48.560
呃

19:48.560 --> 19:49.560
就是兩檔之內的

19:49.560 --> 19:52.560
他們自己各自檔內的這種diversity的話

19:52.560 --> 19:54.560
其實會不會去

19:54.560 --> 19:55.560
幫助抑制這種

19:55.560 --> 19:56.560
less credible news

19:56.560 --> 19:58.560
to create a larger cascade

19:58.560 --> 19:59.560
但是我們的

19:59.560 --> 20:00.560
呃

20:00.560 --> 20:01.560
結果會發現說

20:01.560 --> 20:02.560
其實也不一定

20:02.560 --> 20:03.560
就是說

20:03.560 --> 20:04.560
在某些情況下

20:04.560 --> 20:05.560
的確可以去降低

20:05.560 --> 20:06.560
呃

20:06.560 --> 20:07.560
呃

20:07.560 --> 20:08.560
這個

20:08.560 --> 20:10.560
比較不準確新聞的

20:10.560 --> 20:11.560
傳播的

20:11.560 --> 20:12.560
呃

20:12.560 --> 20:13.560
速度

20:13.560 --> 20:14.560
不能講速度

20:14.560 --> 20:15.560
就是怕遲度

20:15.560 --> 20:16.560
但是其實有一些情況下

20:16.560 --> 20:17.560
他是會發現說

20:17.560 --> 20:18.560
其實你增加這種diversity

20:18.560 --> 20:19.560
反而會增加

20:19.560 --> 20:20.560
呃

20:20.560 --> 20:22.560
不準確的新聞去傳播的更遠

20:22.560 --> 20:23.560
所以這主要是我們的

20:23.560 --> 20:24.560
呃

20:24.560 --> 20:25.560
結論

20:25.560 --> 20:26.560
好

20:26.560 --> 20:27.560
那我就

20:27.560 --> 20:28.560
繼續了

20:28.560 --> 20:29.560
就好

20:29.560 --> 20:30.560
那我現在這是主要我們的結論

20:30.560 --> 20:31.560
然後我就稍微講

20:31.560 --> 20:32.560
開始講一下我們的model

20:32.560 --> 20:34.560
讓大家知道說這個model到底

20:34.560 --> 20:36.560
大致上在做些什麼

20:36.560 --> 20:38.560
首先我們這個model有三個stage

20:38.560 --> 20:40.560
最一開始的stage0呢

20:40.560 --> 20:42.560
就是對一些fundamental的事情

20:42.560 --> 20:43.560
就這邊有一個social network

20:43.560 --> 20:44.560
然後大家每個人

20:44.560 --> 20:46.560
他自己對某件事情

20:46.560 --> 20:47.560
假設就投

20:47.560 --> 20:49.560
到底要投川普還是拜登的這種想法

20:49.560 --> 20:51.560
然後新聞就有

20:51.560 --> 20:53.560
有一個有一個新聞就是被

20:53.560 --> 20:55.560
realize

20:55.560 --> 20:57.560
然後他可能就給某一些人看

20:57.560 --> 20:58.560
呃

20:58.560 --> 20:59.560
然後第二個stage呢

20:59.560 --> 21:00.560
就是你知道

21:00.560 --> 21:01.560
在投票之前

21:01.560 --> 21:02.560
大家的互動的stage

21:02.560 --> 21:03.560
然後大家可以

21:03.560 --> 21:04.560
大家可能如果看到新聞呢

21:04.560 --> 21:05.560
他就決定

21:05.560 --> 21:06.560
到底要不要傳

21:06.560 --> 21:07.560
如果傳的話呢

21:07.560 --> 21:08.560
我

21:08.560 --> 21:09.560
我這邊有一個decision

21:09.560 --> 21:10.560
variable

21:10.560 --> 21:11.560
SI meaning that

21:11.560 --> 21:12.560
1的話就是

21:12.560 --> 21:13.560
喔我傳了這個新聞

21:13.560 --> 21:15.560
0的話就沒有

21:15.560 --> 21:16.560
然後最後呢

21:16.560 --> 21:18.560
在這個interaction stage

21:18.560 --> 21:19.560
結束之後

21:19.560 --> 21:20.560
最後大家就決定要不要vote

21:20.560 --> 21:22.560
然後AI

21:22.560 --> 21:23.560
就是那個action

21:23.560 --> 21:24.560
就是說喔我到底要投

21:24.560 --> 21:26.560
假設負1就是偏左

21:26.560 --> 21:27.560
正1就是偏右

21:27.560 --> 21:28.560
就其實就是一個binary variable

21:28.560 --> 21:30.560
然後你choose 1

21:30.560 --> 21:31.560
嗯

21:31.560 --> 21:33.560
然後在這個model裡頭呢

21:33.560 --> 21:34.560
因為呃

21:34.560 --> 21:35.560
有一些technical assumption

21:35.560 --> 21:37.560
就我是假設

21:37.560 --> 21:39.560
你知道這個agent是非常多

21:39.560 --> 21:40.560
多到爆炸

21:40.560 --> 21:42.560
就是無窮多個

21:42.560 --> 21:43.560
好不好

21:43.560 --> 21:44.560
就是你可以想像這個population非常的大

21:44.560 --> 21:45.560
但是他是用

21:45.560 --> 21:47.560
0到1之間的這種時數系來

21:47.560 --> 21:49.560
index每一個人

21:49.560 --> 21:51.560
所以總共

21:51.560 --> 21:53.560
不可數的無窮多個人

21:53.560 --> 21:55.560
在這個社會裡頭

21:55.560 --> 21:57.560
然後他是一個connected

21:57.560 --> 21:59.560
by this social network

21:59.560 --> 22:01.560
然後這個social network是directed

22:01.560 --> 22:03.560
就是你知道他是一個follower的這種型態

22:03.560 --> 22:05.560
假設我

22:05.560 --> 22:07.560
有一個箭頭指向高顯的話

22:07.560 --> 22:09.560
就代表我follow了高顯

22:09.560 --> 22:11.560
在這個social network裡頭

22:11.560 --> 22:13.560
然後

22:13.560 --> 22:15.560
這個social network怎麼形成的呢

22:15.560 --> 22:17.560
就因為我們也不是說

22:17.560 --> 22:19.560
真的去apply data到這裡

22:19.560 --> 22:21.560
然後為了要讓我們的analysis比較

22:21.560 --> 22:22.560
tractable

22:22.560 --> 22:23.560
我們會用一個呃

22:23.560 --> 22:25.560
大家傳統大家都會用的

22:25.560 --> 22:27.560
random network model

22:27.560 --> 22:29.560
就是說你這個network是randomly

22:29.560 --> 22:31.560
製造出來的

22:31.560 --> 22:33.560
符合了某些特性之後的條件之下

22:33.560 --> 22:35.560
random製造出來的

22:35.560 --> 22:37.560
嗯

22:37.560 --> 22:39.560
然後我在這裡頭呢

22:39.560 --> 22:41.560
主要有一個參數是

22:41.560 --> 22:43.560
告訴大家說這個connectivity lambda

22:43.560 --> 22:45.560
connectivity lambda代表的是

22:45.560 --> 22:47.560
平均每一個人

22:47.560 --> 22:49.560
他follow了多少人

22:49.560 --> 22:51.560
呃不是說平均每一個人

22:51.560 --> 22:53.560
他有多少個followers

22:53.560 --> 22:55.560
就大家在這個

22:55.560 --> 22:57.560
model裡面大概記得這個字型就好

22:57.560 --> 22:59.560
就好

22:59.560 --> 23:01.560
這個variable

23:01.560 --> 23:03.560
那當然這個新聞一開始給

23:03.560 --> 23:05.560
很少的人去聽到然後他們決定要不要

23:05.560 --> 23:07.560
傳然後到最後達到

23:07.560 --> 23:09.560
steady state就是你知道他們一直傳

23:09.560 --> 23:11.560
總是會converge

23:11.560 --> 23:13.560
嗯我會

23:13.560 --> 23:15.560
叫最後那個

23:15.560 --> 23:17.560
你說這個社會裡頭有多少比例的人

23:17.560 --> 23:19.560
他到底最後

23:19.560 --> 23:21.560
有聽到這個新聞

23:21.560 --> 23:23.560
那我就把這個size

23:23.560 --> 23:25.560
這個大小叫做Q

23:25.560 --> 23:27.560
你看全部總共是1嘛

23:27.560 --> 23:29.560
那假設有80%的人

23:29.560 --> 23:31.560
那Q就是0.8聽到的

23:31.560 --> 23:33.560
這個新聞然後這個就是我們

23:33.560 --> 23:35.560
接下來會探討的一個主要的variable

23:35.560 --> 23:37.560
嗯

23:37.560 --> 23:39.560
可以嗎到目前為止

23:39.560 --> 23:41.560
Q算是dependent variable

23:41.560 --> 23:43.560
就是你的target metric

23:43.560 --> 23:45.560
對對對它是一個我等一下會講它

23:45.560 --> 23:47.560
對它是一個variable它不是一個我外

23:47.560 --> 23:49.560
你知道它鐵定就是你知道這個系統

23:49.560 --> 23:51.560
它自己產生出來的話你會觀察到

23:51.560 --> 23:53.560
喔有一個Q

23:53.560 --> 23:55.560
然後lambda是我給定的

23:55.560 --> 23:57.560
對我應該對不起我應該

23:57.560 --> 23:59.560
make it more specific

23:59.560 --> 24:01.560
就是lambda是我一開始說喔

24:01.560 --> 24:03.560
我就考慮這個network裡頭

24:03.560 --> 24:05.560
平均每個人有10個follower

24:05.560 --> 24:07.560
就設定為10然後去generate

24:07.560 --> 24:09.560
這個dependent network model

24:09.560 --> 24:11.560
但是Q是根據他們

24:11.560 --> 24:13.560
的strategy去做出來

24:13.560 --> 24:15.560
然後會產生出來的一個數字

24:15.560 --> 24:17.560
ok

24:17.560 --> 24:19.560
嗯

24:19.560 --> 24:21.560
然後我剛才講說

24:21.560 --> 24:23.560
每個人其實都有他自己的

24:23.560 --> 24:25.560
一個想法嘛那其實我們在這個

24:25.560 --> 24:27.560
模型裡頭因為一些utility function

24:27.560 --> 24:29.560
我們在定義的過程當中

24:29.560 --> 24:31.560
其實我們只需要去注意每個人

24:31.560 --> 24:33.560
他對這件事情的

24:33.560 --> 24:35.560
期望值的想法

24:35.560 --> 24:37.560
也就是說我今天問你說

24:37.560 --> 24:39.560
你覺得

24:39.560 --> 24:41.560
這個通膨率是多少

24:41.560 --> 24:43.560
你可能覺得說我覺得平均應該就0.5吧

24:43.560 --> 24:45.560
就這樣所以我們只需要care這個

24:45.560 --> 24:47.560
這個平均值就好所以我叫

24:47.560 --> 24:49.560
然後

24:49.560 --> 24:51.560
每個人都其實看不到別人的

24:51.560 --> 24:53.560
平均值就是說我其實

24:53.560 --> 24:55.560
也不知道高顯對這件事情的看法

24:55.560 --> 24:57.560
但是我大概知道說這整個社會裡頭

24:57.560 --> 24:59.560
呃

24:59.560 --> 25:01.560
呃這個分佈是怎麼樣可能

25:01.560 --> 25:03.560
偏向說今年這個通膨率

25:03.560 --> 25:05.560
是偏高大家可能都落在

25:05.560 --> 25:07.560
這個0.7附近

25:07.560 --> 25:09.560
就是一個function cdf function

25:09.560 --> 25:11.560
然後我就假設說大概有一半

25:11.560 --> 25:13.560
的人覺得是小於0一半的人覺得

25:13.560 --> 25:15.560
大於0這樣這只是一個

25:15.560 --> 25:17.560
呃就simplify一些

25:17.560 --> 25:19.560
notation的方式而已

25:19.560 --> 25:21.560
呃另外

25:21.560 --> 25:23.560
這個事件呢在一開始他就generate

25:23.560 --> 25:25.560
這個news就他產生一個

25:25.560 --> 25:27.560
news然後他是一個時數

25:27.560 --> 25:29.560
然後另外他有credibility data

25:29.560 --> 25:31.560
就是道義之間的一個時數

25:31.560 --> 25:33.560
這個credibility

25:33.560 --> 25:35.560
呢其實本質上

25:35.560 --> 25:37.560
的意思是說

25:37.560 --> 25:39.560
當你看到新聞之後

25:39.560 --> 25:41.560
你會對這個

25:41.560 --> 25:43.560
新聞有多大的sensitivity

25:43.560 --> 25:45.560
就是說我會很相信他的話

25:45.560 --> 25:47.560
那我當然就完全的

25:47.560 --> 25:49.560
把我的belief都改成是這個news

25:49.560 --> 25:51.560
但如果你完全不相信他的話

25:51.560 --> 25:53.560
你可能就你就會覺得說

25:53.560 --> 25:55.560
我就把他當成是garbage

25:55.560 --> 25:57.560
message我就直接還是preserve

25:57.560 --> 25:59.560
my expectation

25:59.560 --> 26:01.560
然後在這裡呢

26:01.560 --> 26:03.560
beta等於1呢我就叫他叫做

26:03.560 --> 26:05.560
fully credible的case

26:05.560 --> 26:07.560
因為我們之後我們主要想要探討的是說

26:07.560 --> 26:09.560
如果fully credible news是這樣子

26:09.560 --> 26:11.560
那如果比fully credible再小一點

26:11.560 --> 26:13.560
把他的credibility

26:13.560 --> 26:15.560
降低的話會不會有更大的

26:15.560 --> 26:17.560
news cascade

26:17.560 --> 26:19.560
不好意思

26:19.560 --> 26:21.560
我可以問個問題嗎

26:21.560 --> 26:23.560
credibility在這邊

26:23.560 --> 26:25.560
就聽你剛剛的解釋聽起來有點像是

26:25.560 --> 26:27.560
那個新聞有多

26:27.560 --> 26:29.560
influential你的定義是

26:29.560 --> 26:31.560
應該

26:31.560 --> 26:33.560
其實他可以被

26:33.560 --> 26:35.560
對其實你可以就是想像

26:35.560 --> 26:37.560
其實他有點像是一個我覺得有點

26:37.560 --> 26:39.560
在這邊其實有點terminology的問題

26:39.560 --> 26:41.560
就是說可能我講credibility有一些人會覺得

26:41.560 --> 26:43.560
他是有一個subjective的

26:43.560 --> 26:45.560
觀念在裡頭但是

26:45.560 --> 26:47.560
這裡的話我們就是假定說你可以

26:47.560 --> 26:49.560
當你收到新聞的時候你知道說

26:49.560 --> 26:51.560
這是CNN的news然後我們大家都

26:51.560 --> 26:53.560
同意CNN的可信度

26:53.560 --> 26:55.560
在那個在什麼level

26:55.560 --> 26:57.560
這樣子

26:57.560 --> 26:59.560
是prior belief

26:59.560 --> 27:01.560
但是可信度

27:01.560 --> 27:03.560
這是homogeneous

27:03.560 --> 27:05.560
對對這是一個common knowledge

27:05.560 --> 27:07.560
就是如果大家收到新聞就ok

27:07.560 --> 27:09.560
這個就是一個非常可信的新聞

27:09.560 --> 27:11.560
沒有大家沒有我沒有讓他

27:11.560 --> 27:13.560
變成heterogeneous

27:13.560 --> 27:15.560
ok

27:15.560 --> 27:17.560
就我剛聽你的

27:17.560 --> 27:19.560
解釋方法聽起來比較像是

27:19.560 --> 27:21.560
他是主觀

27:21.560 --> 27:23.560
衡量的一個東西就如果

27:23.560 --> 27:25.560
我現在收到一個東西然後我覺得他的可信度

27:25.560 --> 27:27.560
很高

27:27.560 --> 27:29.560
那他的credibility就很高在你這個model

27:29.560 --> 27:31.560
裡面可是

27:31.560 --> 27:33.560
就是感覺credibility

27:33.560 --> 27:35.560
可以用比較客觀的方法

27:35.560 --> 27:37.560
來量就是說如果你把像你

27:37.560 --> 27:39.560
剛講的譬如說如果是CNN你把某一些新聞

27:39.560 --> 27:41.560
然後列出來

27:41.560 --> 27:43.560
然後我們可能可以

27:43.560 --> 27:45.560
通過

27:45.560 --> 27:47.560
不知道可能還是要靠

27:47.560 --> 27:49.560
某一種rating之類的然後

27:49.560 --> 27:51.560
用非常多人的rating然後來排名說

27:51.560 --> 27:53.560
那如果我們來看客觀來講

27:53.560 --> 27:55.560
哪一個不用rating

27:55.560 --> 27:57.560
我們來看譬如說每一個新聞的outlet他產出

27:57.560 --> 27:59.560
正確的新聞跟

27:59.560 --> 28:01.560
不正確的新聞的比例是怎樣

28:01.560 --> 28:03.560
那如果他正確的比例很高他credibility就很高

28:03.560 --> 28:05.560
那就不用靠任何的人工的rating

28:05.560 --> 28:07.560
但是聽起來你們是

28:07.560 --> 28:09.560
你在這邊的credibility定義是

28:09.560 --> 28:11.560
就是基本上

28:11.560 --> 28:13.560
how influential it is

28:13.560 --> 28:15.560
其實就他

28:15.560 --> 28:17.560
其實如果你用一些

28:17.560 --> 28:19.560
像一些什麼Gaussian的belief去看

28:19.560 --> 28:21.560
就是你可以其實有一些數學

28:21.560 --> 28:23.560
的東西去解釋他你可以說是

28:23.560 --> 28:25.560
這個news可能是一個signal

28:25.560 --> 28:27.560
然後你說這個beta其實

28:27.560 --> 28:29.560
就是一個

28:29.560 --> 28:31.560
signal多準確

28:31.560 --> 28:33.560
如果他越準確的話其實就變成是說

28:33.560 --> 28:35.560
我越相信這個news

28:35.560 --> 28:37.560
所以那個準確的意思是說

28:37.560 --> 28:39.560
他更接近那個人原本的prior嗎

28:39.560 --> 28:41.560
不是那個準確是

28:41.560 --> 28:43.560
你知道這個東西

28:43.560 --> 28:45.560
signal裡面沒有noise

28:45.560 --> 28:47.560
然後我知道這個東西觀察到的就是那個東西

28:47.560 --> 28:49.560
沒有任何的

28:49.560 --> 28:51.560
觀察上的誤差

28:51.560 --> 28:53.560
我覺得

28:53.560 --> 28:55.560
這應該就是我的問題的

28:55.560 --> 28:57.560
根源就是

28:57.560 --> 28:59.560
我觀察到一個東西沒有noise的時候

28:59.560 --> 29:01.560
我會假定那個東西

29:01.560 --> 29:03.560
我其實不知道那個東西是真的還是假的

29:03.560 --> 29:05.560
所以有兩個approach的方法

29:05.560 --> 29:07.560
第一個就是

29:07.560 --> 29:09.560
我感覺這個東西沒有noise

29:09.560 --> 29:11.560
然後第二個是

29:11.560 --> 29:13.560
因為那個東西客觀上

29:13.560 --> 29:15.560
就譬如說我們有某一種評量

29:15.560 --> 29:17.560
他是一個從一個很好的outlet出來的

29:17.560 --> 29:19.560
所以我猜

29:19.560 --> 29:21.560
就是因為那個原因所以他沒有noise

29:21.560 --> 29:23.560
所以我比較知道你在講的是哪一種

29:23.560 --> 29:25.560
我在講

29:25.560 --> 29:27.560
是我們大家都知道

29:27.560 --> 29:29.560
這是一個observation然後他沒有noise

29:29.560 --> 29:31.560
ok

29:31.560 --> 29:33.560
對observation on the state

29:33.560 --> 29:35.560
然後他沒有noise

29:35.560 --> 29:37.560
所以等於是我就看到那個state

29:37.560 --> 29:39.560
等於說那個牌就翻出來

29:39.560 --> 29:41.560
我們大家全部都親眼看到他是什麼意思

29:41.560 --> 29:43.560
就是說

29:43.560 --> 29:45.560
反正這邊我講credibility就是說

29:45.560 --> 29:47.560
其實就是說

29:47.560 --> 29:49.560
大家都當他看到這個新聞的時候

29:49.560 --> 29:51.560
大家都agree

29:51.560 --> 29:53.560
這樣子的新聞他的準確度在哪裡

29:53.560 --> 29:55.560
然後我說的準確度是說他跟

29:55.560 --> 29:57.560
跟那個

29:57.560 --> 29:59.560
真正你想觀察的那個東西的

29:59.560 --> 30:01.560
誤差

30:01.560 --> 30:03.560
就是

30:03.560 --> 30:05.560
越接近那個

30:05.560 --> 30:07.560
如果你跟我講說這個signal很準確的話

30:07.560 --> 30:09.560
那我的意思就是說

30:09.560 --> 30:11.560
我完全的反映了那一個我想觀察的東西

30:11.560 --> 30:13.560
如果你說這個signal不準確的話

30:13.560 --> 30:15.560
那他可能

30:15.560 --> 30:17.560
somehow有點noise然後可能看到家務

30:17.560 --> 30:19.560
或監務的這種東西

30:19.560 --> 30:21.560
那我把它換成那個

30:21.560 --> 30:23.560
真實世界的角度來看

30:23.560 --> 30:25.560
換句話說如果今天有一個左派的人他看左派的媒體

30:25.560 --> 30:27.560
跟右派的人看右派的媒體

30:27.560 --> 30:29.560
對他們來講

30:29.560 --> 30:31.560
那個情況的credibility都是maximum

30:33.560 --> 30:35.560
我們這個model

30:35.560 --> 30:37.560
我們這個model裡面就是假設說

30:37.560 --> 30:39.560
大家都agree

30:39.560 --> 30:41.560
這一個我們大家都

30:41.560 --> 30:43.560
我也知道你在

30:43.560 --> 30:45.560
當然你可以說現實生活中

30:45.560 --> 30:47.560
democrats如果他看到CNN的news

30:47.560 --> 30:49.560
決定說這個我相信他

30:49.560 --> 30:51.560
然後可能那個共和黨人看到CNN

30:51.560 --> 30:53.560
就說啊什麼東西啊就我不相信

30:53.560 --> 30:55.560
但是

30:55.560 --> 30:57.560
我這個model是假設說

30:57.560 --> 30:59.560
不管怎麼樣的人

30:59.560 --> 31:01.560
他如果看到這個新聞之後我們大家都相信

31:01.560 --> 31:03.560
他的準確度在那個程度

31:03.560 --> 31:05.560
就是說我們是一個假定的狀態

31:05.560 --> 31:07.560
就是假定

31:07.560 --> 31:09.560
我大家都agree

31:09.560 --> 31:11.560
CNN的這個準確程度在0.9

31:11.560 --> 31:13.560
OK

31:13.560 --> 31:15.560
OK

31:15.560 --> 31:17.560
你想的那個問題

31:17.560 --> 31:19.560
其實我的另外一個paper有在study

31:19.560 --> 31:21.560
就是說

31:21.560 --> 31:23.560
現在是白邊

31:23.560 --> 31:25.560
不好意思

31:25.560 --> 31:27.560
就是說

31:27.560 --> 31:29.560
我們現在的狀況是

31:29.560 --> 31:31.560
我另外一個paper有看

31:31.560 --> 31:33.560
有在study這樣的問題

31:33.560 --> 31:35.560
就是說我們先假定

31:35.560 --> 31:37.560
大家都agreeCNN就是0.9

31:37.560 --> 31:39.560
我們看到CNN的我們都同意

31:39.560 --> 31:41.560
他是0.9

31:41.560 --> 31:43.560
那我就暫時把他想像成

31:43.560 --> 31:45.560
我們可能有一個

31:45.560 --> 31:47.560
類似那種國營媒體好了

31:47.560 --> 31:49.560
假設像是日本的NHK

31:49.560 --> 31:51.560
當然也不是所有日本人都喜歡NHK

31:51.560 --> 31:53.560
假設有一個國營媒體然後那個東西是

31:53.560 --> 31:55.560
highly credible

31:55.560 --> 31:57.560
然後其他的媒體我們先不管他

31:57.560 --> 31:59.560
反正他的東西如果出現大家都相信

31:59.560 --> 32:01.560
然後他的credibility就是最高

32:01.560 --> 32:03.560
他不一定是最高

32:03.560 --> 32:05.560
反正我現在就是會調整那個數字

32:05.560 --> 32:07.560
但我只是問說

32:07.560 --> 32:09.560
然後

32:09.560 --> 32:11.560
很好

32:11.560 --> 32:13.560
我們這裡就是說

32:13.560 --> 32:15.560
如果你沒有聽到新聞的話

32:15.560 --> 32:17.560
你就繼續保持你原本的

32:17.560 --> 32:19.560
這個想法

32:19.560 --> 32:21.560
但如果你聽到想法的話就是我剛才講的

32:21.560 --> 32:23.560
你可能會你就是做一個complex combination

32:23.560 --> 32:25.560
就是說

32:25.560 --> 32:27.560
你可以看出來如果是beta等於1

32:27.560 --> 32:29.560
是fully credible的話我完全

32:29.560 --> 32:31.560
是考慮我自己原本的μi

32:31.560 --> 32:33.560
對吧 因為如果是beta等於1的話

32:33.560 --> 32:35.560
我就是完全的改變了

32:35.560 --> 32:37.560
我的想法變成x 但是如果beta

32:37.560 --> 32:39.560
等於0就是我知道這東西完全是garbage

32:39.560 --> 32:41.560
我就是preserve my

32:41.560 --> 32:43.560
prior expectation

32:43.560 --> 32:45.560
就是這是一個

32:45.560 --> 32:47.560
分析比較簡單的方法

32:47.560 --> 32:49.560
然後

32:49.560 --> 32:51.560
再來是我想因為econ裡面

32:51.560 --> 32:53.560
你就是你做任何的事情

32:53.560 --> 32:55.560
其實你都是想try to maximize

32:55.560 --> 32:57.560
your expected utility

32:57.560 --> 32:59.560
然後首先是

32:59.560 --> 33:01.560
如果你決定去分享這個新聞的時候

33:01.560 --> 33:03.560
就像我剛才講的

33:03.560 --> 33:05.560
你得突然在那邊滑手機滑得很開心

33:05.560 --> 33:07.560
突然要停下來然後就是要

33:07.560 --> 33:09.560
我們把interpret as a

33:09.560 --> 33:11.560
status quo

33:11.560 --> 33:13.560
bias就是說你不想

33:13.560 --> 33:15.560
破壞原本的現狀你可能要突然又

33:15.560 --> 33:17.560
做一件事情所以你要花了一個cost

33:17.560 --> 33:19.560
然後在這個

33:19.560 --> 33:21.560
狀況底下我們formulate這個utility function

33:21.560 --> 33:23.560
像這樣子就是說

33:23.560 --> 33:25.560
我會一步一步來解釋說

33:25.560 --> 33:27.560
這個utility function代表了什麼意思

33:27.560 --> 33:29.560
第一個是先

33:29.560 --> 33:31.560
因為我剛才沒有定義這個network model

33:31.560 --> 33:33.560
第一個是

33:33.560 --> 33:35.560
我的utility是

33:35.560 --> 33:37.560
根據我

33:37.560 --> 33:39.560
關心的這個state data

33:39.560 --> 33:41.560
以及我做了一個

33:41.560 --> 33:43.560
sharing decision si 還有

33:43.560 --> 33:45.560
以後我之後我會voting ai

33:45.560 --> 33:47.560
但我也考慮到

33:47.560 --> 33:49.560
我這些follower的

33:49.560 --> 33:51.560
voting decision 以及

33:51.560 --> 33:53.560
最後我可能如果我真的sharing

33:53.560 --> 33:55.560
這個news的話我真的要

33:55.560 --> 33:57.560
花了一個cost

33:57.560 --> 33:59.560
所以第一個是這個其實就是

33:59.560 --> 34:01.560
你aggregate就你考慮到了

34:01.560 --> 34:03.560
你這個follower

34:03.560 --> 34:05.560
的這個action

34:05.560 --> 34:07.560
第一個部分就是direct utility from voting

34:07.560 --> 34:09.560
就是我直接投了然後你可以看得出來

34:09.560 --> 34:11.560
就是你盡可能的你想要

34:11.560 --> 34:13.560
match這個state的sign

34:13.560 --> 34:15.560
你可以看到ai data

34:15.560 --> 34:17.560
你基本上你會挑那個action

34:17.560 --> 34:21.560
去match the sign of the state

34:21.560 --> 34:23.560
你想要知道它到底是偏右還是偏左

34:23.560 --> 34:25.560
另外這個blue part

34:25.560 --> 34:27.560
就是說這個東西

34:27.560 --> 34:29.560
是你去aggregate我考慮到了

34:29.560 --> 34:31.560
我這些follower的

34:31.560 --> 34:33.560
utility

34:33.560 --> 34:35.560
你internalize

34:35.560 --> 34:37.560
你的follower

34:37.560 --> 34:39.560
你其實是想要為了它們好

34:39.560 --> 34:41.560
你只是覺得說我希望你們去投的跟我想的

34:41.560 --> 34:43.560
一樣就這個theta

34:43.560 --> 34:45.560
還是根據你自己的believe去

34:45.560 --> 34:47.560
estimate

34:47.560 --> 34:49.560
但是至於那個action

34:49.560 --> 34:51.560
是depends on

34:51.560 --> 34:53.560
你follower自己的believe

34:53.560 --> 34:55.560
所以你想要try to inference它們的這個action

34:57.560 --> 34:59.560
然後其實這邊我先快速的

34:59.560 --> 35:01.560
跟大家講一下就是我剛才講的

35:01.560 --> 35:03.560
你在voting的狀況底下

35:03.560 --> 35:05.560
其實你是想要match the sign of the state

35:05.560 --> 35:07.560
所以其實這邊有一個很快的

35:07.560 --> 35:09.560
結論就是說

35:11.560 --> 35:13.560
當我有收到的新聞之後

35:13.560 --> 35:15.560
然後你知道就是剛才那個

35:15.560 --> 35:17.560
beta s加一點beta mu i

35:17.560 --> 35:19.560
然後它大於0了

35:19.560 --> 35:21.560
那當然就代表我現在覺得

35:21.560 --> 35:23.560
這個state應該是比較偏右

35:23.560 --> 35:25.560
那我就投1

35:25.560 --> 35:27.560
偏左的話就投-1

35:27.560 --> 35:29.560
所以其實如果你有收到新聞的話

35:29.560 --> 35:31.560
你會投

35:31.560 --> 35:33.560
正義的condition

35:33.560 --> 35:35.560
就是說這個mu i

35:35.560 --> 35:37.560
足夠大,大過於這個threshold

35:37.560 --> 35:39.560
如果你沒有聽到任何新聞

35:39.560 --> 35:41.560
那當然一開始你覺得已經是偏低

35:41.560 --> 35:43.560
如果一開始你的期望值是

35:43.560 --> 35:45.560
正的那你當然就投

35:45.560 --> 35:47.560
共和黨

35:47.560 --> 35:49.560
如果你覺得一開始你的期望值是負的

35:49.560 --> 35:51.560
那你就投民主黨

35:51.560 --> 35:53.560
所以這個voting decision是比較簡單的部分

35:53.560 --> 35:55.560
然後

35:55.560 --> 35:57.560
我接下來要開始講的就是比較有趣的

35:57.560 --> 35:59.560
就是這個sharing decision

35:59.560 --> 36:01.560
我有一個問題

36:01.560 --> 36:03.560
我不知道

36:03.560 --> 36:05.560
可能這是你等一下要講

36:05.560 --> 36:07.560
utility function

36:07.560 --> 36:09.560
其中一個input是voting decision

36:09.560 --> 36:11.560
但是自己那個agent也有可能

36:11.560 --> 36:13.560
會改變

36:13.560 --> 36:15.560
AI star

36:15.560 --> 36:17.560
但是AI star跟這個AI是沒有關的

36:17.560 --> 36:19.560
是這樣嗎

36:19.560 --> 36:21.560
不好意思

36:21.560 --> 36:23.560
AI star其實就是均衡

36:23.560 --> 36:25.560
好

36:25.560 --> 36:27.560
就是說我現在剛才定義了這個utility function

36:27.560 --> 36:29.560
沒有打信號的部分

36:29.560 --> 36:31.560
就是單純的

36:31.560 --> 36:33.560
我的utility是這樣子

36:33.560 --> 36:35.560
我現在打了信號的意思代表說

36:35.560 --> 36:37.560
在均衡底下之後其實我就是會做這件事情

36:37.560 --> 36:39.560
因為你還記得voting是在最後一刻發生的

36:39.560 --> 36:41.560
對吧

36:41.560 --> 36:43.560
所以大概大家都已經interact完了之後

36:43.560 --> 36:45.560
如果我在那個時間點

36:45.560 --> 36:47.560
在voting的時間點

36:47.560 --> 36:49.560
我有收到新聞的話

36:49.560 --> 36:51.560
那麼我的最好的action

36:51.560 --> 36:53.560
因為我那個時間點投票

36:53.560 --> 36:55.560
我已經沒辦法再影響任何人了

36:55.560 --> 36:57.560
我其實能投的事情就是

36:57.560 --> 36:59.560
我就是要根據我自己的belief去match

36:59.560 --> 37:01.560
那個state

37:01.560 --> 37:03.560
所以那個時候如果你的期望值

37:03.560 --> 37:05.560
就是你如果已經收過新聞了

37:05.560 --> 37:07.560
那你的期望值是1

37:07.560 --> 37:09.560
你的期望值是正的

37:09.560 --> 37:11.560
那那個condition就是這個

37:11.560 --> 37:13.560
然後你會投1

37:13.560 --> 37:15.560
但是如果在那個投票的時間點

37:15.560 --> 37:17.560
你沒有收到任何新聞

37:17.560 --> 37:19.560
那你就是根據你原本的期望值

37:19.560 --> 37:21.560
如果他是正的我就投1

37:21.560 --> 37:23.560
如果是負的我就投負1

37:23.560 --> 37:25.560
ok嗎

37:25.560 --> 37:27.560
聽起來的感覺是

37:27.560 --> 37:29.560
這個utility function是可以

37:29.560 --> 37:31.560
是在

37:31.560 --> 37:33.560
這個agent在present state就可以預測

37:33.560 --> 37:35.560
預測到他的stage 2的

37:35.560 --> 37:37.560
voting decision

37:37.560 --> 37:39.560
對

37:39.560 --> 37:41.560
他其實他在stage 1

37:41.560 --> 37:43.560
對

37:43.560 --> 37:45.560
good question

37:45.560 --> 37:47.560
就是說其實

37:47.560 --> 37:49.560
因為我其實沒有想講的太technical

37:49.560 --> 37:51.560
但是其實應該跟大家講的就是說

37:51.560 --> 37:53.560
你在解這個equilibrium的時候

37:53.560 --> 37:55.560
你可能是倒推回來的

37:55.560 --> 37:57.560
到最後一步我知道大家根據他們自己的belief

37:57.560 --> 37:59.560
他會怎麼投

37:59.560 --> 38:01.560
有收到新聞的人他就是按照上面這個方式投

38:01.560 --> 38:03.560
沒收到新聞的人就按照下面這個方式投

38:03.560 --> 38:05.560
沒收到新聞的人就按照下面這個方式投

38:05.560 --> 38:07.560
然後

38:07.560 --> 38:09.560
所以這個時候你已經知道他們在voting stage

38:09.560 --> 38:11.560
的時候會做出這樣的事情的時候

38:11.560 --> 38:13.560
你在sharing stage的時候你就會考慮說

38:13.560 --> 38:15.560
那我會怎麼樣影響他們最後投票的

38:15.560 --> 38:17.560
這個程度

38:17.560 --> 38:19.560
因為我知道如果我分享

38:19.560 --> 38:21.560
他們就會看到

38:21.560 --> 38:23.560
他們就會照著上面那個方式投

38:23.560 --> 38:25.560
如果我沒有分享他們就會照著下面那個方式投

38:25.560 --> 38:27.560
之類的所以你就要去想這件事情

38:27.560 --> 38:29.560
ok嗎

38:29.560 --> 38:31.560
好

38:31.560 --> 38:33.560
那我趕快講一下這個

38:33.560 --> 38:35.560
因為這個比較有趣一點

38:35.560 --> 38:37.560
就是說到了sharing decision的時候

38:37.560 --> 38:39.560
就變成說你現在已經知道說他們最後

38:39.560 --> 38:41.560
那個stage他們會怎麼vote

38:41.560 --> 38:43.560
然後你在想的就是說

38:43.560 --> 38:45.560
那我到底該不該

38:45.560 --> 38:47.560
分享我的新聞去改變他們的想法

38:47.560 --> 38:49.560
因為我改變的話他們就會照著

38:49.560 --> 38:51.560
那個beta s加一減beta

38:51.560 --> 38:53.560
如果沒有的話就是preserve

38:53.560 --> 38:55.560
他們原本的expectation

38:55.560 --> 38:57.560
對就我剛才講

38:57.560 --> 38:59.560
如果分享的話我就知道說

38:59.560 --> 39:01.560
我的follower都會看到這個新聞

39:01.560 --> 39:03.560
當然有可能

39:03.560 --> 39:05.560
對就是我們就assume

39:05.560 --> 39:07.560
你的follower真的就會看到這個新聞

39:07.560 --> 39:09.560
另外一個就是說如果你沒分享的話

39:09.560 --> 39:11.560
那你就要想

39:11.560 --> 39:13.560
我沒有分享但是

39:13.560 --> 39:15.560
我的follower也有可能從別的地方

39:15.560 --> 39:17.560
聽到新聞對吧

39:17.560 --> 39:19.560
因為你現在已經知道有這個新聞在這個社會裡頭

39:19.560 --> 39:21.560
所以你已經知道說

39:21.560 --> 39:23.560
有一些人也在傳這個新聞

39:23.560 --> 39:25.560
那到底我的follower有多可能聽到這個新聞

39:25.560 --> 39:27.560
那其實這個東西呢

39:27.560 --> 39:29.560
在這個分析當中

39:29.560 --> 39:31.560
你會預測說

39:31.560 --> 39:33.560
在均衡的底下

39:33.560 --> 39:35.560
到底這個新聞

39:35.560 --> 39:37.560
可以傳的多遠

39:37.560 --> 39:39.560
所以你在想的就是這個sizeQ

39:39.560 --> 39:41.560
你可以想像就是說

39:41.560 --> 39:43.560
這個sizeQ鐵定會正相關的影響到

39:43.560 --> 39:45.560
你的follower

39:45.560 --> 39:47.560
多可能聽到這個新聞

39:47.560 --> 39:49.560
在這個equally

39:49.560 --> 39:51.560
從別人那邊聽到的新聞

39:51.560 --> 39:53.560
而不是你自己

39:53.560 --> 39:55.560
因為如果你它假設這個Q是1

39:55.560 --> 39:57.560
那你就知道鐵定他會從別人那邊聽到新聞

39:57.560 --> 39:59.560
因為每個人都在傳

39:59.560 --> 40:01.560
就是這個size非常大

40:01.560 --> 40:03.560
就等於是說那我就不用傳

40:03.560 --> 40:05.560
對

40:05.560 --> 40:07.560
那接下來這個問題就來了

40:07.560 --> 40:09.560
就是它現在

40:09.560 --> 40:11.560
決定了sharing decision之後

40:11.560 --> 40:13.560
它就形成了這個sharing strategy

40:13.560 --> 40:15.560
就是它的策略是這樣

40:15.560 --> 40:17.560
然後每一個人都做了這些事情之後呢

40:17.560 --> 40:19.560
經過這個spread dynamics

40:19.560 --> 40:21.560
就是你知道這個傳播的這個鏈

40:21.560 --> 40:23.560
它才會去決定了

40:23.560 --> 40:25.560
這個new spread sizeQ

40:25.560 --> 40:27.560
所以其實它形成了一個loop

40:27.560 --> 40:29.560
大家有沒有看出來

40:29.560 --> 40:31.560
就是我每一個人分享了一個新聞之後呢

40:31.560 --> 40:33.560
經過了

40:33.560 --> 40:35.560
因為新聞會這樣子慢慢的傳出去嘛

40:35.560 --> 40:37.560
然後它就形成了spread size

40:37.560 --> 40:39.560
可是這個其實你也預測到說

40:39.560 --> 40:41.560
喔我傳出去之後這種spread size

40:41.560 --> 40:43.560
進而又影響了我到底

40:43.560 --> 40:45.560
我的follower有多可能聽到這樣的新聞

40:45.560 --> 40:47.560
所以那個時候可能你覺得說

40:47.560 --> 40:49.560
所以就是它是一個feedback

40:49.560 --> 40:51.560
就等於是說如果你覺得好像有很多人會傳

40:51.560 --> 40:53.560
那你就不傳

40:53.560 --> 40:55.560
你又知道說

40:55.560 --> 40:57.560
那現在我又應該傳了

40:57.560 --> 40:59.560
因為大家都覺得好像我不應該傳

40:59.560 --> 41:01.560
就是它會有一個feedback

41:01.560 --> 41:03.560
然後會達到一個均衡

41:03.560 --> 41:05.560
所以這個Q呢

41:05.560 --> 41:07.560
是一個indigenous generated variable

41:07.560 --> 41:09.560
它是一個

41:09.560 --> 41:11.560
它不是一個

41:11.560 --> 41:13.560
它是有一個feedback去決定它

41:13.560 --> 41:15.560
這個均衡底下這個數字應該長什麼樣

41:15.560 --> 41:17.560
然後我就

41:17.560 --> 41:19.560
如果大家感興趣那個

41:19.560 --> 41:21.560
那些equation去怎麼樣

41:21.560 --> 41:23.560
大家可以去看一下paper

41:23.560 --> 41:25.560
但這是主要的idea就是說

41:25.560 --> 41:27.560
你在決定sharing的時候你得去考慮

41:27.560 --> 41:29.560
喔到均衡的時候

41:29.560 --> 41:31.560
這個傳播的鏈有多大

41:31.560 --> 41:33.560
但是有可能它就影響我到底

41:33.560 --> 41:35.560
要不要去傳

41:35.560 --> 41:37.560
然後這是我們的這個

41:37.560 --> 41:39.560
第一個雷瑪就是說

41:39.560 --> 41:41.560
characterize到底

41:41.560 --> 41:43.560
假設你已經知道這spread size是Q的話

41:43.560 --> 41:45.560
那你

41:45.560 --> 41:47.560
會傳這個新聞的

41:47.560 --> 41:49.560
condition是這樣

41:49.560 --> 41:51.560
其實就是你的expectation

41:51.560 --> 41:53.560
因為你現在是

41:53.560 --> 41:55.560
拿到新聞了對吧

41:55.560 --> 41:57.560
你拿到新聞的expectation

41:57.560 --> 41:59.560
然後乘上你覺得這個news

41:59.560 --> 42:01.560
它可以影響多少的

42:01.560 --> 42:03.560
你的follower

42:03.560 --> 42:05.560
假設你傳了結果你發現所有的follower

42:05.560 --> 42:07.560
不會因為你的這個decision而改變他的想法的話

42:07.560 --> 42:09.560
那你就沒有意義

42:09.560 --> 42:11.560
去傳這個新聞

42:11.560 --> 42:13.560
所以這個成績如果大於C的話

42:13.560 --> 42:15.560
那他就會傳

42:15.560 --> 42:17.560
那這裡就是說

42:17.560 --> 42:19.560
其實就是

42:19.560 --> 42:21.560
就是我剛才講的那個strategic substitute

42:21.560 --> 42:23.560
如果你說這個Q已經很多

42:23.560 --> 42:25.560
就是你知道這個spread size

42:25.560 --> 42:27.560
可以很大的時候

42:27.560 --> 42:29.560
那你就可以看到這個成績就會變小對吧

42:29.560 --> 42:31.560
因為它是反向的

42:31.560 --> 42:33.560
所以你就越不想傳

42:33.560 --> 42:35.560
然後另外是說從這個雷瑪

42:35.560 --> 42:37.560
你可以導出一個threshold strategy

42:37.560 --> 42:39.560
就是說你可以發現

42:39.560 --> 42:41.560
其實每一個人收到新聞之後呢

42:41.560 --> 42:43.560
如果這個新聞是

42:43.560 --> 42:45.560
偏向共和黨的

42:45.560 --> 42:47.560
那你就知道說

42:47.560 --> 42:49.560
如果一開始這個人的expectation

42:49.560 --> 42:51.560
大過了某一個threshold

42:51.560 --> 42:53.560
那他就會傳這個新聞

42:53.560 --> 42:55.560
然後小於這個threshold的人他都不會傳這個新聞

42:55.560 --> 42:57.560
如果這個新聞是

42:57.560 --> 42:59.560
支持democrats的話呢

42:59.560 --> 43:01.560
那麼你知道說

43:01.560 --> 43:03.560
如果那些

43:03.560 --> 43:05.560
原本就偏左派的人呢

43:05.560 --> 43:07.560
他就會分享這個新聞

43:07.560 --> 43:09.560
但是偏右的人就不會想分享這個新聞

43:09.560 --> 43:11.560
所以這是一個threshold

43:11.560 --> 43:13.560
我們叫它是一個threshold strategy

43:13.560 --> 43:15.560
就是你知道

43:15.560 --> 43:17.560
大於他的就傳

43:17.560 --> 43:19.560
小於他的就不傳

43:21.560 --> 43:23.560
那接下來的問題就是說

43:23.560 --> 43:25.560
什麼時候這一個

43:25.560 --> 43:27.560
news cascade會

43:27.560 --> 43:29.560
可以maximize

43:29.560 --> 43:31.560
我應該再

43:31.560 --> 43:33.560
more specific一點就是說

43:33.560 --> 43:35.560
什麼樣的credibility

43:35.560 --> 43:37.560
可以使得這個news

43:37.560 --> 43:39.560
傳得最遠

43:39.560 --> 43:41.560
傳得最大

43:41.560 --> 43:43.560
Fully credible

43:43.560 --> 43:45.560
for credibility就是最好的

43:45.560 --> 43:47.560
然後首先我們要回答這個問題

43:47.560 --> 43:49.560
就要去

43:49.560 --> 43:51.560
看一下說到底

43:51.560 --> 43:53.560
Fully credible news

43:53.560 --> 43:55.560
他會產生的這個spread size到底有多大

43:55.560 --> 43:57.560
然後第一個是

43:57.560 --> 43:59.560
這個圖呢

43:59.560 --> 44:01.560
他其實是根據x的

44:01.560 --> 44:03.560
這個magnitude在畫的

44:03.560 --> 44:05.560
我只考慮正的,因為負的話

44:05.560 --> 44:07.560
其實就是一個symmetry的case

44:07.560 --> 44:09.560
所以大家可以不用太care

44:09.560 --> 44:11.560
然後就0到c

44:11.560 --> 44:13.560
就是當你這個magnitude

44:13.560 --> 44:15.560
of the news是很小很小的時候

44:15.560 --> 44:17.560
你會發現說

44:17.560 --> 44:19.560
even是fully credible news

44:19.560 --> 44:21.560
就是沒有人要傳

44:21.560 --> 44:23.560
就是他會導致說這個新聞傳不出去

44:23.560 --> 44:25.560
是0

44:25.560 --> 44:27.560
如果說這個magnitude of news很強大的話

44:27.560 --> 44:29.560
就是你知道

44:29.560 --> 44:31.560
這個news他既是credible

44:31.560 --> 44:33.560
然後他又告訴我們

44:33.560 --> 44:35.560
一定要投一下拜登的話

44:35.560 --> 44:37.560
不是拜登,因為現在是偏右

44:37.560 --> 44:39.560
大家很相信他

44:39.560 --> 44:41.560
然後他又那麼的強

44:41.560 --> 44:43.560
就是他的magnitude很強的話

44:43.560 --> 44:45.560
那大家就會很願意去傳他

44:45.560 --> 44:47.560
很願意去告訴別人說你應該要投川普

44:47.560 --> 44:49.560
這個時候他會

44:49.560 --> 44:51.560
這個傳播會達到他的極大值

44:51.560 --> 44:53.560
這個極大值就是

44:53.560 --> 44:55.560
這個社會能形成的極大值

44:55.560 --> 44:57.560
我叫他QG

44:57.560 --> 44:59.560
就是一個join component

44:59.560 --> 45:01.560
就是他有connected最大的那一個component

45:01.560 --> 45:03.560
但是如果這個news

45:03.560 --> 45:05.560
在中間這個範圍

45:05.560 --> 45:07.560
他是因為我剛才講的

45:07.560 --> 45:09.560
就是有一個strategic substitute

45:09.560 --> 45:11.560
就是我知道別人要傳的話我就不傳

45:11.560 --> 45:13.560
但是我如果不傳

45:13.560 --> 45:15.560
別人又知道他要傳

45:15.560 --> 45:17.560
然後就是在那個均衡底下呢

45:17.560 --> 45:19.560
這個數字會導致大家會覺得

45:19.560 --> 45:21.560
他在boundary

45:21.560 --> 45:23.560
他會覺得我其實沒有特別覺得

45:23.560 --> 45:25.560
該傳或不傳

45:25.560 --> 45:27.560
就是剛好在那個feel indifferent的那個

45:27.560 --> 45:29.560
界線

45:29.560 --> 45:31.560
所以在

45:31.560 --> 45:33.560
news他是moderate的情況下

45:33.560 --> 45:35.560
其實你可以characterize

45:35.560 --> 45:37.560
就是他的spread size

45:37.560 --> 45:39.560
那我們現在已經知道說

45:39.560 --> 45:41.560
Fully credible news

45:41.560 --> 45:43.560
會是這樣

45:43.560 --> 45:45.560
他的size會是這樣子

45:45.560 --> 45:47.560
那麼現在很明顯的就是

45:47.560 --> 45:49.560
如果news在這個範圍裡頭呢

45:49.560 --> 45:51.560
你就知道說

45:51.560 --> 45:53.560
Fully credible news不會傳出去

45:53.560 --> 45:55.560
因為他鐵定是0嘛

45:55.560 --> 45:57.560
他鐵定是最差的

45:57.560 --> 45:59.560
另外一個是

45:59.560 --> 46:01.560
這邊最右邊他已經達到他最大值

46:01.560 --> 46:03.560
好討論的

46:03.560 --> 46:05.560
因為就變成說你知道啊

46:05.560 --> 46:07.560
這個Fully credible是最好或最差

46:07.560 --> 46:09.560
但在中間這個時候呢

46:09.560 --> 46:11.560
就我們有另外一個proposition

46:11.560 --> 46:13.560
就告訴你說

46:13.560 --> 46:15.560
怎麼樣情況下這種last credible news

46:15.560 --> 46:17.560
last credible news就是說

46:17.560 --> 46:19.560
比beta還小一點的那些news

46:19.560 --> 46:21.560
他反而可以去

46:21.560 --> 46:23.560
使得這個cascade size

46:23.560 --> 46:25.560
比beta等於1

46:25.560 --> 46:27.560
也就是Fully credible news

46:27.560 --> 46:29.560
還要大

46:29.560 --> 46:31.560
news的這個threshold

46:31.560 --> 46:33.560
我剛才不是講他是一個threshold strategy嗎

46:33.560 --> 46:35.560
如果這個threshold大於x的話

46:35.560 --> 46:37.560
然後我跟

46:37.560 --> 46:39.560
就他可能比較有點technical

46:39.560 --> 46:41.560
的這邊就是說

46:41.560 --> 46:43.560
其實給大家一個比較intuition

46:43.560 --> 46:45.560
的狀況底下

46:45.560 --> 46:47.560
你可以想像就是說

46:47.560 --> 46:49.560
這是一個剛才的decision rule嘛

46:49.560 --> 46:51.560
就是expectation乘上了一個

46:51.560 --> 46:53.560
你可以改變的人的數量

46:53.560 --> 46:55.560
然後會大於1

46:55.560 --> 46:57.560
但是當beta等於1的時候

46:57.560 --> 46:59.560
其實你會reduce到說

46:59.560 --> 47:01.560
這邊x就完全是x

47:01.560 --> 47:03.560
然後根據剛才算的

47:03.560 --> 47:05.560
這個Q star其實是1-c

47:05.560 --> 47:07.560
over x 所以其實這邊是c

47:07.560 --> 47:09.560
over x 其實是大於等於c

47:09.560 --> 47:11.560
就是在那個

47:11.560 --> 47:13.560
在中間這個紅色

47:13.560 --> 47:15.560
這個階段的時候其實大家都是feel

47:15.560 --> 47:17.560
都是感覺到indifferent

47:17.560 --> 47:19.560
要傳不傳他都覺得可以

47:19.560 --> 47:21.560
但是如果你把beta就是稍微

47:21.560 --> 47:23.560
降低的話就讓他比較

47:23.560 --> 47:25.560
沒有那麼precise的時候

47:25.560 --> 47:27.560
但是這個時候你可以

47:27.560 --> 47:29.560
先假定說這個Q star

47:29.560 --> 47:31.560
還是接近c over x

47:31.560 --> 47:33.560
就是這個1-Q star還是接近c over x

47:33.560 --> 47:35.560
你會發現說當你把beta

47:35.560 --> 47:37.560
小於1的時候這個時候

47:37.560 --> 47:39.560
一旦μi大於x

47:39.560 --> 47:41.560
他們都會嚴格的大於c

47:41.560 --> 47:43.560
所以他們都會願意傳

47:43.560 --> 47:45.560
所以就變成說當你beta小於

47:45.560 --> 47:47.560
1的時候呢這些μi

47:47.560 --> 47:49.560
大於x的人其實都願意傳

47:49.560 --> 47:51.560
懂嗎

47:51.560 --> 47:53.560
所以如果這個

47:53.560 --> 47:55.560
對不起就是說

47:55.560 --> 47:57.560
就是你把他等於1

47:57.560 --> 47:59.560
然後再往小於1的部分

47:59.560 --> 48:01.560
也降低一點的話

48:01.560 --> 48:03.560
你會發現說這個threshold

48:03.560 --> 48:05.560
就是μi那些比x

48:05.560 --> 48:07.560
還要大的人呢都願意去

48:07.560 --> 48:09.560
傳的這個新聞

48:09.560 --> 48:11.560
所以只要這個

48:11.560 --> 48:13.560
你可以知道說至少這些人都願意去傳

48:13.560 --> 48:15.560
所以如果這個threshold呢

48:15.560 --> 48:17.560
比這個x還要小的話

48:17.560 --> 48:19.560
你就知道說其實你把beta

48:19.560 --> 48:21.560
小於1降低降到小於1

48:21.560 --> 48:23.560
的時候你可以讓更多人去傳

48:23.560 --> 48:25.560
對這邊可能有點technical

48:25.560 --> 48:27.560
但是就是一個

48:27.560 --> 48:29.560
就是如果intuitively

48:29.560 --> 48:31.560
如果cost 0

48:31.560 --> 48:33.560
的話會

48:33.560 --> 48:35.560
怎樣

48:35.560 --> 48:37.560
因為現在有cost的話

48:37.560 --> 48:39.560
現在感覺有我覺得比較tricky是有cost

48:39.560 --> 48:41.560
然後又有那個

48:41.560 --> 48:43.560
beta又varies然後還有x

48:43.560 --> 48:45.560
然後所以

48:45.560 --> 48:47.560
你可以把cost想像

48:47.560 --> 48:49.560
你不要去改變cost在我們這個case

48:49.560 --> 48:51.560
裡面我們沒有去改變任何的cost

48:51.560 --> 48:53.560
因為我們覺得他就是一個fundamental的東西

48:53.560 --> 48:55.560
然後我們比較好奇的就只是說

48:55.560 --> 48:57.560
credibility跟news之間的一些

48:57.560 --> 48:59.560
關係所以你不要去改變cost

48:59.560 --> 49:01.560
between 0 and 1嗎

49:01.560 --> 49:03.560
還是什麼0 to x

49:03.560 --> 49:05.560
沒有就是他是一個大於0的數

49:05.560 --> 49:07.560
cost就是一個大於0

49:07.560 --> 49:09.560
對就是大於0的數就好

49:09.560 --> 49:11.560
如果他等於0的話其實大家就

49:11.560 --> 49:13.560
不管怎樣他都願意傳因為他覺得

49:13.560 --> 49:15.560
就算是garbage他也願意傳

49:15.560 --> 49:17.560
因為反正不影響我嘛就是你知道

49:17.560 --> 49:19.560
有什麼關係反正我傳了

49:19.560 --> 49:21.560
我縱使照美人山但也沒有什麼關係

49:21.560 --> 49:23.560
因為我沒有花任何的cost

49:23.560 --> 49:25.560
所以cost其實還是有點影響

49:25.560 --> 49:27.560
那個spread size就會最大

49:27.560 --> 49:29.560
對因為

49:29.560 --> 49:31.560
等於是說大家其實沒有

49:31.560 --> 49:33.560
然後那個就會變成一個

49:33.560 --> 49:35.560
很trivial case

49:35.560 --> 49:37.560
我們還是有點依賴這個

49:37.560 --> 49:39.560
有點cost的情況

49:39.560 --> 49:41.560
我覺得這個地方就可能大家

49:41.560 --> 49:43.560
稍微知道一下說中間這個地方

49:43.560 --> 49:45.560
我們是有一個condition

49:45.560 --> 49:47.560
去告訴大家說到底

49:47.560 --> 49:49.560
for中間這個線段

49:49.560 --> 49:51.560
這個紅色moderate news的線段

49:51.560 --> 49:53.560
怎麼樣的什麼樣

49:53.560 --> 49:55.560
credibility的news可以create a logic case

49:55.560 --> 49:57.560
就是說其實如果滿足了這個條件

49:57.560 --> 49:59.560
那麼其實比較

49:59.560 --> 50:01.560
less credible的news他就可以

50:01.560 --> 50:03.560
所以我們用這樣子一個condition

50:03.560 --> 50:05.560
去討論

50:05.560 --> 50:07.560
接下來的問題是還有

50:07.560 --> 50:09.560
這個是非常重要就是說

50:09.560 --> 50:11.560
這個colorary告訴我們

50:11.560 --> 50:13.560
說對這些

50:13.560 --> 50:15.560
只要news要大於c

50:15.560 --> 50:17.560
因為如果news小於c的話

50:17.560 --> 50:19.560
那你知道說這個

50:19.560 --> 50:21.560
beta等於1鐵定是

50:21.560 --> 50:23.560
導致沒有人在傳這個新聞

50:23.560 --> 50:25.560
所以我們只考慮s大於c

50:25.560 --> 50:27.560
當你知道s大於c的時候你可以知道說

50:27.560 --> 50:29.560
只要我這個network

50:29.560 --> 50:31.560
足夠的連結在一起的話

50:31.560 --> 50:33.560
就是你知道他有一個threshold

50:33.560 --> 50:35.560
就是你只要大於那一個數字

50:35.560 --> 50:37.560
就是你平均的followers

50:37.560 --> 50:39.560
只要大於那個數字

50:39.560 --> 50:41.560
那麼鐵定比較

50:41.560 --> 50:43.560
不credible的news

50:43.560 --> 50:45.560
可以create a logic case than fully credible news

50:45.560 --> 50:47.560
所以這是一個

50:47.560 --> 50:49.560
還滿重要的colorary

50:49.560 --> 50:51.560
就是告訴你說

50:51.560 --> 50:53.560
只要這個network足夠的

50:53.560 --> 50:55.560
緊密

50:55.560 --> 50:57.560
只要你有足夠

50:57.560 --> 50:59.560
平均足夠多的followers的時候

50:59.560 --> 51:01.560
你就會讓那些

51:01.560 --> 51:03.560
比較不準確的新聞去create a logic case

51:03.560 --> 51:05.560
其實這邊的intuition很簡單

51:05.560 --> 51:07.560
其實就只是告訴你說

51:07.560 --> 51:09.560
因為network越緊密的話

51:09.560 --> 51:11.560
越緊密

51:11.560 --> 51:13.560
那我的followers

51:13.560 --> 51:15.560
很容易就聽到別人傳來的訊息

51:15.560 --> 51:17.560
因為他有很多個管道可以去聽到別人的訊息

51:17.560 --> 51:19.560
那麼你就

51:19.560 --> 51:21.560
這就會進而去導致說

51:21.560 --> 51:23.560
那我可能就不太想要傳訊息

51:23.560 --> 51:25.560
因為你知道說

51:25.560 --> 51:27.560
大家連結這麼緊密

51:27.560 --> 51:29.560
只要他稍微從某個管道聽到

51:29.560 --> 51:31.560
他就聽到了

51:31.560 --> 51:33.560
那麼這個時候會變成說

51:33.560 --> 51:35.560
那什麼樣的人在這樣的情況下

51:35.560 --> 51:37.560
他還願意傳新聞呢

51:37.560 --> 51:39.560
這是一個非常非常非常極端的人

51:39.560 --> 51:41.560
然後如果說

51:41.560 --> 51:43.560
這個

51:43.560 --> 51:45.560
新聞是比較

51:45.560 --> 51:47.560
lower credibility的話

51:47.560 --> 51:49.560
你知道說因為lower credibility

51:49.560 --> 51:51.560
他不太能去

51:51.560 --> 51:53.560
改變大家的想法

51:53.560 --> 51:55.560
因為看到他有點lower credibility

51:55.560 --> 51:57.560
我可能還是會比較考慮到我原本的想法

51:57.560 --> 51:59.560
所以這個時候其實

51:59.560 --> 52:01.560
極端的人還是很多的

52:01.560 --> 52:03.560
反而相對於如果你讓一個

52:03.560 --> 52:05.560
fully credible放下去之後

52:05.560 --> 52:07.560
很converge到同一個點

52:07.560 --> 52:09.560
那個時候反而是沒有什麼extremism

52:09.560 --> 52:11.560
所以這是為什麼在

52:11.560 --> 52:13.560
在這種情況底下

52:13.560 --> 52:15.560
lower credibility news can create logic

52:15.560 --> 52:17.560
因為這個時候population裡面還是

52:17.560 --> 52:19.560
很多的extremism

52:19.560 --> 52:21.560
但是反而在你讓那個news

52:21.560 --> 52:23.560
非常fully credible的時候反而沒有什麼

52:23.560 --> 52:25.560
extremism所以就沒有

52:25.560 --> 52:27.560
這種news spread的產生

52:27.560 --> 52:29.560
就是說news spread的size會比較小

52:31.560 --> 52:33.560
好

52:33.560 --> 52:35.560
那最後一個階段比較有趣一點

52:35.560 --> 52:37.560
就是說我們考慮到說

52:37.560 --> 52:39.560
這個population的case

52:39.560 --> 52:41.560
其實你可以大家就直接想像

52:41.560 --> 52:43.560
每個人他的

52:43.560 --> 52:45.560
either他是from共和黨

52:45.560 --> 52:47.560
either from民主黨

52:47.560 --> 52:49.560
如果他是from共和黨就是紅色這個

52:49.560 --> 52:51.560
這個curve

52:51.560 --> 52:53.560
然後他就是randomly drawn from

52:53.560 --> 52:55.560
這個distribution

52:55.560 --> 52:57.560
然後如果是藍色

52:57.560 --> 52:59.560
如果他一開始是偏民主黨的話

52:59.560 --> 53:01.560
那他可能就是在左邊

53:01.560 --> 53:03.560
這個random這個population

53:03.560 --> 53:05.560
跟黨內的這個

53:05.560 --> 53:07.560
多元化的程度

53:07.560 --> 53:09.560
第一個就是μbar

53:09.560 --> 53:11.560
如果這個μbar很大的話就代表說population越強

53:11.560 --> 53:13.560
兩端的這個peak是

53:13.560 --> 53:15.560
離各自越遠

53:15.560 --> 53:17.560
然後σμ的話就代表說

53:17.560 --> 53:19.560
這個variance在

53:19.560 --> 53:21.560
這個黨內的大小是多少

53:21.560 --> 53:23.560
就大家可以只要記得這些事情就好了

53:25.560 --> 53:27.560
然後這個圖呢

53:27.560 --> 53:29.560
其實就最有趣的圖就是這樣子

53:29.560 --> 53:31.560
就是說

53:31.560 --> 53:33.560
給定的news和cost

53:33.560 --> 53:35.560
然後我去問說

53:35.560 --> 53:37.560
因為我剛才已經講了嘛

53:37.560 --> 53:39.560
只要這個network

53:39.560 --> 53:41.560
足夠的

53:41.560 --> 53:43.560
就是只要你的平均的

53:43.560 --> 53:45.560
follower數

53:45.560 --> 53:47.560
超過了一個threshold之後呢

53:47.560 --> 53:49.560
你就會使得這些

53:49.560 --> 53:51.560
less credible news

53:51.560 --> 53:53.560
傳得比較遠

53:53.560 --> 53:55.560
所以我只需要去討論

53:55.560 --> 53:57.560
到底這個population跟這個

53:57.560 --> 53:59.560
diversity如何去影響

53:59.560 --> 54:01.560
這樣子的一個threshold

54:01.560 --> 54:03.560
如果我讓他的threshold降得更低

54:03.560 --> 54:05.560
那代表有更多的network

54:05.560 --> 54:07.560
可以使得這種

54:07.560 --> 54:09.560
less credible news

54:09.560 --> 54:11.560
如果我讓這個threshold變得更高

54:11.560 --> 54:13.560
那代表說只有那一些

54:13.560 --> 54:15.560
非常非常緊密的network

54:15.560 --> 54:17.560
才有可能使得

54:17.560 --> 54:19.560
less credible news就是傳得比較遠

54:19.560 --> 54:21.560
所以這邊第一個

54:21.560 --> 54:23.560
結論就是說

54:23.560 --> 54:25.560
沿著這條綠色線你會發現說

54:25.560 --> 54:27.560
把population變大的時候呢

54:27.560 --> 54:29.560
你降低了

54:29.560 --> 54:31.560
這個threshold

54:31.560 --> 54:33.560
meaning that

54:33.560 --> 54:35.560
其實有更多的network可以使得

54:35.560 --> 54:37.560
就是甚至連不緊密的network

54:37.560 --> 54:39.560
都可以使得這種

54:39.560 --> 54:41.560
less credible news

54:41.560 --> 54:43.560
傳得更遠

54:43.560 --> 54:45.560
另外是

54:45.560 --> 54:47.560
那就我剛才講的就是

54:47.560 --> 54:49.560
這ingroup diversity到底能不能幫忙

54:49.560 --> 54:51.560
改變這樣子的一個

54:51.560 --> 54:53.560
態勢

54:53.560 --> 54:55.560
你會發現說其實

54:55.560 --> 54:57.560
第一可是如果說

54:57.560 --> 54:59.560
這個population其實很小很小的時候

54:59.560 --> 55:01.560
如果你在一個population

55:01.560 --> 55:03.560
不大的一個社會

55:03.560 --> 55:05.560
你去改變這個ingroup diversity的時候

55:05.560 --> 55:07.560
會發生什麼事?其實你去

55:07.560 --> 55:09.560
你這時候加了ingroup diversity

55:09.560 --> 55:11.560
你其實反而是去增加了

55:11.560 --> 55:13.560
更多的極端的那一些人的想法

55:13.560 --> 55:15.560
就是你知道你把variance變大之後

55:15.560 --> 55:17.560
就更多人在極端的那個部分

55:17.560 --> 55:19.560
所以反而其實它會增加

55:19.560 --> 55:21.560
那一些less credible news

55:21.560 --> 55:23.560
被傳播的

55:23.560 --> 55:25.560
可能性所以它就

55:25.560 --> 55:27.560
導致那個spread size其實是

55:27.560 --> 55:29.560
更容易變大

55:29.560 --> 55:31.560
然後降低了這個threshold

55:31.560 --> 55:33.560
network threshold

55:33.560 --> 55:35.560
但如果說其實這個population

55:35.560 --> 55:37.560
其實somehow還蠻大

55:37.560 --> 55:39.560
大過這個news本身的話

55:39.560 --> 55:41.560
其實如果你增加的話

55:41.560 --> 55:43.560
其實是可以降低

55:43.560 --> 55:45.560
這個news

55:45.560 --> 55:47.560
這個less credible news被傳播的

55:47.560 --> 55:49.560
大小

55:49.560 --> 55:51.560
但是一旦到你

55:51.560 --> 55:53.560
大過了某一個程度的時候

55:53.560 --> 55:55.560
其實又反向的它會

55:57.560 --> 55:59.560
使得這個less credible news

55:59.560 --> 56:01.560
被傳播的更遠

56:01.560 --> 56:03.560
原因是因為當你把diversity

56:03.560 --> 56:05.560
這樣增高的太快的時候

56:05.560 --> 56:07.560
其實你又

56:07.560 --> 56:09.560
再一次的使得這個

56:09.560 --> 56:11.560
社會出現了很多的這種極端的

56:11.560 --> 56:13.560
想法的人,然後他們其實都很願意

56:13.560 --> 56:15.560
去傳一些less credible news

56:15.560 --> 56:17.560
所以

56:17.560 --> 56:19.560
為什麼其實include diversity

56:19.560 --> 56:21.560
你去增加它,有時候是可以的

56:21.560 --> 56:23.560
但是增加太過不是一件好事

56:27.560 --> 56:29.560
你要conclude,但是我問一下最後一個點

56:29.560 --> 56:31.560
你剛剛是說diversity增加的時候

56:31.560 --> 56:33.560
極端的人

56:33.560 --> 56:35.560
就會變多

56:35.560 --> 56:37.560
對對

56:37.560 --> 56:39.560
我給大家看一下這個圖就好了

56:39.560 --> 56:41.560
就是說

56:41.560 --> 56:43.560
因為我現在都是等於是說給定一個數字

56:43.560 --> 56:45.560
我只

56:45.560 --> 56:47.560
變換了另外一個的東西

56:47.560 --> 56:49.560
的magnitude

56:49.560 --> 56:51.560
對吧

56:51.560 --> 56:53.560
所以其實你看這個圖

56:53.560 --> 56:55.560
只要看紅色的部分就好了

56:55.560 --> 56:57.560
假設紅色的peak固定在1這個點

56:57.560 --> 56:59.560
其實它就固定在1這個點

56:59.560 --> 57:01.560
你把這個variance變大的時候

57:01.560 --> 57:03.560
其實它同時

57:03.560 --> 57:05.560
以distribution來講兩邊

57:05.560 --> 57:07.560
其實它有點把

57:07.560 --> 57:09.560
其實是有把一些

57:09.560 --> 57:11.560
extremist推得更極端

57:11.560 --> 57:13.560
所以導致說

57:13.560 --> 57:15.560
對

57:15.560 --> 57:17.560
這感覺是一個很強的assumption

57:17.560 --> 57:19.560
因為第一個是你不要先假設

57:19.560 --> 57:21.560
右派或左派

57:21.560 --> 57:23.560
它的分佈是高懸

57:23.560 --> 57:25.560
然後第二個是

57:25.560 --> 57:27.560
第二個是

57:27.560 --> 57:29.560
他們

57:29.560 --> 57:31.560
對啊這個好像

57:31.560 --> 57:33.560
非常複雜

57:33.560 --> 57:35.560
假設你變得比較寬一點

57:35.560 --> 57:37.560
在你這個情況裡面就diversity變高

57:37.560 --> 57:39.560
那

57:39.560 --> 57:41.560
這些比較extreme的人

57:41.560 --> 57:43.560
群體的影響到底是什麼

57:43.560 --> 57:45.560
好像

57:45.560 --> 57:47.560
等於是說

57:47.560 --> 57:49.560
在我們這個model裡面其實就是說

57:49.560 --> 57:51.560
我剛才講extremist他沒有很強

57:51.560 --> 57:53.560
比那種moderate鐵定

57:53.560 --> 57:55.560
他的強

57:55.560 --> 57:57.560
因為我剛才其實有看

57:57.560 --> 57:59.560
那個utility function的話你會知道說

57:59.560 --> 58:01.560
他如果覺得大家投錯的話對他來講

58:01.560 --> 58:03.560
傷害比較大

58:03.560 --> 58:05.560
他希望大家真的去投對

58:05.560 --> 58:07.560
所以像

58:07.560 --> 58:09.560
這個情況底下就是說其實如果

58:09.560 --> 58:11.560
很多人都還蠻

58:11.560 --> 58:13.560
polarization不大的時候

58:13.560 --> 58:15.560
反而你去增加這個variance的時候

58:15.560 --> 58:17.560
你其實是把很多人都push away到那個極端去

58:17.560 --> 58:19.560
所以才會導致說其實那個時候

58:19.560 --> 58:21.560
如果這個社會已經不是很分化的話

58:21.560 --> 58:23.560
其實你沒有必要去增加diversity

58:23.560 --> 58:25.560
但

58:25.560 --> 58:27.560
當你這個社會比較極端一點

58:27.560 --> 58:29.560
就像你剛才講的

58:29.560 --> 58:31.560
然後你把variance變大的時候

58:31.560 --> 58:33.560
其實你一開始是有點降低了

58:33.560 --> 58:35.560
在極端的那一部分的人的

58:35.560 --> 58:37.560
數量

58:37.560 --> 58:39.560
但是其實

58:39.560 --> 58:41.560
比較詭異的事情是如果你增加diversity

58:41.560 --> 58:43.560
你反而增加了

58:43.560 --> 58:45.560
然後原本他是民主黨的人

58:45.560 --> 58:47.560
結果你增加了diversity之後反而他居然有一些

58:47.560 --> 58:49.560
很極端在民主黨裡面的人

58:49.560 --> 58:51.560
居然去支持了川普

58:51.560 --> 58:53.560
是蠻奇怪的啦

58:53.560 --> 58:55.560
但是就是這是一個你知道

58:55.560 --> 58:57.560
在分析上說我們導出

58:57.560 --> 58:59.560
這樣的結果

58:59.560 --> 59:01.560
然後的確他

59:01.560 --> 59:03.560
他其實也不是我講Gaussian like

59:03.560 --> 59:05.560
他也不是只有Gaussian

59:05.560 --> 59:07.560
他還是有一些

59:07.560 --> 59:09.560
我沒有把他們比較generalize一點

59:09.560 --> 59:11.560
但是就是說他還是在某一個class的function

59:11.560 --> 59:13.560
底下

59:13.560 --> 59:15.560
就是他會滿足這樣子的現象

59:15.560 --> 59:17.560
但如果你考慮了一些function

59:17.560 --> 59:19.560
out of那個class的話

59:19.560 --> 59:21.560
那可能就會有不一樣的結果

59:21.560 --> 59:23.560
但是對這是我們目前得到的一些insight

59:23.560 --> 59:25.560
ok

59:25.560 --> 59:27.560
對然後

59:27.560 --> 59:29.560
然後我就conclude

59:29.560 --> 59:31.560
等於是說我們

59:31.560 --> 59:33.560
provide這個model

59:33.560 --> 59:35.560
去study some new sharing decision

59:35.560 --> 59:37.560
然後還有非常這種individual sharing decision

59:37.560 --> 59:39.560
什麼樣的新聞會傳得比較遠

59:39.560 --> 59:41.560
然後包含像

59:41.560 --> 59:43.560
他怎麼跟這個

59:45.560 --> 59:47.560
這個社會的一些特性有關

59:47.560 --> 59:49.560
然後我們就

59:49.560 --> 59:51.560
在裡頭我們會發現其實

59:51.560 --> 59:53.560
polarization一旦你把它增大的話

59:53.560 --> 59:55.560
鐵定就是會使得這種

59:55.560 --> 59:57.560
less credible news

59:57.560 --> 59:59.560
更容易被傳

59:59.560 --> 01:00:01.560
因為他其實somehow增加兩端

01:00:01.560 --> 01:00:03.560
extremist的

01:00:03.560 --> 01:00:05.560
數量

01:00:05.560 --> 01:00:07.560
所以他其實使得這個社會

01:00:07.560 --> 01:00:09.560
更容易去傳的這種less credible news

01:00:09.560 --> 01:00:11.560
那另外就是說如果你去增加

01:00:11.560 --> 01:00:13.560
這種perspective discrepancy

01:00:13.560 --> 01:00:15.560
就是我們剛才在討論

01:00:15.560 --> 01:00:17.560
跟Sean在討論的問題就是說

01:00:17.560 --> 01:00:19.560
其實

01:00:19.560 --> 01:00:21.560
it really depends on

01:00:21.560 --> 01:00:23.560
你到底怎麼樣影響

01:00:23.560 --> 01:00:25.560
那些extremist的分布

01:00:25.560 --> 01:00:27.560
好謝謝大家

01:00:27.560 --> 01:00:29.560
我希望這個

01:00:29.560 --> 01:00:31.560
就是如果大家真的很感興趣

01:00:31.560 --> 01:00:33.560
裡頭那些technical的部分的話

01:00:33.560 --> 01:00:35.560
就可以看一下

01:00:35.560 --> 01:00:37.560
那個paper

01:00:37.560 --> 01:00:39.560
因為我其實obstruct蠻多的

01:00:39.560 --> 01:00:41.560
technical的部分

01:00:41.560 --> 01:00:43.560
大家可能有些地方有點聽到了

01:00:43.560 --> 01:00:45.560
有點覺得好像不太懂

01:00:45.560 --> 01:00:47.560
對所以不好意思

01:00:47.560 --> 01:00:49.560
不好意思我可以再問

01:00:49.560 --> 01:00:51.560
再追問一下那個diversity

01:00:51.560 --> 01:00:53.560
的問題嗎

01:00:53.560 --> 01:00:55.560
有一個情況是

01:00:55.560 --> 01:00:57.560
如果我們單純考慮你剛剛的

01:00:57.560 --> 01:00:59.560
兩個高懸

01:00:59.560 --> 01:01:01.560
譬如說右邊的那個

01:01:01.560 --> 01:01:03.560
distribution他的

01:01:03.560 --> 01:01:05.560
極端值

01:01:05.560 --> 01:01:07.560
他的左側極端值

01:01:07.560 --> 01:01:09.560
其實會接近另一個distribution的

01:01:09.560 --> 01:01:11.560
中間值

01:01:11.560 --> 01:01:13.560
他的tail如果沒有這麼大的話

01:01:13.560 --> 01:01:15.560
所以換句話說在某些情況底下

01:01:15.560 --> 01:01:17.560
在某一個檔裡面的比較extreme的人

01:01:17.560 --> 01:01:19.560
可能反而是比較

01:01:19.560 --> 01:01:21.560
就是

01:01:21.560 --> 01:01:23.560
接近兩群人的比較中間的分布

01:01:23.560 --> 01:01:25.560
懂我意思嗎譬如說

01:01:25.560 --> 01:01:27.560
就像你剛剛舉的那個例子

01:01:27.560 --> 01:01:29.560
假設我今天是民主黨的人

01:01:29.560 --> 01:01:31.560
然後我去支持一個共和黨的候選人

01:01:31.560 --> 01:01:33.560
就Trump是一個極端中的極端

01:01:33.560 --> 01:01:35.560
我們就假設一個一般的正常的共和黨候選人

01:01:35.560 --> 01:01:37.560
那可能表示的不是

01:01:37.560 --> 01:01:39.560
就是同時表示的

01:01:39.560 --> 01:01:41.560
我是民主黨裡面比較極端的人

01:01:41.560 --> 01:01:43.560
可是同時在整群人裡面的distribution裡面

01:01:43.560 --> 01:01:45.560
我可能是比較接近中間的

01:01:45.560 --> 01:01:47.560
懂我意思嗎

01:01:47.560 --> 01:01:49.560
對

01:01:49.560 --> 01:01:51.560
換句話說就是

01:01:51.560 --> 01:01:53.560
每一個distribution裡面都有兩端

01:01:53.560 --> 01:01:55.560
那一端就會是真正的extremist

01:01:55.560 --> 01:01:57.560
對不對

01:01:57.560 --> 01:01:59.560
就是那一端譬如說

01:01:59.560 --> 01:02:01.560
他是左派中的左派或右派中的右派

01:02:01.560 --> 01:02:03.560
可是如果是右派中的左派

01:02:03.560 --> 01:02:05.560
跟左派中的右派呢

01:02:05.560 --> 01:02:07.560
好像他反而會往群體之間集中

01:02:07.560 --> 01:02:09.560
那他們兩群人表現出來的行為

01:02:09.560 --> 01:02:11.560
好像會有一點點不太一樣

01:02:11.560 --> 01:02:13.560
我也有類似的問題

01:02:13.560 --> 01:02:15.560
就是這個右下角這個圖

01:02:15.560 --> 01:02:17.560
比如說

01:02:17.560 --> 01:02:19.560
為什麼在zero

01:02:19.560 --> 01:02:21.560
就是說在紅色zero左邊的還是紅色

01:02:21.560 --> 01:02:23.560
他就不是變成藍色

01:02:23.560 --> 01:02:25.560
就是那個

01:02:25.560 --> 01:02:27.560
我這邊的紅色跟藍色

01:02:27.560 --> 01:02:29.560
就是說他一開始他挑的黨是什麼

01:02:29.560 --> 01:02:31.560
然後但是他可能在這件事情

01:02:31.560 --> 01:02:33.560
大家在這件事情裡頭

01:02:33.560 --> 01:02:35.560
你知道就像

01:02:35.560 --> 01:02:37.560
共和黨裡面也有人覺得

01:02:37.560 --> 01:02:39.560
他不喜歡川普這種感覺

01:02:39.560 --> 01:02:41.560
所以這個grouping跟這個

01:02:41.560 --> 01:02:43.560
vote decision是

01:02:43.560 --> 01:02:45.560
兩件

01:02:45.560 --> 01:02:47.560
這不是一個overlap的事情

01:02:47.560 --> 01:02:49.560
對等於是說

01:02:49.560 --> 01:02:51.560
這個model就是說一開始我們要怎麼樣去決定

01:02:51.560 --> 01:02:53.560
每一個人的perspective

01:02:53.560 --> 01:02:55.560
就是他的perspective是怎麼被randomly抽出來

01:02:55.560 --> 01:02:57.560
一開始就說我先投一個硬幣

01:02:57.560 --> 01:02:59.560
一半一半他是共和黨一半是民主黨

01:02:59.560 --> 01:03:01.560
但是他是民主黨之後我就知道說

01:03:01.560 --> 01:03:03.560
他可能concentrate在那個peak

01:03:03.560 --> 01:03:05.560
在E那個附近

01:03:05.560 --> 01:03:07.560
但他也有可能在這件事情他可能是

01:03:07.560 --> 01:03:09.560
你知道他可能非常極端

01:03:09.560 --> 01:03:11.560
他跑去支持了偏民主黨的部分

01:03:11.560 --> 01:03:13.560
對

01:03:13.560 --> 01:03:15.560
然後

01:03:15.560 --> 01:03:17.560
其實剛才根據那個Sean講的東西

01:03:17.560 --> 01:03:19.560
就是說其實

01:03:19.560 --> 01:03:21.560
呃

01:03:21.560 --> 01:03:23.560
我想一下因為

01:03:23.560 --> 01:03:25.560
等於是說你可以

01:03:25.560 --> 01:03:27.560
我可以再elaborate一下意思就是說

01:03:27.560 --> 01:03:29.560
當有在某一群人裡面的

01:03:29.560 --> 01:03:31.560
polarization

01:03:31.560 --> 01:03:33.560
在你這個裡面第一是diversity

01:03:33.560 --> 01:03:35.560
在那群人裡面的diversity產生的時候

01:03:35.560 --> 01:03:37.560
diversify產生的時候

01:03:37.560 --> 01:03:39.560
一邊的人其實是會往

01:03:39.560 --> 01:03:41.560
average那邊

01:03:41.560 --> 01:03:43.560
就是移過去

01:03:43.560 --> 01:03:45.560
然後另一個人其實是整整的

01:03:45.560 --> 01:03:47.560
就是extremist

01:03:47.560 --> 01:03:49.560
那這兩群人的行為感覺

01:03:49.560 --> 01:03:51.560
是可以分開來討論的

01:03:51.560 --> 01:03:53.560
對對對其實應該這樣講

01:03:53.560 --> 01:03:55.560
為什麼我一開始說

01:03:55.560 --> 01:03:57.560
其實如果polarization變大的時候

01:03:57.560 --> 01:03:59.560
其實一開始你增加diversity

01:03:59.560 --> 01:04:01.560
不是反而更好嗎

01:04:01.560 --> 01:04:03.560
就你還記得我

01:04:03.560 --> 01:04:05.560
你還記得我剛才那個結論其實是

01:04:05.560 --> 01:04:07.560
呃

01:04:07.560 --> 01:04:09.560
下面的嗎就是說其實

01:04:09.560 --> 01:04:11.560
increasing是好的

01:04:11.560 --> 01:04:13.560
因為你讓那個threshold變大就是變得更難的意思

01:04:13.560 --> 01:04:15.560
所以就是說

01:04:15.560 --> 01:04:17.560
一開始其實你在

01:04:17.560 --> 01:04:19.560
你知道它其實它都有一個相對的極端值

01:04:19.560 --> 01:04:21.560
就是如果你polarization已經很大

01:04:21.560 --> 01:04:23.560
就等於說你的peak其實有點落在

01:04:23.560 --> 01:04:25.560
其實不是1可能是落在一個你知道

01:04:25.560 --> 01:04:27.560
3的位置然後如果你這個時候

01:04:27.560 --> 01:04:29.560
然後這個新聞其實比較

01:04:29.560 --> 01:04:31.560
沒那麼極端

01:04:31.560 --> 01:04:33.560
然後等於是說如果你

01:04:33.560 --> 01:04:35.560
把diversity降低的時候

01:04:35.560 --> 01:04:37.560
你等於是somehow你把那個distribution

01:04:37.560 --> 01:04:39.560
壓平了對吧

01:04:39.560 --> 01:04:41.560
所以其實你也把

01:04:41.560 --> 01:04:43.560
diversity升高吧

01:04:43.560 --> 01:04:45.560
diversity升高之後其實你有點

01:04:45.560 --> 01:04:47.560
那個shape原本是這樣子

01:04:47.560 --> 01:04:49.560
因為diversity小的時候

01:04:49.560 --> 01:04:51.560
其實它就比較寬

01:04:51.560 --> 01:04:53.560
對但你看變寬的時候其實你會發現說

01:04:53.560 --> 01:04:55.560
其實這個越extremist

01:04:55.560 --> 01:04:57.560
原本是偏右的extremist

01:04:57.560 --> 01:04:59.560
那個數量其實是會減低的

01:04:59.560 --> 01:05:01.560
是會減低

01:05:01.560 --> 01:05:03.560
因為它對吧因為你現在

01:05:03.560 --> 01:05:05.560
假設你peak在這邊

01:05:05.560 --> 01:05:07.560
然後如果你把它壓低的話

01:05:07.560 --> 01:05:09.560
很多人其實開始往左邊跑

01:05:09.560 --> 01:05:11.560
另外的為什麼到後來

01:05:11.560 --> 01:05:13.560
它又開始有點

01:05:13.560 --> 01:05:15.560
反向的又變化是因為

01:05:15.560 --> 01:05:17.560
就我剛才講的就其實就像你講的

01:05:17.560 --> 01:05:19.560
剛才民主黨有一些人他原本

01:05:19.560 --> 01:05:21.560
你知道接近那個民主黨的peak

01:05:21.560 --> 01:05:23.560
但是你一旦把那個diversity變高的時候

01:05:23.560 --> 01:05:25.560
它開始去接近了

01:05:25.560 --> 01:05:27.560
共和黨的部分它可能一開始在moderate

01:05:27.560 --> 01:05:29.560
那個時候可能還在

01:05:29.560 --> 01:05:31.560
increasing的階段但是一旦它

01:05:31.560 --> 01:05:33.560
也變成了共和黨的

01:05:33.560 --> 01:05:35.560
extremist的時候它就變decreasing

01:05:35.560 --> 01:05:37.560
所以那個是就是那個

01:05:37.560 --> 01:05:39.560
consistion的變化是這樣

01:05:39.560 --> 01:05:41.560
所以比較像是

01:05:41.560 --> 01:05:43.560
比較像是在model

01:05:43.560 --> 01:05:45.560
裡面比較會產生的事情

01:05:45.560 --> 01:05:47.560
現實狀況好像不太容易產生

01:05:47.560 --> 01:05:49.560
對等於說現實狀況

01:05:49.560 --> 01:05:51.560
底下是說

01:05:51.560 --> 01:05:53.560
pratically就是說問題在於

01:05:53.560 --> 01:05:55.560
你要怎麼measure這個polarization

01:05:55.560 --> 01:05:57.560
跟那個diversity就是說

01:05:57.560 --> 01:05:59.560
我覺得還是可以somehow可以用Gaussian like

01:05:59.560 --> 01:06:01.560
去model這個問題

01:06:01.560 --> 01:06:03.560
就是說這個diversity的那個量度

01:06:03.560 --> 01:06:05.560
到底在哪裡還有那個polarization

01:06:05.560 --> 01:06:07.560
然後還有那個news本身

01:06:07.560 --> 01:06:09.560
所以就變成是這些問題

01:06:09.560 --> 01:06:11.560
就是說你可能會覺得

01:06:11.560 --> 01:06:13.560
這個嗎給一個8好像有點誇張

01:06:13.560 --> 01:06:15.560
但是有可能現實生活中其實我們可能只考慮

01:06:15.560 --> 01:06:17.560
那個2-4的那個範圍

01:06:17.560 --> 01:06:19.560
對就是

01:06:19.560 --> 01:06:21.560
有點像是給大家

01:06:21.560 --> 01:06:23.560
一個idea說這個趨勢會是怎麼樣

01:06:23.560 --> 01:06:25.560
但實際上在哪一個範圍就不知道

01:06:25.560 --> 01:06:27.560
了解了解

01:06:27.560 --> 01:06:29.560
不好意思我再追問一個問題

01:06:29.560 --> 01:06:31.560
就是因為你的那個credibility是

01:06:31.560 --> 01:06:33.560
基本上在0跟1

01:06:33.560 --> 01:06:35.560
換句話來說你的

01:06:35.560 --> 01:06:37.560
less credible或者是

01:06:37.560 --> 01:06:39.560
lower credibility其實意思是相對於

01:06:39.560 --> 01:06:41.560
1來講

01:06:41.560 --> 01:06:43.560
相對於

01:06:43.560 --> 01:06:45.560
fully credible的news來講

01:06:45.560 --> 01:06:47.560
你往低一點點的地方走

01:06:47.560 --> 01:06:49.560
反而傳播的會就是尺度會比較大

01:06:49.560 --> 01:06:51.560
那

01:06:51.560 --> 01:06:53.560
會不會對應到

01:06:53.560 --> 01:06:55.560
真實世界上你的

01:06:55.560 --> 01:06:57.560
lower credibility的news

01:06:57.560 --> 01:06:59.560
其實就是像CNN這樣的outlet

01:06:59.560 --> 01:07:01.560
因為在現實世界上不會有

01:07:01.560 --> 01:07:03.560
真正是1的news outlet

01:07:03.560 --> 01:07:05.560
所以你的

01:07:05.560 --> 01:07:07.560
less credible news傳的比較遠

01:07:07.560 --> 01:07:09.560
其實是對應到真實世界的

01:07:09.560 --> 01:07:11.560
我們覺得有很高的credible

01:07:11.560 --> 01:07:13.560
的那些news outlet或者是news

01:07:13.560 --> 01:07:15.560
對

01:07:15.560 --> 01:07:17.560
我們也有在想

01:07:17.560 --> 01:07:19.560
這個問題就是說

01:07:23.560 --> 01:07:25.560
對因為

01:07:25.560 --> 01:07:27.560
我們的確有在想過這個問題就是說

01:07:27.560 --> 01:07:29.560
其實生活中其實不是

01:07:29.560 --> 01:07:31.560
那麼的fully credible news

01:07:31.560 --> 01:07:33.560
但是

01:07:33.560 --> 01:07:35.560
但是你還是可以知道說

01:07:35.560 --> 01:07:37.560
就是

01:07:37.560 --> 01:07:39.560
因為這個地方可能只有一些

01:07:39.560 --> 01:07:41.560
quotative的case就是它只告訴你說

01:07:41.560 --> 01:07:43.560
跟1比的話它

01:07:43.560 --> 01:07:45.560
下降你把1往下降之後

01:07:45.560 --> 01:07:47.560
它可能這個

01:07:47.560 --> 01:07:49.560
scale會變大spread size會變大

01:07:49.560 --> 01:07:51.560
但它沒有

01:07:51.560 --> 01:07:53.560
足夠的訊息告訴你說它到底是

01:07:55.560 --> 01:07:57.560
哪一段它是會變大的

01:07:57.560 --> 01:07:59.560
我只有告訴你那個趨勢是會變大

01:07:59.560 --> 01:08:01.560
但是你可能說說不定它

01:08:01.560 --> 01:08:03.560
1到0.95的時候是變大

01:08:03.560 --> 01:08:05.560
但是0.95之後又下去了

01:08:05.560 --> 01:08:07.560
對吧有可能它的peak是發展在0.9

01:08:07.560 --> 01:08:09.560
所以那個地方我就

01:08:09.560 --> 01:08:11.560
不知道了

01:08:11.560 --> 01:08:13.560
所以你們現在可以估計出來

01:08:13.560 --> 01:08:15.560
它的peak大概會長在什麼地方

01:08:15.560 --> 01:08:17.560
現在是沒有辦法

01:08:17.560 --> 01:08:19.560
因為它這個等於你要solve

01:08:19.560 --> 01:08:21.560
那個optimization question

01:08:21.560 --> 01:08:23.560
然後就會等於是

01:08:23.560 --> 01:08:25.560
所以我們後來就只有

01:08:25.560 --> 01:08:27.560
比較像是告訴你說

01:08:27.560 --> 01:08:29.560
所以我們的argument都比較偏向

01:08:29.560 --> 01:08:31.560
less credible跟

01:08:31.560 --> 01:08:33.560
fully credible

01:08:33.560 --> 01:08:35.560
因為我猜測就是

01:08:35.560 --> 01:08:37.560
因為講less credible的時候大家心目中

01:08:37.560 --> 01:08:39.560
跑出來的東西有點不太一樣

01:08:39.560 --> 01:08:41.560
因為在你的model裡面

01:08:41.560 --> 01:08:43.560
less credible的意思就是相對於

01:08:43.560 --> 01:08:45.560
比較不credible嘛

01:08:45.560 --> 01:08:47.560
那我剛剛問這個問題

01:08:47.560 --> 01:08:49.560
應該是下一個問題其實就是

01:08:49.560 --> 01:08:51.560
如果你們能夠預測出來

01:08:51.560 --> 01:08:53.560
你們可以estimate出來那個peak在哪裡

01:08:53.560 --> 01:08:55.560
有可能你把那個model應用到

01:08:55.560 --> 01:08:57.560
真實生活中的時候

01:08:57.560 --> 01:08:59.560
你可以來算每一個新聞outlet的peak

01:08:59.560 --> 01:09:01.560
那或許算出來你們的

01:09:01.560 --> 01:09:03.560
less credible的

01:09:03.560 --> 01:09:05.560
在你們model裡面的news outlet

01:09:05.560 --> 01:09:07.560
對應到真實世界其實就是我們覺得

01:09:07.560 --> 01:09:09.560
比較有credible的那些

01:09:09.560 --> 01:09:11.560
就是如果兩邊可以對應起來的話

01:09:11.560 --> 01:09:13.560
故事就會通

01:09:13.560 --> 01:09:15.560
應該這樣講就是說

01:09:15.560 --> 01:09:17.560
我

01:09:17.560 --> 01:09:19.560
我們有所有的equation你可以用

01:09:19.560 --> 01:09:21.560
就甚至你要用

01:09:21.560 --> 01:09:23.560
用那種

01:09:23.560 --> 01:09:25.560
去算那個peak也可以

01:09:25.560 --> 01:09:27.560
只是

01:09:27.560 --> 01:09:29.560
因為我沒有辦法去證明說那個peak

01:09:29.560 --> 01:09:31.560
到底是

01:09:31.560 --> 01:09:33.560
會落在什麼區間你知道嗎

01:09:33.560 --> 01:09:35.560
就是我能mathematically

01:09:35.560 --> 01:09:37.560
proof的東西就是告訴你說

01:09:37.560 --> 01:09:39.560
它有這個趨勢就是

01:09:39.560 --> 01:09:41.560
那個condition是什麼但是

01:09:41.560 --> 01:09:43.560
我們有所有的equation就是你可以去

01:09:43.560 --> 01:09:45.560
用collaboration就是說去算

01:09:45.560 --> 01:09:47.560
那到底那個peak會長什麼

01:09:47.560 --> 01:09:49.560
在哪個位置如果你用computational

01:09:49.560 --> 01:09:51.560
可以算只是說

01:09:51.560 --> 01:09:53.560
我沒有辦法mathematically proof

01:09:53.560 --> 01:09:55.560
那個peak的點在哪裡

01:09:55.560 --> 01:09:57.560
或者是它到哪裡會下降

01:09:57.560 --> 01:09:59.560
就有點

01:09:59.560 --> 01:10:01.560
那個就對我們來講比較難

01:10:01.560 --> 01:10:03.560
謝謝

01:10:09.560 --> 01:10:11.560
主持人回來了

01:10:11.560 --> 01:10:13.560
就是我們這個演講

01:10:13.560 --> 01:10:15.560
基本上是一個小時

01:10:15.560 --> 01:10:17.560
之前跟靜嘉講是一個小時

01:10:17.560 --> 01:10:19.560
大概50分鐘的演講然後大概10到

01:10:19.560 --> 01:10:21.560
20分鐘的Q&A討論

01:10:21.560 --> 01:10:23.560
但是我們今天的形式所以變得比較像是

01:10:23.560 --> 01:10:25.560
就是在演講過程中

01:10:25.560 --> 01:10:27.560
就參雜了Q&A

01:10:27.560 --> 01:10:29.560
所以我基本上就是當作我們已經

01:10:29.560 --> 01:10:31.560
把Q&A結束了所以現在就是看說

01:10:31.560 --> 01:10:33.560
靜嘉願不願意再多

01:10:33.560 --> 01:10:35.560
留一點時間然後

01:10:35.560 --> 01:10:37.560
可以再繼續做討論那我不知道你

01:10:37.560 --> 01:10:39.560
大概願意再多大概10分鐘嗎

01:10:39.560 --> 01:10:41.560
再繼續簡單討論

01:10:43.560 --> 01:10:45.560
可以3點半嗎

01:10:45.560 --> 01:10:47.560
3點半因為我剛好跟嘉佑約了

01:10:47.560 --> 01:10:49.560
3點半沒關係

01:10:49.560 --> 01:10:51.560
ok所以就是7分鐘後

01:10:51.560 --> 01:10:53.560
對但大家也可以

01:10:53.560 --> 01:10:55.560
就是如果還有什麼其他問題的話

01:10:55.560 --> 01:10:57.560
可以就是email我

01:10:57.560 --> 01:10:59.560
然後我可以在這邊先answer一些

01:10:59.560 --> 01:11:01.560
就是可能比較大方向的question

01:11:01.560 --> 01:11:03.560
好那我先做

01:11:03.560 --> 01:11:05.560
另外一件事情就是我可不可以

01:11:05.560 --> 01:11:07.560
我就先把錄影先關掉了

01:11:07.560 --> 01:11:09.560
然後就是大家就

01:11:09.560 --> 01:11:11.560
對好那我就先關錄影

