WEBVTT

00:00.000 --> 00:03.000
Thank you, Yen-Yung.

00:03.000 --> 00:09.000
We have talked about how to join Project Terra.

00:09.000 --> 00:14.000
Today, we are going to start the lecture.

00:14.000 --> 00:17.000
Before we start, let me introduce the speaker.

00:17.000 --> 00:23.000
Today's speaker is Professor Hsieh Ming-Hsiu from Sydney University of Science and Technology.

00:23.000 --> 00:28.000
Professor Hsieh is also a senior at NTU.

00:28.000 --> 00:34.000
In 2008, he got his Ph.D. from the University of Sydney.

00:34.000 --> 00:39.000
He has worked in Japan and Cambridge.

00:39.000 --> 00:51.000
His research direction from Ph.D. to now is related to quantum computer and quantum information.

00:51.000 --> 00:56.000
His more detailed direction is related to quantum information.

00:56.000 --> 01:08.000
From the beginning of error correction to focus on quantum machine learning and different projects.

01:08.000 --> 01:15.000
Next, Professor Hsieh will introduce his research.

01:15.000 --> 01:21.000
By the way, I would like to promote that NTU will have a team this year.

01:21.000 --> 01:28.000
I hope we can work on quantum computing together.

01:28.000 --> 01:34.000
If you are interested, I believe Professor Hsieh can introduce the team later.

01:34.000 --> 01:37.000
There are electrical engineering and physics.

01:37.000 --> 01:40.000
I think this is a big project.

01:41.000 --> 01:46.000
I hope Professor Hsieh can introduce the team later.

01:46.000 --> 01:51.000
I believe this project is good for Taiwan's research.

01:51.000 --> 01:54.000
Professor Hsieh, you can start.

01:54.000 --> 01:58.000
Hello everyone, my name is Hsieh.

01:58.000 --> 02:01.000
Thank you, Hsieh Ming-Hsiu.

02:01.000 --> 02:06.000
I am very happy to share with you today.

02:06.000 --> 02:15.000
The Minister of Science and Technology has a SOC in NTU.

02:15.000 --> 02:17.000
System on Chip.

02:17.000 --> 02:20.000
They have a front page.

02:20.000 --> 02:26.000
They will find some front page topics every year.

02:26.000 --> 02:30.000
This year they chose quantum computation.

02:30.000 --> 02:33.000
They invited me to give a speech.

02:33.000 --> 02:36.000
Ted just mentioned that.

02:36.000 --> 02:43.000
Now Taiwan is starting to pay attention to quantum computation.

02:43.000 --> 02:48.000
Hardware or software development.

02:48.000 --> 02:52.000
The Ministry of Science and Technology has started to invest.

02:52.000 --> 02:55.000
Of course, there are many in Taiwan.

02:55.000 --> 02:58.000
But there are very few overseas.

02:58.000 --> 03:02.000
This year, there are about 7,000 to 7,500 million.

03:02.000 --> 03:11.000
Now they have set up a center for quantum technology in NTU.

03:11.000 --> 03:13.000
It's a five-year plan.

03:13.000 --> 03:15.000
There are 50 million in a year.

03:15.000 --> 03:17.000
The Ministry of Science and Technology has 25 million.

03:17.000 --> 03:20.000
The Ministry of Education has 25 million.

03:20.000 --> 03:25.000
I am also in charge of the International Advisory Board.

03:26.000 --> 03:31.000
After Taiwan started to invest in this place.

03:31.000 --> 03:33.000
There are many opportunities.

03:33.000 --> 03:36.000
If you happen to be in the field.

03:36.000 --> 03:40.000
In fact, there are many people in this field.

03:40.000 --> 03:43.000
Because quantum computing is a very cross-field.

03:43.000 --> 03:45.000
You can also find it in my talk later.

03:45.000 --> 03:47.000
It also has a lot to do with CS.

03:47.000 --> 03:50.000
It also needs to do these things now.

03:50.000 --> 03:54.000
For example, quantum control needs to be micro-wave controlled.

03:54.000 --> 03:57.000
So traditional micro-wave people can also come in.

03:57.000 --> 04:02.000
Then look at what your process is.

04:02.000 --> 04:04.000
Semiconductor talents can also come in.

04:04.000 --> 04:06.000
Superconductor talents can also come in.

04:06.000 --> 04:09.000
These classic physics people can also come in.

04:09.000 --> 04:15.000
So no matter what field you are.

04:15.000 --> 04:18.000
Engineering, science, or electronics.

04:18.000 --> 04:22.000
As long as you are interested in quantum computing.

04:22.000 --> 04:24.000
You can come in very quickly.

04:24.000 --> 04:29.000
In fact, I also studied a master's degree in Taiwan University.

04:29.000 --> 04:30.000
It's a telecommunications company.

04:30.000 --> 04:33.000
Then I went to Nanyang University to study for a doctorate.

04:33.000 --> 04:36.000
I just switched to quantum error correction.

04:36.000 --> 04:39.000
Then slowly do some information computation.

04:39.000 --> 04:43.000
Then I did a lot of other things.

04:43.000 --> 04:48.000
So what is it like to cross-field with students from science and engineering colleges?

04:53.000 --> 04:56.000
Some background introduction.

04:56.000 --> 04:57.000
Then there's my talk.

04:57.000 --> 05:03.000
Because I mainly prepared for the SOC workshop.

05:03.000 --> 05:04.000
It's only 40 minutes.

05:04.000 --> 05:08.000
So I probably only have 40 minutes of material.

05:08.000 --> 05:11.000
Then you can use Q&A later.

05:11.000 --> 05:15.000
See what kind of questions you have about this direction.

05:15.000 --> 05:17.000
You can bring it up.

05:17.000 --> 05:20.000
Of course, in the middle of my report later.

05:21.000 --> 05:25.000
You can also bring up any questions you have.

05:25.000 --> 05:28.000
Let me remind you.

05:28.000 --> 05:29.000
Sorry.

05:29.000 --> 05:32.000
Because we have a lot of participants today.

05:32.000 --> 05:33.000
So we have a prediction.

05:33.000 --> 05:37.000
The microphone is off when everyone enters.

05:37.000 --> 05:39.000
So if you want to ask a question.

05:39.000 --> 05:42.000
Please click on the microphone icon above.

05:42.000 --> 05:47.000
This way you won't feel ignored.

05:47.000 --> 05:51.000
We usually welcome questions at any time.

05:51.000 --> 05:54.000
But I'm afraid there's a lot of responses today.

05:54.000 --> 05:55.000
So when you ask a question.

05:55.000 --> 05:58.000
Please click on the icon.

05:58.000 --> 06:01.000
Okay, let's get started.

06:01.000 --> 06:06.000
Okay, I'll continue my report.

06:06.000 --> 06:10.000
This is my title page.

06:10.000 --> 06:14.000
I mainly want to introduce some.

06:14.000 --> 06:16.000
Because we know that machine learning.

06:16.000 --> 06:19.000
Now it's a very popular topic.

06:19.000 --> 06:22.000
Quantum Computation is another popular topic.

06:22.000 --> 06:25.000
Quantum Computation.

06:25.000 --> 06:29.000
Basically, everyone has a vague idea about it.

06:29.000 --> 06:31.000
That is, it can be used to do some.

06:31.000 --> 06:34.000
High-performance operations.

06:34.000 --> 06:36.000
So, uh.

06:36.000 --> 06:37.000
So, uh.

06:37.000 --> 06:39.000
About three or five years ago.

06:39.000 --> 06:40.000
In fact, earlier.

06:40.000 --> 06:42.000
Someone started to notice that.

06:42.000 --> 06:44.000
How to use quantum computers.

06:44.000 --> 06:47.000
To do some machine learning tasks.

06:47.000 --> 06:50.000
But it was said that the early development was slower.

06:50.000 --> 06:52.000
Because everyone said.

06:52.000 --> 06:54.000
Especially in academia.

06:54.000 --> 06:56.000
People will think that.

06:56.000 --> 07:00.000
Your effect on your quantum mechanics.

07:00.000 --> 07:03.000
Then your quantum computer.

07:03.000 --> 07:05.000
The power of this computation.

07:05.000 --> 07:07.000
Your definitions are not very clear yet.

07:07.000 --> 07:09.000
To do this quantum machine learning.

07:09.000 --> 07:12.000
It seems to be a bit, uh.

07:12.000 --> 07:14.000
A little bit of this.

07:14.000 --> 07:17.000
Uh, it's a little unrealistic.

07:17.000 --> 07:19.000
So, uh.

07:19.000 --> 07:21.000
So, uh.

07:21.000 --> 07:23.000
Before 2010.

07:23.000 --> 07:25.000
That is, in this quantum machine learning topic.

07:25.000 --> 07:27.000
In fact, very few people do it.

07:27.000 --> 07:29.000
Then, uh.

07:29.000 --> 07:31.000
The main results are also relatively limited.

07:31.000 --> 07:33.000
So, uh.

07:33.000 --> 07:35.000
Until the last three or five years.

07:35.000 --> 07:37.000
That is, everyone has been from this.

07:37.000 --> 07:39.000
Uh, this technology.

07:39.000 --> 07:41.000
In this news.

07:41.000 --> 07:43.000
For general public news.

07:43.000 --> 07:45.000
You also find that.

07:45.000 --> 07:47.000
Uh, all the big companies have invested.

07:47.000 --> 07:49.000
Google, IBM.

07:49.000 --> 07:51.000
Microsoft, Intel.

07:51.000 --> 07:54.000
Especially like Intel, IBM, Google.

07:54.000 --> 07:56.000
They all have more than 50 qubits of machine.

07:56.000 --> 07:58.000
That is to say, their, this.

07:58.000 --> 08:00.000
Highway development can already be 50 qubits.

08:00.000 --> 08:02.000
In fact, you can already do a little bit.

08:02.000 --> 08:03.000
A little something like this.

08:03.000 --> 08:05.000
So, uh.

08:05.000 --> 08:08.000
In the academic world, everyone started to go back and say.

08:08.000 --> 08:11.000
In fact, quantum computers may still be used.

08:11.000 --> 08:12.000
To do some.

08:12.000 --> 08:14.000
Uh, the operation of this big data.

08:14.000 --> 08:16.000
So that's why this quantum machine learning.

08:16.000 --> 08:18.000
In the last few years.

08:18.000 --> 08:20.000
Very, uh.

08:20.000 --> 08:21.000
Very hot.

08:21.000 --> 08:23.000
So, uh.

08:23.000 --> 08:25.000
Uh, so in 2017.

08:25.000 --> 08:27.000
In Nature.

08:27.000 --> 08:29.000
Uh, this journal, it has.

08:29.000 --> 08:31.000
Two reviewed articles.

08:31.000 --> 08:33.000
That is, two of the same.

08:33.000 --> 08:35.000
Uh, the same, uh.

08:35.000 --> 08:37.000
The same, uh, the same value.

08:37.000 --> 08:39.000
And then it just happened to be the first two.

08:39.000 --> 08:41.000
Uh, it's all in the review of this quantum machine.

08:41.000 --> 08:43.000
Uh, uh, uh.

08:43.000 --> 08:45.000
What about me?

08:45.000 --> 08:47.000
This slide is from.

08:47.000 --> 08:49.000
One of the review articles.

08:49.000 --> 08:51.000
It was taken out, it was by Monta, this person.

08:51.000 --> 08:53.000
Uh, it's written like this.

08:53.000 --> 08:55.000
He actually said.

08:55.000 --> 08:57.000
He did some summary, which means he took it to.

08:57.000 --> 08:59.000
Before 2017, that is to say.

08:59.000 --> 09:01.000
Uh, which one.

09:01.000 --> 09:03.000
You can do it with quantum computation.

09:03.000 --> 09:05.000
And then?

09:05.000 --> 09:07.000
What kind of acceleration does it have?

09:07.000 --> 09:09.000
Uh, on the far left.

09:09.000 --> 09:11.000
He's actually just.

09:11.000 --> 09:13.000
It's just, uh, it's classification.

09:13.000 --> 09:15.000
What are the problems like this?

09:15.000 --> 09:17.000
For example, he has that dangerous inference.

09:17.000 --> 09:19.000
Uh.

09:19.000 --> 09:21.000
Uh, let's say perceptron perceptron.

09:21.000 --> 09:23.000
It's like classification.

09:23.000 --> 09:25.000
Uh, let's say.

09:25.000 --> 09:27.000
The left and right, or if it's linear.

09:27.000 --> 09:29.000
That's what you're going to do.

09:29.000 --> 09:31.000
Uh, and then.

09:31.000 --> 09:33.000
Uh.

09:33.000 --> 09:35.000
The third is fitting.

09:35.000 --> 09:37.000
It's similar to what we used to have in curve fitting.

09:37.000 --> 09:39.000
You'll see your curve is probably.

09:39.000 --> 09:41.000
If it's a very complicated curve.

09:41.000 --> 09:43.000
For example, you can use linearity or sine wave to.

09:43.000 --> 09:45.000
To fit this curve.

09:45.000 --> 09:47.000
Uh, then.

09:47.000 --> 09:49.000
Uh, the fourth is the Boltzmann machine.

09:49.000 --> 09:51.000
We're probably just saying this is more statistical.

09:51.000 --> 09:53.000
Uh.

09:53.000 --> 09:55.000
That's classical Boltzmann machine.

09:55.000 --> 09:57.000
Of course, there's a corresponding quantum Boltzmann machine.

09:57.000 --> 09:59.000
Uh, that Boltzmann machine is also this.

09:59.000 --> 10:01.000
Uh, uh.

10:01.000 --> 10:03.000
Uh, similar to neural network.

10:03.000 --> 10:05.000
It's actually a very similar concept.

10:05.000 --> 10:07.000
And then there's PCA.

10:07.000 --> 10:09.000
Uh, Principle Component Analysis.

10:09.000 --> 10:11.000
Uh, this is basically.

10:11.000 --> 10:13.000
PCA is also a machine learning.

10:13.000 --> 10:15.000
Uh, one.

10:15.000 --> 10:17.000
Uh, a very weird study.

10:17.000 --> 10:19.000
A problem like this.

10:19.000 --> 10:21.000
You have a covariance matrix.

10:21.000 --> 10:23.000
Then you have to put it in a right angle.

10:23.000 --> 10:25.000
After that, you just need to focus on.

10:25.000 --> 10:27.000
A relatively large value.

10:27.000 --> 10:29.000
So they're called, uh.

10:29.000 --> 10:31.000
Principle component.

10:31.000 --> 10:33.000
The biggest one, the biggest one, the biggest one.

10:33.000 --> 10:35.000
It means that it affects your distribution.

10:35.000 --> 10:37.000
Is relatively large.

10:37.000 --> 10:39.000
So you cut off some of the smaller ones.

10:39.000 --> 10:41.000
Uh, the value.

10:41.000 --> 10:43.000
Uh, this is what classical PCA is doing.

10:43.000 --> 10:45.000
Uh, uh, and then there's SVM.

10:45.000 --> 10:47.000
This is actually called a vector.

10:47.000 --> 10:49.000
Uh, supporting vector.

10:49.000 --> 10:51.000
Basically, it's also part of this.

10:51.000 --> 10:53.000
Uh, classification problem.

10:53.000 --> 10:55.000
Um, the second column?

10:55.000 --> 10:57.000
The second row on the left is to say that this is the acceleration on the value.

10:57.000 --> 10:59.000
Uh, uh, uh.

10:59.000 --> 11:01.000
Uh, it means, uh,

11:01.000 --> 11:03.000
for example, uh,

11:03.000 --> 11:05.000
Perceptron, it has this, uh,

11:05.000 --> 11:07.000
Square root, it's called the acceleration of square root n.

11:07.000 --> 11:09.000
It's your sample size.

11:09.000 --> 11:11.000
If you have a point, you're going to do the classification.

11:11.000 --> 11:13.000
Then use the value, it will have one.

11:13.000 --> 11:15.000
Probably, uh,

11:15.000 --> 11:17.000
n-n-n-n-n-n-n-n-n-n-n-n-n-n-n-n-n-n-n-n

11:17.000 --> 11:19.000
So there's this acceleration.

11:19.000 --> 11:21.000
Some of the questions it has a value acceleration.

11:21.000 --> 11:23.000
Log n is the value of the value of the value.

11:23.000 --> 11:25.000
And then, uh,

11:25.000 --> 11:27.000
You see some signals in this place.

11:27.000 --> 11:29.000
In fact, this signal is

11:29.000 --> 11:31.000
It's actually these accelerations.

11:31.000 --> 11:33.000
There are some conditions.

11:33.000 --> 11:35.000
It has some assumptions, so it's not

11:35.000 --> 11:37.000
If you're going to

11:37.000 --> 11:39.000
Uh, from this classical

11:39.000 --> 11:41.000
To the classical

11:41.000 --> 11:43.000
Its acceleration will not

11:43.000 --> 11:45.000
To the value of the value

11:45.000 --> 11:47.000
It's just that, uh, my classical

11:47.000 --> 11:49.000
Data, I have to map it first.

11:49.000 --> 11:51.000
Map to a quantum state

11:51.000 --> 11:53.000
Quantum state is your quantum

11:53.000 --> 11:55.000
A type that the computer can handle

11:55.000 --> 11:57.000
Is, uh, your input

11:57.000 --> 11:59.000
To a quantum machine

11:59.000 --> 12:01.000
You must have one, just say this

12:01.000 --> 12:03.000
An input that the machine can accept

12:03.000 --> 12:05.000
That's it, so you're from classical

12:05.000 --> 12:07.000
Data to map to this quantum data

12:07.000 --> 12:09.000
Where is this place

12:09.000 --> 12:11.000
In fact, there is a, uh

12:11.000 --> 12:13.000
There is a trade-off

12:13.000 --> 12:15.000
It's basically impossible to do very well now

12:15.000 --> 12:17.000
Because you can imagine

12:17.000 --> 12:19.000
The classical data, I must have every data

12:19.000 --> 12:21.000
I have to read it once, so you can

12:21.000 --> 12:23.000
Map it over, right?

12:23.000 --> 12:25.000
Uh, so

12:25.000 --> 12:27.000
In this place, you must be

12:27.000 --> 12:29.000
With your data size

12:29.000 --> 12:31.000
There is already a proportional relationship

12:31.000 --> 12:33.000
What about these accelerations

12:33.000 --> 12:35.000
It's usually just looking at

12:35.000 --> 12:37.000
I already have a preprocessing

12:37.000 --> 12:39.000
Map it to the quantum state

12:39.000 --> 12:41.000
And then it can

12:41.000 --> 12:43.000
What about the calculation of these quantities

12:43.000 --> 12:45.000
It has this index acceleration

12:45.000 --> 12:47.000
This is what this signal means

12:47.000 --> 12:49.000
That's it

12:49.000 --> 12:51.000
But if there is no signal, this is

12:51.000 --> 12:53.000
Hey, uh, it's

12:53.000 --> 12:55.000
Overall, I can have an index

12:55.000 --> 12:57.000
The acceleration of this square root n

12:57.000 --> 12:59.000
Okay, what about this a

12:59.000 --> 13:01.000
It's actually a call

13:01.000 --> 13:03.000
This algorithm

13:03.000 --> 13:05.000
Then I will introduce it later

13:05.000 --> 13:07.000
It's actually a global

13:07.000 --> 13:09.000
Uh, a more advanced version of global search

13:09.000 --> 13:11.000
Then I will introduce

13:11.000 --> 13:13.000
Global search

13:13.000 --> 13:15.000
Then this place means y

13:15.000 --> 13:17.000
That is to say, in these methods

13:17.000 --> 13:19.000
It actually uses this

13:19.000 --> 13:21.000
Amplitude amplification or global

13:21.000 --> 13:23.000
Search like this

13:23.000 --> 13:25.000
Then the other one is hhl

13:25.000 --> 13:27.000
It's a quantum

13:27.000 --> 13:29.000
Very famous algorithm now

13:29.000 --> 13:31.000
I'll introduce it later. It's actually used to solve the linear equation.

13:31.000 --> 13:33.000
If you say

13:33.000 --> 13:35.000
Quantum computation

13:35.000 --> 13:37.000
Quantum algorithm to solve the linear equation

13:37.000 --> 13:39.000
It will have an index acceleration

13:39.000 --> 13:41.000
Then we know that machine learning

13:41.000 --> 13:43.000
Uh, a lot of problems

13:43.000 --> 13:45.000
You can map it to the solution

13:45.000 --> 13:47.000
So you can do this

13:47.000 --> 13:49.000
You can just use this hhl algorithm

13:49.000 --> 13:51.000
To solve

13:51.000 --> 13:53.000
I'm not familiar with this piece

13:53.000 --> 13:55.000
So I didn't go to

13:55.000 --> 13:57.000
Go to

13:57.000 --> 13:59.000
I don't explain much

13:59.000 --> 14:01.000
That's what I just said

14:01.000 --> 14:03.000
You have to put classical data

14:03.000 --> 14:05.000
Map to quantum state

14:05.000 --> 14:07.000
Basically you need an encoding step

14:07.000 --> 14:09.000
Then this is what qrem is doing

14:09.000 --> 14:11.000
N means

14:11.000 --> 14:13.000
This method, for example, the first

14:13.000 --> 14:15.000
Bayesian inference, it doesn't use

14:15.000 --> 14:17.000
This qrem place

14:17.000 --> 14:19.000
Because qrem is actually a

14:19.000 --> 14:21.000
It's a more complicated operation

14:21.000 --> 14:23.000
So you can jump as much as you can

14:23.000 --> 14:25.000
You can try not to use it

14:25.000 --> 14:27.000
Don't use it

14:27.000 --> 14:29.000
Ok

14:29.000 --> 14:31.000
Is there a problem?

14:31.000 --> 14:33.000
No problem, I'll go down

14:33.000 --> 14:35.000
Introduce this

14:35.000 --> 14:37.000
From here

14:37.000 --> 14:39.000
I will introduce some quantum algorithms

14:39.000 --> 14:41.000
Why

14:41.000 --> 14:43.000
Why is there an index acceleration?

14:43.000 --> 14:45.000
Basically because there are these

14:45.000 --> 14:47.000
These are more basic

14:47.000 --> 14:49.000
This quantum algorithm

14:49.000 --> 14:51.000
As your

14:51.000 --> 14:53.000
This

14:53.000 --> 14:55.000
From

14:55.000 --> 14:57.000
This

14:57.000 --> 14:59.000
The more complicated algorithm

14:59.000 --> 15:01.000
Then do more complicated things

15:01.000 --> 15:03.000
Then I introduced these

15:03.000 --> 15:05.000
These are more fundamental

15:05.000 --> 15:07.000
There are a few

15:07.000 --> 15:09.000
Basically you are going to read these textbooks

15:09.000 --> 15:11.000
There are already introductions in the textbooks

15:11.000 --> 15:13.000
I basically know here

15:13.000 --> 15:15.000
Everyone is not doing this

15:15.000 --> 15:17.000
Quantum information or computation

15:17.000 --> 15:19.000
So I basically only talk about the results

15:19.000 --> 15:21.000
Everyone can basically have an impression

15:21.000 --> 15:23.000
The first one is Fourier transform

15:23.000 --> 15:25.000
Why is quantum computation

15:25.000 --> 15:27.000
It's so useful because

15:27.000 --> 15:29.000
Quantum

15:29.000 --> 15:31.000
You can let you go

15:31.000 --> 15:33.000
Do

15:33.000 --> 15:35.000
Do the action of superposition

15:35.000 --> 15:37.000
Your state

15:37.000 --> 15:39.000
Your state is

15:39.000 --> 15:41.000
For example, we are 0 1, right?

15:41.000 --> 15:43.000
Quantum state is 0 1

15:43.000 --> 15:45.000
Superposition

15:45.000 --> 15:47.000
What about this superposition

15:47.000 --> 15:49.000
That is, you can use parallel operations

15:49.000 --> 15:51.000
You can

15:51.000 --> 15:53.000
You can do a 0 operation

15:53.000 --> 15:55.000
Do a 1 operation

15:55.000 --> 15:57.000
Then correspond to it

15:57.000 --> 15:59.000
Its superposition will correspond to

15:59.000 --> 16:01.000
Your operation will superposition

16:01.000 --> 16:03.000
Quantum mechanics is a linear

16:03.000 --> 16:05.000
Linear

16:05.000 --> 16:07.000
What about this place

16:07.000 --> 16:09.000
So why

16:09.000 --> 16:11.000
Quantum computer

16:11.000 --> 16:13.000
Why is it so effective

16:13.000 --> 16:15.000
Because of this quantum Fourier transform

16:15.000 --> 16:17.000
If we talk about science students

16:17.000 --> 16:19.000
Everyone knows what Fourier transform is doing

16:19.000 --> 16:21.000
That is, he wants to put a state

16:21.000 --> 16:23.000
Plus this

16:23.000 --> 16:25.000
Plus this face

16:25.000 --> 16:27.000
This is called Fourier coefficient

16:27.000 --> 16:29.000
This omega n xk

16:29.000 --> 16:31.000
If you say there are n bits

16:31.000 --> 16:33.000
Then your capital n

16:33.000 --> 16:35.000
Is the square root of 2n

16:35.000 --> 16:37.000
This is what you do to n bits

16:37.000 --> 16:39.000
A Fourier transform

16:39.000 --> 16:41.000
Then my notation is actually

16:41.000 --> 16:43.000
Quantum notation

16:43.000 --> 16:45.000
Basically this x

16:45.000 --> 16:47.000
There is a

16:47.000 --> 16:49.000
This place

16:49.000 --> 16:51.000
This place

16:51.000 --> 16:53.000
It's actually a quantum state

16:53.000 --> 16:55.000
You can think of it as a vector

16:55.000 --> 16:57.000
This is a

16:57.000 --> 16:59.000
That is to say there are 2n

16:59.000 --> 17:01.000
One

17:01.000 --> 17:03.000
A vector element that is a

17:03.000 --> 17:05.000
This technical detail

17:05.000 --> 17:07.000
It doesn't matter if you don't need to know

17:07.000 --> 17:09.000
Then

17:09.000 --> 17:11.000
I can't introduce this Fourier transform

17:11.000 --> 17:13.000
The introduction is too detailed, I just want to tell you

17:13.000 --> 17:15.000
What is the difference between it and classical

17:15.000 --> 17:17.000
Our science students

17:17.000 --> 17:19.000
Everyone knows that classical Fourier transform

17:19.000 --> 17:21.000
How many operations do you need

17:21.000 --> 17:23.000
If you say you have n

17:23.000 --> 17:25.000
n bits

17:25.000 --> 17:27.000
The operation you need is n

17:27.000 --> 17:29.000
Multiplied by the value of 2

17:29.000 --> 17:31.000
n square

17:31.000 --> 17:33.000
So it is

17:33.000 --> 17:35.000
It's not just it's polynomial

17:35.000 --> 17:37.000
In number of bits

17:37.000 --> 17:39.000
It's exponential in number of bits

17:39.000 --> 17:41.000
This is what classical Fourier transform needs

17:41.000 --> 17:43.000
It's n times 2n

17:43.000 --> 17:45.000
So many operations

17:45.000 --> 17:47.000
You need so many operations

17:47.000 --> 17:49.000
But in quantum Fourier transform

17:49.000 --> 17:51.000
You only need

17:51.000 --> 17:53.000
n square

17:53.000 --> 17:55.000
That is to say, n is your number of bits

17:55.000 --> 17:57.000
So you have a place

17:57.000 --> 17:59.000
Uh, uh, the acceleration of the index

17:59.000 --> 18:01.000
Uh, exponential speed

18:01.000 --> 18:03.000
Uh, exponential speed

18:03.000 --> 18:05.000
That

18:05.000 --> 18:07.000
Uh, the reason for this

18:07.000 --> 18:09.000
Of course, it just happens to be this operation

18:09.000 --> 18:11.000
Can be divided into this bit

18:11.000 --> 18:13.000
Single qubit operation and this two qubit operation

18:13.000 --> 18:15.000
Then you add it up

18:15.000 --> 18:17.000
That is to say, its operation

18:17.000 --> 18:19.000
You can decompose it into this elementary quantum gate

18:19.000 --> 18:21.000
Then it just needs n

18:21.000 --> 18:23.000
n square and so many

18:23.000 --> 18:25.000
Yeah, if you're interested in this

18:25.000 --> 18:27.000
You can go to Wikipedia

18:27.000 --> 18:29.000
It's also very simple

18:29.000 --> 18:31.000
If you have a background in physics

18:31.000 --> 18:33.000
It's easy to understand

18:33.000 --> 18:35.000
Uh, so this place has an index

18:35.000 --> 18:37.000
So your algorithm if you need

18:37.000 --> 18:39.000
If you use quantum Fourier transform

18:39.000 --> 18:41.000
You just have a big acceleration

18:41.000 --> 18:43.000
And then this

18:43.000 --> 18:45.000
Uh, and then you

18:45.000 --> 18:47.000
This, uh, quantum Fourier transform

18:47.000 --> 18:49.000
It will be used in some

18:49.000 --> 18:51.000
More complicated this is called phase estimation

18:51.000 --> 18:53.000
In this algorithm

18:53.000 --> 18:55.000
I will introduce phase in a moment

18:55.000 --> 18:57.000
I will introduce phase estimation in the next slide

18:57.000 --> 18:59.000
Because phase estimation is a very important algorithm

18:59.000 --> 19:01.000
Okay, what is phase estimation doing?

19:01.000 --> 19:03.000
What is phase estimation doing?

19:03.000 --> 19:05.000
It is to estimate your eigenvalue

19:05.000 --> 19:07.000
That is to say, suppose I have a unitary

19:07.000 --> 19:09.000
U, and then

19:09.000 --> 19:11.000
I have one, uh, this vector

19:11.000 --> 19:13.000
This is the eigenvector of U

19:13.000 --> 19:15.000
Psi, right?

19:15.000 --> 19:17.000
Then we know that your U

19:17.000 --> 19:19.000
Multiply by your eigenvector

19:19.000 --> 19:21.000
You will take your eigenvalue

19:21.000 --> 19:23.000
It will be equal to the eigenvalue multiplied by your eigenvector

19:23.000 --> 19:25.000
Right?

19:25.000 --> 19:27.000
Then this phase estimation is to estimate

19:27.000 --> 19:29.000
Because of your eigenvalue

19:29.000 --> 19:31.000
Because it is unitary, it is only related to this theta

19:31.000 --> 19:33.000
Right? So we're going to estimate this theta

19:33.000 --> 19:35.000
Right? So we're going to estimate this theta

19:35.000 --> 19:37.000
Uh, what about this?

19:37.000 --> 19:39.000
What about this estimation?

19:39.000 --> 19:41.000
That is to say, this place is also

19:41.000 --> 19:43.000
That is, uh, this take-home message is like this

19:43.000 --> 19:45.000
Uh, there is a quantum algorithm

19:45.000 --> 19:47.000
Uh, there is a quantum algorithm

19:47.000 --> 19:49.000
It can estimate your eigenvalue

19:49.000 --> 19:51.000
Can estimate your eigenvalue

19:51.000 --> 19:53.000
It's very efficient

19:53.000 --> 19:55.000
It's very efficient

19:55.000 --> 19:57.000
How about this?

19:57.000 --> 19:59.000
How about this?

19:59.000 --> 20:01.000
It can use all 1 over

20:01.000 --> 20:03.000
It can use all 1 over

20:03.000 --> 20:05.000
It can use all 1 over

20:05.000 --> 20:09.000
If you say, if your requirement is

20:09.000 --> 20:11.000
If you say, if your requirement is

20:11.000 --> 20:13.000
It just needs all 1 over

20:13.000 --> 20:15.000
to calculate this eigenvalue

20:15.000 --> 20:17.000
Then we know

20:17.000 --> 20:19.000
In fact, many later algorithms

20:19.000 --> 20:21.000
In fact, many later algorithms

20:21.000 --> 20:23.000
The most important part of it is

20:23.000 --> 20:25.000
I have a matrix

20:25.000 --> 20:27.000
Because quantum mechanics

20:27.000 --> 20:29.000
You can use this matrix to express

20:29.000 --> 20:31.000
You can use this matrix to express

20:31.000 --> 20:33.000
A matrix

20:33.000 --> 20:35.000
What do you need to focus on?

20:35.000 --> 20:37.000
Just the place where its eigenvalue is large

20:37.000 --> 20:39.000
Just the place where its eigenvalue is large

20:39.000 --> 20:41.000
So we can use some

20:41.000 --> 20:43.000
Fastest method

20:43.000 --> 20:45.000
Make some changes

20:45.000 --> 20:47.000
Then let it just estimate this

20:47.000 --> 20:49.000
Bigger eigenvalue

20:49.000 --> 20:51.000
Then you can

20:51.000 --> 20:53.000
Smaller eigenvalue

20:53.000 --> 20:55.000
Truncate it

20:55.000 --> 20:57.000
Then this truncate

20:57.000 --> 20:59.000
It basically doesn't affect

20:59.000 --> 21:01.000
Because if you look at its distance

21:01.000 --> 21:03.000
For example, trace distance

21:03.000 --> 21:05.000
It's basically just comparing its eigenvalue

21:05.000 --> 21:07.000
So if you truncate a smaller eigenvalue

21:07.000 --> 21:09.000
So if you truncate a smaller eigenvalue

21:09.000 --> 21:11.000
And then

21:11.000 --> 21:13.000
Like this Fastest method

21:13.000 --> 21:15.000
It uses, for example, I just mentioned

21:15.000 --> 21:17.000
Hhl is the solution

21:17.000 --> 21:19.000
Linear equation algorithm

21:19.000 --> 21:21.000
It should be the most famous

21:21.000 --> 21:23.000
It should be the most famous

21:23.000 --> 21:25.000
It can be used to do

21:25.000 --> 21:27.000
The value factor is highly efficient

21:29.000 --> 21:31.000
It can be used to do

21:31.000 --> 21:33.000
The value factor is highly efficient

21:33.000 --> 21:35.000
It can

21:35.000 --> 21:37.000
It can

21:37.000 --> 21:39.000
It's so effective

21:39.000 --> 21:41.000
That's it

21:41.000 --> 21:43.000
That's it

21:43.000 --> 21:45.000
That's it

21:45.000 --> 21:47.000
That's it

21:49.000 --> 21:51.000
Here

21:51.000 --> 21:53.000
Here

21:53.000 --> 21:55.000
Here

21:55.000 --> 21:57.000
This

21:57.000 --> 21:59.000
This

21:59.000 --> 22:01.000
This

22:01.000 --> 22:03.000
This

22:03.000 --> 22:05.000
This

22:05.000 --> 22:07.000
This place is in classical

22:07.000 --> 22:09.000
Actually there is no way to avoid

22:09.000 --> 22:11.000
We know that we used to be on

22:11.000 --> 22:13.000
It should be high school

22:13.000 --> 22:15.000
Is the Gauss elimination method

22:15.000 --> 22:17.000
I have n variables n equations

22:17.000 --> 22:19.000
I just delete one variable first

22:19.000 --> 22:21.000
Then slowly delete all the variables

22:21.000 --> 22:23.000
Until the last variable and then push it back

22:23.000 --> 22:25.000
This is the Gauss elimination method

22:25.000 --> 22:27.000
Then, but in quantum

22:27.000 --> 22:29.000
If you say this x is a quantum state

22:29.000 --> 22:31.000
It already has superposition to help you

22:31.000 --> 22:33.000
Then v is also a quantum state

22:33.000 --> 22:35.000
To do this

22:35.000 --> 22:37.000
You only need to log n

22:37.000 --> 22:39.000
n is the size of your matrix

22:39.000 --> 22:41.000
The matrix of this a

22:41.000 --> 22:43.000
Is n by n

22:43.000 --> 22:45.000
Then you only need to log n so much

22:45.000 --> 22:47.000
Then we know that the Gauss elimination method

22:47.000 --> 22:49.000
You probably need n squared

22:49.000 --> 22:51.000
Steps like this

22:51.000 --> 22:53.000
Then this

22:53.000 --> 22:55.000
This place is actually in major

22:55.000 --> 22:57.000
This matrix a is

22:57.000 --> 22:59.000
How regular

22:59.000 --> 23:01.000
How should it be said

23:01.000 --> 23:03.000
The biggest eigenvalue and the smallest eigenvalue

23:03.000 --> 23:05.000
You don't want it to be too different

23:05.000 --> 23:07.000
So this kappa is a bit

23:07.000 --> 23:09.000
This linear equation

23:09.000 --> 23:11.000
In the end

23:11.000 --> 23:13.000
His

23:13.000 --> 23:15.000
What is his behavior

23:15.000 --> 23:17.000
So this is actually a technical condition

23:17.000 --> 23:19.000
It doesn't matter if you don't care first

23:19.000 --> 23:21.000
Everyone basically only compares this log n

23:21.000 --> 23:23.000
Then

23:23.000 --> 23:25.000
In the best classic algorithm

23:25.000 --> 23:27.000
In fact, it is n

23:27.000 --> 23:29.000
If your matrix is n by n

23:29.000 --> 23:31.000
You don't need to do so many operations

23:31.000 --> 23:33.000
Basically with the Gauss elimination method

23:33.000 --> 23:35.000
A little better than the Gauss elimination method

23:35.000 --> 23:37.000
This is actually a teacher at MIT

23:37.000 --> 23:39.000
Aaron Harrow

23:39.000 --> 23:41.000
They are all at MIT

23:41.000 --> 23:43.000
They proposed it in 2009

23:43.000 --> 23:45.000
You see, it's less than 10 years

23:45.000 --> 23:47.000
This breakthrough within 10 years

23:47.000 --> 23:49.000
This article until now

23:49.000 --> 23:51.000
It seems that I have almost 600 citations

23:51.000 --> 23:53.000
It's because of the quantum algorithm

23:53.000 --> 23:55.000
It's all up

23:55.000 --> 23:57.000
Then this machine learning also got up

23:57.000 --> 23:59.000
A lot of this step

23:59.000 --> 24:01.000
This matrix

24:01.000 --> 24:03.000
Inversion step, so now citation

24:03.000 --> 24:05.000
This paper is very high

24:05.000 --> 24:07.000
So it's the same

24:07.000 --> 24:09.000
It's like this

24:09.000 --> 24:11.000
Linear equation

24:11.000 --> 24:13.000
The quantum algorithm has an index acceleration

24:13.000 --> 24:15.000
That's it

24:15.000 --> 24:17.000
Okay, then

24:17.000 --> 24:19.000
The other one is that in addition to HHL

24:19.000 --> 24:21.000
The other one is most commonly used in machine learning

24:21.000 --> 24:23.000
Is global search

24:23.000 --> 24:25.000
What is global search?

24:25.000 --> 24:27.000
Then this data space

24:27.000 --> 24:29.000
You don't need to have some structure

24:29.000 --> 24:31.000
It's an unsorted search

24:31.000 --> 24:33.000
Then use this global search

24:33.000 --> 24:35.000
What about this quantum algorithm

24:35.000 --> 24:37.000
It will have the acceleration of square root n

24:37.000 --> 24:39.000
What about this square root n

24:39.000 --> 24:41.000
n is your

24:41.000 --> 24:43.000
This size of the database

24:43.000 --> 24:45.000
Sorry

24:45.000 --> 24:47.000
Then basically global search

24:47.000 --> 24:49.000
What are you doing?

24:49.000 --> 24:51.000
If my omega is an n-bit sequence

24:51.000 --> 24:53.000
I wrote it into this vector form

24:53.000 --> 24:55.000
It's like this

24:59.000 --> 25:01.000
Then this

25:01.000 --> 25:03.000
Every omega is a 0 1 bit

25:03.000 --> 25:05.000
Every omega i

25:05.000 --> 25:07.000
Is a 0 1 bit

25:07.000 --> 25:09.000
Then I just want from this

25:09.000 --> 25:11.000
All of this bit sequence

25:11.000 --> 25:13.000
This ps below me is all of the bit sequence

25:13.000 --> 25:15.000
The superposition

25:15.000 --> 25:17.000
I want to identify from the inside

25:17.000 --> 25:19.000
A particular

25:19.000 --> 25:21.000
This omega

25:21.000 --> 25:23.000
From a uniform superposition

25:23.000 --> 25:25.000
I want to identify this omega

25:25.000 --> 25:27.000
This is what global search is doing

25:27.000 --> 25:29.000
That global is basically

25:29.000 --> 25:31.000
Very simple

25:31.000 --> 25:33.000
It uses two very elementary

25:33.000 --> 25:35.000
This operation

25:35.000 --> 25:37.000
This is basically

25:37.000 --> 25:39.000
These two are reflection

25:39.000 --> 25:41.000
Is to reverse

25:41.000 --> 25:43.000
I have a picture below

25:43.000 --> 25:45.000
That is

25:45.000 --> 25:47.000
It is a

25:47.000 --> 25:49.000
Geometry picture like this

25:49.000 --> 25:51.000
I use this picture to show

25:51.000 --> 25:53.000
It's called omega

25:53.000 --> 25:55.000
This y-axis

25:55.000 --> 25:57.000
This omega is what I want to estimate

25:57.000 --> 25:59.000
What about this s

25:59.000 --> 26:01.000
Is all of the state

26:01.000 --> 26:03.000
Uniform superposition

26:03.000 --> 26:05.000
Because omega is also in this s

26:05.000 --> 26:07.000
So

26:07.000 --> 26:09.000
Sorry

26:09.000 --> 26:11.000
There is a call

26:13.000 --> 26:15.000
Because omega is also in this s

26:15.000 --> 26:17.000
An element

26:17.000 --> 26:19.000
This omega is positive

26:19.000 --> 26:21.000
But you can

26:21.000 --> 26:23.000
It's positive with this omega

26:23.000 --> 26:25.000
This

26:35.000 --> 26:37.000
OK

26:37.000 --> 26:39.000
That

26:39.000 --> 26:41.000
What about the two operations just now

26:41.000 --> 26:43.000
One is US, one is UW

26:43.000 --> 26:45.000
That is, there are two operations in the previous slide

26:45.000 --> 26:47.000
What are these two operations doing

26:47.000 --> 26:49.000
That is, this UW

26:49.000 --> 26:51.000
This operation is for this s

26:51.000 --> 26:53.000
This one

26:53.000 --> 26:55.000
This plane

26:55.000 --> 26:57.000
It is s

26:57.000 --> 26:59.000
You use this u

26:59.000 --> 27:01.000
Omega this operation is used in s

27:01.000 --> 27:03.000
It's actually s, this s, this place

27:03.000 --> 27:05.000
Do a flip for s prime

27:05.000 --> 27:07.000
So when you do the first step, it will flip here

27:07.000 --> 27:09.000
The following gray line

27:09.000 --> 27:11.000
Can everyone see it?

27:11.000 --> 27:13.000
Should be right

27:13.000 --> 27:15.000
I can see it

27:15.000 --> 27:17.000
Because it's too quiet

27:17.000 --> 27:19.000
I don't know if I can see it like this

27:19.000 --> 27:21.000
OK

27:21.000 --> 27:23.000
Do the first flip

27:23.000 --> 27:25.000
It will become the gray line below

27:25.000 --> 27:27.000
Right then

27:27.000 --> 27:29.000
It's the second flip

27:29.000 --> 27:31.000
Is to flip to s

27:31.000 --> 27:33.000
So it's now this gray line

27:33.000 --> 27:35.000
Will run to the top here

27:35.000 --> 27:37.000
If you assume that at first

27:37.000 --> 27:39.000
s and s prime

27:39.000 --> 27:41.000
s and s prime

27:41.000 --> 27:43.000
Is the angle of theta over 2

27:43.000 --> 27:45.000
Then you do the first flip

27:45.000 --> 27:47.000
You will be here below

27:47.000 --> 27:49.000
Here is also theta over 2

27:49.000 --> 27:51.000
Then you flip to s now

27:51.000 --> 27:53.000
It will go up here

27:53.000 --> 27:55.000
There is a theta angle, right?

27:55.000 --> 27:57.000
That is to say, you did a round

27:57.000 --> 27:59.000
That is to say, u omega and us

27:59.000 --> 28:01.000
After doing a round

28:01.000 --> 28:03.000
You actually put s this angle

28:03.000 --> 28:05.000
s this s this vector

28:05.000 --> 28:07.000
Up to the direction of omega

28:07.000 --> 28:09.000
Then you just need it now

28:09.000 --> 28:11.000
Your goal now

28:11.000 --> 28:13.000
Is to let you repeat this step

28:13.000 --> 28:15.000
Let the last

28:15.000 --> 28:17.000
It can be close to omega

28:17.000 --> 28:19.000
Right, you just let it keep flipping

28:19.000 --> 28:21.000
To omega flip to where you want

28:21.000 --> 28:23.000
Then you can search

28:23.000 --> 28:25.000
Search to the value you want

28:25.000 --> 28:27.000
This global

28:27.000 --> 28:29.000
In fact, it is very interesting that he is not doing quantum information

28:29.000 --> 28:31.000
He only has one

28:31.000 --> 28:33.000
One to two pieces of quantum paper

28:33.000 --> 28:35.000
He basically proposed this global search

28:35.000 --> 28:37.000
Classical

28:37.000 --> 28:39.000
He is a classic CS person

28:39.000 --> 28:41.000
Then he mentioned this very interesting result

28:41.000 --> 28:43.000
Then he is very famous now

28:43.000 --> 28:45.000
This is a very fundamental

28:45.000 --> 28:47.000
A quantum algorithm

28:49.000 --> 28:51.000
Because this is a search algorithm

28:51.000 --> 28:53.000
And it is your data space

28:53.000 --> 28:55.000
No need to have

28:55.000 --> 28:57.000
No need to have assumptions

28:57.000 --> 28:59.000
So it is an unsorted search

28:59.000 --> 29:01.000
So it is very useful

29:01.000 --> 29:03.000
It is in many algorithms

29:03.000 --> 29:05.000
This is a global search

29:05.000 --> 29:07.000
Ok

29:07.000 --> 29:09.000
Uh

29:09.000 --> 29:11.000
Uh

29:11.000 --> 29:13.000
I need to introduce one

29:13.000 --> 29:15.000
Because the progress of quantum machine learning

29:15.000 --> 29:17.000
Very fast

29:17.000 --> 29:19.000
Then the progress of 2017

29:19.000 --> 29:21.000
This review article

29:21.000 --> 29:23.000
In fact, it has been a bit

29:23.000 --> 29:25.000
There have been a lot of results in the past year

29:25.000 --> 29:27.000
There is a very interesting result

29:27.000 --> 29:29.000
Is the recommendation system

29:29.000 --> 29:31.000
Uh

29:31.000 --> 29:33.000
Recommendation system I think everyone knows

29:33.000 --> 29:35.000
You do online shopping

29:35.000 --> 29:37.000
Or you watch netflix

29:37.000 --> 29:39.000
You watch netflix

29:39.000 --> 29:41.000
After you choose

29:41.000 --> 29:43.000
You can finally say

29:43.000 --> 29:45.000
Give him a star

29:45.000 --> 29:47.000
See if you like five stars

29:47.000 --> 29:49.000
Or three stars

29:49.000 --> 29:51.000
Do you like it

29:51.000 --> 29:53.000
He has an algorithm

29:53.000 --> 29:55.000
Will recommend you a similar movie

29:55.000 --> 29:57.000
Online shopping is the same

29:57.000 --> 29:59.000
What did you buy

29:59.000 --> 30:01.000
Will recommend you something like

30:01.000 --> 30:03.000
So this is the recommendation system

30:03.000 --> 30:05.000
Uh system is doing

30:05.000 --> 30:07.000
That uh

30:07.000 --> 30:09.000
Recommendation system

30:09.000 --> 30:11.000
You use

30:11.000 --> 30:13.000
Describe it in math

30:13.000 --> 30:15.000
Describe what it is

30:15.000 --> 30:17.000
I have n users

30:17.000 --> 30:19.000
This n

30:19.000 --> 30:21.000
N

30:21.000 --> 30:23.000
Every user

30:23.000 --> 30:25.000
He has m things

30:25.000 --> 30:27.000
You can choose, right

30:27.000 --> 30:29.000
I have a movie, I have a database

30:29.000 --> 30:31.000
Then every user can choose

30:31.000 --> 30:33.000
All the movies in this database

30:33.000 --> 30:35.000
Uh

30:35.000 --> 30:37.000
You can put this thing

30:37.000 --> 30:39.000
Think of it as a big evidence

30:39.000 --> 30:41.000
This evidence is really big because

30:41.000 --> 30:43.000
For example, I have a million movies

30:43.000 --> 30:45.000
So my m is

30:45.000 --> 30:47.000
1 million

30:47.000 --> 30:49.000
If I say 1 million users

30:49.000 --> 30:51.000
Then my evidence is 1 million times

30:51.000 --> 30:53.000
Such a big size

30:53.000 --> 30:55.000
Of course, usually

30:55.000 --> 30:57.000
Most of the entries are empty

30:57.000 --> 30:59.000
Because you can't say 1 million movies

30:59.000 --> 31:01.000
All finished

31:01.000 --> 31:03.000
So you can only watch

31:03.000 --> 31:05.000
For example, 10,000 movies

31:05.000 --> 31:07.000
So this rank is very important

31:07.000 --> 31:09.000
Most of this matrix

31:09.000 --> 31:11.000
Uh, the rank is very low

31:11.000 --> 31:13.000
What about the recommendation system

31:13.000 --> 31:15.000
What is this algorithm basically doing

31:15.000 --> 31:17.000
He just wants to reconstruct

31:17.000 --> 31:19.000
This matrix

31:19.000 --> 31:21.000
I already chose some elements

31:21.000 --> 31:23.000
Then I want to be on you

31:23.000 --> 31:25.000
I want to reconstruct other places

31:25.000 --> 31:27.000
This is what the recommendation system does

31:27.000 --> 31:29.000
Then this place is very interesting

31:29.000 --> 31:31.000
In 2017

31:31.000 --> 31:33.000
What about us

31:33.000 --> 31:35.000
Uh, in this quantum information

31:35.000 --> 31:37.000
Quantum machine learning

31:37.000 --> 31:39.000
Uh, where

31:39.000 --> 31:41.000
They sent a big message

31:41.000 --> 31:43.000
They have a algorithm now

31:43.000 --> 31:45.000
Just need

31:45.000 --> 31:47.000
Log m n so much

31:47.000 --> 31:49.000
This is very impressive

31:49.000 --> 31:51.000
Why

31:51.000 --> 31:53.000
Because before this algorithm

31:53.000 --> 31:55.000
All classic

31:55.000 --> 31:57.000
Do recommendation system

31:57.000 --> 31:59.000
Algorithm

31:59.000 --> 32:01.000
All need at least

32:01.000 --> 32:03.000
Polynomial

32:03.000 --> 32:05.000
In m and n

32:05.000 --> 32:07.000
So you can see this quantum algorithm

32:07.000 --> 32:09.000
There is an increase in the number of points

32:09.000 --> 32:11.000
Right, this recommendation system

32:11.000 --> 32:13.000
Is a very important algorithm

32:13.000 --> 32:15.000
Because all your online shopping

32:15.000 --> 32:17.000
As long as it is related to online

32:17.000 --> 32:19.000
Maybe this

32:19.000 --> 32:21.000
Uh, this

32:21.000 --> 32:23.000
What are they advertising

32:23.000 --> 32:25.000
Also have this recommendation system

32:25.000 --> 32:27.000
Build in

32:27.000 --> 32:29.000
That is to say, everyone felt at that time

32:29.000 --> 32:31.000
Quantum algorithm is very useful

32:31.000 --> 32:33.000
Uh, but

32:33.000 --> 32:35.000
This year in 2018

32:35.000 --> 32:37.000
There is a student in Texas

32:37.000 --> 32:39.000
It seems to be

32:39.000 --> 32:41.000
Scott Aaronson

32:41.000 --> 32:43.000
It's not a student

32:43.000 --> 32:45.000
It's like a specialty

32:45.000 --> 32:47.000
This kind of student

32:47.000 --> 32:49.000
He should be only 18 years old

32:49.000 --> 32:51.000
Uh

32:51.000 --> 32:53.000
He just

32:53.000 --> 32:55.000
He read this quantum algorithm paper

32:55.000 --> 32:57.000
Found it

32:57.000 --> 32:59.000
What about this quantum algorithm paper

32:59.000 --> 33:01.000
In fact, this quantum algorithm paper

33:01.000 --> 33:03.000
It's actually not entirely

33:03.000 --> 33:05.000
Classic recommendation system

33:05.000 --> 33:07.000
With classic recommendation system

33:07.000 --> 33:09.000
Basically not doing the same thing

33:09.000 --> 33:11.000
It's actually just estimating this

33:11.000 --> 33:13.000
Uh, this is inside

33:13.000 --> 33:15.000
The most likely

33:15.000 --> 33:17.000
Entry

33:17.000 --> 33:19.000
This low probability entry

33:19.000 --> 33:21.000
Basically, you don't need to reconstruct

33:21.000 --> 33:23.000
What about their quantum algorithm

33:23.000 --> 33:25.000
Do it like this

33:25.000 --> 33:27.000
Quantum algorithm

33:27.000 --> 33:29.000
Can go to

33:29.000 --> 33:31.000
These high probability values

33:31.000 --> 33:33.000
Then the second

33:33.000 --> 33:35.000
You don't need to reconstruct the whole

33:35.000 --> 33:37.000
All elements

33:37.000 --> 33:39.000
So this will have this index

33:39.000 --> 33:41.000
That's it

33:41.000 --> 33:43.000
This 18-year-old

33:43.000 --> 33:45.000
He actually

33:45.000 --> 33:47.000
What about this quantum idea

33:47.000 --> 33:49.000
He found this

33:49.000 --> 33:51.000
Sampling can be done

33:51.000 --> 33:53.000
That is, in 2018, this is about a few months ago

33:53.000 --> 33:55.000
Oh, no, it's July

33:55.000 --> 33:57.000
Uh

33:57.000 --> 33:59.000
He also uses a

33:59.000 --> 34:01.000
Classic algorithm can do exactly the same

34:01.000 --> 34:03.000
Uh, this

34:03.000 --> 34:05.000
Efficiency

34:05.000 --> 34:07.000
So in the recommendation system

34:07.000 --> 34:09.000
This quantum algorithm is completely

34:09.000 --> 34:11.000
No acceleration, it's the same as the classic algorithm

34:11.000 --> 34:13.000
It's exactly the same

34:13.000 --> 34:15.000
But this is another interesting place

34:15.000 --> 34:17.000
That is, in this quantum information and quantum computation

34:17.000 --> 34:19.000
What about

34:19.000 --> 34:21.000
No matter what field you are in, you can come in

34:21.000 --> 34:23.000
You have classical knowledge

34:23.000 --> 34:25.000
You can take your classical knowledge

34:25.000 --> 34:27.000
To improve your

34:27.000 --> 34:29.000
Classical algorithm

34:29.000 --> 34:31.000
Uh, and then you

34:31.000 --> 34:33.000
You're starting on both sides

34:33.000 --> 34:35.000
It's kind of like a competition

34:35.000 --> 34:37.000
Keep pushing the algorithm on both sides

34:37.000 --> 34:39.000
The efficiency keeps going up

34:39.000 --> 34:41.000
This is a very interesting result

34:41.000 --> 34:43.000
So good

34:43.000 --> 34:45.000
Uh, and then

34:45.000 --> 34:47.000
Uh, because I've been doing some of this lately

34:47.000 --> 34:49.000
This aspect of work

34:49.000 --> 34:51.000
So I took this opportunity

34:51.000 --> 34:53.000
Uh, this opportunity

34:53.000 --> 34:55.000
I also told you

34:55.000 --> 34:57.000
I'm wearing

35:01.000 --> 35:03.000
The place

35:03.000 --> 35:05.000
What kind of questions did this place have just now

35:05.000 --> 35:07.000
Next is that I want to introduce

35:07.000 --> 35:09.000
My my

35:09.000 --> 35:11.000
Some of the results on this quantum machine learning

35:11.000 --> 35:13.000
Is there a problem

35:13.000 --> 35:15.000
It seems like

35:15.000 --> 35:17.000
Some people want to ask questions

35:17.000 --> 35:19.000
But that one

35:19.000 --> 35:21.000
There's a jump

35:21.000 --> 35:23.000
Oh, really? I didn't notice

35:23.000 --> 35:25.000
Good good

35:25.000 --> 35:27.000
Now we're going to

35:27.000 --> 35:29.000
Because it's another one

35:29.000 --> 35:31.000
It's more like my topic

35:31.000 --> 35:33.000
We can pause a little bit

35:33.000 --> 35:35.000
Let everyone ask

35:35.000 --> 35:37.000
These algorithms

35:41.000 --> 35:43.000
Hello

35:43.000 --> 35:45.000
My question is

35:45.000 --> 35:47.000
That is

35:47.000 --> 35:49.000
Maybe in the short term

35:49.000 --> 35:51.000
We might just

35:51.000 --> 35:53.000
Rely on dozens of qubits

35:53.000 --> 35:55.000
Or I don't know

35:55.000 --> 35:57.000
Something like 100 qubits

35:57.000 --> 35:59.000
For this kind of really

35:59.000 --> 36:01.000
Strong is really

36:01.000 --> 36:03.000
These

36:03.000 --> 36:05.000
For example, like recommendation system

36:05.000 --> 36:07.000
This kind of thing

36:07.000 --> 36:09.000
Is there a way to do this

36:09.000 --> 36:11.000
Or a few hundred qubits

36:11.000 --> 36:13.000
Test

36:13.000 --> 36:15.000
Uh

36:15.000 --> 36:17.000
Uh

36:17.000 --> 36:19.000
This may not be

36:19.000 --> 36:21.000
But your question is very good

36:21.000 --> 36:23.000
Because my next report is basically

36:23.000 --> 36:25.000
Focus on this question

36:25.000 --> 36:27.000
So that's it

36:27.000 --> 36:29.000
We

36:29.000 --> 36:31.000
What I do with my students

36:31.000 --> 36:33.000
Now this

36:33.000 --> 36:35.000
Hardware development

36:35.000 --> 36:37.000
Can do this

36:37.000 --> 36:39.000
That is to say, we need this

36:39.000 --> 36:41.000
The circuit size is actually very small

36:41.000 --> 36:43.000
I'll give you one later

36:43.000 --> 36:45.000
This is a more specific number

36:45.000 --> 36:47.000
Good good

36:47.000 --> 36:49.000
Thank you

36:49.000 --> 36:51.000
Because of these

36:51.000 --> 36:53.000
Most of the algorithms

36:53.000 --> 36:55.000
All

36:55.000 --> 36:57.000
I need a bigger scale

36:57.000 --> 36:59.000
This quantum computer can do

36:59.000 --> 37:01.000
A negative quantum computer

37:01.000 --> 37:03.000
That is to say

37:03.000 --> 37:05.000
Uh he can't

37:05.000 --> 37:07.000
Just a small device

37:07.000 --> 37:09.000
You can do these things

37:09.000 --> 37:11.000
Right

37:11.000 --> 37:13.000
I also want to ask you

37:13.000 --> 37:15.000
Is the circuit size talking about the circuit depth?

37:15.000 --> 37:17.000
You can do a few gates

37:17.000 --> 37:19.000
This thing

37:19.000 --> 37:21.000
There are still others

37:21.000 --> 37:23.000
Or qubit size

37:23.000 --> 37:25.000
Or circuit depth

37:25.000 --> 37:27.000
I'll give you one later

37:27.000 --> 37:29.000
My example is

37:29.000 --> 37:31.000
You will see later

37:31.000 --> 37:33.000
How many qubits do you need

37:33.000 --> 37:35.000
How many gates do you need

37:39.000 --> 37:41.000
Any other questions

37:41.000 --> 37:43.000
Can you hear that

37:43.000 --> 37:45.000
Can

37:45.000 --> 37:47.000
Let me introduce myself

37:47.000 --> 37:49.000
Sorry

37:49.000 --> 37:51.000
I am that Guo Enrui

37:51.000 --> 37:53.000
Now in

37:53.000 --> 37:55.000
University of Maryland

37:55.000 --> 37:57.000
Hello

37:57.000 --> 37:59.000
Just like me

37:59.000 --> 38:01.000
As far as I know

38:01.000 --> 38:03.000
For example, like Shor's algorithm

38:03.000 --> 38:05.000
It has exponential acceleration

38:05.000 --> 38:07.000
Then like Gravel's search

38:07.000 --> 38:09.000
At least

38:09.000 --> 38:11.000
Even if

38:11.000 --> 38:13.000
At least you can reach the square root of n

38:13.000 --> 38:15.000
I want to ask

38:15.000 --> 38:17.000
Now everyone is mainly doing quantum algorithms

38:17.000 --> 38:19.000
Is studying quantum algorithms

38:19.000 --> 38:21.000
In different

38:21.000 --> 38:23.000
Different aspects

38:23.000 --> 38:25.000
Expansion of different problems

38:25.000 --> 38:27.000
That is, now everyone is mainly studying

38:27.000 --> 38:29.000
In this

38:29.000 --> 38:31.000
Part of the algorithm

38:31.000 --> 38:33.000
Right algorithm

38:33.000 --> 38:35.000
Actually from

38:35.000 --> 38:37.000
From this 1980s

38:37.000 --> 38:39.000
That one

38:39.000 --> 38:41.000
Everyone started to think

38:41.000 --> 38:43.000
Should it be possible to have a quantum computer

38:43.000 --> 38:45.000
Do some

38:45.000 --> 38:47.000
That's the one

38:47.000 --> 38:49.000
He mentioned that maybe we can

38:49.000 --> 38:51.000
Can have a quantum device to do the operation

38:51.000 --> 38:53.000
From that time on

38:53.000 --> 38:55.000
Quantum algorithm is a very, very

38:55.000 --> 38:57.000
Important topic

38:57.000 --> 38:59.000
Its influence is basically

38:59.000 --> 39:01.000
Very comprehensive

39:01.000 --> 39:03.000
For example, we know

39:03.000 --> 39:05.000
In this crypto

39:05.000 --> 39:07.000
In the early days, we were very focused on

39:07.000 --> 39:09.000
This cryptography

39:09.000 --> 39:11.000
Cryptography basically has some

39:11.000 --> 39:13.000
Assumption of computation

39:13.000 --> 39:15.000
Right, that is, I want to assume

39:15.000 --> 39:17.000
What kind of problem

39:17.000 --> 39:19.000
Not good

39:19.000 --> 39:21.000
Then

39:21.000 --> 39:23.000
That

39:23.000 --> 39:25.000
This is the assumption of computation

39:25.000 --> 39:27.000
Many places may

39:27.000 --> 39:29.000
It means that if you say there is a good one

39:29.000 --> 39:31.000
You have a good quantum algorithm

39:31.000 --> 39:33.000
Your assumption of computation is not true

39:33.000 --> 39:35.000
Not established

39:35.000 --> 39:37.000
The most classic is this rsa

39:37.000 --> 39:39.000
Because it assumes this

39:39.000 --> 39:41.000
Prime number is

39:41.000 --> 39:43.000
It's not easy to be affected

39:43.000 --> 39:45.000
It's not easy to find its

39:45.000 --> 39:47.000
The value factor

39:47.000 --> 39:49.000
That's why it's so famous

39:49.000 --> 39:51.000
Another reason

39:51.000 --> 39:53.000
So

39:53.000 --> 39:55.000
You design a good quantum algorithm

39:55.000 --> 39:57.000
You may be able to break a lot

39:57.000 --> 39:59.000
A lot of things

39:59.000 --> 40:01.000
This is why the quantum algorithm is very important

40:01.000 --> 40:03.000
A reason

40:03.000 --> 40:05.000
Thank you

40:07.000 --> 40:09.000
Thank you

40:09.000 --> 40:11.000
That

40:11.000 --> 40:13.000
I'll continue

40:13.000 --> 40:15.000
We'll have one last time

40:15.000 --> 40:17.000
Q&A, you can ask any questions

40:17.000 --> 40:19.000
Okay, that's it

40:19.000 --> 40:21.000
University of Sydney

40:21.000 --> 40:23.000
I'm from the University of Sydney

40:23.000 --> 40:25.000
I happen to be with

40:25.000 --> 40:27.000
The last author

40:27.000 --> 40:29.000
Tao Dacheng

40:29.000 --> 40:31.000
In this classical machine learning

40:31.000 --> 40:33.000
Is a very famous person

40:33.000 --> 40:35.000
This group

40:35.000 --> 40:37.000
He is also interested in this machine learning

40:37.000 --> 40:39.000
Quantum machine learning is very interesting

40:39.000 --> 40:41.000
So I took his students

40:41.000 --> 40:43.000
The first author is his student

40:43.000 --> 40:45.000
From the University of Sydney

40:45.000 --> 40:47.000
Our paper

40:47.000 --> 40:49.000
Just put it on the archive a few days ago

40:49.000 --> 40:51.000
Just put it on the archive in September

40:51.000 --> 40:53.000
We basically

40:53.000 --> 40:55.000
The idea is basically

40:55.000 --> 40:57.000
Combine some classical

40:57.000 --> 40:59.000
Classical machine learning

40:59.000 --> 41:01.000
Then combine some

41:01.000 --> 41:03.000
Quantum algorithm

41:03.000 --> 41:05.000
The idea

41:05.000 --> 41:07.000
Then our

41:07.000 --> 41:09.000
Our target is that we can

41:09.000 --> 41:11.000
Now this hardware

41:11.000 --> 41:13.000
We can do this

41:13.000 --> 41:15.000
Proposal like this

41:15.000 --> 41:17.000
Okay, that's the first one

41:17.000 --> 41:19.000
Let me do a little background introduction

41:19.000 --> 41:21.000
I just introduced global search

41:21.000 --> 41:23.000
Right global search

41:23.000 --> 41:25.000
It can be used basically

41:25.000 --> 41:27.000
Machine learning to implement

41:27.000 --> 41:29.000
How to implement

41:29.000 --> 41:31.000
Basically global search has to do one thing

41:31.000 --> 41:33.000
What is it

41:33.000 --> 41:35.000
I want to find a state

41:35.000 --> 41:37.000
This size, this file, this state

41:37.000 --> 41:39.000
Let it get closer

41:39.000 --> 41:41.000
Omega is the direction I want

41:41.000 --> 41:43.000
I want him to get closer to Omega

41:43.000 --> 41:45.000
The better

41:45.000 --> 41:47.000
I just want to

41:47.000 --> 41:49.000
Basically, this is me

41:49.000 --> 41:51.000
I am doing this place

41:51.000 --> 41:53.000
What are you doing

41:53.000 --> 41:55.000
I want to

41:55.000 --> 41:57.000
The closer he gets to Omega, the better

41:57.000 --> 41:59.000
I want him

41:59.000 --> 42:01.000
The less part perpendicular to Omega

42:01.000 --> 42:03.000
Right, this is basically

42:03.000 --> 42:05.000
What is this equation doing

42:05.000 --> 42:07.000
Then we just said

42:07.000 --> 42:09.000
That's why we can

42:09.000 --> 42:11.000
We can come and learn this

42:11.000 --> 42:13.000
This state

42:13.000 --> 42:15.000
We just use

42:15.000 --> 42:17.000
We use circuit to learn him

42:17.000 --> 42:19.000
Because just that global

42:19.000 --> 42:21.000
The algorithm is that I have two operations

42:21.000 --> 42:23.000
I'm just going to flip it, right

42:23.000 --> 42:25.000
Keep doing it and then flip it to a certain state

42:25.000 --> 42:27.000
Just say about n

42:27.000 --> 42:29.000
This is probably this

42:29.000 --> 42:31.000
This step

42:31.000 --> 42:33.000
I can flip it to the state I want

42:33.000 --> 42:35.000
Right

42:35.000 --> 42:37.000
Then this variational

42:37.000 --> 42:39.000
This idea is basically

42:39.000 --> 42:41.000
Anyway, I'm going to find a state

42:41.000 --> 42:43.000
The closer to this

42:43.000 --> 42:45.000
Omega is better, right?

42:45.000 --> 42:47.000
I just want to

42:47.000 --> 42:49.000
I can use machine learning to recognize this state

42:49.000 --> 42:51.000
Right, this is also this

42:51.000 --> 42:53.000
Biomonte

42:53.000 --> 42:55.000
This nature just wrote that nature

42:55.000 --> 42:57.000
Review article

42:57.000 --> 42:59.000
A thought from their group

42:59.000 --> 43:01.000
This is also a paper in May

43:01.000 --> 43:03.000
This development is very fast

43:03.000 --> 43:05.000
Then he went to recognize this

43:05.000 --> 43:07.000
Recognize this circuit

43:07.000 --> 43:09.000
How does he recognize it?

43:09.000 --> 43:11.000
Hey, I designed two operations

43:11.000 --> 43:13.000
One of them is this P Omega

43:13.000 --> 43:15.000
This operation is what I just had in that slide

43:15.000 --> 43:17.000
And then another PS is just

43:17.000 --> 43:19.000
That is to say, there are two at the beginning

43:19.000 --> 43:21.000
This flip operation

43:21.000 --> 43:23.000
One is Omega and the other is S

43:23.000 --> 43:25.000
It's not exactly

43:25.000 --> 43:27.000
Do P Omega and PS

43:27.000 --> 43:29.000
He can do P Omega again

43:29.000 --> 43:31.000
Give him an alpha angle

43:31.000 --> 43:33.000
Give him a beta angle

43:33.000 --> 43:35.000
What about the angle of this beta

43:35.000 --> 43:37.000
This can be used

43:37.000 --> 43:39.000
This can be used

43:39.000 --> 43:41.000
Optimization

43:41.000 --> 43:43.000
To update your alpha and beta

43:43.000 --> 43:45.000
Right

43:45.000 --> 43:47.000
We are doing

43:47.000 --> 43:49.000
We can all use some mms

43:49.000 --> 43:51.000
Right to do this

43:51.000 --> 43:53.000
To do update

43:53.000 --> 43:55.000
Then he is to update this alpha and beta

43:55.000 --> 43:57.000
Angle to let you next round

43:57.000 --> 43:59.000
Your alpha and beta angles are different

43:59.000 --> 44:01.000
Right then

44:01.000 --> 44:03.000
Then they thought

44:03.000 --> 44:05.000
Hey, if I use this machine

44:05.000 --> 44:07.000
What about the method of learning

44:07.000 --> 44:09.000
What is the comparison with Global Search

44:09.000 --> 44:11.000
Very interesting, look at the next picture

44:11.000 --> 44:13.000
This is their numerical experiment

44:13.000 --> 44:15.000
They just used four cubits

44:15.000 --> 44:17.000
I used four cubits here

44:17.000 --> 44:19.000
And then

44:19.000 --> 44:21.000
And then this blue dot

44:21.000 --> 44:23.000
It's called Global Search

44:23.000 --> 44:25.000
Global Search means

44:25.000 --> 44:27.000
We just said you need to flip, right

44:27.000 --> 44:29.000
You need this

44:29.000 --> 44:31.000
Omega and S do a round like this

44:31.000 --> 44:33.000
Right

44:33.000 --> 44:35.000
Is this a round

44:35.000 --> 44:37.000
One round is two steps, right

44:37.000 --> 44:39.000
And then you need to do a few rounds

44:39.000 --> 44:41.000
This Global Search probably tells you

44:41.000 --> 44:43.000
Probably four rounds

44:43.000 --> 44:45.000
Is eight operations

44:45.000 --> 44:47.000
In fact, it is

44:47.000 --> 44:49.000
2n plus 1, so it should be nine

44:49.000 --> 44:51.000
Right

44:51.000 --> 44:53.000
Nine words

44:53.000 --> 44:55.000
Look at this

44:55.000 --> 44:57.000
Horizontal

44:57.000 --> 44:59.000
X-axis, you will find

45:03.000 --> 45:05.000
Several times

45:05.000 --> 45:07.000
This point is done nine times

45:07.000 --> 45:09.000
Global Search

45:09.000 --> 45:11.000
It can get the biggest

45:11.000 --> 45:13.000
The biggest chance you see is 1

45:13.000 --> 45:15.000
You see you are in this Oracle P

45:15.000 --> 45:17.000
This is equal to 9

45:17.000 --> 45:19.000
Your chance is 1, right

45:19.000 --> 45:21.000
This means that Global Search

45:21.000 --> 45:23.000
At this point, you can get the biggest chance

45:23.000 --> 45:25.000
And then at other points

45:25.000 --> 45:27.000
You see this probability is fluctuating

45:27.000 --> 45:29.000
Right, it's actually like this

45:29.000 --> 45:31.000
Up and down, right, it's only in

45:31.000 --> 45:33.000
The probability is the biggest

45:33.000 --> 45:35.000
And then in this part of the red cross

45:35.000 --> 45:37.000
They got it by machine learning

45:37.000 --> 45:39.000
Very interesting

45:39.000 --> 45:41.000
At nine

45:41.000 --> 45:43.000
It can be the same as Global Search

45:43.000 --> 45:45.000
The result

45:45.000 --> 45:47.000
But in other places

45:47.000 --> 45:49.000
It can be better than Global Search

45:49.000 --> 45:51.000
It's more robust

45:51.000 --> 45:53.000
That is to say

45:53.000 --> 45:55.000
You won't be because of yours

45:55.000 --> 45:57.000
For example, I was supposed to be in the nine

45:57.000 --> 45:59.000
I'm going to stop

45:59.000 --> 46:01.000
But I stopped early

46:01.000 --> 46:03.000
For example, I stopped at 8

46:03.000 --> 46:05.000
I'm this up and down

46:05.000 --> 46:07.000
I did it eight times

46:07.000 --> 46:09.000
What if you use Variation

46:09.000 --> 46:11.000
It will be better, right

46:11.000 --> 46:13.000
It will be robust to your system design

46:13.000 --> 46:15.000
What about this idea

46:15.000 --> 46:17.000
That is to say, we

46:17.000 --> 46:19.000
We want to say that this idea

46:19.000 --> 46:21.000
Perception

46:21.000 --> 46:23.000
Perception is basically

46:23.000 --> 46:25.000
That is to say, you are also going to search

46:25.000 --> 46:27.000
So basically you can put this

46:27.000 --> 46:29.000
Global Search Embedded in your Perception

46:29.000 --> 46:31.000
You just have to identify you

46:31.000 --> 46:33.000
Mislabeled this value

46:33.000 --> 46:35.000
Right, that is to say

46:35.000 --> 46:37.000
That is to say, we

46:37.000 --> 46:39.000
Use this idea

46:39.000 --> 46:41.000
This is our step

46:41.000 --> 46:43.000
Give me a database

46:43.000 --> 46:45.000
This database

46:45.000 --> 46:47.000
I have so many points

46:47.000 --> 46:49.000
i from 1 to n

46:49.000 --> 46:51.000
I have so many points

46:51.000 --> 46:53.000
Then every point of mine

46:53.000 --> 46:55.000
Xi is my input

46:55.000 --> 46:57.000
Every point of mine

46:57.000 --> 46:59.000
I have m so many features

46:59.000 --> 47:01.000
I just want to go from feature

47:01.000 --> 47:03.000
To identify my

47:03.000 --> 47:05.000
To identify my label

47:05.000 --> 47:07.000
This yi is my label

47:07.000 --> 47:09.000
It may be positive or negative

47:09.000 --> 47:11.000
Then, of course, the first step

47:11.000 --> 47:13.000
I want to put this classical data

47:13.000 --> 47:15.000
Encode to a quantum state

47:15.000 --> 47:17.000
What about this quantum state

47:17.000 --> 47:19.000
What do we do

47:19.000 --> 47:21.000
That is to say, I put this feature

47:21.000 --> 47:23.000
I put this

47:23.000 --> 47:25.000
Xi

47:25.000 --> 47:27.000
Encode to my input

47:27.000 --> 47:29.000
Then

47:29.000 --> 47:31.000
Then I have another

47:31.000 --> 47:33.000
This index register

47:33.000 --> 47:35.000
I just came to keep track

47:35.000 --> 47:37.000
I have a few

47:37.000 --> 47:39.000
A few samples

47:39.000 --> 47:41.000
This i this place

47:41.000 --> 47:43.000
I just need to say I have n

47:43.000 --> 47:45.000
N so many

47:45.000 --> 47:47.000
I need to log n

47:47.000 --> 47:49.000
Because

47:49.000 --> 47:51.000
Because you know

47:51.000 --> 47:53.000
Quantum state can be superposition

47:53.000 --> 47:55.000
So I just need to log n so many

47:55.000 --> 47:57.000
I can keep track

47:57.000 --> 47:59.000
This n

47:59.000 --> 48:01.000
This n

48:01.000 --> 48:03.000
Such a big data

48:03.000 --> 48:05.000
Data set

48:05.000 --> 48:07.000
The same

48:07.000 --> 48:09.000
If I say there are m features

48:09.000 --> 48:11.000
This feature register

48:11.000 --> 48:13.000
I just need to log n so many

48:13.000 --> 48:15.000
That is to say, it actually has a

48:15.000 --> 48:17.000
Index compression

48:17.000 --> 48:19.000
Of course, this step is actually

48:19.000 --> 48:21.000
I'll tell you from the beginning

48:21.000 --> 48:23.000
It actually needs a

48:23.000 --> 48:25.000
A more non-trivial algorithm

48:25.000 --> 48:27.000
But I'll come back to this issue later

48:29.000 --> 48:31.000
Uh, and then

48:31.000 --> 48:33.000
The first step is to say

48:33.000 --> 48:35.000
I'm going to do this UK operation

48:35.000 --> 48:37.000
What about this UK operation

48:37.000 --> 48:39.000
What am I going to do

48:39.000 --> 48:41.000
I want to identify this K

48:41.000 --> 48:43.000
Basically, this

48:43.000 --> 48:45.000
My state basically means

48:45.000 --> 48:47.000
My K

48:47.000 --> 48:49.000
Has been mislabeled

48:49.000 --> 48:51.000
So I'm going to mislabel

48:51.000 --> 48:53.000
This place introduces a

48:53.000 --> 48:55.000
Face

48:55.000 --> 48:57.000
What about this UK

48:57.000 --> 48:59.000
I want to do this thing

48:59.000 --> 49:01.000
But what about me

49:01.000 --> 49:03.000
I'm going to design a

49:03.000 --> 49:05.000
Learning algorithm, I'm going to learn

49:05.000 --> 49:07.000
I'm going to

49:07.000 --> 49:09.000
Approximate this UK

49:09.000 --> 49:11.000
With this

49:11.000 --> 49:13.000
With this low depth

49:13.000 --> 49:15.000
Quantum circuit

49:15.000 --> 49:17.000
Approximate UK and then achieve this

49:17.000 --> 49:19.000
Basically this is

49:19.000 --> 49:21.000
And then

49:21.000 --> 49:23.000
Because this is different from global search

49:23.000 --> 49:25.000
Because we have feature register

49:25.000 --> 49:27.000
With index register

49:27.000 --> 49:29.000
Feature register is for you

49:29.000 --> 49:31.000
To recognize your

49:31.000 --> 49:33.000
What does your distribution look like

49:33.000 --> 49:35.000
Right?

49:35.000 --> 49:37.000
There is no feature

49:37.000 --> 49:39.000
You just need to do your index register

49:39.000 --> 49:41.000
Right?

49:41.000 --> 49:43.000
But because

49:43.000 --> 49:45.000
We're in front of this

49:45.000 --> 49:47.000
Because you're done

49:47.000 --> 49:49.000
This

49:49.000 --> 49:51.000
Give you this

49:51.000 --> 49:53.000
Add a face

49:53.000 --> 49:55.000
Because he actually

49:55.000 --> 49:57.000
With this index

49:57.000 --> 49:59.000
He actually has one

49:59.000 --> 50:01.000
These two registers

50:01.000 --> 50:03.000
It actually exists

50:03.000 --> 50:05.000
You do the operation for K

50:05.000 --> 50:07.000
You will affect you

50:07.000 --> 50:09.000
Feature this register

50:09.000 --> 50:11.000
So we need to do one more step

50:11.000 --> 50:13.000
We need to do this step

50:13.000 --> 50:15.000
We need to put the feature

50:15.000 --> 50:17.000
This register

50:17.000 --> 50:19.000
With your index register

50:19.000 --> 50:21.000
Disentangle it

50:21.000 --> 50:23.000
So you see this is now

50:23.000 --> 50:25.000
It means that there is no correlation in the middle

50:25.000 --> 50:27.000
There is no correlation

50:27.000 --> 50:29.000
That is, we

50:29.000 --> 50:31.000
What about our circuit

50:31.000 --> 50:33.000
Disentangle

50:33.000 --> 50:35.000
This operation

50:35.000 --> 50:37.000
These two operations

50:37.000 --> 50:39.000
We're going to use the method of machine learning

50:39.000 --> 50:41.000
And then

50:41.000 --> 50:43.000
Basically, this is my two

50:43.000 --> 50:45.000
Basic operation

50:45.000 --> 50:47.000
This picture is a demo

50:47.000 --> 50:49.000
This ul1 is what I just did

50:49.000 --> 50:51.000
And then, no, ul1

50:51.000 --> 50:53.000
Plus this control g

50:53.000 --> 50:55.000
Basically, this is what I just did

50:55.000 --> 50:57.000
And then

50:57.000 --> 50:59.000
This ul1

50:59.000 --> 51:01.000
In fact, because this is just learning

51:01.000 --> 51:03.000
Your feature, so it's just in this feature

51:03.000 --> 51:05.000
Register

51:05.000 --> 51:07.000
Disentangle can also be used

51:07.000 --> 51:09.000
In this feature register

51:09.000 --> 51:11.000
And then disentangle

51:11.000 --> 51:13.000
This unit

51:13.000 --> 51:15.000
This is basically just

51:15.000 --> 51:17.000
The second inversion of this global search

51:17.000 --> 51:19.000
For this s

51:19.000 --> 51:21.000
An inversion of this plane

51:21.000 --> 51:23.000
What about this inversion

51:23.000 --> 51:25.000
Because it's going to do an inversion of your index

51:25.000 --> 51:27.000
So it's just an index register

51:27.000 --> 51:29.000
This is a

51:29.000 --> 51:31.000
This is a

51:31.000 --> 51:33.000
An iteration

51:33.000 --> 51:35.000
Then I need a total of about

51:35.000 --> 51:37.000
All n so many iterations

51:37.000 --> 51:39.000
And then you'll find

51:39.000 --> 51:41.000
That's what we're actually doing here

51:41.000 --> 51:43.000
This quantum

51:43.000 --> 51:45.000
Quantum state

51:45.000 --> 51:47.000
This quantum circuit

51:47.000 --> 51:49.000
I use this classical

51:49.000 --> 51:51.000
Optimization to do

51:51.000 --> 51:53.000
Just like this variation of global search

51:53.000 --> 51:55.000
It actually has an angle that can be controlled

51:55.000 --> 51:57.000
I'm using classical

51:57.000 --> 51:59.000
To do optimization

51:59.000 --> 52:01.000
That is to say, there are some MMD

52:01.000 --> 52:03.000
This is more

52:03.000 --> 52:05.000
Anyway, this is some classical optimization

52:05.000 --> 52:07.000
Machine learning often does some things

52:07.000 --> 52:09.000
Then I update and do it again

52:09.000 --> 52:11.000
I've been doing square root n so many times

52:11.000 --> 52:13.000
Ah

52:13.000 --> 52:15.000
Just like global search

52:15.000 --> 52:17.000
Square root n so many times

52:17.000 --> 52:19.000
I can adjust it to the angle I want

52:19.000 --> 52:21.000
Like this

52:21.000 --> 52:23.000
This is our

52:23.000 --> 52:25.000
Simple experiment

52:25.000 --> 52:27.000
Then we can

52:27.000 --> 52:29.000
We use experiments to implement

52:29.000 --> 52:31.000
That

52:31.000 --> 52:33.000
What about this place

52:33.000 --> 52:35.000
I

52:35.000 --> 52:37.000
Ah

52:37.000 --> 52:39.000
Say

52:39.000 --> 52:41.000
Inside this square

52:41.000 --> 52:43.000
I told you that every one of me

52:43.000 --> 52:45.000
Every one of this

52:45.000 --> 52:47.000
How big is this

52:47.000 --> 52:49.000
Our circuit

52:49.000 --> 52:51.000
It's probably three

52:51.000 --> 52:53.000
Three three three

52:53.000 --> 52:55.000
Three layers like this

52:55.000 --> 52:57.000
Or five layers

52:57.000 --> 52:59.000
Because of our

52:59.000 --> 53:01.000
Our

53:01.000 --> 53:03.000
Feature is probably

53:03.000 --> 53:05.000
Just

53:05.000 --> 53:07.000
Our example

53:07.000 --> 53:09.000
It's actually quite small

53:09.000 --> 53:11.000
We'll have a bigger example later

53:11.000 --> 53:13.000
Our feature size is probably

53:13.000 --> 53:15.000
Four

53:15.000 --> 53:17.000
There are four features in each sample

53:17.000 --> 53:19.000
Then you will find

53:19.000 --> 53:21.000
My success probability

53:21.000 --> 53:23.000
Can be up to

53:23.000 --> 53:25.000
About 80%

53:25.000 --> 53:27.000
Ah

53:27.000 --> 53:29.000
The one on the left is this

53:29.000 --> 53:31.000
You identify your

53:31.000 --> 53:33.000
Mislabel index

53:33.000 --> 53:35.000
This probability

53:35.000 --> 53:37.000
The error rate is probably

53:37.000 --> 53:39.000
It can be up to 80%

53:39.000 --> 53:41.000
90% like this

53:41.000 --> 53:43.000
Classification

53:43.000 --> 53:45.000
This place

53:45.000 --> 53:47.000
Then

53:47.000 --> 53:49.000
Perception can only do this

53:49.000 --> 53:51.000
Linear partition

53:51.000 --> 53:53.000
What if we want to

53:53.000 --> 53:55.000
How do we do it

53:55.000 --> 53:57.000
We just have to combine these

53:57.000 --> 53:59.000
Perception

53:59.000 --> 54:01.000
I don't know if there is

54:01.000 --> 54:03.000
Is there any of this

54:03.000 --> 54:05.000
More familiar with machine learning

54:05.000 --> 54:07.000
We are

54:07.000 --> 54:09.000
There is one called Ensemble Learning

54:09.000 --> 54:11.000
Basically the idea is

54:11.000 --> 54:13.000
I have a big

54:13.000 --> 54:15.000
Ah database

54:15.000 --> 54:17.000
I have a bigger sample

54:17.000 --> 54:19.000
I don't need to

54:19.000 --> 54:21.000
I don't need to use this whole sample

54:21.000 --> 54:23.000
What can I do

54:23.000 --> 54:25.000
I can

54:25.000 --> 54:27.000
I can sample from the inside

54:27.000 --> 54:29.000
Some smaller data

54:29.000 --> 54:31.000
Then I use these smaller data

54:31.000 --> 54:33.000
Set to train

54:33.000 --> 54:35.000
My perception

54:35.000 --> 54:37.000
Then I use my

54:37.000 --> 54:39.000
A few weaker perceptions

54:39.000 --> 54:41.000
I can combine it into one

54:41.000 --> 54:43.000
Strong perception

54:43.000 --> 54:45.000
This idea is called

54:45.000 --> 54:47.000
This is the idea of ​​Ensemble Learning

54:47.000 --> 54:49.000
Then

54:49.000 --> 54:51.000
Doing this is sub-sampling

54:51.000 --> 54:53.000
Because I don't need to

54:53.000 --> 54:55.000
Such a big database

54:55.000 --> 54:57.000
I just sample some smaller data

54:57.000 --> 54:59.000
This is the concept of sub-sampling

54:59.000 --> 55:01.000
So if I say I can train

55:01.000 --> 55:03.000
My capital T

55:07.000 --> 55:09.000
Then I can

55:09.000 --> 55:11.000
This yt

55:11.000 --> 55:13.000
Is the outcome of each vt

55:13.000 --> 55:15.000
Then my ct

55:15.000 --> 55:17.000
Is my preset threshold

55:17.000 --> 55:19.000
Then I can use this thing

55:19.000 --> 55:21.000
To do a better

55:21.000 --> 55:23.000
This

55:23.000 --> 55:25.000
Ah

55:25.000 --> 55:27.000
Then we want to know

55:27.000 --> 55:29.000
Will this combine be better than

55:29.000 --> 55:31.000
My weak

55:31.000 --> 55:33.000
Right

55:33.000 --> 55:35.000
Then we will do a numerical

55:35.000 --> 55:37.000
Conclusion

55:37.000 --> 55:39.000
What are the benefits of this

55:39.000 --> 55:41.000
It can

55:41.000 --> 55:43.000
You can put your bigger

55:43.000 --> 55:45.000
Training set to break it down into

55:45.000 --> 55:47.000
Smaller training set

55:47.000 --> 55:49.000
Then you train this weak classifier

55:49.000 --> 55:51.000
Then this just fits

55:51.000 --> 55:53.000
This quantum machine learning now

55:53.000 --> 55:55.000
Because we mentioned at the beginning

55:55.000 --> 55:57.000
What is the bottleneck of quantum machine learning

55:57.000 --> 55:59.000
What is it

55:59.000 --> 56:01.000
Classical data

56:01.000 --> 56:03.000
Quantum state

56:03.000 --> 56:05.000
This is almost all

56:05.000 --> 56:07.000
Quantum machine learning proposal

56:07.000 --> 56:09.000
Then we use

56:09.000 --> 56:11.000
The idea of sub-sampling

56:11.000 --> 56:13.000
The idea of ensemble learning

56:13.000 --> 56:15.000
We can overcome this problem

56:15.000 --> 56:17.000
Because you are actually a small data set

56:17.000 --> 56:19.000
You are still quite efficient

56:19.000 --> 56:21.000
You don't need to say

56:21.000 --> 56:23.000
I have a hundred thousand points

56:23.000 --> 56:25.000
With me a

56:25.000 --> 56:27.000
This complexity

56:27.000 --> 56:29.000
It's not just a hundred thousand

56:29.000 --> 56:31.000
Divided by one hundred so much

56:31.000 --> 56:33.000
It's actually every step

56:33.000 --> 56:35.000
After the complexity you need

56:35.000 --> 56:37.000
The complexity is multiplied by the index

56:37.000 --> 56:39.000
So we use

56:39.000 --> 56:41.000
This concept is actually very

56:41.000 --> 56:43.000
Very fit for now

56:43.000 --> 56:45.000
The development of quantum hardware

56:45.000 --> 56:47.000
Good

56:47.000 --> 56:49.000
Then

56:49.000 --> 56:51.000
Next is a more

56:51.000 --> 56:53.000
One of CS

56:53.000 --> 56:55.000
We want to characterize our efficiency

56:55.000 --> 56:57.000
If we say every data set

56:57.000 --> 56:59.000
Every data set

56:59.000 --> 57:01.000
Because we want to train some

57:01.000 --> 57:03.000
Weak classifier

57:03.000 --> 57:05.000
If I say

57:05.000 --> 57:07.000
Log square root n so many points

57:07.000 --> 57:09.000
Then we

57:09.000 --> 57:11.000
Query complexity

57:11.000 --> 57:13.000
This capital T means that I have a few

57:13.000 --> 57:15.000
I have a total

57:15.000 --> 57:17.000
Weak classifier number is

57:17.000 --> 57:19.000
This capital T so many

57:19.000 --> 57:21.000
Then you will find that because it is actually

57:21.000 --> 57:23.000
Still related to this global algorithm

57:23.000 --> 57:25.000
So it is with you

57:25.000 --> 57:27.000
This square root of the data set

57:27.000 --> 57:29.000
So if you say it's log n

57:29.000 --> 57:31.000
Square root is probably

57:31.000 --> 57:33.000
Multiply by this quantity

57:33.000 --> 57:35.000
This m is the size of your feature

57:35.000 --> 57:37.000
This is related to me

57:37.000 --> 57:39.000
How many steps do you need to do

57:39.000 --> 57:41.000
How many steps do you need to do

57:41.000 --> 57:43.000
Then this is probably

57:43.000 --> 57:45.000
Heuristic is probably

57:45.000 --> 57:47.000
Log n so many steps

57:47.000 --> 57:49.000
We will demonstrate later

57:49.000 --> 57:51.000
If I say I choose log n

57:51.000 --> 57:53.000
So many classical optimization

57:53.000 --> 57:55.000
Then every data set of mine

57:55.000 --> 57:57.000
I'll have one later

57:57.000 --> 57:59.000
Performance comparison

57:59.000 --> 58:01.000
Run time is probably

58:01.000 --> 58:03.000
With log n

58:03.000 --> 58:05.000
Multiply this

58:05.000 --> 58:07.000
Polynomial relationship

58:07.000 --> 58:09.000
So basically it is very efficient

58:09.000 --> 58:11.000
it is good

58:11.000 --> 58:13.000
it is good

58:13.000 --> 58:15.000
This is our

58:15.000 --> 58:17.000
A practical example we run

58:17.000 --> 58:19.000
A classical database

58:19.000 --> 58:21.000
Tens of thousands of points

58:21.000 --> 58:23.000
10,000 points

58:23.000 --> 58:25.000
Then every point

58:25.000 --> 58:27.000
This feature is four

58:27.000 --> 58:29.000
Is four features

58:29.000 --> 58:31.000
Can be encoded on two qubits

58:31.000 --> 58:33.000
Then we sub-sampling

58:33.000 --> 58:35.000
We just sample

58:35.000 --> 58:37.000
We just make it a sample of four smaller databases

58:37.000 --> 58:39.000
Then every database

58:39.000 --> 58:41.000
Only eight points

58:41.000 --> 58:43.000
So this ratio is very small

58:43.000 --> 58:45.000
It's about 8 out of 10,000

58:45.000 --> 58:47.000
Then we found that if you use 8 out of 10,000

58:47.000 --> 58:49.000
You can follow

58:49.000 --> 58:51.000
You can get it directly from this

58:51.000 --> 58:53.000
From this 10,000 points

58:53.000 --> 58:55.000
To train

58:55.000 --> 58:57.000
Your perception

58:57.000 --> 58:59.000
Your combined efficiency is basically

58:59.000 --> 59:01.000
With you

59:01.000 --> 59:03.000
10,000 points to do the same

59:03.000 --> 59:05.000
So you look at the last of this table

59:05.000 --> 59:07.000
The last column

59:07.000 --> 59:09.000
The last column means that I have combined

59:09.000 --> 59:11.000
I have four

59:11.000 --> 59:13.000
This week

59:13.000 --> 59:15.000
This week's perception

59:15.000 --> 59:17.000
This is my last combined success probability

59:17.000 --> 59:19.000
You will find that it is

59:19.000 --> 59:21.000
It can be up to about 80%

59:21.000 --> 59:23.000
Of course with

59:23.000 --> 59:25.000
It's not so good

59:25.000 --> 59:27.000
But

59:27.000 --> 59:29.000
Hardware can be implemented now

59:29.000 --> 59:31.000
Basically this is already a very

59:31.000 --> 59:33.000
Very

59:33.000 --> 59:35.000
Very good proposal because it is now

59:35.000 --> 59:37.000
Hardware can also be implemented

59:37.000 --> 59:39.000
Ah

59:39.000 --> 59:41.000
This is my example

59:41.000 --> 59:43.000
Ah oh yes

59:43.000 --> 59:45.000
This place

59:45.000 --> 59:47.000
There is a caveat

59:47.000 --> 59:49.000
This is

59:49.000 --> 59:51.000
We

59:51.000 --> 59:53.000
We can also another one

59:53.000 --> 59:55.000
If you say you have a way to let you

59:55.000 --> 59:57.000
Ah sample

59:57.000 --> 59:59.000
Ah this data set

59:59.000 --> 01:00:01.000
If you say your subsampling

01:00:01.000 --> 01:00:03.000
You can sample away

01:00:03.000 --> 01:00:05.000
From this

01:00:05.000 --> 01:00:07.000
Perception of each week

01:00:07.000 --> 01:00:09.000
Because perception is basically

01:00:09.000 --> 01:00:11.000
Classify left or classify right

01:00:11.000 --> 01:00:13.000
If you say your sample

01:00:13.000 --> 01:00:15.000
When you do subsampling

01:00:15.000 --> 01:00:17.000
You can avoid this

01:00:17.000 --> 01:00:19.000
These points

01:00:19.000 --> 01:00:21.000
This probability can also be increased to 92%

01:00:23.000 --> 01:00:25.000
Say this depends on you

01:00:25.000 --> 01:00:27.000
This method of subsampling

01:00:27.000 --> 01:00:29.000
At the most

01:00:29.000 --> 01:00:31.000
Say at the most extreme

01:00:31.000 --> 01:00:33.000
If you say even if you use uniform sampling

01:00:33.000 --> 01:00:35.000
Then we can still get 80%

01:00:35.000 --> 01:00:37.000
If you say your sampling you can adjust

01:00:37.000 --> 01:00:39.000
You can get 9 times 2

01:00:39.000 --> 01:00:41.000
9 times 2 is already very impressive

01:00:41.000 --> 01:00:43.000
I think so

01:00:43.000 --> 01:00:45.000
I don't know his community

01:00:45.000 --> 01:00:47.000
Reason

01:00:47.000 --> 01:00:49.000
I think his community can do very well

01:00:49.000 --> 01:00:51.000
So at least in the quantum community

01:00:51.000 --> 01:00:53.000
No one can do it like us

01:00:53.000 --> 01:00:55.000
So good

01:00:55.000 --> 01:00:57.000
This place is just that

01:00:57.000 --> 01:00:59.000
Ah

01:00:59.000 --> 01:01:01.000
The question asked by the agent is

01:01:01.000 --> 01:01:03.000
How many operations do we need

01:01:03.000 --> 01:01:05.000
In the numerical experiment we just did

01:01:05.000 --> 01:01:07.000
We actually use that regated

01:01:07.000 --> 01:01:09.000
Cloud platform they have a library

01:01:09.000 --> 01:01:11.000
Then we implement

01:01:11.000 --> 01:01:13.000
We all use his standard library

01:01:13.000 --> 01:01:15.000
If they want they can take our code

01:01:15.000 --> 01:01:17.000
Can compile to their

01:01:17.000 --> 01:01:19.000
This circuit can be run like this

01:01:19.000 --> 01:01:21.000
Then

01:01:21.000 --> 01:01:23.000
We say that in encoding

01:01:23.000 --> 01:01:25.000
We want to put classical map to quantum state

01:01:25.000 --> 01:01:27.000
If you use subsampling you only need to use

01:01:27.000 --> 01:01:29.000
29 operations

01:01:29.000 --> 01:01:31.000
Probably use 29 operations

01:01:31.000 --> 01:01:33.000
Then this is all from him

01:01:33.000 --> 01:01:35.000
That's what I just said

01:01:35.000 --> 01:01:37.000
You use their library

01:01:37.000 --> 01:01:39.000
You can

01:01:39.000 --> 01:01:41.000
After you input the database

01:01:41.000 --> 01:01:43.000
He will tell you your

01:01:43.000 --> 01:01:45.000
How many gates do you need

01:01:45.000 --> 01:01:47.000
So we

01:01:47.000 --> 01:01:49.000
Input it about 29

01:01:49.000 --> 01:01:51.000
On average 29

01:01:51.000 --> 01:01:53.000
Then the operations behind us

01:01:53.000 --> 01:01:55.000
Don't we have a few operations

01:01:55.000 --> 01:01:57.000
That is, you have to flip your face

01:01:57.000 --> 01:01:59.000
And then you have to disentangle

01:01:59.000 --> 01:02:01.000
Right then

01:02:01.000 --> 01:02:03.000
What about the operation we need in total

01:02:03.000 --> 01:02:05.000
Ah

01:02:05.000 --> 01:02:07.000
That's what we need

01:02:07.000 --> 01:02:09.000
About 36

01:02:09.000 --> 01:02:11.000
Can control your angle

01:02:11.000 --> 01:02:13.000
Then

01:02:13.000 --> 01:02:15.000
Then

01:02:15.000 --> 01:02:17.000
Then

01:02:17.000 --> 01:02:19.000
Then

01:02:19.000 --> 01:02:21.000
Then

01:02:21.000 --> 01:02:23.000
You can

01:02:23.000 --> 01:02:25.000
So if you say

01:02:25.000 --> 01:02:27.000
Decomposing

01:02:27.000 --> 01:02:29.000
We probably need a total of 146

01:02:29.000 --> 01:02:31.000
Jingle with

01:02:31.000 --> 01:02:33.000
You can do our experiment

01:02:33.000 --> 01:02:35.000
Like this

01:02:35.000 --> 01:02:37.000
Okay, this is probably the details of our experiment

01:02:37.000 --> 01:02:39.000
Then

01:02:39.000 --> 01:02:41.000
Well, this one after this

01:02:41.000 --> 01:02:43.000
The latter is more complicated

01:02:43.000 --> 01:02:45.000
I won't talk about it first

01:02:45.000 --> 01:02:47.000
Anyway, when the time comes, everyone has an opinion

01:02:47.000 --> 01:02:49.000
Maybe I can come back later

01:02:49.000 --> 01:02:51.000
Give other talk like this

01:02:51.000 --> 01:02:53.000
Okay, I don't know

01:02:53.000 --> 01:02:55.000
Do you have any questions

01:02:55.000 --> 01:02:57.000
Like this

01:02:57.000 --> 01:02:59.000
Thank you

01:02:59.000 --> 01:03:01.000
Hello

01:03:01.000 --> 01:03:03.000
Can you ask a question

01:03:03.000 --> 01:03:05.000
Related to your talk

01:03:05.000 --> 01:03:07.000
Okay, no problem

01:03:07.000 --> 01:03:09.000
Because you mentioned it at the beginning

01:03:09.000 --> 01:03:11.000
Let me introduce myself first

01:03:11.000 --> 01:03:13.000
My name is Chen Yuan, I am a fourth grade

01:03:13.000 --> 01:03:15.000
Then

01:03:15.000 --> 01:03:17.000
You mentioned that Taiwan is planning

01:03:17.000 --> 01:03:19.000
Want to

01:03:19.000 --> 01:03:21.000
It's also related to computation

01:03:21.000 --> 01:03:23.000
This is more famous

01:03:23.000 --> 01:03:25.000
Like Microsoft

01:03:25.000 --> 01:03:27.000
Should be

01:03:27.000 --> 01:03:29.000
Or google

01:03:29.000 --> 01:03:31.000
Buy john martini's lab

01:03:31.000 --> 01:03:33.000
That Taiwan

01:03:33.000 --> 01:03:35.000
Have decided to use

01:03:35.000 --> 01:03:37.000
Which one

01:03:37.000 --> 01:03:39.000
Which direction

01:03:39.000 --> 01:03:41.000
To do

01:03:41.000 --> 01:03:43.000
This is a good question

01:03:43.000 --> 01:03:45.000
Basically

01:03:45.000 --> 01:03:47.000
Taiwan's tendency is more

01:03:47.000 --> 01:03:49.000
It should be said that the high-level

01:03:49.000 --> 01:03:51.000
Government technology minister

01:03:51.000 --> 01:03:53.000
Their tendency is more

01:03:53.000 --> 01:03:55.000
Hope to use semiconductor

01:03:55.000 --> 01:03:57.000
Yes, the semiconductor

01:03:57.000 --> 01:03:59.000
The big company has not yet invested

01:03:59.000 --> 01:04:01.000
I can't say that either

01:04:01.000 --> 01:04:03.000
The big company is now

01:04:03.000 --> 01:04:05.000
It may have a main force

01:04:05.000 --> 01:04:07.000
But he didn't give up

01:04:07.000 --> 01:04:09.000
Other proposals

01:04:09.000 --> 01:04:11.000
The best semiconductor is Australia

01:04:11.000 --> 01:04:13.000
Australia

01:04:13.000 --> 01:04:15.000
University of New South Wales

01:04:15.000 --> 01:04:17.000
University of New South Wales

01:04:17.000 --> 01:04:19.000
They are leading the world

01:04:19.000 --> 01:04:21.000
Semiconductor technology

01:04:21.000 --> 01:04:23.000
Their Qubit is using

01:04:23.000 --> 01:04:25.000
Semiconductor process

01:04:25.000 --> 01:04:27.000
So then

01:04:27.000 --> 01:04:29.000
Taiwan has TSMC

01:04:29.000 --> 01:04:31.000
Everyone still hopes to use semiconductor

01:04:31.000 --> 01:04:33.000
So the government department technology department

01:04:33.000 --> 01:04:35.000
Preferred approach is also

01:04:35.000 --> 01:04:37.000
Semiconductor

01:04:37.000 --> 01:04:39.000
Then Taiwan University

01:04:39.000 --> 01:04:41.000
Now it is said that the Taiwan University of Physics

01:04:41.000 --> 01:04:43.000
Then with the Taiwan University of Electrical Engineering

01:04:43.000 --> 01:04:45.000
Li Junyun

01:04:45.000 --> 01:04:47.000
With

01:04:47.000 --> 01:04:49.000
Teacher Chen Shiyuan

01:04:51.000 --> 01:04:53.000
They are now saying that they have

01:04:53.000 --> 01:04:55.000
A team is now

01:04:55.000 --> 01:04:57.000
Follow is to say that they want to

01:04:57.000 --> 01:04:59.000
Mainly to work with

01:04:59.000 --> 01:05:01.000
Cooperate with University of New South Wales

01:05:01.000 --> 01:05:03.000
They want to develop semiconductor technology

01:05:03.000 --> 01:05:05.000
Then now this Tsinghua University

01:05:05.000 --> 01:05:07.000
This research center

01:05:13.000 --> 01:05:15.000
Inside a

01:05:15.000 --> 01:05:17.000
Project to do superconductivity

01:05:17.000 --> 01:05:19.000
In fact, the Central Academy of Sciences has a teacher doing superconductivity

01:05:19.000 --> 01:05:21.000
Qubit

01:05:23.000 --> 01:05:25.000
So

01:05:25.000 --> 01:05:27.000
In this Tsinghua University

01:05:27.000 --> 01:05:29.000
There are people doing superconductivity experiments

01:05:29.000 --> 01:05:31.000
Of course there is also light and snow

01:05:31.000 --> 01:05:33.000
There is also a group of people doing light and snow

01:05:33.000 --> 01:05:35.000
Qubit

01:05:35.000 --> 01:05:37.000
Light and snow, of course, also need

01:05:37.000 --> 01:05:39.000
Sorry

01:05:41.000 --> 01:05:43.000
Sorry

01:05:43.000 --> 01:05:45.000
I just want to ask if this is in the field

01:05:45.000 --> 01:05:47.000
Generally speaking, which direction

01:05:47.000 --> 01:05:49.000
Is the most likely to be done

01:05:49.000 --> 01:05:51.000
The most robust and then the easiest

01:05:51.000 --> 01:05:53.000
Large-scale production

01:05:53.000 --> 01:05:55.000
It's not easy

01:05:55.000 --> 01:05:57.000
Because these are all super low temperatures

01:05:59.000 --> 01:06:01.000
Superconductivity now needs

01:06:01.000 --> 01:06:03.000
Hundreds of

01:06:03.000 --> 01:06:05.000
Mini-K

01:06:05.000 --> 01:06:07.000
It's almost absolute zero

01:06:07.000 --> 01:06:09.000
Then semiconductor

01:06:09.000 --> 01:06:11.000
Can go to

01:06:11.000 --> 01:06:13.000
Maybe

01:06:13.000 --> 01:06:15.000
Around 4K

01:06:15.000 --> 01:06:17.000
Now

01:06:17.000 --> 01:06:19.000
Large-scale is almost

01:06:19.000 --> 01:06:21.000
At present

01:06:21.000 --> 01:06:23.000
No idea

01:06:25.000 --> 01:06:27.000
It's not like our computer can be at room temperature

01:06:27.000 --> 01:06:29.000
These devices all need a

01:06:29.000 --> 01:06:31.000
A big refrigerator

01:06:31.000 --> 01:06:33.000
Cool it down to almost zero

01:06:33.000 --> 01:06:35.000
Absolute zero

01:06:35.000 --> 01:06:37.000
So

01:06:37.000 --> 01:06:39.000
At present, everyone's business model

01:06:39.000 --> 01:06:41.000
It's still more like crowd computing

01:06:41.000 --> 01:06:43.000
For example, they said

01:06:43.000 --> 01:06:45.000
Regetti IBM

01:06:45.000 --> 01:06:47.000
Or Microsoft, they are basically

01:06:47.000 --> 01:06:49.000
The future trend is that I have one

01:06:49.000 --> 01:06:51.000
Is cloud

01:06:51.000 --> 01:06:53.000
Then let you access

01:06:53.000 --> 01:06:55.000
You can have some more complicated

01:06:55.000 --> 01:06:57.000
You can upload it to my server

01:06:57.000 --> 01:06:59.000
Then my quantum computer will help you calculate

01:06:59.000 --> 01:07:01.000
The current business model is like this

01:07:03.000 --> 01:07:05.000
Thank you

01:07:09.000 --> 01:07:11.000
I thought

01:07:11.000 --> 01:07:13.000
Most of the people in Caltech

01:07:13.000 --> 01:07:15.000
Are doing theory

01:07:15.000 --> 01:07:17.000
Caltech is now doing experiments

01:07:17.000 --> 01:07:19.000
Which direction

01:07:19.000 --> 01:07:21.000
Caltech itself

01:07:21.000 --> 01:07:23.000
It doesn't seem to be experimenting with quantum computation

01:07:23.000 --> 01:07:25.000
We have an institution called IQIM

01:07:25.000 --> 01:07:27.000
This is quantum information

01:07:27.000 --> 01:07:29.000
It's called

01:07:29.000 --> 01:07:31.000
It's called

01:07:31.000 --> 01:07:33.000
It's all theory

01:07:33.000 --> 01:07:35.000
The group of people

01:07:35.000 --> 01:07:37.000
Yes

01:07:41.000 --> 01:07:43.000
Let me add that I am now a graduate of Dongda

01:07:43.000 --> 01:07:45.000
What we do here is

01:07:45.000 --> 01:07:47.000
Just the semiconductor

01:07:47.000 --> 01:07:49.000
How to make a semiconductor

01:07:49.000 --> 01:07:51.000
To do Qubit

01:07:51.000 --> 01:07:53.000
That's true

01:07:53.000 --> 01:07:55.000
New South Wales

01:07:55.000 --> 01:07:57.000
Very leading

01:07:57.000 --> 01:07:59.000
Especially recently

01:07:59.000 --> 01:08:01.000
From the end of last year

01:08:01.000 --> 01:08:03.000
About 80 million

01:08:03.000 --> 01:08:05.000
Establish a new company

01:08:05.000 --> 01:08:07.000
And their country's funds

01:08:07.000 --> 01:08:09.000
Invest in this area

01:08:09.000 --> 01:08:11.000
That 80 million is US dollars

01:08:11.000 --> 01:08:13.000
That's right

01:08:15.000 --> 01:08:17.000
So I think

01:08:17.000 --> 01:08:19.000
All directions are

01:08:19.000 --> 01:08:21.000
Very difficult

01:08:21.000 --> 01:08:23.000
I was before

01:08:23.000 --> 01:08:25.000
When I was in PhD

01:08:25.000 --> 01:08:27.000
Also use

01:08:27.000 --> 01:08:29.000
But

01:08:31.000 --> 01:08:33.000
My personal idea is

01:08:33.000 --> 01:08:35.000
It's not that easy

01:08:35.000 --> 01:08:37.000
He's probably

01:08:37.000 --> 01:08:39.000
A bottleneck

01:08:39.000 --> 01:08:41.000
I don't know yet

01:08:41.000 --> 01:08:43.000
How to overcome

01:08:45.000 --> 01:08:47.000
Yes, but because I do experiments

01:08:47.000 --> 01:08:49.000
So if

01:08:49.000 --> 01:08:51.000
If you want to discuss

01:08:51.000 --> 01:08:53.000
Let's continue to discuss

01:08:55.000 --> 01:08:57.000
But for now

01:08:57.000 --> 01:08:59.000
For the content of today's speech

01:08:59.000 --> 01:09:01.000
Is there a problem

01:09:13.000 --> 01:09:15.000
Yes, I want to remind you

01:09:15.000 --> 01:09:17.000
If you want to see that

01:09:17.000 --> 01:09:19.000
Senior's video

01:09:19.000 --> 01:09:21.000
I have a link below

01:09:21.000 --> 01:09:23.000
That link

01:09:23.000 --> 01:09:25.000
If you want to find

01:09:25.000 --> 01:09:27.000
If you don't know the problem

01:09:27.000 --> 01:09:29.000
You can click on the link

01:09:31.000 --> 01:09:33.000
In the chat

01:09:33.000 --> 01:09:35.000
There is a link

01:09:35.000 --> 01:09:37.000
My slides are all online

01:09:37.000 --> 01:09:39.000
So you can watch it anytime

01:09:39.000 --> 01:09:41.000
It will always be there

01:09:41.000 --> 01:09:43.000
I have a question

01:09:43.000 --> 01:09:45.000
Sorry

01:09:45.000 --> 01:09:47.000
My question

01:09:47.000 --> 01:09:49.000
I remember

01:09:49.000 --> 01:09:51.000
I'm watching now

01:09:51.000 --> 01:09:53.000
Because I'm not doing theory

01:09:53.000 --> 01:09:55.000
But I know

01:09:55.000 --> 01:09:57.000
It seems to be in the algorithm

01:09:57.000 --> 01:09:59.000
For

01:09:59.000 --> 01:10:01.000
If you don't know how to deal with it

01:10:01.000 --> 01:10:03.000
At least there is

01:10:03.000 --> 01:10:05.000
Grover

01:10:05.000 --> 01:10:07.000
To do a basic acceleration

01:10:07.000 --> 01:10:09.000
But we want

01:10:09.000 --> 01:10:11.000
What you want

01:10:11.000 --> 01:10:13.000
Things should be

01:10:13.000 --> 01:10:15.000
Want to do

01:10:15.000 --> 01:10:17.000
Not just polynomial

01:10:17.000 --> 01:10:19.000
But exponential acceleration

01:10:19.000 --> 01:10:21.000
So inside

01:10:21.000 --> 01:10:23.000
Inside

01:10:23.000 --> 01:10:25.000
Several algorithms

01:10:29.000 --> 01:10:31.000
Recommendation now

01:10:31.000 --> 01:10:33.000
I saw it before

01:10:33.000 --> 01:10:35.000
Austin

01:10:35.000 --> 01:10:37.000
This news

01:10:37.000 --> 01:10:39.000
I think it's super cool

01:10:39.000 --> 01:10:41.000
Found

01:10:41.000 --> 01:10:43.000
Is a

01:10:43.000 --> 01:10:45.000
I thought only quantum computers could do it

01:10:45.000 --> 01:10:47.000
Found out

01:10:47.000 --> 01:10:49.000
Can be done

01:10:49.000 --> 01:10:51.000
What do they call it

01:10:51.000 --> 01:10:53.000
Quantum Inspired Algorithm

01:10:53.000 --> 01:10:55.000
I think it's really cool

01:10:55.000 --> 01:10:57.000
Can I make a comment

01:10:57.000 --> 01:10:59.000
Yes

01:10:59.000 --> 01:11:01.000
This is basically

01:11:01.000 --> 01:11:03.000
If you say now

01:11:03.000 --> 01:11:05.000
Strict

01:11:05.000 --> 01:11:07.000
Complexity Theory

01:11:07.000 --> 01:11:09.000
For those who do theoretical computer science

01:11:09.000 --> 01:11:11.000
They actually mean

01:11:11.000 --> 01:11:13.000
You can't define it yet

01:11:13.000 --> 01:11:15.000
Quantum Computation

01:11:15.000 --> 01:11:17.000
Really

01:11:17.000 --> 01:11:19.000
Really

01:11:19.000 --> 01:11:21.000
Very strict proof of acceleration

01:11:21.000 --> 01:11:23.000
Even like Grover

01:11:23.000 --> 01:11:25.000
Even like this Schultz Algorithm

01:11:25.000 --> 01:11:27.000
We know he has it now

01:11:27.000 --> 01:11:29.000
He now has this

01:11:29.000 --> 01:11:31.000
But it's just

01:11:31.000 --> 01:11:33.000
The best classic algorithm

01:11:33.000 --> 01:11:35.000
Then we know

01:11:35.000 --> 01:11:37.000
What about this factoring

01:11:37.000 --> 01:11:39.000
He is not a

01:11:39.000 --> 01:11:41.000
He is a question of mouth NP

01:11:41.000 --> 01:11:43.000
He said

01:11:43.000 --> 01:11:45.000
Not to say

01:11:45.000 --> 01:11:47.000
Ah

01:11:47.000 --> 01:11:49.000
It should be said that the current bottleneck is

01:11:49.000 --> 01:11:51.000
Classical may

01:11:51.000 --> 01:11:53.000
I don't know how to do it

01:11:53.000 --> 01:11:55.000
Maybe one day there will be one

01:11:55.000 --> 01:11:57.000
There is also a Schultz algorithm

01:11:57.000 --> 01:11:59.000
This classical algorithm

01:11:59.000 --> 01:12:01.000
Schultz Algorithm

01:12:01.000 --> 01:12:03.000
Yes

01:12:03.000 --> 01:12:05.000
Because of Complexity Class

01:12:05.000 --> 01:12:07.000
Not to say this

01:12:07.000 --> 01:12:09.000
Factoring is the most difficult problem

01:12:09.000 --> 01:12:11.000
He is not a question of NP

01:12:11.000 --> 01:12:13.000
He is not a question of NP

01:12:13.000 --> 01:12:15.000
So

01:12:15.000 --> 01:12:17.000
It's all like this now

01:12:17.000 --> 01:12:19.000
Although we have some

01:12:19.000 --> 01:12:21.000
Some

01:12:21.000 --> 01:12:23.000
Quantum algorithms are better than modern classic algorithms

01:12:23.000 --> 01:12:25.000
But the point is

01:12:25.000 --> 01:12:27.000
This is to say

01:12:27.000 --> 01:12:29.000
There will be a classic algorithm

01:12:29.000 --> 01:12:31.000
Will improve

01:12:31.000 --> 01:12:33.000
This is also

01:12:33.000 --> 01:12:35.000
Very interesting

01:12:35.000 --> 01:12:37.000
I also encourage if

01:12:37.000 --> 01:12:39.000
People who do CS

01:12:39.000 --> 01:12:41.000
You should be able to say

01:12:41.000 --> 01:12:43.000
Bring your classical knowledge

01:12:43.000 --> 01:12:45.000
Let's take a look at these quantum algorithms

01:12:45.000 --> 01:12:47.000
Or

01:12:47.000 --> 01:12:49.000
Or to discuss

01:12:49.000 --> 01:12:51.000
You are interested in the corresponding quantum version

01:12:51.000 --> 01:12:53.000
Maybe it's like this

01:12:53.000 --> 01:12:55.000
Maybe one day you can also

01:12:55.000 --> 01:12:57.000
A very good way

01:12:57.000 --> 01:12:59.000
This way

01:12:59.000 --> 01:13:01.000
Yes

01:13:01.000 --> 01:13:03.000
Do you have any questions?

01:13:03.000 --> 01:13:05.000
Please say

01:13:05.000 --> 01:13:07.000
I want to ask you again

01:13:07.000 --> 01:13:09.000
At the beginning of your quantum

01:13:09.000 --> 01:13:11.000
Principle Component Analysis

01:13:11.000 --> 01:13:13.000
Is it the HHL algorithm?

01:13:13.000 --> 01:13:15.000
Or later

01:13:15.000 --> 01:13:17.000
There are other extensions

01:13:17.000 --> 01:13:19.000
Uh

01:13:19.000 --> 01:13:21.000
It is possible

01:13:21.000 --> 01:13:23.000
It is possible to use this HHL

01:13:23.000 --> 01:13:25.000
But I didn't go to see it

01:13:25.000 --> 01:13:27.000
Because I just entered this field

01:13:27.000 --> 01:13:29.000
Not long

01:13:29.000 --> 01:13:31.000
Basically this principle component

01:13:31.000 --> 01:13:33.000
It is definitely a face estimation

01:13:33.000 --> 01:13:35.000
Because

01:13:35.000 --> 01:13:37.000
Basically it is to identify these

01:13:37.000 --> 01:13:39.000
The covariance matrix is relatively large

01:13:39.000 --> 01:13:41.000
This eigenvalue

01:13:41.000 --> 01:13:43.000
Maybe you can put HHL

01:13:43.000 --> 01:13:45.000
Do it like this

01:13:49.000 --> 01:13:51.000
Hello i have a question

01:13:51.000 --> 01:13:53.000
Ok you ask

01:13:53.000 --> 01:13:55.000
Self-introduction

01:13:55.000 --> 01:13:57.000
Uh

01:13:57.000 --> 01:13:59.000
Uh

01:13:59.000 --> 01:14:01.000
I did a high-performance experiment

01:14:01.000 --> 01:14:03.000
Is

01:14:03.000 --> 01:14:05.000
I am doing dark matter

01:14:05.000 --> 01:14:07.000
But because I did

01:14:07.000 --> 01:14:09.000
Is actually with

01:14:09.000 --> 01:14:11.000
Very close

01:14:11.000 --> 01:14:13.000
So when I was in college

01:14:13.000 --> 01:14:15.000
I went to the teacher's class

01:14:15.000 --> 01:14:17.000
I almost did it

01:14:17.000 --> 01:14:19.000
My question is like this

01:14:19.000 --> 01:14:21.000
Uh actually

01:14:21.000 --> 01:14:23.000
You just

01:14:23.000 --> 01:14:25.000
Is what you said

01:14:25.000 --> 01:14:27.000
In fact, it is more like

01:14:27.000 --> 01:14:29.000
Is there

01:14:29.000 --> 01:14:31.000
Strict mathematical logic

01:14:31.000 --> 01:14:33.000
Machine learning

01:14:33.000 --> 01:14:35.000
But now the most powerful machine learning is some kind of fossil logic

01:14:35.000 --> 01:14:37.000
Neural net

01:14:37.000 --> 01:14:39.000
Now quantum

01:14:39.000 --> 01:14:41.000
Everyone is in this direction

01:14:41.000 --> 01:14:43.000
Use quantum to do fossil logic

01:14:43.000 --> 01:14:45.000
What is the situation now

01:14:45.000 --> 01:14:47.000
Will be

01:14:47.000 --> 01:14:49.000
Traditionally more powerful

01:14:49.000 --> 01:14:51.000
Still don't know

01:14:51.000 --> 01:14:53.000
Because I don't know

01:14:53.000 --> 01:14:55.000
I don't know

01:14:55.000 --> 01:14:57.000
Ok ok

01:14:57.000 --> 01:14:59.000
Since you ask these questions

01:14:59.000 --> 01:15:01.000
I will continue to talk about it

01:15:01.000 --> 01:15:03.000
In fact, one of the results behind me

01:15:03.000 --> 01:15:05.000
In fact, it may be related to this

01:15:05.000 --> 01:15:07.000
That is to say

01:15:07.000 --> 01:15:09.000
Can everyone see it

01:15:13.000 --> 01:15:15.000
Can see

01:15:15.000 --> 01:15:17.000
Basically

01:15:17.000 --> 01:15:19.000
Me and my student

01:15:19.000 --> 01:15:21.000
The question we want to ask is

01:15:21.000 --> 01:15:23.000
Because you know that we actually use this

01:15:23.000 --> 01:15:25.000
Circuit to learn

01:15:25.000 --> 01:15:27.000
You are actually your quantum circuit

01:15:27.000 --> 01:15:29.000
You have a parameter in it

01:15:29.000 --> 01:15:31.000
Then you can use this optimization

01:15:31.000 --> 01:15:33.000
To adjust your parameters to produce the state you want

01:15:33.000 --> 01:15:35.000
Right

01:15:35.000 --> 01:15:37.000
There is a question that you want to know

01:15:37.000 --> 01:15:39.000
Such a quantum circuit

01:15:39.000 --> 01:15:41.000
We call parametric quantum circuit

01:15:41.000 --> 01:15:43.000
His

01:15:43.000 --> 01:15:45.000
Expressive power because we know

01:15:45.000 --> 01:15:47.000
Machine learning has two types, one is classification

01:15:47.000 --> 01:15:49.000
One is generative model

01:15:49.000 --> 01:15:51.000
That is to say, I want to produce a distribution

01:15:51.000 --> 01:15:53.000
I want to produce a target distribution

01:15:53.000 --> 01:15:55.000
Then we want to know this quantum circuit

01:15:55.000 --> 01:15:57.000
This

01:15:57.000 --> 01:15:59.000
The ability to generate this

01:15:59.000 --> 01:16:01.000
Generative ability is how good

01:16:01.000 --> 01:16:03.000
Right

01:16:03.000 --> 01:16:05.000
So I did it with my student

01:16:05.000 --> 01:16:07.000
Did the following thing

01:16:07.000 --> 01:16:09.000
That is to say

01:16:09.000 --> 01:16:11.000
If I say I can have

01:16:11.000 --> 01:16:13.000
L block

01:16:13.000 --> 01:16:15.000
This every

01:16:15.000 --> 01:16:17.000
A block of this square

01:16:17.000 --> 01:16:19.000
Then

01:16:19.000 --> 01:16:21.000
In fact, the last row

01:16:21.000 --> 01:16:23.000
Is measurement

01:16:23.000 --> 01:16:25.000
After measurement, it is a classical data

01:16:25.000 --> 01:16:27.000
Then I can put this

01:16:27.000 --> 01:16:29.000
Do some classical optimization

01:16:29.000 --> 01:16:31.000
Put this

01:16:31.000 --> 01:16:33.000
Parameter feedback

01:16:33.000 --> 01:16:35.000
Because this is all adjustable

01:16:35.000 --> 01:16:37.000
Adjustable parameters

01:16:37.000 --> 01:16:39.000
Then I want to know

01:16:39.000 --> 01:16:41.000
This type of circuit

01:16:41.000 --> 01:16:43.000
I finally generated these classical distributions

01:16:43.000 --> 01:16:45.000
With

01:16:45.000 --> 01:16:47.000
We know that the Boltzmann machine

01:16:47.000 --> 01:16:49.000
Can also be used to generate distributions

01:16:49.000 --> 01:16:51.000
Right

01:16:51.000 --> 01:16:53.000
You just mentioned these like this neural network

01:16:53.000 --> 01:16:55.000
Basically, the Boltzmann machine is like this

01:16:55.000 --> 01:16:57.000
That is to say, the most general Boltzmann machine

01:16:57.000 --> 01:16:59.000
The picture in the middle

01:16:59.000 --> 01:17:01.000
That is to say, it has a visible layer and a hidden layer

01:17:01.000 --> 01:17:03.000
Then all the layers are fully connected

01:17:03.000 --> 01:17:05.000
Right

01:17:05.000 --> 01:17:07.000
Then we all know that this kind of fully connected

01:17:07.000 --> 01:17:09.000
Very powerful

01:17:09.000 --> 01:17:11.000
This is basically Deep Neural Network

01:17:11.000 --> 01:17:13.000
Everything is connected

01:17:13.000 --> 01:17:15.000
Then

01:17:15.000 --> 01:17:17.000
Of course there is another type of Boltzmann machine

01:17:17.000 --> 01:17:19.000
That is to say, it is actually

01:17:19.000 --> 01:17:21.000
It only has layers and layers

01:17:21.000 --> 01:17:23.000
Connected

01:17:23.000 --> 01:17:25.000
Every

01:17:25.000 --> 01:17:27.000
The middle of your own layer is not

01:17:27.000 --> 01:17:29.000
This is not connected

01:17:29.000 --> 01:17:31.000
Right, this is Restricted Boltzmann Machine

01:17:31.000 --> 01:17:33.000
These two are classic methods

01:17:33.000 --> 01:17:35.000
Can be generated

01:17:35.000 --> 01:17:37.000
Then the picture on my left

01:17:37.000 --> 01:17:39.000
That is to say this is

01:17:39.000 --> 01:17:41.000
Another version of this picture

01:17:41.000 --> 01:17:43.000
That is to say

01:17:43.000 --> 01:17:45.000
The layout of each block of the circuit is different

01:17:45.000 --> 01:17:47.000
I'm on the left

01:17:47.000 --> 01:17:49.000
The layout of each circuit on the left

01:17:49.000 --> 01:17:51.000
The layout of each block of the circuit is the same

01:17:51.000 --> 01:17:53.000
The quantum circuit on my right

01:17:53.000 --> 01:17:55.000
It actually has one

01:17:55.000 --> 01:17:57.000
Its every layout

01:17:57.000 --> 01:17:59.000
In fact, the first layout is the most powerful

01:17:59.000 --> 01:18:01.000
Because it

01:18:01.000 --> 01:18:03.000
The first one

01:18:03.000 --> 01:18:05.000
The first one is that it has a lot of C-NOT gates

01:18:05.000 --> 01:18:07.000
Can be connected

01:18:07.000 --> 01:18:09.000
The second one, it's actually your C-NOT gate

01:18:09.000 --> 01:18:11.000
It's already less

01:18:11.000 --> 01:18:13.000
And it's

01:18:13.000 --> 01:18:15.000
It's every block

01:18:15.000 --> 01:18:17.000
Then all the way to the end

01:18:17.000 --> 01:18:19.000
This

01:18:19.000 --> 01:18:21.000
Connectivity is actually very limited

01:18:21.000 --> 01:18:23.000
Then we want to know

01:18:23.000 --> 01:18:25.000
These circuit layouts

01:18:25.000 --> 01:18:27.000
This

01:18:27.000 --> 01:18:29.000
From the perspective of deep distribution

01:18:29.000 --> 01:18:31.000
Which one is the most powerful

01:18:31.000 --> 01:18:33.000
Just these two quantum

01:18:33.000 --> 01:18:35.000
With these two classical

01:18:35.000 --> 01:18:37.000
That's basically it

01:18:37.000 --> 01:18:39.000
The most powerful is the one on the left

01:18:39.000 --> 01:18:41.000
This quantum circuit

01:18:41.000 --> 01:18:43.000
This quantum circuit

01:18:43.000 --> 01:18:45.000
Each of them is

01:18:45.000 --> 01:18:47.000
The same layout

01:18:47.000 --> 01:18:49.000
Then each layout actually has this

01:18:49.000 --> 01:18:51.000
It has a C-NOT between any two points

01:18:51.000 --> 01:18:53.000
Can be connected

01:18:53.000 --> 01:18:55.000
This is the most powerful

01:18:55.000 --> 01:18:57.000
It's more powerful than the general Boltzmann machine

01:18:57.000 --> 01:18:59.000
It's more powerful than the general Boltzmann machine

01:18:59.000 --> 01:19:01.000
In terms of deep

01:19:01.000 --> 01:19:03.000
Distribution

01:19:03.000 --> 01:19:05.000
Then this general Boltzmann machine

01:19:05.000 --> 01:19:07.000
It's better than this quantum circuit

01:19:07.000 --> 01:19:09.000
The ability to generate

01:19:09.000 --> 01:19:11.000
Because this quantum circuit

01:19:11.000 --> 01:19:13.000
In fact, it

01:19:13.000 --> 01:19:15.000
It's actually more limited

01:19:15.000 --> 01:19:17.000
It's not all

01:19:17.000 --> 01:19:19.000
All of this

01:19:19.000 --> 01:19:21.000
There's a connection between the lines

01:19:21.000 --> 01:19:23.000
So the general Boltzmann machine

01:19:23.000 --> 01:19:25.000
Will be stronger than this circuit

01:19:25.000 --> 01:19:27.000
This circuit will be stronger than this

01:19:27.000 --> 01:19:29.000
Boltzmann machine

01:19:29.000 --> 01:19:31.000
This is what we haven't published

01:19:31.000 --> 01:19:33.000
A result of the paper

01:19:33.000 --> 01:19:35.000
Maybe next week it will be put on the archive

01:19:35.000 --> 01:19:37.000
If all goes well

01:19:37.000 --> 01:19:39.000
This is

01:19:39.000 --> 01:19:41.000
On the one hand

01:19:41.000 --> 01:19:43.000
Also answer your question

01:19:43.000 --> 01:19:45.000
In fact, the quantum circuit

01:19:45.000 --> 01:19:47.000
It's in the perspective of deep distribution

01:19:47.000 --> 01:19:49.000
It's actually

01:19:49.000 --> 01:19:51.000
Classic

01:19:51.000 --> 01:19:53.000
The classic Boltzmann machine is stronger

01:19:53.000 --> 01:19:55.000
Of course

01:19:55.000 --> 01:19:57.000
Maybe there are some specific tasks

01:19:57.000 --> 01:19:59.000
Now we don't know yet

01:19:59.000 --> 01:20:01.000
How does the quantum circuit compare with the Boltzmann machine

01:20:01.000 --> 01:20:03.000
This is still unknown

01:20:05.000 --> 01:20:07.000
Senior, can I ask you

01:20:07.000 --> 01:20:09.000
Can you go back to the page above

01:20:09.000 --> 01:20:11.000
it is good

01:20:11.000 --> 01:20:13.000
Because like this

01:20:13.000 --> 01:20:15.000
The two pictures above

01:20:15.000 --> 01:20:17.000
Does it really correspond to the physical

01:20:17.000 --> 01:20:19.000
His connection

01:20:19.000 --> 01:20:21.000
Like this

01:20:21.000 --> 01:20:23.000
It might be

01:20:23.000 --> 01:20:25.000
Near snapper coupling

01:20:25.000 --> 01:20:27.000
So he can only follow the side

01:20:27.000 --> 01:20:29.000
He's gonna do a bunch of swaps

01:20:29.000 --> 01:20:31.000
Right, right, right

01:20:31.000 --> 01:20:33.000
The second picture

01:20:33.000 --> 01:20:35.000
It's kind of like

01:20:35.000 --> 01:20:37.000
With this actual

01:20:37.000 --> 01:20:39.000
Implementation set up

01:20:39.000 --> 01:20:41.000
Consider

01:20:41.000 --> 01:20:43.000
Because there are some set ups

01:20:45.000 --> 01:20:47.000
So in that

01:20:47.000 --> 01:20:49.000
When you use

01:20:49.000 --> 01:20:51.000
Every one of them

01:20:51.000 --> 01:20:53.000
Like he's doing

01:20:53.000 --> 01:20:55.000
One swap is three CNOT

01:20:55.000 --> 01:20:57.000
Every CNOT

01:20:57.000 --> 01:20:59.000
He can now

01:20:59.000 --> 01:21:01.000
About how much

01:21:01.000 --> 01:21:03.000
Their

01:21:03.000 --> 01:21:05.000
Fidelity is not high

01:21:05.000 --> 01:21:07.000
I heard it's low, but I don't know

01:21:07.000 --> 01:21:09.000
How much

01:21:09.000 --> 01:21:11.000
I remember the best is only 80%

01:21:11.000 --> 01:21:13.000
May be worse

01:21:13.000 --> 01:21:15.000
Because he's actually every

01:21:15.000 --> 01:21:17.000
Connectivity between qubits

01:21:17.000 --> 01:21:19.000
Different

01:21:19.000 --> 01:21:21.000
A little worse

01:21:23.000 --> 01:21:25.000
Because I think the above

01:21:25.000 --> 01:21:27.000
They just got one million

01:21:27.000 --> 01:21:29.000
One hundred million

01:21:29.000 --> 01:21:31.000
This investment

01:21:31.000 --> 01:21:33.000
Very powerful

01:21:33.000 --> 01:21:35.000
They

01:21:35.000 --> 01:21:37.000
That's pretty important to them

01:21:37.000 --> 01:21:39.000
Because they even

01:21:39.000 --> 01:21:41.000
They do it themselves

01:21:41.000 --> 01:21:43.000
But I think the above two pictures

01:21:43.000 --> 01:21:45.000
It's like that

01:21:45.000 --> 01:21:47.000
Compared with that

01:21:47.000 --> 01:21:49.000
Really

01:21:49.000 --> 01:21:51.000
Like that

01:21:51.000 --> 01:21:53.000
He is

01:21:53.000 --> 01:21:55.000
A series of times he can

01:21:55.000 --> 01:21:57.000
As long as he can

01:21:57.000 --> 01:21:59.000
With five

01:21:59.000 --> 01:22:01.000
That

01:22:01.000 --> 01:22:03.000
CNOT

01:22:03.000 --> 01:22:05.000
So I think

01:22:05.000 --> 01:22:07.000
At least

01:22:07.000 --> 01:22:09.000
Why

01:22:09.000 --> 01:22:11.000
At least for people

01:22:11.000 --> 01:22:13.000
Ask them

01:22:13.000 --> 01:22:15.000
The biggest idea is

01:22:15.000 --> 01:22:17.000
Where is the biggest advantage

01:22:17.000 --> 01:22:19.000
I think this is what they can do

01:22:19.000 --> 01:22:21.000
Emphasize

01:22:21.000 --> 01:22:23.000
Like their CNOT

01:22:23.000 --> 01:22:25.000
It should be up to 97

01:22:25.000 --> 01:22:27.000
Around 98

01:22:27.000 --> 01:22:29.000
It seems like someone has 99

01:22:29.000 --> 01:22:31.000
But at least I think

01:22:31.000 --> 01:22:33.000
Their advantage

01:22:33.000 --> 01:22:35.000
Yeah yeah yeah

01:22:35.000 --> 01:22:37.000
Mr. Cao

01:22:37.000 --> 01:22:39.000
Gate is lower but

01:22:39.000 --> 01:22:41.000
The chance is bigger

01:22:42.000 --> 01:22:44.000
Any other questions

01:22:56.000 --> 01:22:58.000
It seems like there's no problem

01:23:02.000 --> 01:23:04.000
Okay

01:23:04.000 --> 01:23:06.000
If there's no problem today

01:23:06.000 --> 01:23:08.000
Thank you for your participation

01:23:08.000 --> 01:23:10.000
Thank you everyone

01:23:10.000 --> 01:23:12.000
Thank you

01:23:17.000 --> 01:23:19.000
My personal website is here

01:23:19.000 --> 01:23:21.000
If you have any questions

01:23:21.000 --> 01:23:23.000
You're welcome to contact me

01:23:26.000 --> 01:23:28.000
We will

01:23:28.000 --> 01:23:30.000
Put the link of the video

01:23:30.000 --> 01:23:32.000
And

01:23:32.000 --> 01:23:34.000
Senior's personal website

01:23:34.000 --> 01:23:36.000
On our announcement

01:23:36.000 --> 01:23:38.000
On our website

01:23:38.000 --> 01:23:40.000
Thank you

01:23:40.000 --> 01:23:42.000
Our recording will be

01:23:42.000 --> 01:23:44.000
In a day or two

01:23:44.000 --> 01:23:46.000
We will put it on

01:23:46.000 --> 01:23:48.000
Pyra's

01:23:48.000 --> 01:23:50.000
Pyra's website

01:23:50.000 --> 01:23:52.000
No problem

01:23:52.000 --> 01:23:54.000
Yeah

01:23:54.000 --> 01:23:56.000
Okay, thank you everyone

01:23:56.000 --> 01:23:58.000
Thank you

01:23:58.000 --> 01:24:00.000
Bye bye

01:24:00.000 --> 01:24:02.000
Bye bye

