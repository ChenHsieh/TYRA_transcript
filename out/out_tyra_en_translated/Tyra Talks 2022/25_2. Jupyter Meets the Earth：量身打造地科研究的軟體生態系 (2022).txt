Thank you everyone for coming to the speech on January 22, 2022.
Today's speaker is Dr. Zheng Huaijie.
He obtained a master's degree and master's degree from Taiwan University between 2010 and 2013,
and then stayed for a while at NTU Haiyan.
Later, in 2015, he was a Ph.D. student at Cornell University's Department of Earth and Atmospheric Science.
Last year, he obtained a Ph.D. degree and joined the research team of Fernando Perez from the University of California, Buckeye, California.
He is now implementing a plan, which is the topic he is going to talk about today, the Joe Piter Meets the Earth plan.
He will talk about how to use these softwares in atmospheric and geoscientific applications.
Let's welcome Dr. Zheng Huaijie to give a speech.
Everyone can turn on the microphone to encourage our speaker.
Thank you for your introduction.
Let me share my screen.
Can you see it?
Thank you again for your introduction.
Thank you for coming to listen to my speech.
My name is Zheng Huaijie.
The topic I want to talk about today is the Joe Piter Meets the Earth plan I am implementing as a Ph.D. student at UC Berkeley.
I have posted a link to the video in the chat room.
If you are interested, you can read it yourself.
But what you see should be the same.
The main goal of this plan is to build the first software ecosystem.
If you hear anything you don't understand, please feel free to interrupt me at any time.
Because there may be some Korean words.
I'm not sure if you can understand.
So please feel free to interrupt me at any time.
Why can't I use it?
Today, in the next hour or so, I will divide the content into five parts.
First, I will add some things, including what I am doing now and what I was doing before.
How did these things lead me to this plan?
Before I talk about Joe Piter Meets the Earth, I will talk about what Joe Piter is.
What kind of challenges does earth science currently face?
Finally, we will discuss what the goal of Joe Piter Meets the Earth is and what we have accomplished so far.
The last part is our future prospects and plans.
And we see some efforts being made in the geoscience community.
My own field of research is geoscience, geophysics, earth physics, and geospatial deformation.
Here is a demo.
I will tell you what my research plan is doing.
You can imagine that there is an iceberg in front of you.
There will be some ice cracks on the iceberg.
As the iceberg flows, these cracks will change its position.
If you have a satellite today, you can take a picture of the iceberg every once in a while.
In this way, you can look at these pictures and calculate the movement speed of each crack on the iceberg.
In this way, you can calculate the movement speed of the entire iceberg.
This example is one of my many research plans.
Although most of my research plans are not complete, most of them are like this.
It is to use a very rich set of satellite data to monitor the changes in the ice circle.
This ice circle includes the ice on the earth, including the sea ice, and even the ice on other planets.
Most of these changes are physical changes.
For example, the speed of the iceberg, the change in the water time, the change in the water time of the iceberg, or other physical parameters.
These parameters have a very deep connection to the entire field of earth science, especially the field of global change.
When I joined Cornell in 2015, I started to put my research center on ice science.
I have been doing this for about 6 or 7 years.
When I was using these satellite data, I found that the scale and the amount of data we used was so huge.
Traditional analysis methods sometimes seem to be less efficient.
I have been thinking about how to maintain the efficiency of analysis and academic communication while using a lot of data.
For me, the answer is open science.
This is the era of big data.
Open science means that all the details of your research should be as open as possible to the public.
For example, open your data so that others can easily access it.
Upload your original code or city code.
Everyone can Google your tool as long as they need it.
Even when you have some research results, you can upload your research results.
Whether it's a picture or a video, upload it.
Even cooperate with the media to promote your research.
These things are all open science.
Although it sounds simple, it's actually quite difficult to do.
Because you will find that when you really want to open all your things, data, city code, notes, and results, there will be some challenges.
These challenges are why I joined the Jupiter Meteors team and why I am doing this project now.
So let's talk about Jupiter first.
How much do you know about Jupiter?
This is a public opinion survey.
If you have seen the chat room, I have already posted a link.
You can rename or type your name.
It doesn't matter, I won't confirm.
But you can choose how much you know about Jupiter.
Let me know about everyone's background.
It seems that everyone has heard of Jupiter.
About two-thirds of people have used Notebook or Jupiter Lab.
One-third of the people are using it every day.
It seems that everyone has a certain degree of understanding of Jupiter.
Oh, I have increased to 7.3.
Thank you for your vote.
Everyone voted, so let's move on to the next one.
There will be other questions later, so let's move on to the next video.
If you want me to define what Jupiter is,
I would say that Jupiter is actually a homework system for quantum mechanics.
A homework system means that it can help you complete a task you want to complete.
Of course, your task may have a lot of different work elements.
Jupiter provides different tools to help you meet different needs in your task.
Let me give you an example.
Let's say you have a research idea in your mind.
Then it starts to take shape.
Then you start to explore.
Hey, does this research idea make sense?
You may want to use your computer to download some data.
Then write some programs to analyze.
Initial analysis to see if things are what you think they are.
When you are sure that this project is developable,
you may want to use more resources, such as computing resources.
Or you may want to find other co-authors to implement this project.
To analyze large amounts of data.
Jupiter's tool is to tie all these things together.
So that when you are looking for data,
or when you are doing mass computing,
or when you are cooperating with others,
you can have a common platform to communicate with each other.
You will notice that I put IPython in the center circle.
This is because IPython is actually the predecessor of Jupyter.
IPython was designed by Fernando PÃ©rez 20 years ago.
The original purpose was to write code.
When you are analyzing data,
you want to be able to present what the data looks like in real time.
This concept was invented with IPython.
Then it gradually became popular.
Now we put this project in the next generation of Jupyter.
When we design Jupyter,
in addition to allowing Jupyter tools to allow you to analyze data science,
we also have a very big goal.
We want to be able to communicate with others very well and efficiently
at any stage of the user's use of these tools.
For example, Jupyter Notebook is a file.
You can easily copy it to others.
Then others can get the file directly.
If you have used JupyterHub,
it is actually like a server.
Everyone can log into this server as a different user.
They will save the same image interface.
This interface is based on JupyterLab.
On this platform,
they can use the same data freely.
You can develop different cities.
Others in your team can easily see your city
and communicate directly.
So for some people,
Jupyter provides these tools
to promote a very good community discussion.
Some people think that Jupyter actually represents
a community formed by people using Jupyter.
Among so many tools,
Jupyter has a core tool called Jupyter Notebook.
It used to be called IPython Notebook,
but now it's called Jupyter Notebook.
Now that you've used it,
let's jump over to it.
It's basically a file.
You can save it with a browser.
After saving,
you can see that
this is a professional format
for displaying text and mathematical formulas.
In the same file,
you can construct your city code.
You can write city code and execute it.
You can display interactive results.
You can adjust the parameters here.
You can see what the final image looks like.
The last step is
to simply pass the entire notebook to others
so that they can 100% re-study it.
Here's a picture
to give you a little insight
into how Jupyter Notebook
achieved this goal.
First, when you open a notebook,
it's actually the notebook's service
that turns your computer into a server.
Users need to use
a browser and HTTP protocol
to store the content on the server.
The user's operations
on the server
will be recorded in the notebook file.
When the user needs to compute,
the server will call a computing core,
which is the kernel.
This core may be Python,
but in fact,
if you have a good setup,
it can also use other cores to compute,
such as R, C++, or even Julia.
In the most general use case,
your notebook server
is installed on your own computer.
Your notebook file is also on your computer.
But we can also use the same logic
to install the server
on cloud computing resources
or even on HPC,
which is a supercomputer.
In this way,
these cloud computing resources
or supercomputers
can be upgraded
to become your data processing center.
You can directly log in
to these cloud computing resources
and open your program.
You can get or read data
and analyze it
directly on the same interface.
In this way,
your personal computer
is a place
where you can save
typing and reading results.
Most of the computing
is done on the cloud.
This is what we hope to achieve
through Jupyter Notebook.
That's all for Jupyter.
It's very simple.
Next, I'd like to ask
how well you know about
earth science.
There are five statements here.
They are shallow and deep.
Please choose one
according to
your knowledge level.
Oh, it seems
the result is a little weird.
It seems that
your knowledge about
earth science is
scattered.
It's on average
between A and D.
Some people seem to
be familiar with earth science.
But some people
may not know
what we are doing now.
But it doesn't matter.
Next,
I won't tell you
what earth science is.
But what I want to say is
what challenges we face
as earth scientists.
And how we can solve
these challenges
through Jupyter.
Have you finished voting?
OK, let's move on
to the next video.
For most people,
when it comes to earth science,
you may think
it's just a group of scientists
going out into the wild.
They collect samples,
bring them back to the lab,
analyze them,
study them,
and then write a paper.
That's it.
That's right.
Traditionally,
earth science
is basically like this.
For example,
this picture.
I took this picture
7 or 8 years ago
with a Japanese
volcanic scientist,
Shogo Kimura.
We took this picture
when we were doing
field research in a big oil pit.
Traditionally,
there's not much information
about earth science.
Because the information
has to be obtained
from the wild.
Most of the information
is written on your notebook.
Just a few lines.
And then you go back
to the lab and process it.
But with the emergence
of new technology
and new methods,
for example,
like this one.
This picture,
although this picture
is very old,
it's already 7 or 8 years old.
But when we were
out in the wild,
we actually used
instrument support.
We wanted to measure
the temperature of the surface
of a big oil pit.
So we brought
a infrared camera.
The information
involved in the infrared camera
is not at all like
the information
you would write
on a wild notebook.
You will find that
this information
is already digitized
at the very beginning.
And it can provide
some information
that is continuous
in time and space.
That is to say,
the size of the data
itself
will become very large.
It used to be one or two strokes,
but now there are several,
just different dimensions,
and then several megabytes
or several gigabytes of data
waiting for you to analyze.
This is just
the part of the field investigation.
But now
we have some technology
that allows us
to collect data
without going out in the wild.
For example,
you can use a drone
or a higher-end,
or farther,
satellite data
to help you analyze
what is happening on Earth.
For example,
now,
a satellite,
a Earth observation satellite,
can produce
several TB of data
every day.
Think about it,
we have dozens of
Earth observation satellites
flying in the sky,
and then
we also observe
for a long time,
not just one day,
but also several decades,
even several years.
So,
the amount of data
added up
is so huge
that no one knows
how to deal with it.
This is a problem
that observers
will face.
On the other hand,
simulators
actually
have the same problem,
because they will say,
wow,
now I have so much data,
so I can improve
the resolution of
my Earth model.
I can analyze
for example,
what happened
in a few days,
a few minutes,
a few seconds,
or
what happened
in a few meters
or a few centimeters
.
Then,
they can improve
the accuracy of their models,
and then
this large amount of observation data
can be used to verify
whether their models
are accurate.
But no matter which one,
whether it is observed
or simulated,
you have to deal with
and analyze
such large-scale data,
you have to have
relative computing resources.
Not to mention,
there may be many types
of data
in Earth science.
For example,
if you are a
Earth observation satellite today,
if you have a camera
installed on it,
then the data you collect
is basically
a photo,
a video,
a bit like a
telescope,
like this picture on the left.
It's a video,
uh,
not a video,
sorry,
a photo.
But,
there are also other types of data
that you may be able to collect,
for example,
you may be able to collect
some geographical space data,
and then they have
so-called,
uh,
maybe their
scattered
bit by bit
all over the place,
and maybe they can
form a certain
shape,
like a line,
or a polygon,
and so on.
What about
the different data structures?
How do you
put them together
and analyze them?
This is what
Earth scientists
are currently
trying very hard
to solve.
And,
these,
and most of these
different types of data
have so-called
background data,
which is
called metadata
in English.
Uh,
its concept is,
uh,
for example,
let's make a satellite image today.
This satellite image
actually has other data,
such as,
uh,
which satellite shot it,
when was it shot,
and then,
what was the
angle of the orbit
at that time,
uh,
and other orbit parameters,
and then,
which wave
was the image taken in,
was it a visible wave,
or a infrared wave,
and so on,
and so on,
and so on.
Any data
about this image
is considered
background data.
Now,
these background data
may not have
much impact
when you
make a satellite image,
but if you
tell others today
how to
re-study,
or
what you need to
consider when you
make a result,
what you need to
pay attention to,
then you may
have to flip the
background data.
In other words,
in most cases,
these background data
are actually
to be passed
along with
your data.
So,
when we
communicate,
when we
do academic communication,
how do we do
this?
To be honest,
I don't know
if it's true,
but some people
say that
scientists on
Earth spend
about 80% of
their time
looking for
data.
Here,
I want to
give you
an example.
This is
a screen
screenshot.
I want to
use this
screenshot
to share
with you
that
finding data
is really
difficult.
It sounds
simple,
but it's
not.
Here,
I want to
find
data on
the
surface
reflectance
rate.
I want to
find out
the surface
reflectance
rate
of Taiwan
at a
certain
time.
I know
there is
a device
called
MODIS
that can
observe
this
data.
MODIS
is a
website
called
NASA Earth
Data.
It is
completely
open.
Anyone
can download
this
data
if they
know
how to
search
and store
data.
The problem
is that
this
interface
is really
complicated.
First,
you need to
go to
Earth
Data
and
search
for
this
data.
Why is there
so many
data?
Because
MODIS
is a
satellite
camera,
but
when
processing
data,
there are
many
levels.
Each
level
has
different
scientific
values,
so
they
classify
them
in
different
ways.
So
first of
all,
you have
to know
the
name of
this
data
very
clearly.
Then,
of course,
731
data
levels.
Then,
you can
draw
where you
want to
search on
Earth.
For
example,
I put
this
data
in
my
computer.
Then,
you have
to know
which
time and
which
time point
I want to
capture.
Then,
press the
download
link
one by one
and
download it
to your
computer.
Finally,
put these
files in the
same
folder one
by one
and
download it.
In
my
case,
it may
take two
to three
days,
or even
longer.
And
this is still
a relatively
relaxed
situation.
If
you want to
find
less
open
data
today,
for
example,
German
or French
space
races,
you
can
search for
this
content.
So,
we have
these
difficulties,
which
leads me
to say that
I personally
think that
data
science,
including
how to
obtain
data,
and
how to
process and
analyze
these
data,
data
science
itself
is a
very
complex
field.
So,
I
will
hold
this
conference
once in
the United
States.
There
will be
thousands or
tens of
thousands of
researchers
attending
this
conference
and
presenting
their
research.
At
this
conference,
there
will be
scientific
collaboration
or
if NASA
has a
new
data machine
and
NASA
people
come and
tell you
how to
use it.
But
last year,
there were
two
workshops
related to
data
science.
One
was
how to
use
Python
to
analyze
data.
I
personally
think that
this
phenomenon
happened
recently.
It
happened
less than
one or
two years
ago,
maybe
2020 or
2021.
But
I think
this is
the current
trend.
In the
future,
this trend
will only
increase
as
time
goes
by.
So
I
think
this
trend
will
only
increase
as
time
goes
by.
So
I
think
this
trend
will
only
increase
as
time
goes
by.
Thank
you.
Thank
you.
So
speaking of
this,
I would like to
ask everyone
what do you think
is the most difficult
thing to do
in a research
plan?
Is it
looking for
data?
Or
analyzing
data?
Or
promoting or
sharing
research
results?
Or
you are
not
doing
research at
all?
I
see
about
half of
you
think
writing
articles,
promoting
or sharing
research results
is the
most difficult.
Half.
There
are
really
a lot.
It's
already
more than
half.
And
looking for
data is
about
three times.
And
the rest
is
analyzing
data.
It looks like
everyone has
different ideas.
Then
these three
aspects of
research are
difficult for
some people.
I have more than
half
who think
promoting and
sharing research
results are the
most difficult.
That's
right.
Personally,
if I had to
choose,
I would
probably
choose C
or A.
I'm not
sure.
The
above
questions
are what
Jupyter Meteor
wants to
solve.
Let me
look at
Jupyter
again.
Jupyter
itself is
an ecosystem.
In
simple terms,
in addition to
Jupyter's
own tools,
there are
many other
tools.
They may
not be
developed by
the Jupyter
team,
but
Jupyter
team
often uses
them because
they can
assist
them in
your
research process.
There are
different
areas.
How to
say?
For example,
you may
use Python
to write
your program.
When you
use it,
you may
use some
core components
of Python.
For example,
you may
use
SciPy or
you may
use some
more professional
components.
For example,
if you want to
do parallel
computing,
you may
have heard of
Dask or
have used
Dask.
If you
want to
do image
processing,
I think
you may
have used
Scikit-
image.
In addition
to these
professional
components,
there are
some
components
that
are used
for those
who are
dealing with
astronomical
observations.
Syntax
is used
for those
who are
doing
earth
physics.
It is
used for
those
who
are
calculating
geosystem
or
something
like that.
These
different
components
have different
areas
and
we
say
it is
an ecosystem.
In terms
of geosystem
research,
we will
find that
geosystem
research
also has
different
areas,
just like
other
research.
For
example,
I call it
life cycle
here,
because
I found
that this
is actually
related to
time.
So
if you
are
doing
geosystem
research,
you
need to
collect
a lot of
data.
Whether
you are
going out
to collect
data or
you are
directly
collecting
data on
the Internet
to see
if there
is
any
data
that
is better
than
what
you
are
collecting.
So
you
need to
collect
a lot
of
data
and
collect
a lot
of
data
and
collect
a lot
of
data
and
collect
a lot
of
data
and
collect
a lot
of
data
and
collect
a lot
of
data
and
collect
a lot
of
data
and
collect
a lot
of
data
and
solve
a lot
of
problems
that
other
people
might
have
to solve.
And
If you
want to
publish
your
research,
you might
want to
use
Finder or
Jupyter NB Viewer
so that
other people
can see
your
notebook.
And
lastly,
if you
need to
teach,
you might
want to
use
JupyterHub
so that
students
don't
have to
provide
their
notebook
and
it can
be used
for
teaching.
So
we see
geological
research
is
actually
a very
interesting
field.
So
we
thought
that
we
can
promote
our
Jupyter
Ecology
so that
it can
be used
by
future
generations
for
geological
research.
On the
other hand,
we can
get feedback
from
geological
researchers.
For
example,
if they
think
this
tool
is good
or
hard to
use,
they
can
let
the
development
team
know
that
this
tool
can
be used
by
future
generations.
So
we
started
this
Jupyter
Meteors
project.
I
joined
this
project
last
year.
You
can
see
the
people
in this
project
are
scientists
and
physicists.
They
have
different
perspectives.
Some
are
scientists
and
physicists.
Specifically,
we
want to
provide
some
practical
examples
for
geological
research.
We
want to
use
these
examples
to
make
geological
research
as
efficient as
possible.
We
want to
use these
examples
to
see
what
we can
do
to
develop
Jupyter
in the
future.
There
are
at
least
two or
three
examples
on
Jupyter
that
I
published
at
the
AGU
conference
last
year.
These
are
my,
Shashank
Bhushan,
Max
Van
Wick
DeVry,
Will
Kotitsky,
and
David
Hsien's
research
projects.
I
won't
go into
the
details
here,
but
the
key
point
is that
this
poster
was
released
publicly
on
the
ESSOAR
archive,
so
you can
check it
out
at
any time
through
this
link.
But
you can
see
the
QR
code
on
the
next
page.
This
is the
page I
want to
show you
today.
This
is
the
page.
You
can see
that
this is
actually
a
page
built
on
GitHub.
It
looks like
a document
that
I
wrote.
It
is actually
a
compilation of
many
different
notebooks,
which means
that
every page
you click
here is
actually
originally
a
notebook.
You
can see
that
it has
a lot of
content
telling
you how
to get
the
content
you
want.
Jupyter
Book has
a button
called
finder
in the
upper right
corner.
You
can
turn
this
GitHub
page
into
a
page
where
you
can
run
code
directly.
But
it
takes
a
long
time.
Let's
take a
look.
You
can
imagine
that
when
I
was
reporting
this
poster
at the
AGU
conference,
I
could
tell
most
of the
audience
about
Jupyter
Book.
But
when I
was
reporting
this
poster
at the
AGU
conference,
I
could
use
the
QR code
or
my
laptop
to
show
them
the
details
of the
code
and
show
them
the
details
of the
code.
So
you
can
run
the
final
code
again.
You
can
change
the
content
like
blah blah
blah.
You
can
change
the
content
directly.
That's
about it.
Let's
go back
to the
video.
Now
we can
have a deeper
and more
efficient
academic
exchange.
Here's another
example, but
I'm not going
to show
too many
examples.
This
example is
an article
I
submitted
last year.
It's still
in the
draft.
The
screen
you see
now is
actually
GitHub's
page.
The
supplementary
material.
All of
this article's
supplementary
material is
actually on
GitHub.
And
it's
compiled
in the
Driftbook
format.
So
you can
see
like
this
page
is
saying
if
you want
to
reproduce
this
article's
material,
you can
just
execute
it and
it will
take the
material you
want to
draw
from the
supplementary
material
from
other
articles.
In other
words,
when we
use these
tools
to publish
articles in
the future,
the
process,
the
format,
and
the
material
will
be
connected
to your
article,
so they
will
have a
DOI.
In other
words,
the
materials you
publish
will not
disappear
in the
vast
ocean
of the
Internet
as
time
goes by.
Okay,
so
my main
question
is,
what does
a DOI
mean?
I actually
don't know
what DOI
is.
Okay,
thank you for
asking.
DOI
stands for
digital
identification.
You
can
imagine it
as
something like
the concept
of
a
lock number.
However,
in the
Internet
world,
for example,
you may have to change
your website
due to
funding or
other factors.
Even publishers
may change
their website
from time to
time,
so if
you save
an article
in the
website,
you
may be
able to
do it
this year
or next
year,
but
it
may
fail
ten years
later.
The
identification code
will not
change
according to
the
publisher's
website.
In other
words,
if you
register a
set of
DOI
today,
the identification
code,
that is,
this
DOI.org
and
10.5194
will not
change
according to
the publisher's
website.
You
can connect
your
identification
code to
the
DOI
website
and
it will
be
the
actual
location
and
the
latest
version.
The
next
question is
why
can you
put your
code on
the DOI
?
This
is a
certain
condition.
Publishers,
the
publishers of
academic journals
have basically
done this
thing.
For
city code
or
information,
the
service I
am using
now is
called
Zenodo.
Zenodo
is
that
CERN,
that is,
the
European
lead
counter.
They
have a
lot of
information
and
they can
upload
their
information
and
city code
to their
server.
Then
when you
upload everything
and
get all
the
background
information
right,
they
will
register
a
DOI
for you
as
the
version of
the
DOI.
There are
two places.
One is
Zenodo
that I
just
said
is provided by
CERN.
The
other one
is also
done by
the
Europeans
called
Pangea,
but
its
content
is the
same as
this,
but
there are
different
services
provided
by
Pangea.
Let me
briefly
explain
that.
What we
talked about
before was
the main
purpose of
Jupyter
Meteor
and
what we
have done
so far.
Next,
I want to
talk a little
about
what we
are going
to do in
the future
and
what happened
in the
community.
The
community
has
some
geek
enthusiasts.
They
are using
Jupyter
and
Dask
for
parallel
computing.
They
are also
using
X-Array
to
process
their
data.
We
have a
close
relationship
with
the
community
and
they are
actively
promoting
using these
three
to do
Earth
research.
They
are also
making
a lot
of
use of
them.
For
example,
Scott
Henderson
from
the
University
of
Washington
published
a
paper
on how
to
use
Jupyter
to
do
some
parallel
computing.
With
these
feedbacks,
whether
from
the
Jupyter
Meteor
team
or
from
other
communities,
we
are
thinking
about
how
to
improve
Jupyter
and how
to
use
Jupyter
in
real-time
collaboration.
This
feature
allows you
to use
Jupyter
in the
Google
Doc
way.
You
can
share
a link
with
your
partner
and
you
can
edit
the
notebook
in
Jupyter
and
you
can
share
the
notebook
with
your
partner.
You
can
share
the
notebook
with
your
partner
and
you
can
share
the
notebook
with
your
partner.
This
feature
is
already
very
big.
We
find that
sometimes it
is even
more than
one
scientific
research
talk,
not
two
scientific
research
talk
that
can
cover.
So
a few
years
ago,
there
was
a
project
called
Jupyter
Hub.
Their
purpose
is to
design
the
next
generation
of
Jupyter
Hub
and
Jupyter
Book.
They
also
conducted
many
teaching
and
promotion
activities
and
hope
to
bring
the
next
generation
of
Jupyter
Hub
to
the
world.
One
thing that
makes us
very happy
is that
in the
first two
years,
the
whole
geological
community
began to
notice
this
Jupyter
ecosystem
and
started
to
learn more
about
it.
So
GMVDU is
a
geological
teaching
website.
You can
see that
their
website is
also
written in
the
form of
Jupyter
Book.
They
have some
very cool
content.
For
example,
there is
an app
here.
I'm not sure
if it takes
some time,
but if you're
interested,
you can
try it.
Then I
won't operate
here.
Oh,
okay.
Then you can
move around
here and
see what
interesting
things happen.
So,
on the
other hand,
in addition to
these research
communities,
we are also very
excited to
say that
there are more and
more business
communities
recently.
For example,
Microsoft
launched a
plan called
Planetary Computer
in 2020.
What
they
actually want
to do is
provide
Microsoft's
budget
resources
to the
geological
community.
Their
stock price
has increased
significantly.
With these
business communities,
I personally
think that
the investment
of these
business communities
can make
this Jupiter
ecosystem more
perfect and
truly become
the data
analysis standard
for geological
research in
the next
era.
That's
my
share
for today.
Thank you
all.
If you have any
questions,
please
let me know.
Thank you,
Huaijie.
Do you have
any questions
you want to
ask?
Can I
ask a question?
Sure.
Who was
that?
Me.
I'll
go first.
Hi,
Huaijie.
I'm
Wangjie.
Hi.
I actually
have a
very
basic
question
that I
want to
ask.
What
is the
basic
question?
How
does a
Jupiter
user
get into
a
developer?
I'm
curious about
this.
I'm a
heavy
Jupiter
user,
but I
always feel
that there
is a
big
red
line for
developers.
I'm
curious
about
how
you
get
into
this
red
line.
Thank
you.
For me,
I think
Jupiter is
pretty
grassroots.
They
have a
very active
community
interaction.
Some
software
don't
have that
strong
connection
between
developers and
users.
But
Jupiter
has a
very active
community
interaction.
I think
if you're
interested in
developing
Jupiter,
I think
you can
start by
joining their
discussion
group.
Jupiter
itself
has a
GitHub.
In addition
to the
GitHub issue,
you can post
your questions
or participate
in the
discussion.
They
also have
a
discussion
group.
They
have a
discussion
group.
Okay.
Here
is a
link.
In
addition to
the
discussion,
let me
see.
I
find
something.
Yes,
that's
right.
So,
in addition
to the
discussion,
they also
have some
discussion groups.
In these
two places,
Discourse and
GitHub,
many
users
will
post
questions
and answer
questions.
You will
see many
developers
coming and
going.
So,
I think
if you
want to
go from
users to
developers,
the first
step is
to
establish
your
team.
And
then you
can feel
which
questions
they really
want to
solve now.
These
questions
may be
very
detailed,
but
these
detailed
questions
are
easier
for
developers
to
handle.
Through
these
detailed
questions,
you can
get
a better
understanding
of
the
problem.
So,
I think
that's
all.
Thank you.
Hello,
I have a
question.
Hello,
I have a
question.
Hello,
I have a
question.
Hello,
I have a
question.
Hello,
I have a
question.
Hello,
I have a
question.
Hello,
I have a
question.
Hello,
I have a
question.
Hello,
I have
a question.
Hello,
I have
a question.
Hello,
I have a
question.
In the last
statistics,
how do you
share
your
research
from
your own
research
from the
program to
a readable
page or
a Jupyter
book?
For
example,
you
just
quickly
looked at
a lot of
GitHub
or
your
Jupyter
book.
I
want to
ask,
for
example,
how do
you define
or how
does your
workflow
work?
How
do you
combine
your
work
and
your
GitHub
and
publish?
What
tools
are
needed?
How
do you
combine
your
work and
your
GitHub?
I
think
we don't
have the
most standard
answer yet.
We
want to
now,
we
think there
is a
way to
do it.
For
a
research
team,
they can
have a
shared
work environment.
This
work
environment
is
JupyterHub.
You
can install
JupyterHub on
your
computer
or
a
cloud
resource.
In
this way,
all your
research
materials,
code,
data,
etc.
are
basically
in the
cloud.
You
don't
need
your
computer.
If
you
are
using
GitHub,
you
can
connect
GitHub to
JupyterHub.
We
are
using
GitHub's
identity
authentication
to
log in
to
JupyterHub.
Our
JupyterHub
has
an
administrator
who
manages
the
environment
in
JupyterHub.
If
you are
using
Python or
Conda,
you
will
have
a
pre-set
environment.
Of
course,
every
user
can
install
their
environment
on
their
own.
You
can
choose
to
save
on
JupyterHub.
Whether
it's
a public
way or
a GitHub
member,
you
can
upload
to
GitHub
in
an
unpublic
way.
The
advantage is
that
whether
other
contributors
are
in the
same
JupyterHub
and
working
in
the
same
JupyterHub,
you
can
upload
to
GitHub
as
much as
possible.
Secondly,
you
can
share
your
work
environment
with
other
contributors.
This
is
what
JupyterHub
is
trying to
do.
If
your
research
requires
a
large
amount
of
gg or
gt
data,
because
we know
that
GitHub
itself
cannot
store
such
large
amounts
of
data,
you
must
find
other
data
stores.
This
is
what
JupyterHub
is
trying
to
do.
If
you have
any
thoughts
about
this
question,
please
let me
know.
I'd love
to
hear
your
thoughts.
Thank
you.
Is
there
anything
else?
I
think
that
JupyterHub
is
a
great
platform.
It
is
a
great
resource.
It
is
a
great
platform.
It
is
a
great
resource.
I
think
that
JupyterHub
is a
great
effort.
I
think
that
JupyterHub
is a
great
resource.
I
think
I
think
that
JupyterHub
is a
great
resource.
It
has
a
great
efficiency.
It
can
be subscribed
right
away.
You
can
subscribe
to
JupyterHub
right
away.
I
think
that
JupyterHub
is a
great
resource.
I
think
that
JupyterHub
is a
great
resource.
I
think
that
JupyterHub
is a
great
resource.
I
think
that
JupyterHub
is a
great
resource.
I
think
that
JupyterHub
is a
great
resource.
I
think
that
JupyterHub
is a
great
resource.
I
think
that
JupyterHub
is a
great
resource.
I
think
that
JupyterHub
is a
great
resource.
I
think
that
JupyterHub
is a
great
resource.
I
think
that
JupyterHub
is a
great
resource.
I
think
that
JupyterHub
is a
great
resource.
I
think
that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
is a
great
resource.
I
think that
JupyterHub
has a
community
called
EarthCube.
I
think that
you can imagine it as
an organization
under NSF.
I just posted a link.
You can see what they are doing.
They are
an organization
that
applies for funds from NSF.
They invite
other people
to join their organization.
They invite other people to join their organization.
These plans are related to
data, tools,
and research.
These plans are related to
data, tools, and research.
They save money for these plans.
It's like
indirectly
applying for
funds from NSF.
applying for funds from NSF.
You mean that
EarthCube's funds
are not entirely from NSF?
I think that
their funds
are entirely from NSF.
I think that
their funds are entirely from NSF.
I think that
their funds are entirely from NSF.
EarthCube's organization
is based on
one of NSF's plans.
You can see the number of plans.
You can see the number of plans.
They are using
this kind of funds.
But there is still a problem.
But there is still a problem.
There is a problem
that I think is interesting.
A few days ago,
EarthCube had a meeting.
They discussed that
if there is a data repository
how can the traditional
way of applying for funds
to maintain the data repository
to maintain the data repository
to maintain the data repository
If we really follow
the traditional way,
we will definitely run out of funds
and the plan will be terminated.
I don't think
they have a very good answer
I don't think they have a very good answer
because no matter what the answer is,
it takes a lot of effort,
but it is a very difficult challenge

and you can ask
if they can change this.
if they can change this.

It takes a long time
before you can do it.
It takes a long time before you can do it.
It is not like the short-term
or two to three-year preservation
That's about it.
That's about it.
We are still figuring out more.
We are still figuring out more.
Thank you for your research.
It is true that
we need someone to do this.
It is true that we need someone to do this.
It is true that we need someone to do this.
Someone just posted
Thank you.
NASA is a
I think
it is a
very forward-looking organization
on this issue.
They announced
a plan
last year or the year before
that after a certain year
that after a certain year
all the data of NASA
must meet the standards of Open Science
must meet the standards of Open Science
must meet the standards of Open Science
including the data before
and the data now collected
must be in line with
the data now collected
This requires a lot of people
to do it.
to do it.
to do it.
Do you have any questions?
Do you have any questions?
Can I ask a question?
Go ahead.
I have two questions.
The first one is
I have left the country
I don't know if I mentioned it last year.
I am sorry if I did.
I am sorry if I did.
I first learned Python
and then I started using Jupyter
and then I started using Jupyter
and then I started using Jupyter
demo
demo
demo
demo
In science complex
In science complex
In science complex
With Jupyter
Take Python script code
and Use metadata plot
and Use metadata plot
and Use metadata plot
In this comparison
In this comparison
What do you think is the advantage?
Or the interaction?
Because interaction has other tools
we can use
I haven't found out
I haven't found out
why we should use Jupyter
and not Python script
and not Python script
And use command line
to draw, and plot
And the second question
is about data structure
Because you mentioned
there is another
data structure in D-technology
called X-array
And
I know the data format
of HDF5
Because what I'm doing now
is more about earthquake science
And when we collect data
there will be
large size
and time
So the data structure
is a big problem
HDF5 is very efficient
So I want to ask
When you use X-array
What are the advantages
compared to HDF5?
Or why
HDF5 used a long time
in geophysics
It looks like the format you are used to
Why not use X-array?
And
To answer
the question
If you want to promote a tool
How to promote a tool?
Convince people it's fast
And they will use it
I was convinced
Our research team
My boss
asked me to find
a suitable database
The database I used was SQL
So I talked about SQL
But later I found
Many people only use HDF5
I was thinking
How come I never heard of SQL
SQL is so fast
Why use HDF5?
After using it
I found HDF5 is faster
and has advantages
So I was convinced
If you want to promote
Let it know how fast it is
So the above two questions
Please answer
Ok
The first question
Is to ask
What are the advantages of Jupyter compared to PythonScript?
The second question
is
What is the second question?
The second question is the data structure
Why there is an X-array
X-array VS HDF5
Ok
The first question
I have two different answers
The first answer is simple
Jupyter Notebook
Compared to PythonScript
It can contain more files
When you write PythonScript
You can only put
You can only put
files in the folder
But
And the format of the file
can only be in text
It can't be in some
For example, LaTeX or pictures
But in Jupyter
You can put
But in Jupyter
You can put
You can put
You can use different
Markdown format to write
Then you can
You can use LaTeX to mark your
Mathematics
You can even insert a picture
Insert a video
Insert different links
These extra things
Can be used in a better way
To explain why you want to
Or when your format
After a picture
You can directly explain below
What happened in the picture
The advantage is
In the format block
Jupyter Notebook will display the result directly
This is also a general PythonScript
Can't do
So simply put
Jupyter Notebook
Can make you do
In
When writing your format
You can put all your
Explanation
To be included
This is a simple answer
The complicated answer is that we want to
Through Jupyter Notebook to change
After we write
The standard of academic articles
Especially in
Ah
Or in that
Supplemental information
Then I just had something
Ah
I recently uploaded an article
Here I am still writing
Not yet published
But his
Supplemental information
In fact
In fact, there are many notebooks
In the past
In an era without notebooks
If you really want to upload the format to others
Then there will be a format and an article
Then maybe add a lot of
The picture of the format
Then we can put it all together in a document
Then arrange them so that
The reader can be more accurate
What happened in these things
Then others can
Easier to follow
Ah to execute
To review your results
This is the first question
The second question is
Ah
In my opinion, HDF5 and
Xray actually
It's not a conflict between the two
HDF5
Ah
Its advantage is
Ah
Ah
With reading
It is
The data stored in the structure
So reading is fast
Then you have to
Draw a few layers of data at any time
Then Xray
It's actually on the data
Optimized especially in
If you use Xray
To read a array
Then
This array can be easily cut into several
Different small arrays
Then each array is sent directly to the different
Ah
Different parallel processing workers
Then start parallel processing directly
So I would say the two of them
There are different interests in data analysis
It's not
It's not a set of conflicts
OK
I just had a notification on my phone
So I just interrupted you
I just heard you say
So you think Xray is mainly because it can
Parallel processing in this regard
Is it like this?
Ah, I didn't say it was an advantage
I said they were dealing with different things
Oh, OK
Because HDF5 can actually
Use parallel processing to read
The data inside
Does that make sense?
The difference is even smaller
No, Xray
The data structure processed by Xray
Only Array
Oh, OK, I understand
So
But it's for Array
This data structure has done a lot of optimization
OK
So yeah, so I still think
They are actually two different things
You won't hear that someone is in Xray
Put a bunch of metadata
Oh, I understand
Thank you
Thank you
Can I ask another question?
OK
Please
In the chat
I put a link
In the chat
It's a github data website
Very suitable for
The audience to directly read
Your stuff
Is that version directly from github
You can turn it into that format
Or is it another design?
Yes
It is
An automated process
Directly from that github
Turned into a version suitable for reading
Can I share my screen?
To explain this question
You may need a screen
OK
This is my
Check where my github is
Suppose this
Suppose this
Suppose there is a
Github storage
So if I want to automatically
Turn this storage into
Github page
Then I am through
A github action
The script does
So you go here
You can see what I did
Then there will be some
Things you will see
Every time you submit
Then there will be a github action
Execute here
This action is actually
Automatic
Put in
What's in the github folder
To compile
The github page you see
If you are interested
You can ask me how to do it
But if you want to know
What is in this action
There is a
The folder is called
You can see here
There is a build
This is probably
You want to let this github action
Execute the necessary settings
That's about it
Simply put, that's it
So you need to have this workflow
You need to have a folder
Tell this workflow how to compile
Your file
That's it
I think this
This thing feels like
A lot of areas will be interested
It looks like
Everyone here should be quite interested
I would suggest you
For example, we invite you
To open a workshop during the summer vacation
To teach everyone how to do this
Sure
Of course
Everyone is very interested
Share
Current practice
OK
Maybe there are a few other things
You can
Anyway, I may contact you later
No problem
Is there any problem here?
Jack said thank you for sharing
Thank you everyone
Thank you everyone for being there until the last moment
Thank you very much
It's really interesting
OK
That's the end of our speech today
That's the end of our speech today
Thank you very much
Then we will meet again later
No problem
If you are interested
If you have more questions, please contact me
I will post my email here
Quickly
Thank you
So you can know
How to contact me
Stop recording
