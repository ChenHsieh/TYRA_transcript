Okay, let's get started.
Oh, I hear the recording has started.
Okay, so the topic I'm going to talk about today is
Phylogenetic Components with Meta-Optics.
Because my main research background is
the interaction between light and matter,
and then, through this interaction,
we can further manipulate light's behavior.
So the main application we want to do is
how to reduce the size of the current
phylogenetic components on the market.
For example, transparency or bias.
So, what is meta?
I'll talk about it later.
The word meta-optics is actually
the Greek word for meta.
I'll talk about it later.
Before we get into the topic,
I want to share a picture.
I don't know if you've seen this picture.
This is from the ancient Roman era.
The picture on the left is from the ancient Roman era.
This is a wine cup.
What's amazing about this is
you can see that the colors are different.
But they are actually the same cup.
The color is different because
they found that when they put the light source outside,
the color of the cup is green.
But if they put the light source inside the cup,
the cup will turn red.
That is to say, the material on the cup is very special.
If you look at the cup from the perspective of reflection,
it is green.
But if you put the light source inside,
the color you see is transparent.
So after you put the light source inside the cup,
the color you see is red.
At this time, people think this is amazing.
They also use this kind of material
to make church colored glass.
We all know that
churches in Europe
have very beautiful colored glass.
Why are there so many different colors?
The reason is the same as the cup.
The principle of its operation is very similar.
Why does this phenomenon occur?
Later, people found that
there is a thing called localized surface plasma.
What does this mean?
Why doesn't it move?
They found that
if we have a colored light source,
it will interact with a metal nanoparticle.
After interacting with it,
it will accumulate some free electrons
on the surface of the nanoparticle
under the appropriate conditions.
These free electrons
will allow it to produce a similar dipole inside,
an H-ray dipole or a magnetic dipole.
Let it further produce,
let it radiate electrons from other dipoles.
Then we will see different colors.
When will this phenomenon occur?
It mainly occurs
when our nanoparticles
are smaller than the dipole of the colored light.
This thing will only occur.
So the high-angle cup,
the colored high-angle cup,
later they did a further study
and found that the high-angle cup
actually contained a lot of gold particles of different size.
This is gold particle.
The size of these metal particles
compared with the dipole of the visible light,
the visible light dipole is about 400 to 700 nanometers.
Compared with it, it is smaller than the size of the dipole.
So they thought that
the reason for the different color
may come from this
local surface plasmon resonance.
The result of localized surface plasmon resonance.
After this resonance,
what special phenomenon will we have?
It actually has a lot of advantages that we can control,
that is, we can have.
For example, they found that
this resonance has a bias with the dipole of the colored light.
The bias is the direction in which the electron waves resonate.
You can see that this picture may be more obvious.
For example, the color here is very colorful,
very beautiful,
there are five or six colors.
Here you can't see any color at all.
These two pictures are actually the same sample
color.
Their only difference is that
they changed the direction of the dipole of the colored light.
This red and white arrow is the direction of its dipole resonance.
When the direction of the dipole of the colored light
is along the y-axis,
they will see that the chip above
will produce different colors.
In fact, you can imagine that
the chip uses some micro-imaging technology
to make some metal disks
that are smaller than visible wavelengths.
Like this disk.
Then they change its diameter or cycle.
We can see different colors
in the reflected light part.
But when they turn a bias,
the colors are all gone.
So you can use it to do something.
For example, this thing can be used to make
color filters that have a bias control feature.
Another special thing is that
we used to know that
for example,
why are we so interested in this thing now?
For example, we know that gold is often used to make decorations.
For example, rings and necklaces.
But gold,
as long as we use gold to make a decoration,
whether I pinch it into a square,
a circle,
or a ring,
its color is yellow.
But like I just said,
if we put this gold,
all the particles here are gold,
but they are at a very small scale.
If its scale is smaller than the wavelength,
we can find that
as its size changes,
the colors we see are different.
This is very different from the optical phenomenon
that we see on the object.
The main reason for this is because
of the localized surface plasma.
The next feature is that
if the two metals are very close together,
there is a very small nano gap
between the two metal particles,
there will be a very strong near-field coupling.
The two of them will interweave each other.
This interweaving will make them
a bit like the simple electronics we learned before.
It's like the feeling of end-to-end power generation.
Because its scale is very small,
the more end-to-end power it can accumulate,
the stronger the near-field power generation it produces.
If it is very close,
the interweaving between the two
will cause it to have a stronger field enhancement.
Finally, this resonance
has a lot to do with the surrounding environment.
It is very sensitive to the environment.
That is to say,
if the surrounding environment's resolution changes,
its resonance wavelength,
which is the color we saw in the original factory, will change.
For example, this stick now,
if it is in the air,
I see blue.
But if I put it in the water
and look at it again,
it may turn red.
This feature
is also used by some people
to say that we can do some sound sensing.
It is based on the change in color
to judge what is the object
in the surrounding environment.
OK.
After introducing the Localized Surface Plasma,
I will tell you
what is Metamaterial.
As I said,
the word Meta
comes from Greek.
It means the same in English.
Metamaterial is a kind of material.
It has some features.
These features are not found in natural materials.
We call it Metamaterial.
Simply put,
we can use the shape of it
or the distance between the particles
to change its optical properties.
These are called Metamaterial.
Why do we have these features?
It should be said that
we need to produce Metamaterial properties.
What is the strict condition?
As I said,
we generally know that natural materials
are composed of atoms.
For example, CO2, H2O.
Because we know that
the distance between them is very small.
If I take the surface plasma as 500 nm,
which is about the surface plasma of green light,
as an example,
these two
have a very, very big difference in their magnitude.
So its optical properties
are mainly determined by this molecule or atom.
For example, gold is AU.
No matter how I rub it,
it is yellow.
Metamaterial is what I just said.
If we now put the distance
or size between the particles
to be reduced to the original size,
which is the level of the magnetic field,
which is about Lambda over 4 to Lambda over 10,
at this magnitude,
we can use man-made methods
to change the optical properties of the material itself.
Then we can further manipulate
some of the behavior of light or electromagnetic waves.
This can be produced by the resonance
at the magnitude of the magnetic field.
By using this method to manipulate light,
we call it metamaterial.
It is mainly triangular.
Although my structure is very small,
its thickness in the z-direction can be very thick.
My very thick is only compared with the surface plasma of green light.
For example, it can be one or two microns.
Let me ask you a question.
10 to 100 microns?
No, 1 to 10 microns is fine.
It can be several microns.
So 10 nanometers to 100 micrometers is fine.
The magnitude I'm talking about here is a bit broad.
Mainly because the example I gave earlier is visible light.
But the advantage of this thing is that
my work plasma may not necessarily be visible light.
I can even be a microwave wave.
So 10 micrometers is Terahertz?
100 microns.
If it is 100 microns,
it should be 3 Terahertz.
If I'm not mistaken.
It's about the range of Terahertz.
It's far away.
So its work plasma can be very broad.
Here is a very special example.
The metamaterial I just mentioned.
When I first saw this phenomenon,
there was no such word as metamaterial.
It's called left-hand material.
Why is it called left-hand material?
Because they found that
the structure of man-made
can control the behavior of light.
We know that the characteristic of light transmission
mainly comes from the refractive index of the ring.
So they thought,
is it because of the refractive index?
Metamaterial is used to manipulate
the refractive index of the ring.
That's why it affects the behavior of light.
Here is a schematic diagram.
We used to study chemistry in high school.
If a cup is an empty cup,
the air refractive index is 1.
If I put a chopstick here, it will be straight.
If I put a refractive index of 1.3 in it,
it's probably water.
We know that because of the refractive index,
it looks like the chopstick is broken.
But if we put a negative refractive index in it,
the chopstick we see at this time will look like this.
This is actually just an experiment.
This is not the result of the experiment.
Another interesting thing is that
if we have this negative refractive index,
we usually know that the beam of light will be full.
In other words, the beam of light is orange here.
If it is a beam of light,
it is along N1sinθ1 and N2sinθ2.
So it keeps refracting.
But if the material in the middle
is a negative refractive material,
the beam of light and the beam of refractive light
will be located on both sides of the beam.
This makes them very interested.
That is to say,
is it true that because of these characteristics,
we can create some real
boundaries that naturally cannot exist,
and then achieve some
light and snow characteristics that we can't imagine at all?
This kind of negative refractive index,
I am trying to prove it here.
But in fact, there is already an experiment to prove
that this thing is really feasible.
But I didn't put their experiment results here.
It is to prove that by
properly designing the size of this material,
or the elements of the material itself,
they can achieve the negative refractive index phenomenon.
I think I can skip here.
Next, I will talk about
the Metamaterial I just mentioned.
I just said it can be very thick,
it can be three-dimensional.
But in fact, our main purpose is to
control the light.
Can we further reduce the element?
They want to say,
if I make Metamaterial only one layer,
because I just said that Metamaterial can be many layers,
it means that it can be very thick.
If I only have one layer,
can I achieve the same effect?
This one-layer Metamaterial,
they call it Metasurface.
A surface that is the same as a general surface.
Yes, so it's called Metasurface.
Here is an example.
For example, I now have a metal stick.
After I inject a electromagnetic wave into it,
because this magnitude is much smaller
than the injected light wave field,
so I can directly use the concept of
injecting electromagnetic waves to
see the result of this resonance.
So if my injected light wave field
vibrates along this direction,
I can theoretically accumulate positive and negative electrons
at both ends of the stick.
This accumulated positive and negative electron
can make us equivalent to an electrode.
After this electrode vibrates,
another electromagnetic wave will be radiated.
If we take a closer look at this structure
of penetrating light waves and phase light waves,
under a fixed wavelength,
it is obvious that
if the length of the stick changes,
just like I just said,
because this material,
this Metasurface or Metamaterial,
has a lot to do with its
resonance characteristics and size.
So when I make the length longer
or shorter,
we can see that its resonance wave
will gradually be flattened.
At this time,
if I look at a fixed wavelength,
its magnitude or phase
can be changed.
A point that everyone is very concerned about
is the phase.
Is this a simulation?
Yes, this is a simulation.
Both of these are simulations.
If we can manipulate the phase,
we can further manipulate
the wavelength of the electromagnetic wave,
which is the characteristics of its transmission.
For example, if I now have a
sample substrate,
and I record a flat wave,
if I put some of the
Metasurface nanostructure on the surface,
because its size is different,
the phase deviation they feel
will be different.
The different phase deviations
will make the phase delay
of the original wave
different,
which means that after the original interference,
they can reconstruct
another wave front.
And this wave front
is completely different from the Metasurface.
Although this magnitude is less than
the Metasurface wavelength,
we can control the electromagnetic wave
characteristics
with the Metasurface nanostructure.
Here are some examples of applications.
This is probably
to say that
we can not only manipulate the electromagnetic wave
government and phase,
in fact, the wavelength and deviation
can be manipulated
by Metasurface.
For example, they can
do some optical image
or do some deviation conversion,
which I will introduce later.
Here is a very simple image
that is, why this thing
can be so interesting
and help us to design some
flat optical components.
I use the simplest one before
is our deflection law
to explain to you.
For example, if we used
Hagen's principle to explain
the deflection of this thing,
that is, if I have two materials
in the space now,
the deflection rate is N1 and N2 respectively.
After the deflection wave comes in,
every point on this interface
is reflected by the deflection light,
I can think of it as a
two-point light source.
So here is a little bit gray,
gray and white dots,
round dots.
I just split it
into a very small point
in each space.
This small point is reflected by the deflection light
and interacts with the deflection light.
I think of it as a two-point light source.
The deflection wave
coming out of the point light source
will be a circle.
This circle will eventually
reconstruct another deflection wave in the original factory.
Because each of them
has the same surface,
the phase coming out of their radiation
has no delay.
So their
original transmission
will be as flat as the deflection light,
which is the tradition.
How did they explain this thing
with Higgins before?
When I am now in the diagonal direction,
you can see that the red part
is the wave front.
This wave front
touches the time on this interface
will be different.
It will first touch the point on the left.
So after the point on the left is touched by the light,
it will be regarded as the first
two-point light source
to start radiation.
Then this point is touched.
But because it is slower to be touched,
it will produce
this radiation slower.
In this way,
to the end here.
Because the time they were touched
is different, we can think of it as
their radiation
is different.
So you can see that the shape of the radiation
produced by them is different from here.
The radiation is getting smaller from left to right.
This will cause
the wave front to be oblique.
Bing Jie, Zhang Yang has a question.
He has a question.
He said
Transmittance's light source
is mainly a design decision.
What about Resonance's Q-factor?
How high and low can it be now?
This thing?
How high can the Q-factor be?
How is it determined?
Q-factor
has a lot of things.
It will be affected by a lot of things.
First of all, the most intuitive
is its loss.
Because the material I designed here
is made of metal.
The metal in the visible light,
or the part outside the mirror,
after it has been resonance,
because of the dipole,
we can think of it as
a movement of free current.
This part will cause
The second thing that will affect it
is the loss of the original radiation.
In theory, we divide it into two categories.
One is Intrinsic.
One is Extrinsic.
Intrinsic is the heat radiation
that the material itself produces.
The other is the loss of the original radiation
caused by the original radiation.
I classify both of them as the part of the loss.
This part will reduce my Q-factor.
The other part is whether my cavity
is strong enough.
Because my current structure
is based on the loss of the original radiation.
So even if there is a shock
on it,
I can think of it as a movement of free current.
But this movement of free current
cannot be perfect
because this cavity is not very strong.
If I want a very strong cavity,
in theory, we should have
almost 100% reflectivity on both sides.
At this time, my Q-factor can be very high.
But because of my current structure,
I just wait for it to accumulate
and let it accumulate radiation on both sides.
But this cavity is not that strong.
So my Q-factor will be reduced.
These factors
result in the
Plasmon Resonance
produced by this kind of metal.
Its Q-factor will not be too high.
As far as I know,
if it is made of metal,
without considering
any cavity,
that is, without considering any mirror,
that is, the perfect mirror in this system,
its Q-factor
can only reach a few hundred.
This is already the highest.
But usually it is only a few tens.
He said he understood.
OK, thank you.
Then,
if I have the
nanoparticle I just talked about,
I am now
in the same direction.
But because of my nanoparticle,
each nanoparticle has a different size.
The size is different,
just like what I just showed in this picture.
Under the same wavelength,
the phase delay
felt by each different size will be different.
At this time,
it works as if
each particle,
although they both feel the
electromagnetic wave,
but after their resonance,
the radiation phase will also be delayed.
This is very interesting.
It allows us to achieve
transparency.
In theory,
I am transparent.
But if I design the structure
appropriately above,
I can see that it is written out.
I can use
Momentum's picture to explain it.
I don't think it needs to be explained.
Basically, it is the phase delay.
Here is a simple experiment result.
If I design a stick
of different lengths on the surface,
you can see that
Can you go back to the page
and explain Momentum? I don't quite understand.
Momentum, in theory,
we know that its K
is 2π除λ.
If I have
different structures here,
in theory, I can equate it to
each structure
can provide a
horizontal momentum.
How does this horizontal momentum decide?
This horizontal momentum is determined by
2π除λ.
What does this λ mean?
This λ of 2π除λ
means that my structure
has a phase delay
from 0 to
the minimum length of 360 degrees.
That is, I can see it as a
pixel of light.
A pixel of light.
If a pixel of light is λ,
we know that its K is 2π除λ.
Because I have a
phase change of T,
I can equate it to
the horizontal momentum of
2π除λ on this
surface.
And these two
Momentum boxes
can let us see through the light.
These two boxes
are obviously in this direction.
This is why we can
achieve the phenomenon of
paranormal penetration.
This is a
simple experiment result.
After designing different
lengths of sticks on the
surface, if my light
is perpendicular to the light,
I want to see if it can
reflect back in the opposite direction.
This is the result of the experiment.
This is the result of the calculation.
The curve of different colors represents
different angles of light.
Black is when the light
is perpendicular to the light,
and white is when the light
is perpendicular to the light.
The reflection angle is
about 45 degrees.
This proves that we
give it a horizontal momentum
in the horizontal direction.
Why don't I see through the light here?
Because the structure of this design
has a thick metal at the bottom.
This thick metal helps
us block all the light.
So we only see the reflected light.
Why do we only see the reflected light here?
You can also see that
when the light is perpendicular to the light,
if you look at the scattering,
you can see that the light
is perpendicular to the light.
Let me ask you a question.
What wavelength is the light
reflected?
The working wavelength is
about 780 nm.
This is the boundary between
the reflected light and the reflected light.
After doing this demo,
we also want to demonstrate
that its efficiency can be very high.
You can see that the efficiency of the calculation
can be more than 90%.
The experimental beam is also 80%.
I'm talking about the time when the reflection was recorded.
So why do we have to choose this wavelength?
Because the inter-beam scattering
is at 550 nm,
so if we use gold to make
the inter-beam scattering,
its resonance will never happen before 550 nm.
Because the loss is too big.
So the farther we work from 550 nm,
in theory, its efficiency can be better.
Of course, this is just the characteristic of the material itself.
Other factors also affect
its efficiency, such as
structural design.
This is the final optimization result.
I want to share with you
most of my work.
The first part is that we want to use aluminum
to make a visible Metasurface,
and then make some
flat components.
The other part is that
we want to make a transparent mirror.
Why do we want to make a transparent mirror?
Because what I just said is
that the most important thing
about Metasurface now
is that it can greatly reduce
the size of the components
we can buy on the market.
For example,
the simplest
and most impressive
is the iPhone
or our smartphone
camera lens.
After the iPhone 6,
you can find that
its body is actually very thin,
but its lens protrudes a piece.
This is because
when the body becomes thin,
it has to maintain
the resolution of the image
it takes
.
This premise
will cause it to
not be able to greatly reduce
the size of the mirror.
It has to insert a lot of different mirror groups
and stack them up,
so that the image produced after taking pictures
will be clearer,
so that some contrast and color difference can be eliminated.
I will introduce this later.
I don't know if I have enough time,
so I may be a little faster.
In fact, if you
take a look at the
current direction of the
battery wave,
we call it bias.
In fact, whether it is
the linear bias of the y-direction
or the linear bias of the x-direction,
or when it rotates,
it produces a circular bias.
No matter what the bias is,
I can split its positive and negative
into three components, x, y, and z.
I can easily stack
these three components
in the same way.
I should say that I can split
any bias light into these three components.
So our future design
will be based on this logic.
Bias is actually quite useful
in life.
For example, 3D images are the most common.
If you go to see a 3D movie,
it will give you a 3D glasses.
These 3D glasses are
what the left eye sees
and what the right eye sees.
Its bias is also perpendicular to each other.
When it causes this illusion,
the image you see will look like a 3D.
So why do you see
that the image is foggy when you take off your glasses?
Because your two eyes
detect the image of two biases at the same time.
Or
we often see that
some people who play photography
will know that
they will put some filters related to bias
in front of the lens,
which can shoot some light
on some slower
or stronger surface
to make
them more clear.
Or
do some
biological or chemical molecules detection.
Because some biological or chemical molecules
will take the initiative
to bias
the bias of the light.
Different molecules
have different angles of bias.
Some are big and some are small.
Some people use this thing
to make chemical molecules
detection.
What are the
most common
ways to manipulate
bias on the market?
Let me give you three examples.
The first one is linear bias.
For example,
if there is a dirty battery,
the battery factory is messy.
If you want to turn it into a pure
battery factory,
for example,
the battery factory is a
horizontal wire.
If the battery factory is along this wire,
it will be absorbed.
The volume of the battery
will be penetrated.
So it uses this method
to filter out the bias it doesn't want.
This is what I found on the Internet.
You can buy it on the market.
Because we need to effectively
absorb all the light in the x-direction.
So its thickness must be thick enough.
Usually this thickness is about a millimeter.
This diameter is one inch.
This diameter is half an inch.
Another one is that after we produce
linear bias, we want to do
a rotation of bias light.
For example, the linear bias of the
green light is 45 degrees.
If I want to rotate it to negative 45 degrees,
we will use 1 in 2 waves.
The main thing is that this material
itself can provide different
phase differences
in the x- and y-directions,
so that when the light penetrates,
the bias of the x-direction
slowly slows down,
and the y-direction slowly speeds up,
so that the x- and y-directions
of the green light are in the positive direction
respectively.
After coming out, it will become
a negative and a positive,
and then use this method to rotate it.
Because it has to accumulate
enough bias delay,
so its thickness must be thick enough.
Or to produce linear bias light.
This is to give the
x- and y-dimensions
an additional bias delay,
so that the angle of the bias delay
is large enough that the
x- and y-directions of the x- and y-directions
are exactly 90 degrees.
Then it can become the original bias light.
It also has to have enough bias delay,
so its thickness must also be very thick.
What are the benefits of using linear bias light?
We don't need to use the thickness of
the minimiter level,
we can produce any bias light we want.
For example, we provide a
design method called
Geometry Faced Metasurface,
which is a superimposed interface that combines
the positions of the x- and y-directions.
What does this mean?
For example, if I have a stick now,
I record a right-handed light
and look at the penetration of the left-handed light.
At this time, because the
bias light of the penetrating light
is different from the recorded light,
so I call it conversion efficiency.
We can see that the conversion efficiency is here.
Then I look at the x- and y-directions of the
bias light, and I will see a value.
At this time, if I rotate it
a theta angle, this theta angle is
the angle with the y-axis.
We will find a very magical thing
that its efficiency will hardly change,
and its
position will change to 2 theta.
Then,
as long as I let it rotate
at the same angle
on this surface,
I can make
its position change from 0
to 2π.
Every time I rotate a theta angle,
its bias delay will become 2 theta.
Another interesting point is that
if the same structure,
the direction of my rotation is exactly the same,
but at this time I turn into a left-handed light
and look at the penetration of the right-handed light.
At this time, I will find a
more interesting thing,
its bias delay can reach 360 degrees,
but it is from 0 to 360 and becomes
0 to negative 360.
This thing can help us design
some components that can be manipulated by bias.
For example, if you look at it with the right-handed light,
it will become a focal penetration.
If you look at it with the left-handed light,
it will become a scattered penetration.
In other words, I can combine
many different optical functions
on the same optical component,
and its
magnitude is very thin.
The thickness of this metal is only
50 nanometers,
so it is much smaller
than the previous
50 nanometers.
This is what we are talking about,
because its magnitude is very small,
so the concept we propose here is that
we can integrate all the different chips
on the same sample.
Then after I enter the color light,
I hit different chips
and the reflected light can produce a different fragrance.
Compared with the general traditional components,
I want to produce the original light,
for example, I at least need a
linear light,
a linear polarizer,
and a quarter wave,
to produce the original light.
But now if I only use our metasurface,
my thickness only needs about
dozens of nanometers to complete
this thing.
Let me tell you
why we use aluminum,
because I just mentioned that gold,
because its intervention coefficient is around 500 to 550 nanometers,
so it is impossible
to work on the entire optical spectrum.
Silver can work on the entire optical spectrum,
but there is a big disadvantage of silver,
which is that it is very easy to oxidize,
so the components cannot last long.
So we choose aluminum here.
Here is a demo for everyone,
that is to say,
we use LISO to pattern
some different aluminum sticks
of different lengths and sizes,
and its color will change drastically.
This is its tradition.
Indeed, its resonance can
expand from 400 nanometers of blue light
to 750 nanometers of red light.
Here is the design of the component.
I won't talk about it.
Simply put, we optimized
its structure dimension
so that it can produce the highest
work efficiency.
Next, I will tell you
how to use the same component
to achieve the production
of any parameter.
First of all,
after I design a stick here,
as I just said,
I make it rotate
in the direction of change.
I can let it produce 0 to 2π
and I can produce an abnormal reflection.
The interesting thing about this abnormal reflection
is that my rotation angle is fixed,
so if I enter the color light
at this time,
it will produce an abnormal reflection
of the right light here.
Conversely, if I enter the color light
and it is the right light,
it will produce an abnormal reflection
of the left light,
but it is on the other side
and it is already achieved.
If I enter a linear parameter light,
which is horizontal,
I mean the x-parameter light.
Because the x-parameter light
can be regarded as the addition of
the right light and the left light,
so it can let me produce
the left and right parameters at the same time.
So I use a simple rotation
to achieve the adjustment of the original parameter light
if I enter the color light as a linear parameter light.
How do I produce any linear parameter light?
We introduce another
parameter light that looks exactly the same as it,
but the rotation direction of the structure is opposite.
The first group of rotation is clockwise,
and the second group of rotation is counterclockwise.
In this case,
when I enter a linear parameter light,
I can achieve the reflection of
the right and left parameters at the same time on the same side.
Then I make a spatial parallelism
between the two of them.
This parallelism will make a difference
in the position between the two of them.
This difference in the position
can be determined by this d.
As mentioned earlier,
the difference in the position
can be equal to 2πd divided by Lx.
Lx is the length.
So you can see that the difference in the position
can be changed by the change in d.
So after the two of them interfere with each other,
they can be multiplied into
different linear parameters.
For example, if d is 0,
it means that the difference in the position
between the two original parameters is 0.
At this time, their reflection light
will also be an x-parameter light.
It's a bit like a mirror.
If I let its d
be designed to
have a difference in the position
of π,
it will become a y-parameter light.
That is, Lx's reflection light will become y.
In this way, I can make it
a positive 45-degree linear light
or a negative 45-degree linear light.
So it's all reflected.
Now there's no way to do the refraction.
Isn't it just a projection?
We can do projection here,
but the efficiency of projection will be very low.
Because I just said that the loss of metal is relatively large.
So our demo here is mainly reflected.
The work I will do later will be projected.
But our material will be converted from metal
to electrolyte.
OK, good, continue.
Then here is its SEM map.
That is, we integrate
the six samples together.
Then the optical system.
Here is a test result.
We usually use
this POSCALISphere
to show
what the
refraction of light
is.
In fact, this map is very simple to see.
If this map is the earth,
its north pole represents the purest right-axis light.
The south pole is the purest left-axis light.
The four points on the equator
represent the
linear light.
The four points in the east, west, south and north
represent the purest
x, y, positive 45
and negative 45-degree linear light.
And these three maps are based on
the experiment results of these three
green light wavelengths.
The black dots are the theoretical results
of ideal prediction.
And the
black dots with colors
are the results of our experiment measurement.
It can be said that they are almost very match.
Some may have some miscalculations,
but they are still quite close to our theoretical prediction results.
Then it proves that we can
achieve different equilibrium states
based on our experimental results.
This is an acoustic-optic modulator.
This is an acoustic-optic modulator.
This is an acoustic-optic modulator.
We want to design a different structure,
and make it a stick-length.
So the resonance will only be produced
when the polarity of the infrared light is along the length.
That's when I see the image.
If I rotate the polarity of the light,
the image will disappear.
When the white light comes in,
I hope to see RGB in the original.
If I rotate the polarity of the light,
I will see different images.
I skip the design principle.
This is a sample picture.
This is the experiment result.
If the white light comes in,
I can see the RGB pattern in the original.
The same is reflected.
If I slowly rotate the polarity of the light,
I will see that the image will disappear.
This is the first part of
making a polarity-dependent holographic image.
The second part is the lens.
The lens is widely used in our daily life.
For example, a microscope or a camera lens.
The main thing is to focus on the lens.
There are several big problems with the lens.
One of them is the difference between the two.
The difference is the light coming in from different angles.
It will be focused in different places.
If I want to make a full-color image,
there will be a big difference.
The difference is that the light comes in from different angles,
but it will be focused in different places.
This makes it impossible for us to make a full-color image.
In order to satisfy this problem,
they will stack two lenses together
to compensate for the difference in color.
They can be focused at the same point
in different places.
This makes it possible to make a full-color image.
This is why we can't make full-color images.
Because they have to stack many lenses together
so that they can be focused at the same point
in different places.
Theoretically, if you add one more lens,
you can only make a full-color image.
For example, if I want to make a full-color image,
you can imagine that I need at least ten or twenty lenses.
It may not be enough.
Here is a picture.
Why is the lens of our smart phone so thick?
Because it has a lot of different lenses in it.
In order to satisfy the compensation of the difference in color,
the picture we take will not have distortion.
Or the color will not run away.
It's the same as what you see with your eyes.
This is why we want to use MetaServer as a lens.
I just mentioned that we used to use metal.
We want to make a high-efficiency lens.
If I use metal,
all the examples I just mentioned can only be reflective.
On the other hand, if I want to make a penetrative lens,
I have to convert it into an anodized material.
Anodized material does not have a distortion rate,
so there will be no heat loss when it is compensated.
Without heat loss,
it can greatly reduce the efficiency of work.
Here is a history.
This may also be skipped.
First of all, we use GetInNitro as a material.
It has a high enough distortion rate in visible light.
We want to use anodized material to make MetaService.
The prerequisite is that its distortion rate is at least greater than 2.
Because anodized material is not like metal,
it has a free electron accumulation.
So its resonance must rely on the displacement current.
If the displacement current has resonance,
it means that the distortion rate itself
must be large enough to compare with the surrounding environment.
Only then can it produce a strong enough displacement current
to produce anodized material accumulation.
At least, as far as I can see,
if compared with air, it is at least 2.
Similarly, we use PPFace,
which is the MetaService of GeometryFaceFace,
which is the rotating method I just mentioned,
to adjust its anodization.
Why do we need to adjust its anodization?
Because we are going to make a focal length.
To make a focal length means that
I am now inserting a plane light into it.
The light in different positions
will feel that its anodization delay is different.
It can only reach the same point.
So this is the anodization distribution
that I have to satisfy in different structures in the space.
Then this is the final design result.
If I insert an experiment,
this is the experimental electronic microscope photo.
This is the MetaService Lens we designed.
We call it MetaLens.
In order to detect its anodization,
when we insert a light into it,
this ultraviolet transceiver
will focus on a certain point in a certain space.
We use a flat platform at the back
to detect how good its anodized light band is.
It can be seen that
when we match it to its anodized surface,
we can see a very beautiful green highlight.
I inserted a green light and laser at this time.
If I move away from it, it will not focus.
In addition to the green light,
we can also do different things.
How far is the distance?
How far can it move?
You mean this stage?
Yes.
The stage we bought at that time was quite high.
It can move up to 7mm.
What about its step size?
Its step size can be up to 500nm.
OK.
Yes.
Thank you.
Go on.
Not only the green light,
we can also do red, blue, and green.
Just change its size.
Just like what I just said.
Because it also has a resonance.
The resonance depends on its size.
Yes.
Next, in addition to doing positive focal length,
we can also do oblique focal length.
It's the same on a flat surface.
But this thing
is very difficult to do in traditional optical anodizing.
Because traditional optical anodizing
is mainly done by hand
to achieve the surface frequency I want.
Anodizing is a glass with a curve.
Different thicknesses
will cause different fragmentation.
If I want to use traditional anodizing
to do oblique focal length,
you can imagine that
this curve
will become a curve on one side.
This is very difficult
in terms of technology.
Our technology is very simple.
I just need to change
the distribution of the surface structure
and move its center
to the left a little bit
or to the right a little bit.
Then I can do oblique focal length.
For example, this picture.
Yes.
This is the experiment result.
You can see that red, blue, and green are focused.
The dotted line
refers to the position of the lens.
The focal length is in the upper right corner.
We designed it in the upper right corner.
We proposed an application for this.
If we integrate all of them
on the same chip,
it's the same because it's very small.
So we can easily
integrate them all together.
At this time,
after I insert a wide-screen light source,
I will see different colors
with different color distribution.
I can use it to divide the light.
For example,
this is our sample photo.
If I insert a red light now,
I can see that it focuses in the upper right corner.
It's the same sample.
If I insert a green light now,
I can see that it focuses
in the upper left and lower right.
If I insert a blue light,
it focuses in the lower left.
If I insert three wavelengths at the same time,
I can see the effect of dividing the light.
The biggest application of this
is on CMOS.
CMOS is a very important component
in the current image sensor.
Traditionally,
a micro lens must be made.
It must be focused first
and then go through a filter
and then go through a detector.
Because the detector can't distinguish colors,
that's why it has to put a filter here.
That's the reason.
It must first determine
that this filter can only receive blue light.
So it has to put a blue light filter here
to filter out the white light in front,
red light and green light.
This causes
the red light and green light
of this part to be wasted
and pushed back and forth.
But for our sample,
we can put all the white light in
and put all the red light here,
green light in the middle,
and blue light on the other side.
We can effectively use
all the energy of the green light
to greatly increase its S-N ratio.
The other biggest advantage
is what I just said.
Our thickness is only 600 nanometers.
Traditionally, it's about 1 to 10 microns.
So we can shrink down
its physical dimension.
Another thing we want to do
is to eliminate the color difference.
As I just said,
different wavelengths
will focus on different positions.
This is the work of people in the past.
This is our work.
Traditionally,
different wavelengths of green light
would focus on different positions in the space.
So it's hard to make a full-color image.
After some special designs,
we provide different color compensation
in different positions
to create a white light focus point.
We're just doing a demo here.
So we're using a metal part
to do a reflective demonstration.
This is the design principle.
I won't talk about it.
I'll just show you the result.
This is the sample photo.
This is the measurement result.
This is the calculation result.
You can see that
my wavelength has changed
from 1.2 microns to 1.65 microns.
Basically, its focal length
hasn't changed at all.
If I do a different
transparent measurement,
you can see that
when the green light wavelength changes,
its focal length
remains at the same position.
If I compare it with
traditional Meta Lens
or other traditional Lens,
in the same wavelength,
its deviation is quite large.
So it proves that
we can completely eliminate color difference.
This is another example.
I'll skip it.
Another example is
what we just talked about.
The biggest use of transparency
is when we want to make a full-color image.
Reflectivity is actually very capable of making a full-color image.
So our work here
is to make a transparency
with high efficiency
to eliminate color difference
and further apply it to make a full-color image.
This is what we just talked about.
Why can we use
the material of the interface
to adjust the fragrance?
Mainly because
there is a big difference in reflectivity.
So it can produce
a cavity-like resonance inside.
So different wavelengths
can produce different
resonance.
Different wavelengths
can produce different fragrance delay.
This is our photo.
Our studio is located in the visible light.
So the refractive wavelength range is from 400 to 640.
We can actually eliminate it to 660.
But because of the deviation here,
I only show it to 640.
The last is to make a full-color image.
After I use a photo to come in,
we use our metalance to eliminate color difference.
We want to be able to
make a full-color image analysis.
This is a full-color photo
we made with our transparency.
You can see that
even the white or yellow
colors are very clear.
Compared with the original photo,
there is not much difference in color.
This proves that
we can eliminate color difference
in the entire refractive wavelength range
and make a full-color image application.
That's about it.
Sorry, I talked a little too fast.
Because the time is a bit delayed.
This is my report today.
Thank you everyone.
I don't know if there are any questions.
If I talk too fast later.
I think it's good.
Yeah, no problem.
Can you hear me?
Yes, we can hear you now.
My question is
Basically, your device
is roughly scaled as
the working frequency.
Basically, right?
Yes, it's smaller than the frequency.
I mean, it should have the same effect.
If today you want
the wavelength of your work
to be doubled,
basically, the length
is scaled to be about 2.
So the area is about 4.
No, no, no.
It's not a linear scale.
It's not a linear scale?
No, it's not.
Because of the resonance.
So it's different from the material.
For example,
this thing is very intuitive.
For example.
For example, I just talked about
this thing.
For example, if we produce resonance,
we can think of it as
the resonance here.
So if you say
the wavelength of my work
is doubled,
in theory, the length should be doubled.
The premise of this thing is
that the resolution of the structure itself does not change.
Oh.
But now I have different wavelengths.
The resolution of the material will change.
So its equivalent wavelength,
the effective lambda
is actually lambda over n.
This n is also the wavelength function.
Oh, yeah.
Yes, so it's not a linear scale.
Now for this kind of material,
can you do it in
millimeter wave
or infrared
and deep IR
device?
Yes, it can be Terahertz or microwave.
On the contrary, the most people do microwave.
Now there are several American companies
established to do this principle
are doing microwave.
Because microwave is easy to do
and the loss is super low.
Then the military use is the widest.
And its materials are basically
for example, aluminum
or some silicon base.
This kind of cheaper and easy to make material
can be done, basically.
Yes, that's right.
So the metal part
is actually quite long,
but why the metal part
has not been commercial product
The main reason is here.
Because metal is not yet silicon
part fabrication compatible.
So why do we want to do
gallium nitride later?
That's the reason.
Because gallium nitride
is at least a semiconductor company.
Now the current manufacturing can be compatible.
Let me tell you
why I want to ask this question.
Maybe you can think about it.
Because we are looking for
Terahertz absorber,
but it has to be very, very
low radioactivity.
So we have a very, very big
material limit.
So we are looking for
material limit is very, very big.
We can't use some
very fancy elements, you know.
So if you can do this thing,
it should be usable.
And it's quite sophisticated.
What do you think your Terahertz
needs?
We need it to be
able to adjust its optical quality
in Terahertz.
Not only optical quality,
but also the quality of EM wave.
But all the materials it uses
have to be very low radioactivity.
In other words,
its natural isotope has to be very low.
So we don't have
many materials we can use.
But if you can use some pure elements,
such as silicon,
or aluminum, or some
not alloy, or that kind of
super heavy metal, or super heavy metal,
you can do it.
That's a very good choice.
For example, can you accept gold and copper?
Copper, yes, gold and copper.
But what do you want to use?
For example, silver, or something weird
that you can't read Chinese, that's not OK.
If it's Terahertz,
gold and copper
can be used.
These are very common materials.
On the other hand,
Terahertz is less likely to see
electrolytes, because electrolytes
in Terahertz's resolution
doesn't seem to be able to reach
such a high value.
Because usually
in the natural world,
the refractive index of electrolytes
will become smaller as the wavelength increases.
So it's visibility
will be the highest,
and then slowly decay.
So in my mind,
I haven't seen anyone
use electrolytes in Terahertz,
such as silicon, or gallium nitride,
or germanium, not germanium,
but silicon nitride,
this kind of electrolyte material
to make Terahertz components.
There's a lot of metal,
like I said, a lot of copper and gold.
OK, thank you.
You're welcome.
Ian, you just mentioned
radioactivity.
What kind of radioactivity do you mean?
Do you mean the radiation
response in space?
No, I mean the radioactivity
of the material itself.
Like bananas have beta decay,
something like that.
Oh, OK.
So the radioactivity
will be higher in space?
Yeah, if you want to use
something that's at the bottom
of the elemental cycle,
it won't work.
The reason why it won't work
is because...
Because it will naturally
have the same value
and then it will easily decay.
Then the decay will release
particles, and the particles
will affect the quality
of the material.
I didn't quite understand
what kind of material
do you usually use
in the microwave range?
Aluminum or gallium nitride?
No, if it's microwave,
the most common thing
is copper, because
copper can print
the pattern they want
directly.
So the pattern they print
is like the nanostructure
of the microwave.
Because the wavelength of the microwave
is dozens of millimeters,
or even centimeters.
So it's easier to make?
Yeah, it's easier to make.
And what they print
is a large area.
You can stick it
on the wall of your house.
Oh, I see.
Are there any other materials
that can do the same thing?
Well,
the most common metal
is
gallium nitride.
No, not copper.
It's gallium aluminum.
These three are the most common.
Oh, thank you.
And if it's...
No, you go first.
Yeah, and if it's
gallium aluminum,
there are a lot of choices.
For example,
as long as it's high enough.
So silicon,
gallium nitride,
silicon nitride,
titanium oxide,
and gallium phosphide.
But gallium phosphide has adsorption,
so the effect may not be as good.
You have a video
where the light hits
the left and right
of the picture.
Oh.
This one?
Yeah.
This one?
No, the first one.
The first one.
The one you just showed.
Yeah.
Oh, so how efficient is it?
If you
hit the light directly,
if it's linearly polarized,
it will turn left and right.
This one,
in practice...
Let me see.
In practice, it's about
30% to
50%
efficient.
OK.
And this is its wavelength.
Yeah, the next one is the wavelength.
In theory,
we expect it to be 70% or so.
But after we published this,
there was one thing
that we didn't consider.
When we calculated this,
we knew that aluminum oxidizes easily.
So when it oxidizes,
there will be 3 to 5 nanometers of aluminum oxide on the surface.
This will affect its resonance and reduce its efficiency.
So this picture is actually talking about this.
This is someone else's work.
He's talking about pure aluminum.
If I design it,
its resonance is this high.
And after the aluminum oxidizes,
it will slowly turn right a little bit.
Then the efficiency will drop a little bit.
This is also seen in our experiment.
Indeed, our simulation
hopes that its peak is here.
But our experimental result
is to turn right,
and then to fall down.
So at that time,
there was speculation that the efficiency of this result could not be so high.
It's because when we calculated it,
when we optimized the structure,
we didn't consider the influence of aluminum oxidization.
The question I want to ask is
if
I'm sorry, I'll ask it again.
If the positive light
keeps reducing
the energy,
in the end,
it will become
a single light
or several lights.
Then it will have to
reflect
these two lights
at the same time
Will there be some
state of entanglement?
Or you don't care about this?
We don't care about this.
But what you're talking about is
actually
what I want to do next.
Because
now the most common
entanglement following source
is to use BBO,
this kind of non-linear crystal
to produce entanglement of
linear light.
But it's linear light.
So I actually thought about this thing at that time.
If I am now a linear light entanglement,
both are H plus V
entanglement,
I put the light through this source.
What is H plus V?
The state of H plus V.
H is horizontal, V is vertical.
It's the entanglement of X and Y.
If I turn the green light
into the state of H plus V entanglement,
can I have
spatial entanglement at the same time?
Or does it become hyper-entanglement?
I'm not sure about this.
But I actually wanted to do this thing at that time.
Because I'm not sure
whether it's H or V.
So after it comes in,
I can't be sure
whether it runs to the left
or to the right.
Because if it's H,
the left is the right.
If it's V, the left is the left.
I think this thing
is likely to be established.
Because this kind of element
has already been done.
We mainly use laser light,
which is a bunch of photons
to integrate with this structure.
If I only have single photons now,
it has already been proven that
it will also work.
In the case that single photons
will also work,
entanglement should be established.
It should have a chance
to happen.
So what I'm going to do
is to use entanglement photons
to transfer to the spin
of quantum dot.
So you're doing quantum light.
Yes.
And then
what I'm going to do
is what I just said.
But now
the entanglement is
vertical and horizontal.
Yes.
If this can be done
with left and right entanglement,
it should be...
Yes, you do it first.
And then after you're sure,
you should think about it.
Before I came here,
I...
Are there any other questions?
OK.
Everyone has no questions.
Audience.
OK.
Thank you, Ping Jie.
Thank you.
You have a good grasp of time.
Actually,
I talked a little too fast.
Anyway,
if you have any questions later,
you can tell me.
Yes.
If you really did it in the end,
will you continue to do this
in Caltech?
I didn't do this in Caltech.
OK.
You can ask Cai Ding Ping later.
Yes.
Because if this is done,
then...
We should...
We are planning to do this
recently.
But...
OK.
Yes.
Have you come up with a good approach?
Or do you already have some approaches?
Just what you just said about BBO.
It can only produce linear light.
Yes.
It can only produce linear light.
Yes.
If it can produce...
Because if you want to produce
spin,
you have to use circular polarizer.
Yes.
So...
Yes.
That's what we are thinking about.
No problem.
OK.
OK.
That's all for today.
Thank you.
Thank you.
Bye bye.
